2014-07-11 11:40:03,341 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.155 instead (on interface eth0)
2014-07-11 11:40:03,342 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-11 11:40:03,409 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-11 11:40:03,410 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-11 11:40:03,860 [spark-akka.actor.default-dispatcher-4] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-11 11:40:03,919 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Starting remoting
2014-07-11 11:40:04,086 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.155:46626]
2014-07-11 11:40:04,088 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.155:46626]
2014-07-11 11:40:04,115 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-11 11:40:04,119 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-11 11:40:04,135 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140711114004-567c
2014-07-11 11:40:04,139 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-11 11:40:04,168 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 34586 with id = ConnectionManagerId(10.74.147.155,34586)
2014-07-11 11:40:04,172 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-11 11:40:04,175 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.155:34586 with 1056.0 MB RAM
2014-07-11 11:40:04,176 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-11 11:40:04,190 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-11 11:40:04,320 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:40:04,337 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:34309
2014-07-11 11:40:04,337 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.155:34309
2014-07-11 11:40:04,353 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-a3bb5fad-293a-4634-a96c-350873ff9b38
2014-07-11 11:40:04,353 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-11 11:40:04,354 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:40:04,356 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:57772
2014-07-11 11:40:04,698 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:40:04,710 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-11 11:40:04,712 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.155:4040
2014-07-11 11:40:05,208 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-11 11:40:05,210 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-11 11:40:05,294 [main] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-11 11:40:05,294 [main] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-11 11:40:05,302 [main] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-11 11:40:05,311 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at CalEigenVector.scala:31
2014-07-11 11:40:05,321 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at CalEigenVector.scala:31) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:05,321 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at CalEigenVector.scala:31)
2014-07-11 11:40:05,322 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:05,326 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:05,332 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[2] at map at CalEigenVector.scala:25), which has no missing parents
2014-07-11 11:40:05,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 0 (MappedRDD[2] at map at CalEigenVector.scala:25)
2014-07-11 11:40:05,390 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2014-07-11 11:40:05,413 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:05,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 1797 bytes in 1 ms
2014-07-11 11:40:05,418 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:05,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:1 as 1797 bytes in 1 ms
2014-07-11 11:40:05,424 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-11 11:40:05,424 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-11 11:40:05,441 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:05,442 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:05,448 [Executor task launch worker-1] INFO  [org.apache.spark.CacheManager] - Partition rdd_2_1 not found, computing it
2014-07-11 11:40:05,448 [Executor task launch worker-0] INFO  [org.apache.spark.CacheManager] - Partition rdd_2_0 not found, computing it
2014-07-11 11:40:05,451 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-11 11:40:05,451 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-11 11:40:06,973 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85228305) called with curMem=32856, maxMem=1107296256
2014-07-11 11:40:06,973 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_2_1 stored as values to memory (estimated size 81.3 MB, free 974.7 MB)
2014-07-11 11:40:06,977 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_2_1 in memory on 10.74.147.155:34586 (size: 81.3 MB, free: 974.7 MB)
2014-07-11 11:40:06,977 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_2_1
2014-07-11 11:40:06,991 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85249276) called with curMem=85261161, maxMem=1107296256
2014-07-11 11:40:06,991 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_2_0 stored as values to memory (estimated size 81.3 MB, free 893.4 MB)
2014-07-11 11:40:06,992 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_2_0 in memory on 10.74.147.155:34586 (size: 81.3 MB, free: 893.4 MB)
2014-07-11 11:40:06,993 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_2_0
2014-07-11 11:40:07,016 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 1174
2014-07-11 11:40:07,017 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-11 11:40:07,018 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-11 11:40:07,022 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 1174
2014-07-11 11:40:07,022 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-11 11:40:07,022 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-11 11:40:07,028 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 1608 ms on localhost (progress: 1/2)
2014-07-11 11:40:07,028 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 1)
2014-07-11 11:40:07,028 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-11 11:40:07,028 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 1620 ms on localhost (progress: 2/2)
2014-07-11 11:40:07,029 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at CalEigenVector.scala:31) finished in 1.620 s
2014-07-11 11:40:07,034 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-11 11:40:07,046 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at CalEigenVector.scala:31, took 1.735362809 s
2014-07-11 11:40:07,072 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:07,074 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:07,074 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 1(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:07,074 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:07,077 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:07,078 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MappedRDD[6] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:07,090 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MappedRDD[6] at map at CalEigenVector.scala:38)
2014-07-11 11:40:07,090 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-11 11:40:07,092 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,093 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2292 bytes in 0 ms
2014-07-11 11:40:07,093 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,094 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:07,094 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-11 11:40:07,094 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-11 11:40:07,097 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,101 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,114 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,114 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,114 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,114 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 678
2014-07-11 11:40:07,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-11 11:40:07,284 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-11 11:40:07,285 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(1, 1)
2014-07-11 11:40:07,286 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 192 ms on localhost (progress: 1/2)
2014-07-11 11:40:07,294 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 678
2014-07-11 11:40:07,294 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-11 11:40:07,294 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-11 11:40:07,296 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(1, 0)
2014-07-11 11:40:07,296 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 203 ms on localhost (progress: 2/2)
2014-07-11 11:40:07,296 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-11 11:40:07,296 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (reduce at CalEigenVector.scala:38) finished in 0.205 s
2014-07-11 11:40:07,296 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.223788983 s
2014-07-11 11:40:07,304 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:07,305 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:07,305 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:07,305 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:07,308 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:07,308 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[10] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:07,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 2 (MappedRDD[10] at map at CalEigenVector.scala:38)
2014-07-11 11:40:07,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2014-07-11 11:40:07,313 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,314 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2293 bytes in 1 ms
2014-07-11 11:40:07,314 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:1 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,315 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:07,315 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-11 11:40:07,315 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-11 11:40:07,319 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,321 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,322 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,322 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,330 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,330 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,394 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 678
2014-07-11 11:40:07,394 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-11 11:40:07,397 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 82 ms on localhost (progress: 1/2)
2014-07-11 11:40:07,398 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 1)
2014-07-11 11:40:07,398 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-11 11:40:07,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 678
2014-07-11 11:40:07,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-11 11:40:07,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-11 11:40:07,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-11 11:40:07,419 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 106 ms on localhost (progress: 2/2)
2014-07-11 11:40:07,419 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-11 11:40:07,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at CalEigenVector.scala:38) finished in 0.097 s
2014-07-11 11:40:07,420 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.115384495 s
2014-07-11 11:40:07,428 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:07,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:07,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 3(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:07,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:07,432 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:07,432 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 3 (MappedRDD[14] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:07,436 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 3 (MappedRDD[14] at map at CalEigenVector.scala:38)
2014-07-11 11:40:07,436 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2014-07-11 11:40:07,437 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,437 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 3.0:0 as 2291 bytes in 0 ms
2014-07-11 11:40:07,438 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0:1 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,438 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 3.0:1 as 2291 bytes in 0 ms
2014-07-11 11:40:07,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-11 11:40:07,439 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-11 11:40:07,441 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,442 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,445 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,445 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,445 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,445 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,771 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-11 11:40:07,771 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-11 11:40:07,773 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-11 11:40:07,773 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-11 11:40:07,773 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-11 11:40:07,773 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 336 ms on localhost (progress: 1/2)
2014-07-11 11:40:07,773 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(3, 0)
2014-07-11 11:40:07,774 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-11 11:40:07,775 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 337 ms on localhost (progress: 2/2)
2014-07-11 11:40:07,775 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2014-07-11 11:40:07,775 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(3, 1)
2014-07-11 11:40:07,775 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 3 (reduce at CalEigenVector.scala:38) finished in 0.339 s
2014-07-11 11:40:07,776 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.347297877 s
2014-07-11 11:40:07,784 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:07,785 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:07,785 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:07,785 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:07,787 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:07,788 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[18] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:07,791 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 4 (MappedRDD[18] at map at CalEigenVector.scala:38)
2014-07-11 11:40:07,791 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2014-07-11 11:40:07,792 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,792 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:07,793 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:1 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,793 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:07,794 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-11 11:40:07,795 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-11 11:40:07,796 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,797 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,799 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,799 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,800 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,800 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,866 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-11 11:40:07,866 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-11 11:40:07,866 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-11 11:40:07,867 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:07,868 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 1)
2014-07-11 11:40:07,868 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-11 11:40:07,869 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-11 11:40:07,869 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-11 11:40:07,871 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:40:07,871 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-11 11:40:07,871 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-11 11:40:07,871 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:40:07,871 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.087424789 s
2014-07-11 11:40:07,878 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:07,880 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:07,880 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 5(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:07,880 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:07,882 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:07,883 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 5 (MappedRDD[22] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:07,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 5 (MappedRDD[22] at map at CalEigenVector.scala:38)
2014-07-11 11:40:07,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2014-07-11 11:40:07,887 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,887 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 5.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:07,888 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0:1 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,888 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 5.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:07,889 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-11 11:40:07,889 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-11 11:40:07,892 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,894 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,895 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,896 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,897 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,898 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-11 11:40:07,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-11 11:40:07,965 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:40:07,965 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(5, 0)
2014-07-11 11:40:07,965 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-11 11:40:07,967 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-11 11:40:07,967 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-11 11:40:07,967 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-11 11:40:07,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(5, 1)
2014-07-11 11:40:07,968 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 80 ms on localhost (progress: 2/2)
2014-07-11 11:40:07,968 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2014-07-11 11:40:07,969 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 5 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:40:07,969 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.090488365 s
2014-07-11 11:40:07,976 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:07,977 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:07,977 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:07,977 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:07,980 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:07,980 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[26] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:07,984 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 6 (MappedRDD[26] at map at CalEigenVector.scala:38)
2014-07-11 11:40:07,984 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2014-07-11 11:40:07,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2292 bytes in 0 ms
2014-07-11 11:40:07,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:1 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:07,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:07,987 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-11 11:40:07,987 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-11 11:40:07,989 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,989 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:07,992 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,992 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:07,993 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:07,993 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,064 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-11 11:40:08,064 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-11 11:40:08,064 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-11 11:40:08,065 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:40:08,066 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-11 11:40:08,067 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-11 11:40:08,067 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-11 11:40:08,067 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-11 11:40:08,068 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 1)
2014-07-11 11:40:08,069 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:40:08,069 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-11 11:40:08,069 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (reduce at CalEigenVector.scala:38) finished in 0.085 s
2014-07-11 11:40:08,069 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.09290579 s
2014-07-11 11:40:08,077 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:08,078 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:08,078 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 7(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:08,078 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:08,081 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:08,082 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 7 (MappedRDD[30] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:08,085 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 7 (MappedRDD[30] at map at CalEigenVector.scala:38)
2014-07-11 11:40:08,085 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2014-07-11 11:40:08,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 7.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:08,087 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0:1 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,087 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 7.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:08,088 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-11 11:40:08,090 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,092 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,093 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,095 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-11 11:40:08,097 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,101 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,101 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-11 11:40:08,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-11 11:40:08,411 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-11 11:40:08,411 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-11 11:40:08,411 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-11 11:40:08,411 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 324 ms on localhost (progress: 1/2)
2014-07-11 11:40:08,411 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-11 11:40:08,411 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(7, 0)
2014-07-11 11:40:08,412 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(7, 1)
2014-07-11 11:40:08,412 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 325 ms on localhost (progress: 2/2)
2014-07-11 11:40:08,413 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2014-07-11 11:40:08,413 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 7 (reduce at CalEigenVector.scala:38) finished in 0.313 s
2014-07-11 11:40:08,414 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.336924945 s
2014-07-11 11:40:08,421 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:08,422 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:08,422 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:08,422 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:08,424 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:08,425 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[34] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:08,428 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 8 (MappedRDD[34] at map at CalEigenVector.scala:38)
2014-07-11 11:40:08,428 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2014-07-11 11:40:08,429 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,429 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:08,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:1 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:08,431 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-11 11:40:08,431 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-11 11:40:08,433 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,433 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,436 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,436 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,436 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,437 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,505 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-11 11:40:08,505 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-11 11:40:08,507 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:40:08,507 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-11 11:40:08,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-11 11:40:08,511 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-11 11:40:08,511 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-11 11:40:08,511 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-11 11:40:08,512 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 1)
2014-07-11 11:40:08,512 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:40:08,512 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-11 11:40:08,512 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:40:08,513 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092021593 s
2014-07-11 11:40:08,520 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:08,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:08,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 9(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:08,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:08,524 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:08,524 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 9 (MappedRDD[38] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:08,528 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 9 (MappedRDD[38] at map at CalEigenVector.scala:38)
2014-07-11 11:40:08,528 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2014-07-11 11:40:08,529 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,529 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 9.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:08,530 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0:1 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,530 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 9.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:08,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-11 11:40:08,531 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-11 11:40:08,533 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,533 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,536 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,536 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,538 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,539 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,603 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-11 11:40:08,603 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-11 11:40:08,605 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:08,605 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(9, 0)
2014-07-11 11:40:08,605 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-11 11:40:08,640 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-11 11:40:08,640 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-11 11:40:08,642 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 111 ms on localhost (progress: 2/2)
2014-07-11 11:40:08,642 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2014-07-11 11:40:08,642 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(9, 1)
2014-07-11 11:40:08,642 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 9 (reduce at CalEigenVector.scala:38) finished in 0.111 s
2014-07-11 11:40:08,643 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.123437777 s
2014-07-11 11:40:08,650 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:08,650 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-11 11:40:08,652 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:08,652 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:08,652 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:08,657 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:08,657 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[42] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:08,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 10 (MappedRDD[42] at map at CalEigenVector.scala:38)
2014-07-11 11:40:08,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 2 tasks
2014-07-11 11:40:08,664 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,664 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2292 bytes in 0 ms
2014-07-11 11:40:08,665 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:1 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,665 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:08,666 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-11 11:40:08,668 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,670 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-11 11:40:08,671 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,671 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,672 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,675 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,675 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,739 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-11 11:40:08,739 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-11 11:40:08,740 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 76 ms on localhost (progress: 1/2)
2014-07-11 11:40:08,741 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-11 11:40:08,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-11 11:40:08,775 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-11 11:40:08,775 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-11 11:40:08,776 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-11 11:40:08,776 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 1)
2014-07-11 11:40:08,776 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 111 ms on localhost (progress: 2/2)
2014-07-11 11:40:08,776 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-11 11:40:08,776 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at CalEigenVector.scala:38) finished in 0.102 s
2014-07-11 11:40:08,777 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.126291614 s
2014-07-11 11:40:08,788 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:08,790 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:08,790 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 11(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:08,790 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:08,792 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:08,793 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 11 (MappedRDD[46] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:08,796 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 11 (MappedRDD[46] at map at CalEigenVector.scala:38)
2014-07-11 11:40:08,796 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2014-07-11 11:40:08,797 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,798 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 11.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:08,798 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0:1 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,798 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 11.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:08,799 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-11 11:40:08,801 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,803 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,803 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,807 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-11 11:40:08,809 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,946 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-11 11:40:08,946 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-11 11:40:08,947 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-11 11:40:08,948 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 150 ms on localhost (progress: 1/2)
2014-07-11 11:40:08,948 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(11, 0)
2014-07-11 11:40:08,950 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-11 11:40:08,950 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-11 11:40:08,950 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-11 11:40:08,951 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(11, 1)
2014-07-11 11:40:08,951 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 153 ms on localhost (progress: 2/2)
2014-07-11 11:40:08,951 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2014-07-11 11:40:08,951 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 11 (reduce at CalEigenVector.scala:38) finished in 0.154 s
2014-07-11 11:40:08,951 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.162779433 s
2014-07-11 11:40:08,959 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:08,960 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:08,960 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:08,960 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:08,962 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:08,963 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[50] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:08,965 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 12 (MappedRDD[50] at map at CalEigenVector.scala:38)
2014-07-11 11:40:08,966 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2014-07-11 11:40:08,966 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,967 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2291 bytes in 1 ms
2014-07-11 11:40:08,970 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:1 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:08,971 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:1 as 2291 bytes in 1 ms
2014-07-11 11:40:08,972 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-11 11:40:08,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,977 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,977 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:08,977 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-11 11:40:08,982 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:08,984 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:08,984 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:09,086 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-11 11:40:09,087 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-11 11:40:09,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-11 11:40:09,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-11 11:40:09,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-11 11:40:09,090 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 123 ms on localhost (progress: 1/2)
2014-07-11 11:40:09,090 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-11 11:40:09,090 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 123 ms on localhost (progress: 2/2)
2014-07-11 11:40:09,090 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-11 11:40:09,090 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 1)
2014-07-11 11:40:09,090 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at CalEigenVector.scala:38) finished in 0.124 s
2014-07-11 11:40:09,091 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.131917576 s
2014-07-11 11:40:09,091 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-11 11:40:09,100 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:09,102 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:09,102 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 13(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:09,102 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:09,104 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:09,105 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 13 (MappedRDD[54] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:09,109 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 13 (MappedRDD[54] at map at CalEigenVector.scala:38)
2014-07-11 11:40:09,109 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2014-07-11 11:40:09,111 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:09,111 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 13.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:09,111 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0:1 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:09,112 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 13.0:1 as 2293 bytes in 1 ms
2014-07-11 11:40:09,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-11 11:40:09,115 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:09,117 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:09,117 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:09,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-11 11:40:09,125 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:09,127 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:09,127 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-11 11:40:10,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-11 11:40:10,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-11 11:40:10,579 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 1469 ms on localhost (progress: 1/2)
2014-07-11 11:40:10,580 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(13, 0)
2014-07-11 11:40:10,591 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-11 11:40:10,591 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-11 11:40:10,591 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-11 11:40:10,592 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(13, 1)
2014-07-11 11:40:10,592 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 1481 ms on localhost (progress: 2/2)
2014-07-11 11:40:10,592 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2014-07-11 11:40:10,592 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 13 (reduce at CalEigenVector.scala:38) finished in 1.469 s
2014-07-11 11:40:10,593 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 1.492050133 s
2014-07-11 11:40:10,601 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:10,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:10,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:10,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:10,604 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:10,605 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[58] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:10,608 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 14 (MappedRDD[58] at map at CalEigenVector.scala:38)
2014-07-11 11:40:10,608 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2014-07-11 11:40:10,609 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,609 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:10,609 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:1 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,610 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:1 as 2294 bytes in 1 ms
2014-07-11 11:40:10,610 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-11 11:40:10,612 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,613 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-11 11:40:10,615 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,617 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,617 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,620 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,620 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,682 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-11 11:40:10,682 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-11 11:40:10,684 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:10,684 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 1)
2014-07-11 11:40:10,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-11 11:40:10,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-11 11:40:10,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-11 11:40:10,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-11 11:40:10,686 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-11 11:40:10,686 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:40:10,686 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-11 11:40:10,686 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:40:10,686 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085092202 s
2014-07-11 11:40:10,693 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:10,694 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:10,694 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 15(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:10,694 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:10,696 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:10,696 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 15 (MappedRDD[62] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:10,699 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 15 (MappedRDD[62] at map at CalEigenVector.scala:38)
2014-07-11 11:40:10,700 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2014-07-11 11:40:10,700 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 15.0:0 as 2294 bytes in 1 ms
2014-07-11 11:40:10,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0:1 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,702 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 15.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:10,702 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-11 11:40:10,704 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,706 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,707 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,707 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-11 11:40:10,709 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,712 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,712 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,777 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-11 11:40:10,777 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-11 11:40:10,780 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-11 11:40:10,780 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-11 11:40:10,780 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-11 11:40:10,780 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-11 11:40:10,781 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:40:10,782 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:40:10,782 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2014-07-11 11:40:10,782 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(15, 1)
2014-07-11 11:40:10,782 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(15, 0)
2014-07-11 11:40:10,783 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 15 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:40:10,783 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.090707716 s
2014-07-11 11:40:10,789 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:10,790 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:10,790 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:10,791 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:10,793 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:10,793 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[66] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:10,796 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 16 (MappedRDD[66] at map at CalEigenVector.scala:38)
2014-07-11 11:40:10,796 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2014-07-11 11:40:10,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:10,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:1 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,798 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:1 as 2294 bytes in 1 ms
2014-07-11 11:40:10,798 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-11 11:40:10,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-11 11:40:10,805 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,805 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,807 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,807 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,809 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,809 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,880 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-11 11:40:10,880 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-11 11:40:10,881 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-11 11:40:10,881 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-11 11:40:10,881 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-11 11:40:10,882 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 1)
2014-07-11 11:40:10,882 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 85 ms on localhost (progress: 1/2)
2014-07-11 11:40:10,882 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-11 11:40:10,883 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-11 11:40:10,883 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 86 ms on localhost (progress: 2/2)
2014-07-11 11:40:10,883 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-11 11:40:10,883 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at CalEigenVector.scala:38) finished in 0.087 s
2014-07-11 11:40:10,884 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094246663 s
2014-07-11 11:40:10,890 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:10,891 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:10,891 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 17(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:10,891 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:10,893 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:10,894 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 17 (MappedRDD[70] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:10,897 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 17 (MappedRDD[70] at map at CalEigenVector.scala:38)
2014-07-11 11:40:10,897 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 17.0 with 2 tasks
2014-07-11 11:40:10,897 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,898 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 17.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:10,898 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0:1 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,899 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 17.0:1 as 2293 bytes in 1 ms
2014-07-11 11:40:10,899 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-11 11:40:10,899 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-11 11:40:10,901 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,902 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,904 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,904 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,904 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,904 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:10,974 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-11 11:40:10,974 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-11 11:40:10,975 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-11 11:40:10,975 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(17, 1)
2014-07-11 11:40:10,975 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:40:10,978 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-11 11:40:10,978 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-11 11:40:10,978 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-11 11:40:10,979 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(17, 0)
2014-07-11 11:40:10,979 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 17 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:40:10,980 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089686623 s
2014-07-11 11:40:10,979 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:40:10,981 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2014-07-11 11:40:10,986 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:10,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:10,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:10,988 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:10,990 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:10,990 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[74] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:10,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 18 (MappedRDD[74] at map at CalEigenVector.scala:38)
2014-07-11 11:40:10,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2014-07-11 11:40:10,994 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,994 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:10,994 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:1 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:10,995 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:1 as 2294 bytes in 1 ms
2014-07-11 11:40:10,995 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-11 11:40:10,997 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:10,999 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,999 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:10,999 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-11 11:40:11,001 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-11 11:40:11,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-11 11:40:11,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-11 11:40:11,076 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 82 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,077 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-11 11:40:11,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-11 11:40:11,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-11 11:40:11,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-11 11:40:11,084 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 89 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,084 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,084 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 1)
2014-07-11 11:40:11,085 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at CalEigenVector.scala:38) finished in 0.092 s
2014-07-11 11:40:11,086 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.099575089 s
2014-07-11 11:40:11,092 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,093 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,093 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 19(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,093 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,095 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,096 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 19 (MappedRDD[78] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,098 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 19 (MappedRDD[78] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,098 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 19.0 with 2 tasks
2014-07-11 11:40:11,099 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,100 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 19.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:11,100 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0:1 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,100 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 19.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:11,101 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-11 11:40:11,102 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,103 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-11 11:40:11,105 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,105 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,105 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,107 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,107 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-11 11:40:11,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-11 11:40:11,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-11 11:40:11,173 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,173 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(19, 1)
2014-07-11 11:40:11,177 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-11 11:40:11,177 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-11 11:40:11,177 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-11 11:40:11,178 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(19, 0)
2014-07-11 11:40:11,178 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,179 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,179 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 19 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:40:11,179 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086845898 s
2014-07-11 11:40:11,185 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,188 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,188 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,188 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,190 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,190 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[82] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,193 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 20 (MappedRDD[82] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,193 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2014-07-11 11:40:11,194 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,194 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:11,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:1 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:11,196 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-11 11:40:11,197 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,198 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-11 11:40:11,200 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,202 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,202 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,204 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,204 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,269 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-11 11:40:11,269 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-11 11:40:11,269 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-11 11:40:11,271 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,271 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 1)
2014-07-11 11:40:11,276 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-11 11:40:11,276 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-11 11:40:11,276 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-11 11:40:11,277 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,277 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,277 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-11 11:40:11,277 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:40:11,278 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092941971 s
2014-07-11 11:40:11,284 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,285 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,285 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 21(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,285 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,286 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,287 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 21 (MappedRDD[86] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,290 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 21 (MappedRDD[86] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,290 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2014-07-11 11:40:11,291 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,291 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 21.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:11,291 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0:1 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,292 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 21.0:1 as 2293 bytes in 1 ms
2014-07-11 11:40:11,292 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-11 11:40:11,293 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-11 11:40:11,294 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,295 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,296 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,296 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,297 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,297 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-11 11:40:11,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-11 11:40:11,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-11 11:40:11,367 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-11 11:40:11,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-11 11:40:11,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-11 11:40:11,368 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,369 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(21, 0)
2014-07-11 11:40:11,369 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(21, 1)
2014-07-11 11:40:11,369 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,369 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,369 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 21 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:40:11,370 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086566776 s
2014-07-11 11:40:11,376 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,377 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,377 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,377 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,379 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,379 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[90] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,382 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 22 (MappedRDD[90] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,382 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 2 tasks
2014-07-11 11:40:11,382 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,383 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:11,383 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:1 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,384 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:11,384 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-11 11:40:11,386 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,387 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-11 11:40:11,388 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,388 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,388 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,390 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,391 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,455 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-11 11:40:11,455 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-11 11:40:11,456 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-11 11:40:11,456 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-11 11:40:11,456 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-11 11:40:11,456 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 1)
2014-07-11 11:40:11,456 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-11 11:40:11,458 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,458 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:40:11,458 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082351768 s
2014-07-11 11:40:11,460 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-11 11:40:11,465 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 23(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,467 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,468 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 23 (MappedRDD[94] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 23 (MappedRDD[94] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 23.0 with 2 tasks
2014-07-11 11:40:11,472 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 23.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,472 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 23.0:0 as 2292 bytes in 0 ms
2014-07-11 11:40:11,473 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 23.0:1 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,473 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 23.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:11,474 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-11 11:40:11,475 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,477 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,478 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,478 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-11 11:40:11,483 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,487 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,488 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,540 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-11 11:40:11,540 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-11 11:40:11,540 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-11 11:40:11,541 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(23, 0)
2014-07-11 11:40:11,541 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,548 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-11 11:40:11,548 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-11 11:40:11,548 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-11 11:40:11,549 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(23, 1)
2014-07-11 11:40:11,549 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,550 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,550 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 23 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:40:11,550 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085240421 s
2014-07-11 11:40:11,556 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,556 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,556 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,557 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,558 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,559 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[98] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,561 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 24 (MappedRDD[98] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,561 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 2 tasks
2014-07-11 11:40:11,562 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,563 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:11,563 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:1 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,563 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:11,564 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-11 11:40:11,568 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-11 11:40:11,570 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,571 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,572 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,572 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,573 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,573 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-11 11:40:11,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-11 11:40:11,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-11 11:40:11,630 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 1)
2014-07-11 11:40:11,630 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,631 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-11 11:40:11,631 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-11 11:40:11,632 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-11 11:40:11,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-11 11:40:11,632 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,633 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,633 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:11,633 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077166513 s
2014-07-11 11:40:11,638 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,639 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,639 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 25(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,639 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,641 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,641 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 25 (MappedRDD[102] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 25 (MappedRDD[102] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 25.0 with 2 tasks
2014-07-11 11:40:11,645 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 25.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,645 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 25.0:0 as 2291 bytes in 0 ms
2014-07-11 11:40:11,645 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 25.0:1 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,646 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 25.0:1 as 2291 bytes in 1 ms
2014-07-11 11:40:11,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-11 11:40:11,646 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-11 11:40:11,648 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,648 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,650 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,650 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,650 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,650 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,698 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-11 11:40:11,698 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-11 11:40:11,699 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-11 11:40:11,699 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(25, 1)
2014-07-11 11:40:11,699 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 54 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-11 11:40:11,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-11 11:40:11,716 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-11 11:40:11,717 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(25, 0)
2014-07-11 11:40:11,717 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,717 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,717 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 25 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:40:11,717 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078992152 s
2014-07-11 11:40:11,724 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,725 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,725 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,725 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,727 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,728 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[106] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,730 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 26 (MappedRDD[106] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,730 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2014-07-11 11:40:11,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2292 bytes in 0 ms
2014-07-11 11:40:11,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:1 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:11,732 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-11 11:40:11,733 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-11 11:40:11,734 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,735 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,736 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,737 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,737 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,737 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,804 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-11 11:40:11,804 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-11 11:40:11,805 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-11 11:40:11,806 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-11 11:40:11,806 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-11 11:40:11,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-11 11:40:11,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-11 11:40:11,820 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 1)
2014-07-11 11:40:11,820 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,820 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,820 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at CalEigenVector.scala:38) finished in 0.089 s
2014-07-11 11:40:11,820 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.095802884 s
2014-07-11 11:40:11,826 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,827 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,827 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 27(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,827 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,829 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,829 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 27 (MappedRDD[110] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,832 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 27 (MappedRDD[110] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,832 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 2 tasks
2014-07-11 11:40:11,832 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 27.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 27.0:0 as 2292 bytes in 1 ms
2014-07-11 11:40:11,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 27.0:1 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 27.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:11,834 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-11 11:40:11,834 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-11 11:40:11,835 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,836 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,837 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,838 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,846 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,846 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-11 11:40:11,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-11 11:40:11,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-11 11:40:11,905 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:40:11,905 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(27, 1)
2014-07-11 11:40:11,913 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-11 11:40:11,913 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-11 11:40:11,913 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-11 11:40:11,914 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(27, 0)
2014-07-11 11:40:11,914 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:40:11,914 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2014-07-11 11:40:11,914 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 27 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:40:11,914 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088047564 s
2014-07-11 11:40:11,920 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:11,921 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:11,921 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:11,921 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:11,922 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:11,923 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[114] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:11,926 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 28 (MappedRDD[114] at map at CalEigenVector.scala:38)
2014-07-11 11:40:11,926 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 2 tasks
2014-07-11 11:40:11,926 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2292 bytes in 1 ms
2014-07-11 11:40:11,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:1 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:11,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:1 as 2292 bytes in 0 ms
2014-07-11 11:40:11,928 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-11 11:40:11,928 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-11 11:40:11,930 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,930 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:11,932 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,932 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:11,933 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,933 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:11,999 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-11 11:40:11,999 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-11 11:40:12,000 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-11 11:40:12,000 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 1)
2014-07-11 11:40:12,000 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,003 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-11 11:40:12,003 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-11 11:40:12,003 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-11 11:40:12,004 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-11 11:40:12,004 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,004 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,004 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:40:12,004 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.084311874 s
2014-07-11 11:40:12,010 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,011 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,011 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 29(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,011 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,013 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,013 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 29 (MappedRDD[118] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,015 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 29 (MappedRDD[118] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,016 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 29.0 with 2 tasks
2014-07-11 11:40:12,016 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 29.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,017 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 29.0:0 as 2291 bytes in 1 ms
2014-07-11 11:40:12,017 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 29.0:1 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,017 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 29.0:1 as 2291 bytes in 0 ms
2014-07-11 11:40:12,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-11 11:40:12,018 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-11 11:40:12,020 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,020 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,022 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,022 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,023 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,023 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,091 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-11 11:40:12,091 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-11 11:40:12,092 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-11 11:40:12,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(29, 1)
2014-07-11 11:40:12,092 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,097 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-11 11:40:12,097 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-11 11:40:12,097 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-11 11:40:12,098 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(29, 0)
2014-07-11 11:40:12,098 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,098 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,098 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 29 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:40:12,098 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088501074 s
2014-07-11 11:40:12,104 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,105 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,105 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,105 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,107 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,107 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[122] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,110 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 30 (MappedRDD[122] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,110 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 2 tasks
2014-07-11 11:40:12,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:12,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:1 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:12,112 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-11 11:40:12,114 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,115 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-11 11:40:12,116 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,117 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,117 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,119 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,119 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,187 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-11 11:40:12,187 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-11 11:40:12,187 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-11 11:40:12,187 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-11 11:40:12,188 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-11 11:40:12,188 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-11 11:40:12,188 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 1)
2014-07-11 11:40:12,189 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,190 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-11 11:40:12,190 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:40:12,190 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086200995 s
2014-07-11 11:40:12,190 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,195 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,197 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,198 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,198 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 31(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,198 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,204 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,205 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 31 (MappedRDD[126] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,207 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 31 (MappedRDD[126] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,207 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2014-07-11 11:40:12,208 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 31.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,208 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 31.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:12,208 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 31.0:1 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,209 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 31.0:1 as 2293 bytes in 1 ms
2014-07-11 11:40:12,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-11 11:40:12,210 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-11 11:40:12,211 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,211 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,213 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,213 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,213 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,213 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,281 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-11 11:40:12,281 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-11 11:40:12,282 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-11 11:40:12,282 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(31, 1)
2014-07-11 11:40:12,282 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,285 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-11 11:40:12,285 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-11 11:40:12,285 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-11 11:40:12,286 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(31, 0)
2014-07-11 11:40:12,286 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,286 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,286 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 31 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:40:12,286 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088881249 s
2014-07-11 11:40:12,291 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,294 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,294 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[130] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,297 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 32 (MappedRDD[130] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,297 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 2 tasks
2014-07-11 11:40:12,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:12,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:1 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,299 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:1 as 2293 bytes in 1 ms
2014-07-11 11:40:12,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-11 11:40:12,301 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,303 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-11 11:40:12,303 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,303 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,305 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,307 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,307 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,372 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-11 11:40:12,372 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-11 11:40:12,372 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-11 11:40:12,372 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-11 11:40:12,372 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-11 11:40:12,372 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-11 11:40:12,373 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-11 11:40:12,373 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 1)
2014-07-11 11:40:12,374 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,374 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:40:12,374 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082674288 s
2014-07-11 11:40:12,380 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 33(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,382 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,382 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 33 (MappedRDD[134] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,385 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 33 (MappedRDD[134] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,385 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2014-07-11 11:40:12,386 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 33.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,386 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 33.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:12,386 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 33.0:1 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,386 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 33.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:12,387 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-11 11:40:12,389 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,391 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,391 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,400 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-11 11:40:12,404 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,416 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,416 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,464 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-11 11:40:12,465 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-11 11:40:12,465 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-11 11:40:12,466 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(33, 1)
2014-07-11 11:40:12,466 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 79 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,493 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-11 11:40:12,493 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-11 11:40:12,494 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-11 11:40:12,495 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(33, 0)
2014-07-11 11:40:12,495 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 110 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,495 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,495 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 33 (reduce at CalEigenVector.scala:38) finished in 0.110 s
2014-07-11 11:40:12,496 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.115928101 s
2014-07-11 11:40:12,501 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,502 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,502 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,502 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,504 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,504 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[138] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,507 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 34 (MappedRDD[138] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,507 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 2 tasks
2014-07-11 11:40:12,508 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,508 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:12,508 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:1 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,509 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:12,509 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-11 11:40:12,511 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,513 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,513 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-11 11:40:12,513 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,515 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,516 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,517 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,575 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-11 11:40:12,575 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-11 11:40:12,576 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-11 11:40:12,578 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 1)
2014-07-11 11:40:12,578 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,582 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-11 11:40:12,582 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-11 11:40:12,582 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-11 11:40:12,583 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-11 11:40:12,583 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,583 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,583 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:40:12,583 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082279865 s
2014-07-11 11:40:12,589 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,590 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,590 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 35(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,590 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,591 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,592 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 35 (MappedRDD[142] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,594 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 35 (MappedRDD[142] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,594 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 2 tasks
2014-07-11 11:40:12,594 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 35.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,595 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 35.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:12,595 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 35.0:1 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,595 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 35.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:12,596 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-11 11:40:12,596 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-11 11:40:12,598 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,598 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,600 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,600 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,606 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,606 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,660 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-11 11:40:12,660 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-11 11:40:12,661 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,662 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(35, 1)
2014-07-11 11:40:12,662 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-11 11:40:12,664 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-11 11:40:12,664 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-11 11:40:12,664 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-11 11:40:12,665 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(35, 0)
2014-07-11 11:40:12,665 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,665 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,665 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 35 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:40:12,665 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076562978 s
2014-07-11 11:40:12,670 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,671 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,671 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,671 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,673 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,673 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[146] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,676 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 36 (MappedRDD[146] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,676 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2014-07-11 11:40:12,677 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,677 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:12,677 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:1 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,678 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:1 as 2294 bytes in 1 ms
2014-07-11 11:40:12,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-11 11:40:12,678 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-11 11:40:12,680 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,680 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,681 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,681 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,682 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,682 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-11 11:40:12,738 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-11 11:40:12,738 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-11 11:40:12,740 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-11 11:40:12,740 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-11 11:40:12,741 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-11 11:40:12,741 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-11 11:40:12,742 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,742 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 1)
2014-07-11 11:40:12,742 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,742 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,742 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:40:12,743 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071945828 s
2014-07-11 11:40:12,749 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,752 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,752 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 37(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,752 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,756 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,757 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 37 (MappedRDD[150] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,759 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 37 (MappedRDD[150] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,759 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2014-07-11 11:40:12,759 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 37.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,760 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 37.0:0 as 2293 bytes in 1 ms
2014-07-11 11:40:12,760 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 37.0:1 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,760 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 37.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:12,761 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-11 11:40:12,761 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-11 11:40:12,763 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,764 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,764 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,765 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,765 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,771 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,820 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-11 11:40:12,820 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-11 11:40:12,821 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(37, 0)
2014-07-11 11:40:12,822 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-11 11:40:12,825 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-11 11:40:12,825 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-11 11:40:12,825 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-11 11:40:12,826 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(37, 1)
2014-07-11 11:40:12,826 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,826 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 37 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:40:12,827 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,827 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078064894 s
2014-07-11 11:40:12,832 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,833 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,833 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,833 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,835 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,835 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[154] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,837 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 38 (MappedRDD[154] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,837 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 2 tasks
2014-07-11 11:40:12,838 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,838 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:12,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:1 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:12,840 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-11 11:40:12,842 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,843 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-11 11:40:12,844 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,844 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,845 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,850 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,850 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,911 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-11 11:40:12,911 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-11 11:40:12,911 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-11 11:40:12,912 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 1)
2014-07-11 11:40:12,912 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:40:12,937 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-11 11:40:12,937 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-11 11:40:12,938 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-11 11:40:12,938 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-11 11:40:12,938 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 100 ms on localhost (progress: 2/2)
2014-07-11 11:40:12,938 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-11 11:40:12,938 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at CalEigenVector.scala:38) finished in 0.100 s
2014-07-11 11:40:12,939 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.106632236 s
2014-07-11 11:40:12,944 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:12,945 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:12,945 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 39(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:12,945 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:12,947 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:12,947 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 39 (MappedRDD[158] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:12,950 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 39 (MappedRDD[158] at map at CalEigenVector.scala:38)
2014-07-11 11:40:12,950 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2014-07-11 11:40:12,950 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 39.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,951 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 39.0:0 as 2294 bytes in 1 ms
2014-07-11 11:40:12,951 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 39.0:1 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:12,951 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 39.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:12,952 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-11 11:40:12,953 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,955 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,955 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-11 11:40:12,955 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:12,957 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:12,958 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:12,958 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,016 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-11 11:40:13,016 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-11 11:40:13,018 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,021 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(39, 0)
2014-07-11 11:40:13,026 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-11 11:40:13,082 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-11 11:40:13,082 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-11 11:40:13,082 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-11 11:40:13,083 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 132 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,083 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,083 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(39, 1)
2014-07-11 11:40:13,084 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 39 (reduce at CalEigenVector.scala:38) finished in 0.124 s
2014-07-11 11:40:13,084 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.139894345 s
2014-07-11 11:40:13,091 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,092 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,092 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,092 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,095 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,096 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[162] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,099 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 40 (MappedRDD[162] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,099 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 2 tasks
2014-07-11 11:40:13,101 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,101 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:13,102 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:1 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,102 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:13,103 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-11 11:40:13,103 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-11 11:40:13,104 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,104 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,106 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,106 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,106 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,106 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,179 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-11 11:40:13,179 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-11 11:40:13,181 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,181 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 1)
2014-07-11 11:40:13,181 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-11 11:40:13,214 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-11 11:40:13,215 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-11 11:40:13,215 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-11 11:40:13,216 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 114 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,216 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,216 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-11 11:40:13,216 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at CalEigenVector.scala:38) finished in 0.098 s
2014-07-11 11:40:13,217 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.125297653 s
2014-07-11 11:40:13,224 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,225 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,225 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 41(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,225 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,226 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,227 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 41 (MappedRDD[166] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,230 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 41 (MappedRDD[166] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,230 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 2 tasks
2014-07-11 11:40:13,230 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 41.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,231 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 41.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:13,231 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 41.0:1 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,232 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 41.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:13,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-11 11:40:13,234 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,239 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,239 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,245 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-11 11:40:13,247 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,256 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,256 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-11 11:40:13,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-11 11:40:13,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-11 11:40:13,348 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(41, 1)
2014-07-11 11:40:13,348 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 117 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-11 11:40:13,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-11 11:40:13,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-11 11:40:13,355 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(41, 0)
2014-07-11 11:40:13,355 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 125 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,355 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,355 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 41 (reduce at CalEigenVector.scala:38) finished in 0.125 s
2014-07-11 11:40:13,355 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.131721074 s
2014-07-11 11:40:13,361 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,362 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,362 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,362 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,364 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,364 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[170] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,366 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 42 (MappedRDD[170] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,366 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 2 tasks
2014-07-11 11:40:13,367 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,367 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:13,367 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:1 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,368 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:1 as 2294 bytes in 1 ms
2014-07-11 11:40:13,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-11 11:40:13,368 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-11 11:40:13,370 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,371 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,371 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,379 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,382 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,382 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,461 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-11 11:40:13,461 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-11 11:40:13,461 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-11 11:40:13,462 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 94 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,462 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 1)
2014-07-11 11:40:13,474 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-11 11:40:13,474 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-11 11:40:13,474 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-11 11:40:13,475 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-11 11:40:13,475 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at CalEigenVector.scala:38) finished in 0.109 s
2014-07-11 11:40:13,475 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 108 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,475 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,475 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.114277142 s
2014-07-11 11:40:13,481 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,482 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,482 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 43(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,482 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,485 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,486 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 43 (MappedRDD[174] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,488 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 43 (MappedRDD[174] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,488 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 2 tasks
2014-07-11 11:40:13,488 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 43.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,489 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 43.0:0 as 2293 bytes in 1 ms
2014-07-11 11:40:13,489 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 43.0:1 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,490 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 43.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:13,490 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-11 11:40:13,490 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-11 11:40:13,491 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,491 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,493 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,493 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,493 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,493 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-11 11:40:13,558 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-11 11:40:13,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-11 11:40:13,558 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-11 11:40:13,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-11 11:40:13,559 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-11 11:40:13,559 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(43, 0)
2014-07-11 11:40:13,559 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,560 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(43, 1)
2014-07-11 11:40:13,560 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,560 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,560 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 43 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:40:13,561 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079249488 s
2014-07-11 11:40:13,567 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,567 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,567 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,568 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,570 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,570 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[178] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,572 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 44 (MappedRDD[178] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,572 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 2 tasks
2014-07-11 11:40:13,573 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,574 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:13,574 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:1 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,574 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:13,574 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-11 11:40:13,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-11 11:40:13,576 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,576 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,577 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,577 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,585 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,585 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,636 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-11 11:40:13,636 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-11 11:40:13,637 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 1)
2014-07-11 11:40:13,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-11 11:40:13,666 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-11 11:40:13,666 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-11 11:40:13,666 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-11 11:40:13,667 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-11 11:40:13,667 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 94 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,667 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,667 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:40:13,668 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.10086612 s
2014-07-11 11:40:13,673 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,673 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,673 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 45(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,673 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,675 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,675 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 45 (MappedRDD[182] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,677 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 45 (MappedRDD[182] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,678 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2014-07-11 11:40:13,678 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 45.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,679 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 45.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:13,679 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 45.0:1 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,679 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 45.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:13,680 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-11 11:40:13,681 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,683 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,683 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,683 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-11 11:40:13,690 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,698 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,698 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,741 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-11 11:40:13,741 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-11 11:40:13,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-11 11:40:13,742 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(45, 1)
2014-07-11 11:40:13,742 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,785 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-11 11:40:13,785 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-11 11:40:13,785 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-11 11:40:13,786 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(45, 0)
2014-07-11 11:40:13,786 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 108 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,786 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,786 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 45 (reduce at CalEigenVector.scala:38) finished in 0.108 s
2014-07-11 11:40:13,787 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.113956971 s
2014-07-11 11:40:13,792 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,792 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,793 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,793 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,794 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,794 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[186] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,797 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 46 (MappedRDD[186] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,797 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2014-07-11 11:40:13,797 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,798 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:13,798 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:1 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,798 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:13,798 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-11 11:40:13,799 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-11 11:40:13,800 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,800 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,801 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,801 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,801 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,801 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,865 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-11 11:40:13,865 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-11 11:40:13,866 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-11 11:40:13,866 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,866 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 1)
2014-07-11 11:40:13,868 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-11 11:40:13,868 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-11 11:40:13,868 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-11 11:40:13,869 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-11 11:40:13,870 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:40:13,869 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,870 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,870 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078126812 s
2014-07-11 11:40:13,875 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 47(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,878 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,878 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 47 (MappedRDD[190] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,884 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 47 (MappedRDD[190] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,885 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 47.0 with 2 tasks
2014-07-11 11:40:13,885 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 47.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 47.0:0 as 2294 bytes in 1 ms
2014-07-11 11:40:13,887 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 47.0:1 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,887 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 47.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:13,888 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-11 11:40:13,888 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-11 11:40:13,889 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,891 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,891 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,893 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,895 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,895 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,952 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-11 11:40:13,952 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-11 11:40:13,953 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-11 11:40:13,953 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(47, 1)
2014-07-11 11:40:13,953 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:13,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-11 11:40:13,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-11 11:40:13,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-11 11:40:13,957 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(47, 0)
2014-07-11 11:40:13,957 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:40:13,957 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2014-07-11 11:40:13,957 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 47 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:40:13,957 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081836704 s
2014-07-11 11:40:13,962 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:13,963 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:13,963 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:13,963 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:13,965 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:13,965 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[194] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:13,968 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 48 (MappedRDD[194] at map at CalEigenVector.scala:38)
2014-07-11 11:40:13,968 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2014-07-11 11:40:13,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,969 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2295 bytes in 0 ms
2014-07-11 11:40:13,969 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:1 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:13,969 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:1 as 2295 bytes in 0 ms
2014-07-11 11:40:13,969 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-11 11:40:13,971 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,971 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-11 11:40:13,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,972 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:13,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:13,973 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:13,973 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,026 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-11 11:40:14,026 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-11 11:40:14,026 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-11 11:40:14,027 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,029 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-11 11:40:14,033 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-11 11:40:14,033 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-11 11:40:14,033 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-11 11:40:14,034 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 1)
2014-07-11 11:40:14,034 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,034 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,034 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:40:14,034 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071723376 s
2014-07-11 11:40:14,039 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,040 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,040 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 49(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,040 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,042 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,042 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 49 (MappedRDD[198] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,044 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 49 (MappedRDD[198] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,044 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 49.0 with 2 tasks
2014-07-11 11:40:14,045 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 49.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,045 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 49.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:14,046 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 49.0:1 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,046 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 49.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:14,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-11 11:40:14,048 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-11 11:40:14,049 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,049 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,050 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,050 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,050 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,050 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-11 11:40:14,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-11 11:40:14,099 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-11 11:40:14,103 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,103 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(49, 0)
2014-07-11 11:40:14,106 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-11 11:40:14,106 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-11 11:40:14,106 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-11 11:40:14,106 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 61 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,107 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,107 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(49, 1)
2014-07-11 11:40:14,107 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 49 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:40:14,107 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.067692229 s
2014-07-11 11:40:14,112 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,113 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,113 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,113 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,115 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,115 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[202] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,117 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 50 (MappedRDD[202] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,117 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2014-07-11 11:40:14,118 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,118 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:14,119 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:1 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,119 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:14,119 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-11 11:40:14,120 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,122 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,122 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,127 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-11 11:40:14,128 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,130 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,130 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,181 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-11 11:40:14,181 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-11 11:40:14,181 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-11 11:40:14,182 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-11 11:40:14,182 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,219 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-11 11:40:14,219 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-11 11:40:14,220 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 102 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,220 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,220 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 1)
2014-07-11 11:40:14,220 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at CalEigenVector.scala:38) finished in 0.102 s
2014-07-11 11:40:14,221 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.108709562 s
2014-07-11 11:40:14,229 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-11 11:40:14,230 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,230 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 51(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,230 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,232 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,235 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 51 (MappedRDD[206] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,242 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 51 (MappedRDD[206] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,242 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 2 tasks
2014-07-11 11:40:14,243 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 51.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,243 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 51.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:14,243 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 51.0:1 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,244 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 51.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:14,244 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-11 11:40:14,245 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,246 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,247 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-11 11:40:14,248 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,249 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,250 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,313 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-11 11:40:14,313 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-11 11:40:14,313 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-11 11:40:14,313 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(51, 0)
2014-07-11 11:40:14,314 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,343 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-11 11:40:14,343 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-11 11:40:14,344 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 101 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,345 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,345 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(51, 1)
2014-07-11 11:40:14,345 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 51 (reduce at CalEigenVector.scala:38) finished in 0.103 s
2014-07-11 11:40:14,346 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.116360825 s
2014-07-11 11:40:14,353 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-11 11:40:14,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,356 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,357 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[210] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,359 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 52 (MappedRDD[210] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,359 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 2 tasks
2014-07-11 11:40:14,360 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,360 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:14,360 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:1 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,361 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:1 as 2294 bytes in 1 ms
2014-07-11 11:40:14,361 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-11 11:40:14,361 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-11 11:40:14,362 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,362 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,364 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,364 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,364 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,364 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,430 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-11 11:40:14,431 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-11 11:40:14,431 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-11 11:40:14,431 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-11 11:40:14,431 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,446 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-11 11:40:14,446 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-11 11:40:14,446 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-11 11:40:14,447 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 1)
2014-07-11 11:40:14,447 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:40:14,447 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,447 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,448 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094937334 s
2014-07-11 11:40:14,453 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 53(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,455 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,456 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 53 (MappedRDD[214] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 53 (MappedRDD[214] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 2 tasks
2014-07-11 11:40:14,459 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 53.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,459 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 53.0:0 as 2295 bytes in 0 ms
2014-07-11 11:40:14,460 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 53.0:1 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,460 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 53.0:1 as 2295 bytes in 0 ms
2014-07-11 11:40:14,461 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-11 11:40:14,461 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-11 11:40:14,462 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,462 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,463 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,463 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,463 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,463 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,530 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-11 11:40:14,530 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-11 11:40:14,530 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-11 11:40:14,531 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(53, 0)
2014-07-11 11:40:14,531 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,539 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-11 11:40:14,539 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-11 11:40:14,539 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-11 11:40:14,540 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(53, 1)
2014-07-11 11:40:14,540 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,540 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,540 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 53 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:40:14,540 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.087252206 s
2014-07-11 11:40:14,545 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,548 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,548 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[218] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 54 (MappedRDD[218] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2014-07-11 11:40:14,551 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,551 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:14,551 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:1 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,552 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:1 as 2293 bytes in 1 ms
2014-07-11 11:40:14,552 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-11 11:40:14,552 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-11 11:40:14,553 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,553 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,554 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,554 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,554 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,554 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,620 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-11 11:40:14,620 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-11 11:40:14,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-11 11:40:14,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-11 11:40:14,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-11 11:40:14,621 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,621 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-11 11:40:14,622 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-11 11:40:14,622 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 1)
2014-07-11 11:40:14,622 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,622 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,622 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:40:14,623 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077315837 s
2014-07-11 11:40:14,628 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,629 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,629 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 55(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,629 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,631 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,631 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 55 (MappedRDD[222] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,633 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 55 (MappedRDD[222] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,634 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2014-07-11 11:40:14,634 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 55.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,635 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 55.0:0 as 2294 bytes in 1 ms
2014-07-11 11:40:14,635 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 55.0:1 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,635 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 55.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:14,636 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-11 11:40:14,637 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,636 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-11 11:40:14,640 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,641 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,641 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,644 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,644 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-11 11:40:14,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-11 11:40:14,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-11 11:40:14,714 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(55, 0)
2014-07-11 11:40:14,714 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-11 11:40:14,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-11 11:40:14,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-11 11:40:14,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(55, 1)
2014-07-11 11:40:14,716 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,717 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 55 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:40:14,717 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,717 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088992814 s
2014-07-11 11:40:14,722 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,723 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,723 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,723 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,724 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,725 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[226] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,727 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 56 (MappedRDD[226] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,727 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 2 tasks
2014-07-11 11:40:14,727 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,728 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:14,728 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:1 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,728 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:14,728 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-11 11:40:14,729 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-11 11:40:14,729 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,729 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,730 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,730 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,730 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,731 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,796 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-11 11:40:14,796 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-11 11:40:14,797 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-11 11:40:14,798 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 1)
2014-07-11 11:40:14,798 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-11 11:40:14,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-11 11:40:14,799 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-11 11:40:14,799 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-11 11:40:14,799 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,799 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,799 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:40:14,800 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077630621 s
2014-07-11 11:40:14,805 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,805 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,805 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 57(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,805 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,807 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,807 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 57 (MappedRDD[230] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,809 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 57 (MappedRDD[230] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 2 tasks
2014-07-11 11:40:14,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 57.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 57.0:0 as 2294 bytes in 1 ms
2014-07-11 11:40:14,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 57.0:1 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 57.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:14,812 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-11 11:40:14,813 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,813 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-11 11:40:14,814 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,815 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,816 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,819 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,819 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,901 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-11 11:40:14,901 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-11 11:40:14,902 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 91 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,903 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-11 11:40:14,903 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-11 11:40:14,904 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(57, 1)
2014-07-11 11:40:14,904 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-11 11:40:14,904 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(57, 0)
2014-07-11 11:40:14,904 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 94 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,904 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 57 (reduce at CalEigenVector.scala:38) finished in 0.094 s
2014-07-11 11:40:14,905 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.100206409 s
2014-07-11 11:40:14,904 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,907 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-11 11:40:14,910 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,911 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,911 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,911 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[234] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,915 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 58 (MappedRDD[234] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,915 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 2 tasks
2014-07-11 11:40:14,915 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,916 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2293 bytes in 1 ms
2014-07-11 11:40:14,916 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:1 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,916 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:14,917 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-11 11:40:14,917 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-11 11:40:14,918 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:14,920 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:14,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:14,983 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-11 11:40:14,983 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-11 11:40:14,984 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:14,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 1)
2014-07-11 11:40:14,985 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-11 11:40:14,985 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-11 11:40:14,985 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-11 11:40:14,985 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-11 11:40:14,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-11 11:40:14,986 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:40:14,986 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-11 11:40:14,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:40:14,987 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076056987 s
2014-07-11 11:40:14,992 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:14,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:14,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 59(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:14,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:14,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:14,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 59 (MappedRDD[238] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:14,996 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 59 (MappedRDD[238] at map at CalEigenVector.scala:38)
2014-07-11 11:40:14,996 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 2 tasks
2014-07-11 11:40:14,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 59.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 59.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:14,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 59.0:1 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:14,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 59.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:14,998 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-11 11:40:14,998 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-11 11:40:15,001 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,003 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,003 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,004 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,004 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,073 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-11 11:40:15,073 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-11 11:40:15,074 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,074 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(59, 0)
2014-07-11 11:40:15,075 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-11 11:40:15,075 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-11 11:40:15,075 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-11 11:40:15,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-11 11:40:15,078 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(59, 1)
2014-07-11 11:40:15,078 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,078 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,078 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 59 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:40:15,078 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08667142 s
2014-07-11 11:40:15,084 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,084 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,084 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,084 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,086 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,086 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[242] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,088 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 60 (MappedRDD[242] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,088 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 2 tasks
2014-07-11 11:40:15,089 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,089 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:15,089 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:1 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,089 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:15,090 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-11 11:40:15,091 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-11 11:40:15,092 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,093 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,094 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,094 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,096 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,096 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-11 11:40:15,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-11 11:40:15,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-11 11:40:15,172 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-11 11:40:15,173 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 83 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,175 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-11 11:40:15,176 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-11 11:40:15,176 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-11 11:40:15,176 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,176 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,177 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 1)
2014-07-11 11:40:15,177 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at CalEigenVector.scala:38) finished in 0.087 s
2014-07-11 11:40:15,177 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.093378056 s
2014-07-11 11:40:15,183 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,183 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,184 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 61(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,184 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,185 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,186 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 61 (MappedRDD[246] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,187 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 61 (MappedRDD[246] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,187 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 2 tasks
2014-07-11 11:40:15,188 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 61.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,188 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 61.0:0 as 2293 bytes in 0 ms
2014-07-11 11:40:15,188 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 61.0:1 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,188 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 61.0:1 as 2293 bytes in 0 ms
2014-07-11 11:40:15,189 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-11 11:40:15,189 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-11 11:40:15,190 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,190 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,191 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,191 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,191 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,191 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,236 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-11 11:40:15,236 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-11 11:40:15,237 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-11 11:40:15,237 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-11 11:40:15,237 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 49 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,237 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(61, 1)
2014-07-11 11:40:15,237 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 49 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,237 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,237 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-11 11:40:15,237 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(61, 0)
2014-07-11 11:40:15,238 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 61 (reduce at CalEigenVector.scala:38) finished in 0.051 s
2014-07-11 11:40:15,238 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.055175931 s
2014-07-11 11:40:15,239 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-11 11:40:15,243 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,244 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,244 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,244 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,246 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,246 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[250] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,248 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 62 (MappedRDD[250] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,248 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 2 tasks
2014-07-11 11:40:15,249 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 124 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,249 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:15,249 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:1 as TID 125 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,250 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:15,250 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 125
2014-07-11 11:40:15,251 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 124
2014-07-11 11:40:15,252 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,252 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,253 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,256 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,256 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,257 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,316 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 125 is 678
2014-07-11 11:40:15,316 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 125 directly to driver
2014-07-11 11:40:15,316 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 125
2014-07-11 11:40:15,317 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 1)
2014-07-11 11:40:15,317 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 125 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,318 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 124 is 678
2014-07-11 11:40:15,318 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 124 directly to driver
2014-07-11 11:40:15,318 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 124
2014-07-11 11:40:15,318 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-11 11:40:15,319 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 124 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,319 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,319 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:15,319 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075724664 s
2014-07-11 11:40:15,324 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,325 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,325 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 63(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,325 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,326 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,327 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 63 (MappedRDD[254] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,328 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 63 (MappedRDD[254] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,328 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 2 tasks
2014-07-11 11:40:15,329 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 63.0:0 as TID 126 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,329 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 63.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:15,329 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 63.0:1 as TID 127 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,329 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 63.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:15,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 126
2014-07-11 11:40:15,330 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 127
2014-07-11 11:40:15,331 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,331 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,332 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,332 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,332 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,332 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,397 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 127 is 678
2014-07-11 11:40:15,397 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 127 directly to driver
2014-07-11 11:40:15,398 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 127 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,398 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(63, 1)
2014-07-11 11:40:15,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 127
2014-07-11 11:40:15,400 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 126 is 678
2014-07-11 11:40:15,400 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 126 directly to driver
2014-07-11 11:40:15,400 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 126
2014-07-11 11:40:15,401 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 126 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,401 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,401 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(63, 0)
2014-07-11 11:40:15,402 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 63 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:40:15,402 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077933934 s
2014-07-11 11:40:15,407 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,408 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,408 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,408 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,409 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,410 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[258] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,411 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 64 (MappedRDD[258] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,411 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 2 tasks
2014-07-11 11:40:15,412 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 128 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,412 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:15,412 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:1 as TID 129 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,412 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:15,413 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 128
2014-07-11 11:40:15,413 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 129
2014-07-11 11:40:15,414 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,414 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,415 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,415 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,415 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,415 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,485 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 129 is 678
2014-07-11 11:40:15,485 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 129 directly to driver
2014-07-11 11:40:15,485 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 128 is 678
2014-07-11 11:40:15,485 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 128 directly to driver
2014-07-11 11:40:15,485 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 128
2014-07-11 11:40:15,485 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 129
2014-07-11 11:40:15,486 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 129 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,486 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 1)
2014-07-11 11:40:15,486 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 128 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,486 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,486 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-11 11:40:15,486 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:40:15,487 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.07963684 s
2014-07-11 11:40:15,492 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,493 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,493 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 65(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,493 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,494 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,495 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 65 (MappedRDD[262] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,496 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 65 (MappedRDD[262] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,496 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 2 tasks
2014-07-11 11:40:15,497 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 65.0:0 as TID 130 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,497 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 65.0:0 as 2295 bytes in 0 ms
2014-07-11 11:40:15,498 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 65.0:1 as TID 131 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,498 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 65.0:1 as 2295 bytes in 0 ms
2014-07-11 11:40:15,498 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 130
2014-07-11 11:40:15,500 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,500 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 131
2014-07-11 11:40:15,501 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,502 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,503 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,503 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,504 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,571 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 130 is 678
2014-07-11 11:40:15,571 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 130 directly to driver
2014-07-11 11:40:15,573 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 130 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,573 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(65, 0)
2014-07-11 11:40:15,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 130
2014-07-11 11:40:15,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 131 is 678
2014-07-11 11:40:15,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 131 directly to driver
2014-07-11 11:40:15,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 131
2014-07-11 11:40:15,575 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(65, 1)
2014-07-11 11:40:15,575 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 65 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:40:15,576 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083816826 s
2014-07-11 11:40:15,575 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 131 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,578 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,581 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,582 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,582 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,582 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,584 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,584 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[266] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,585 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 66 (MappedRDD[266] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,585 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 2 tasks
2014-07-11 11:40:15,586 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 132 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,586 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:15,586 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:1 as TID 133 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,587 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:15,587 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 132
2014-07-11 11:40:15,588 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,589 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,589 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,591 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 133
2014-07-11 11:40:15,592 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,593 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,593 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,653 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 133 is 678
2014-07-11 11:40:15,653 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 133 directly to driver
2014-07-11 11:40:15,654 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 133
2014-07-11 11:40:15,654 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 133 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,655 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 1)
2014-07-11 11:40:15,656 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 132 is 678
2014-07-11 11:40:15,656 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 132 directly to driver
2014-07-11 11:40:15,657 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 132
2014-07-11 11:40:15,657 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-11 11:40:15,657 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 132 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,657 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,657 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:40:15,658 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076358232 s
2014-07-11 11:40:15,663 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,664 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,664 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 67(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,664 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,665 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,665 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 67 (MappedRDD[270] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,667 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 67 (MappedRDD[270] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,667 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 67.0 with 2 tasks
2014-07-11 11:40:15,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 67.0:0 as TID 134 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 67.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:15,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 67.0:1 as TID 135 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 67.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:15,669 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 134
2014-07-11 11:40:15,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 135
2014-07-11 11:40:15,670 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,670 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,670 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,670 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,671 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,671 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,735 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 135 is 678
2014-07-11 11:40:15,735 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 135 directly to driver
2014-07-11 11:40:15,735 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 134 is 678
2014-07-11 11:40:15,735 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 134 directly to driver
2014-07-11 11:40:15,735 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 134
2014-07-11 11:40:15,736 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 135 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,736 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(67, 1)
2014-07-11 11:40:15,736 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 135
2014-07-11 11:40:15,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(67, 0)
2014-07-11 11:40:15,737 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 67 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:15,737 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.074052365 s
2014-07-11 11:40:15,736 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 134 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,737 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,742 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,743 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,743 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,743 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,745 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,745 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[274] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,747 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 68 (MappedRDD[274] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,747 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 2 tasks
2014-07-11 11:40:15,747 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 136 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,748 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:15,748 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:1 as TID 137 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,748 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:15,748 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 136
2014-07-11 11:40:15,749 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 137
2014-07-11 11:40:15,749 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,750 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,750 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,750 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,758 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,759 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,820 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 136 is 678
2014-07-11 11:40:15,821 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 136 directly to driver
2014-07-11 11:40:15,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 136
2014-07-11 11:40:15,822 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 136 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,822 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-11 11:40:15,828 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 137 is 678
2014-07-11 11:40:15,828 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 137 directly to driver
2014-07-11 11:40:15,828 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 137
2014-07-11 11:40:15,828 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 1)
2014-07-11 11:40:15,828 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 137 in 80 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,829 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,829 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:40:15,829 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086403703 s
2014-07-11 11:40:15,834 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,835 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,835 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 69(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,835 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,836 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,837 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 69 (MappedRDD[278] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,838 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 69 (MappedRDD[278] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,838 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 69.0 with 2 tasks
2014-07-11 11:40:15,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 69.0:0 as TID 138 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 69.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:15,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 69.0:1 as TID 139 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 69.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:15,840 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 138
2014-07-11 11:40:15,840 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 139
2014-07-11 11:40:15,841 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,841 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,842 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,842 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,843 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,843 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 139 is 678
2014-07-11 11:40:15,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 139 directly to driver
2014-07-11 11:40:15,904 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 139 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,904 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(69, 1)
2014-07-11 11:40:15,905 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 139
2014-07-11 11:40:15,906 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 138 is 678
2014-07-11 11:40:15,906 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 138 directly to driver
2014-07-11 11:40:15,906 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 138
2014-07-11 11:40:15,907 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 138 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,907 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,907 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(69, 0)
2014-07-11 11:40:15,907 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 69 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:15,908 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.073658659 s
2014-07-11 11:40:15,913 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,914 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,914 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,914 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,915 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,916 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[282] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:15,917 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 70 (MappedRDD[282] at map at CalEigenVector.scala:38)
2014-07-11 11:40:15,917 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 2 tasks
2014-07-11 11:40:15,918 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 140 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,918 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:15,918 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:1 as TID 141 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:15,918 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:15,919 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 141
2014-07-11 11:40:15,919 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 140
2014-07-11 11:40:15,920 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:15,924 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:15,925 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,925 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:15,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 141 is 678
2014-07-11 11:40:15,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 141 directly to driver
2014-07-11 11:40:15,988 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 140 is 678
2014-07-11 11:40:15,988 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 140 directly to driver
2014-07-11 11:40:15,988 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 140
2014-07-11 11:40:15,989 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 1)
2014-07-11 11:40:15,989 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 141 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:40:15,990 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 141
2014-07-11 11:40:15,990 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-11 11:40:15,990 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 140 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:40:15,990 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-11 11:40:15,990 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:40:15,990 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077262054 s
2014-07-11 11:40:15,995 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:15,996 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:15,996 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 71(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:15,996 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:15,998 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:15,998 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 71 (MappedRDD[286] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,006 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 71 (MappedRDD[286] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,006 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 71.0 with 2 tasks
2014-07-11 11:40:16,007 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 71.0:0 as TID 142 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,007 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 71.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,007 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 71.0:1 as TID 143 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,008 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 71.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:16,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 142
2014-07-11 11:40:16,009 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,010 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,010 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,015 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 143
2014-07-11 11:40:16,016 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,017 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,017 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,081 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 142 is 678
2014-07-11 11:40:16,081 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 142 directly to driver
2014-07-11 11:40:16,082 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 142 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,082 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(71, 0)
2014-07-11 11:40:16,083 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 142
2014-07-11 11:40:16,083 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 143 is 678
2014-07-11 11:40:16,083 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 143 directly to driver
2014-07-11 11:40:16,083 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 143
2014-07-11 11:40:16,084 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(71, 1)
2014-07-11 11:40:16,084 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 71 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:40:16,084 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 143 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,084 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,084 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088887576 s
2014-07-11 11:40:16,090 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,093 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,093 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[290] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 72 (MappedRDD[290] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 2 tasks
2014-07-11 11:40:16,095 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 144 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,095 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,095 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:1 as TID 145 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,096 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:1 as 2297 bytes in 1 ms
2014-07-11 11:40:16,096 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 144
2014-07-11 11:40:16,096 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 145
2014-07-11 11:40:16,097 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,097 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,098 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,098 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,098 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,098 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,154 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 145 is 678
2014-07-11 11:40:16,154 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 145 directly to driver
2014-07-11 11:40:16,154 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 145
2014-07-11 11:40:16,154 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 145 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,155 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 1)
2014-07-11 11:40:16,155 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 144 is 678
2014-07-11 11:40:16,155 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 144 directly to driver
2014-07-11 11:40:16,155 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 144
2014-07-11 11:40:16,156 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-11 11:40:16,156 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 144 in 60 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,156 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,156 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at CalEigenVector.scala:38) finished in 0.060 s
2014-07-11 11:40:16,156 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.066097892 s
2014-07-11 11:40:16,161 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,162 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,162 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 73(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,162 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,164 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,164 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 73 (MappedRDD[294] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 73 (MappedRDD[294] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 2 tasks
2014-07-11 11:40:16,166 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 73.0:0 as TID 146 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,166 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 73.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:16,166 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 73.0:1 as TID 147 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,166 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 73.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:16,167 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 146
2014-07-11 11:40:16,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 147
2014-07-11 11:40:16,168 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,168 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,169 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,169 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,169 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,169 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,217 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 147 is 678
2014-07-11 11:40:16,217 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 147 directly to driver
2014-07-11 11:40:16,217 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 147
2014-07-11 11:40:16,218 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(73, 1)
2014-07-11 11:40:16,218 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 147 in 52 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,219 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 146 is 678
2014-07-11 11:40:16,219 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 146 directly to driver
2014-07-11 11:40:16,219 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 146
2014-07-11 11:40:16,220 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(73, 0)
2014-07-11 11:40:16,220 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 146 in 54 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,220 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,220 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 73 (reduce at CalEigenVector.scala:38) finished in 0.054 s
2014-07-11 11:40:16,220 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.059015369 s
2014-07-11 11:40:16,225 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,226 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,226 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,226 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,228 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,228 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[298] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,230 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 74 (MappedRDD[298] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,230 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 2 tasks
2014-07-11 11:40:16,231 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 148 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,231 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:16,231 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:1 as TID 149 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,231 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:16,232 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 148
2014-07-11 11:40:16,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 149
2014-07-11 11:40:16,232 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,233 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,233 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,233 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,234 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,234 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,291 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 149 is 678
2014-07-11 11:40:16,291 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 149 directly to driver
2014-07-11 11:40:16,291 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 148 is 678
2014-07-11 11:40:16,291 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 148 directly to driver
2014-07-11 11:40:16,291 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 148
2014-07-11 11:40:16,292 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 149
2014-07-11 11:40:16,292 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 149 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,292 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 1)
2014-07-11 11:40:16,293 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-11 11:40:16,293 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at CalEigenVector.scala:38) finished in 0.063 s
2014-07-11 11:40:16,293 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.067655102 s
2014-07-11 11:40:16,293 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 148 in 63 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,295 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,298 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,299 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,299 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 75(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,299 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,300 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,301 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 75 (MappedRDD[302] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,302 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 75 (MappedRDD[302] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,302 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 75.0 with 2 tasks
2014-07-11 11:40:16,303 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 75.0:0 as TID 150 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,303 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 75.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,303 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 75.0:1 as TID 151 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,303 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 75.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:16,304 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 150
2014-07-11 11:40:16,304 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 151
2014-07-11 11:40:16,305 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,305 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,306 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,306 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,306 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,306 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,370 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 150 is 678
2014-07-11 11:40:16,370 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 150 directly to driver
2014-07-11 11:40:16,370 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 150
2014-07-11 11:40:16,372 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 150 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,372 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(75, 0)
2014-07-11 11:40:16,375 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 151 is 678
2014-07-11 11:40:16,375 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 151 directly to driver
2014-07-11 11:40:16,375 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 151
2014-07-11 11:40:16,376 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(75, 1)
2014-07-11 11:40:16,376 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 75 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:40:16,376 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 151 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,376 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,376 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077711892 s
2014-07-11 11:40:16,381 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,382 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,382 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,382 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,384 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,384 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[306] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,386 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 76 (MappedRDD[306] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,386 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 2 tasks
2014-07-11 11:40:16,387 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 152 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,387 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2295 bytes in 0 ms
2014-07-11 11:40:16,387 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:1 as TID 153 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,387 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:1 as 2295 bytes in 0 ms
2014-07-11 11:40:16,387 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 153
2014-07-11 11:40:16,388 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,389 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,389 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,391 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 152
2014-07-11 11:40:16,392 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,393 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,394 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,453 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 153 is 678
2014-07-11 11:40:16,453 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 153 directly to driver
2014-07-11 11:40:16,453 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 153
2014-07-11 11:40:16,454 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 1)
2014-07-11 11:40:16,454 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 153 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,462 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 152 is 678
2014-07-11 11:40:16,462 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 152 directly to driver
2014-07-11 11:40:16,462 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 152
2014-07-11 11:40:16,463 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-11 11:40:16,463 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:40:16,463 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 152 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,464 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,464 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082291857 s
2014-07-11 11:40:16,469 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 77(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,471 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,471 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 77 (MappedRDD[310] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,473 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 77 (MappedRDD[310] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,473 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 77.0 with 2 tasks
2014-07-11 11:40:16,473 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 77.0:0 as TID 154 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,474 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 77.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,474 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 77.0:1 as TID 155 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,474 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 77.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:16,474 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 155
2014-07-11 11:40:16,476 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,476 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 154
2014-07-11 11:40:16,477 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,477 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,477 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,543 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 155 is 678
2014-07-11 11:40:16,544 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 155 directly to driver
2014-07-11 11:40:16,545 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 155 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,545 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(77, 1)
2014-07-11 11:40:16,545 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 155
2014-07-11 11:40:16,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 154 is 678
2014-07-11 11:40:16,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 154 directly to driver
2014-07-11 11:40:16,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 154
2014-07-11 11:40:16,557 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(77, 0)
2014-07-11 11:40:16,557 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 154 in 84 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,557 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,557 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 77 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:40:16,558 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089092536 s
2014-07-11 11:40:16,563 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,564 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,564 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,564 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,565 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,566 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[314] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,567 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 78 (MappedRDD[314] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,567 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 2 tasks
2014-07-11 11:40:16,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 156 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:16,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:1 as TID 157 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:16,568 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 156
2014-07-11 11:40:16,569 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 157
2014-07-11 11:40:16,569 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,570 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,570 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,570 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,570 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,571 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 157 is 678
2014-07-11 11:40:16,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 157 directly to driver
2014-07-11 11:40:16,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 157
2014-07-11 11:40:16,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 1)
2014-07-11 11:40:16,633 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 157 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,634 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 156 is 678
2014-07-11 11:40:16,634 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 156 directly to driver
2014-07-11 11:40:16,634 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 156
2014-07-11 11:40:16,634 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-11 11:40:16,634 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 156 in 67 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,634 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,635 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:40:16,635 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071630499 s
2014-07-11 11:40:16,640 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,640 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,640 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 79(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,640 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,642 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,642 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 79 (MappedRDD[318] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,643 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 79 (MappedRDD[318] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 79.0 with 2 tasks
2014-07-11 11:40:16,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 79.0:0 as TID 158 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 79.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 79.0:1 as TID 159 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,645 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 79.0:1 as 2297 bytes in 1 ms
2014-07-11 11:40:16,645 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 158
2014-07-11 11:40:16,646 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,647 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,647 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 159
2014-07-11 11:40:16,647 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,648 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,708 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 158 is 678
2014-07-11 11:40:16,708 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 158 directly to driver
2014-07-11 11:40:16,708 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 158
2014-07-11 11:40:16,709 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(79, 0)
2014-07-11 11:40:16,709 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 158 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 159 is 678
2014-07-11 11:40:16,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 159 directly to driver
2014-07-11 11:40:16,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 159
2014-07-11 11:40:16,714 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(79, 1)
2014-07-11 11:40:16,714 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 79 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:40:16,714 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 159 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,714 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,714 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.074306065 s
2014-07-11 11:40:16,719 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,720 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,720 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,720 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,721 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,722 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[322] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,723 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 80 (MappedRDD[322] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,723 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 2 tasks
2014-07-11 11:40:16,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 160 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:1 as TID 161 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:16,724 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 160
2014-07-11 11:40:16,725 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 161
2014-07-11 11:40:16,726 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,727 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,727 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,727 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,728 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,728 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,793 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 161 is 678
2014-07-11 11:40:16,793 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 161 directly to driver
2014-07-11 11:40:16,793 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 161
2014-07-11 11:40:16,794 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 1)
2014-07-11 11:40:16,794 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 161 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,795 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 160 is 678
2014-07-11 11:40:16,795 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 160 directly to driver
2014-07-11 11:40:16,795 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 160
2014-07-11 11:40:16,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-11 11:40:16,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:40:16,797 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 160 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,797 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,797 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.07809021 s
2014-07-11 11:40:16,802 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,803 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,803 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 81(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,803 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,805 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,806 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 81 (MappedRDD[326] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,807 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 81 (MappedRDD[326] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,807 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 81.0 with 2 tasks
2014-07-11 11:40:16,808 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 81.0:0 as TID 162 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,808 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 81.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:16,809 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 81.0:1 as TID 163 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,809 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 81.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:16,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 162
2014-07-11 11:40:16,809 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 163
2014-07-11 11:40:16,810 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,811 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,811 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,811 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,812 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,812 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,873 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 162 is 678
2014-07-11 11:40:16,874 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 162 directly to driver
2014-07-11 11:40:16,874 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 162
2014-07-11 11:40:16,874 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(81, 0)
2014-07-11 11:40:16,874 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 162 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,876 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 163 is 678
2014-07-11 11:40:16,876 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 163 directly to driver
2014-07-11 11:40:16,876 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 163
2014-07-11 11:40:16,877 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(81, 1)
2014-07-11 11:40:16,877 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 81 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:40:16,877 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 163 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,877 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,877 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075083845 s
2014-07-11 11:40:16,882 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,883 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,883 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,883 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,885 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,885 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[330] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 82 (MappedRDD[330] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 2 tasks
2014-07-11 11:40:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 164 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:1 as TID 165 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:16,888 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 164
2014-07-11 11:40:16,888 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 165
2014-07-11 11:40:16,889 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,890 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,890 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,890 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,890 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,953 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 164 is 678
2014-07-11 11:40:16,953 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 164 directly to driver
2014-07-11 11:40:16,953 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 164
2014-07-11 11:40:16,954 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-11 11:40:16,954 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 164 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:16,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 165 is 678
2014-07-11 11:40:16,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 165 directly to driver
2014-07-11 11:40:16,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 165
2014-07-11 11:40:16,958 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 1)
2014-07-11 11:40:16,958 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:40:16,958 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 165 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:40:16,958 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-11 11:40:16,958 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075612382 s
2014-07-11 11:40:16,967 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:16,968 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:16,968 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 83(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:16,968 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:16,970 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:16,970 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 83 (MappedRDD[334] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:16,972 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 83 (MappedRDD[334] at map at CalEigenVector.scala:38)
2014-07-11 11:40:16,972 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 83.0 with 2 tasks
2014-07-11 11:40:16,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 83.0:0 as TID 166 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 83.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:16,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 83.0:1 as TID 167 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:16,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 83.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:16,974 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 167
2014-07-11 11:40:16,974 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 166
2014-07-11 11:40:16,975 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,975 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:16,976 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,976 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:16,977 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:16,977 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 166 is 678
2014-07-11 11:40:17,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 166 directly to driver
2014-07-11 11:40:17,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 166
2014-07-11 11:40:17,034 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(83, 0)
2014-07-11 11:40:17,034 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 166 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,060 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 167 is 678
2014-07-11 11:40:17,060 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 167 directly to driver
2014-07-11 11:40:17,061 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 167
2014-07-11 11:40:17,061 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(83, 1)
2014-07-11 11:40:17,061 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 83 (reduce at CalEigenVector.scala:38) finished in 0.089 s
2014-07-11 11:40:17,062 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094015993 s
2014-07-11 11:40:17,061 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 167 in 88 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,065 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,069 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,070 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,070 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,070 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,071 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,072 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[338] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,073 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 84 (MappedRDD[338] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,073 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 2 tasks
2014-07-11 11:40:17,074 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 168 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,074 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:17,074 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:1 as TID 169 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,074 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:17,075 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 169
2014-07-11 11:40:17,076 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,077 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,077 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,081 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 168
2014-07-11 11:40:17,083 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,089 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,089 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,179 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 169 is 678
2014-07-11 11:40:17,179 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 169 directly to driver
2014-07-11 11:40:17,179 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 169
2014-07-11 11:40:17,180 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 169 in 106 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,180 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 1)
2014-07-11 11:40:17,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 168 is 678
2014-07-11 11:40:17,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 168 directly to driver
2014-07-11 11:40:17,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 168
2014-07-11 11:40:17,192 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 168 in 118 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,193 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,193 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-11 11:40:17,193 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at CalEigenVector.scala:38) finished in 0.120 s
2014-07-11 11:40:17,193 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.124519366 s
2014-07-11 11:40:17,199 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,203 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,204 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 85(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,204 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,205 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,206 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 85 (MappedRDD[342] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,207 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 85 (MappedRDD[342] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,208 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 85.0 with 2 tasks
2014-07-11 11:40:17,208 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 85.0:0 as TID 170 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,209 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 85.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:17,209 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 85.0:1 as TID 171 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,209 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 85.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:17,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 170
2014-07-11 11:40:17,209 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 171
2014-07-11 11:40:17,210 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,210 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,211 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,211 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,211 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,211 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 171 is 678
2014-07-11 11:40:17,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 171 directly to driver
2014-07-11 11:40:17,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 171
2014-07-11 11:40:17,259 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(85, 1)
2014-07-11 11:40:17,259 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 171 in 49 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 170 is 678
2014-07-11 11:40:17,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 170 directly to driver
2014-07-11 11:40:17,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 170
2014-07-11 11:40:17,276 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(85, 0)
2014-07-11 11:40:17,276 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 170 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,277 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,277 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 85 (reduce at CalEigenVector.scala:38) finished in 0.058 s
2014-07-11 11:40:17,277 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077325303 s
2014-07-11 11:40:17,282 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,282 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,282 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,282 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,284 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,284 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[346] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,286 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 86 (MappedRDD[346] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,286 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 2 tasks
2014-07-11 11:40:17,286 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 172 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,287 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2298 bytes in 0 ms
2014-07-11 11:40:17,287 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:1 as TID 173 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,287 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:1 as 2298 bytes in 0 ms
2014-07-11 11:40:17,288 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 173
2014-07-11 11:40:17,288 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 172
2014-07-11 11:40:17,289 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,289 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,289 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,289 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,295 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,295 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,358 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 173 is 678
2014-07-11 11:40:17,358 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 173 directly to driver
2014-07-11 11:40:17,358 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 173
2014-07-11 11:40:17,359 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 173 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,359 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 1)
2014-07-11 11:40:17,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 172 is 678
2014-07-11 11:40:17,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 172 directly to driver
2014-07-11 11:40:17,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 172
2014-07-11 11:40:17,369 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-11 11:40:17,369 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 172 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,369 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,369 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:40:17,369 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.087231919 s
2014-07-11 11:40:17,374 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,374 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,374 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 87(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,374 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,376 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,376 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 87 (MappedRDD[350] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,378 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 87 (MappedRDD[350] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,378 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 87.0 with 2 tasks
2014-07-11 11:40:17,378 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 87.0:0 as TID 174 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,378 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 87.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:17,379 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 87.0:1 as TID 175 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,379 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 87.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:17,379 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 174
2014-07-11 11:40:17,380 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 175
2014-07-11 11:40:17,380 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,381 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,381 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,383 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,385 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,385 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,442 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 175 is 678
2014-07-11 11:40:17,442 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 175 directly to driver
2014-07-11 11:40:17,442 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 175
2014-07-11 11:40:17,443 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(87, 1)
2014-07-11 11:40:17,443 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 175 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,447 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 174 is 678
2014-07-11 11:40:17,447 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 174 directly to driver
2014-07-11 11:40:17,447 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 174
2014-07-11 11:40:17,448 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 174 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,448 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,448 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(87, 0)
2014-07-11 11:40:17,448 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 87 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:40:17,451 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.07701997 s
2014-07-11 11:40:17,456 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,456 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,457 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,457 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,459 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[354] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,460 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 88 (MappedRDD[354] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,460 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 2 tasks
2014-07-11 11:40:17,460 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 176 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:17,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:1 as TID 177 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:17,462 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 176
2014-07-11 11:40:17,462 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 177
2014-07-11 11:40:17,463 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,463 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,464 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,464 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,471 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,471 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,519 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 177 is 678
2014-07-11 11:40:17,519 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 177 directly to driver
2014-07-11 11:40:17,521 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 177 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 1)
2014-07-11 11:40:17,521 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 177
2014-07-11 11:40:17,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 176 is 678
2014-07-11 11:40:17,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 176 directly to driver
2014-07-11 11:40:17,539 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 176
2014-07-11 11:40:17,539 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 176 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,539 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-11 11:40:17,539 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,539 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:40:17,540 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083715216 s
2014-07-11 11:40:17,547 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,548 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,548 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 89(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,548 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,549 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,549 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 89 (MappedRDD[358] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,550 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 89 (MappedRDD[358] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,550 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 89.0 with 2 tasks
2014-07-11 11:40:17,551 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 89.0:0 as TID 178 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,551 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 89.0:0 as 2294 bytes in 0 ms
2014-07-11 11:40:17,551 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 89.0:1 as TID 179 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,551 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 89.0:1 as 2294 bytes in 0 ms
2014-07-11 11:40:17,552 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 178
2014-07-11 11:40:17,552 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 179
2014-07-11 11:40:17,553 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,554 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,554 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,554 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,554 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,554 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,617 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 178 is 678
2014-07-11 11:40:17,617 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 178 directly to driver
2014-07-11 11:40:17,617 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 178
2014-07-11 11:40:17,618 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(89, 0)
2014-07-11 11:40:17,618 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 178 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,619 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 179 is 678
2014-07-11 11:40:17,619 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 179 directly to driver
2014-07-11 11:40:17,619 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 179
2014-07-11 11:40:17,619 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(89, 1)
2014-07-11 11:40:17,619 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 179 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,620 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 89 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:17,620 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 89.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,620 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072816585 s
2014-07-11 11:40:17,624 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,625 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,625 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,625 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,627 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,627 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[362] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,628 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 90 (MappedRDD[362] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,628 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 2 tasks
2014-07-11 11:40:17,629 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 180 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,629 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:17,629 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:1 as TID 181 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,629 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:17,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 180
2014-07-11 11:40:17,629 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 181
2014-07-11 11:40:17,631 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,631 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,631 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,631 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,632 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,632 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,694 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 181 is 678
2014-07-11 11:40:17,694 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 181 directly to driver
2014-07-11 11:40:17,694 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 181
2014-07-11 11:40:17,694 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 1)
2014-07-11 11:40:17,695 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 181 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,696 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 180 is 678
2014-07-11 11:40:17,696 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 180 directly to driver
2014-07-11 11:40:17,696 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 180
2014-07-11 11:40:17,697 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-11 11:40:17,697 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 180 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,697 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,697 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:17,697 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072687153 s
2014-07-11 11:40:17,703 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,703 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,704 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 91(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,704 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,705 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,705 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 91 (MappedRDD[366] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,706 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 91 (MappedRDD[366] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,706 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 91.0 with 2 tasks
2014-07-11 11:40:17,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 91.0:0 as TID 182 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 91.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:17,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 91.0:1 as TID 183 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 91.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:17,708 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 182
2014-07-11 11:40:17,709 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,709 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,709 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,711 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 183
2014-07-11 11:40:17,712 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,713 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,713 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,771 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 182 is 678
2014-07-11 11:40:17,771 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 182 directly to driver
2014-07-11 11:40:17,771 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 182
2014-07-11 11:40:17,774 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(91, 0)
2014-07-11 11:40:17,774 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 182 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,779 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 183 is 678
2014-07-11 11:40:17,779 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 183 directly to driver
2014-07-11 11:40:17,779 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 183
2014-07-11 11:40:17,780 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(91, 1)
2014-07-11 11:40:17,780 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 91 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:40:17,780 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 183 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,780 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,780 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077492153 s
2014-07-11 11:40:17,786 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,787 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,787 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,795 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,796 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,797 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[370] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,798 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 92 (MappedRDD[370] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,798 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 2 tasks
2014-07-11 11:40:17,798 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 184 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,799 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2296 bytes in 1 ms
2014-07-11 11:40:17,799 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:1 as TID 185 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,799 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:17,799 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 185
2014-07-11 11:40:17,800 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,801 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,801 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,806 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 184
2014-07-11 11:40:17,808 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,809 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,809 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,860 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 185 is 678
2014-07-11 11:40:17,861 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 185 directly to driver
2014-07-11 11:40:17,861 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 185
2014-07-11 11:40:17,861 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 1)
2014-07-11 11:40:17,861 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 185 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,871 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 184 is 678
2014-07-11 11:40:17,871 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 184 directly to driver
2014-07-11 11:40:17,871 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 184
2014-07-11 11:40:17,872 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-11 11:40:17,872 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:40:17,872 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 184 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,872 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,872 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085602296 s
2014-07-11 11:40:17,877 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,877 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,877 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 93(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,877 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,879 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,879 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 93 (MappedRDD[374] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,880 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 93 (MappedRDD[374] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,880 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 93.0 with 2 tasks
2014-07-11 11:40:17,881 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 93.0:0 as TID 186 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,881 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 93.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:17,881 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 93.0:1 as TID 187 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,881 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 93.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:17,881 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 186
2014-07-11 11:40:17,882 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 187
2014-07-11 11:40:17,882 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,883 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,883 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,890 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,891 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,892 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,945 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 186 is 678
2014-07-11 11:40:17,945 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 186 directly to driver
2014-07-11 11:40:17,945 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 186
2014-07-11 11:40:17,946 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(93, 0)
2014-07-11 11:40:17,946 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 186 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:17,958 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 187 is 678
2014-07-11 11:40:17,958 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 187 directly to driver
2014-07-11 11:40:17,958 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 187
2014-07-11 11:40:17,959 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(93, 1)
2014-07-11 11:40:17,958 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 187 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:40:17,959 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 93 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:40:17,959 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2014-07-11 11:40:17,959 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082467141 s
2014-07-11 11:40:17,964 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:17,965 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:17,965 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:17,965 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:17,966 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:17,967 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[378] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:17,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 94 (MappedRDD[378] at map at CalEigenVector.scala:38)
2014-07-11 11:40:17,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 2 tasks
2014-07-11 11:40:17,968 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 188 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,969 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2297 bytes in 1 ms
2014-07-11 11:40:17,969 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:1 as TID 189 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:17,969 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:17,970 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 189
2014-07-11 11:40:17,971 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,971 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 188
2014-07-11 11:40:17,971 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,972 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:17,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:17,973 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:17,973 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,034 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 189 is 678
2014-07-11 11:40:18,034 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 189 directly to driver
2014-07-11 11:40:18,034 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 189
2014-07-11 11:40:18,035 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 1)
2014-07-11 11:40:18,035 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 189 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,036 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 188 is 678
2014-07-11 11:40:18,036 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 188 directly to driver
2014-07-11 11:40:18,036 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 188
2014-07-11 11:40:18,036 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-11 11:40:18,036 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 188 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,037 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,037 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:40:18,037 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072335444 s
2014-07-11 11:40:18,042 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,042 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,042 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 95(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,042 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,044 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,044 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 95 (MappedRDD[382] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,045 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 95 (MappedRDD[382] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,045 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 95.0 with 2 tasks
2014-07-11 11:40:18,046 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 95.0:0 as TID 190 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,046 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 95.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:18,046 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 95.0:1 as TID 191 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,047 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 95.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,047 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 190
2014-07-11 11:40:18,048 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,048 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,049 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,049 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 191
2014-07-11 11:40:18,050 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,051 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,051 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,115 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 191 is 678
2014-07-11 11:40:18,115 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 191 directly to driver
2014-07-11 11:40:18,115 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 191
2014-07-11 11:40:18,115 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 191 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,115 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(95, 1)
2014-07-11 11:40:18,118 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 190 is 678
2014-07-11 11:40:18,118 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 190 directly to driver
2014-07-11 11:40:18,118 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 190
2014-07-11 11:40:18,119 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(95, 0)
2014-07-11 11:40:18,119 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 190 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,119 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 95.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,120 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 95 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:40:18,120 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077993883 s
2014-07-11 11:40:18,125 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,125 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,125 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,125 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[386] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,128 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 96 (MappedRDD[386] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,129 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 2 tasks
2014-07-11 11:40:18,129 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 192 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,129 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2298 bytes in 0 ms
2014-07-11 11:40:18,129 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:1 as TID 193 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,130 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:1 as 2298 bytes in 1 ms
2014-07-11 11:40:18,130 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 192
2014-07-11 11:40:18,131 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 193
2014-07-11 11:40:18,132 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,132 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,132 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,133 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,134 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,134 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,185 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 192 is 678
2014-07-11 11:40:18,185 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 192 directly to driver
2014-07-11 11:40:18,185 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 192
2014-07-11 11:40:18,186 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 192 in 57 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,186 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-11 11:40:18,187 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 193 is 678
2014-07-11 11:40:18,188 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 193 directly to driver
2014-07-11 11:40:18,188 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 193
2014-07-11 11:40:18,188 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 1)
2014-07-11 11:40:18,188 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 193 in 59 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,188 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,188 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at CalEigenVector.scala:38) finished in 0.059 s
2014-07-11 11:40:18,188 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.063804215 s
2014-07-11 11:40:18,194 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,194 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,194 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 97(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,194 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,196 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,196 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 97 (MappedRDD[390] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,197 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 97 (MappedRDD[390] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,197 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 97.0 with 2 tasks
2014-07-11 11:40:18,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 97.0:0 as TID 194 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 97.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:18,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 97.0:1 as TID 195 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 97.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,198 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 194
2014-07-11 11:40:18,199 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 195
2014-07-11 11:40:18,199 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,200 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,200 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,200 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,207 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,207 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,244 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 194 is 678
2014-07-11 11:40:18,244 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 194 directly to driver
2014-07-11 11:40:18,244 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 194
2014-07-11 11:40:18,245 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(97, 0)
2014-07-11 11:40:18,245 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 194 in 47 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,251 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 195 is 678
2014-07-11 11:40:18,251 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 195 directly to driver
2014-07-11 11:40:18,251 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 195
2014-07-11 11:40:18,252 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(97, 1)
2014-07-11 11:40:18,252 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 195 in 54 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,252 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 97.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,252 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 97 (reduce at CalEigenVector.scala:38) finished in 0.055 s
2014-07-11 11:40:18,252 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.058415199 s
2014-07-11 11:40:18,257 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,257 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,257 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,257 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,259 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,259 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[394] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,260 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 98 (MappedRDD[394] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,260 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 2 tasks
2014-07-11 11:40:18,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 196 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:18,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:1 as TID 197 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,262 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 196
2014-07-11 11:40:18,262 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,263 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 197
2014-07-11 11:40:18,263 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,263 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,264 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,264 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,265 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,320 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 196 is 678
2014-07-11 11:40:18,320 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 196 directly to driver
2014-07-11 11:40:18,320 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 196
2014-07-11 11:40:18,321 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-11 11:40:18,321 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 196 in 60 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,323 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 197 is 678
2014-07-11 11:40:18,323 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 197 directly to driver
2014-07-11 11:40:18,323 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 197
2014-07-11 11:40:18,324 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 1)
2014-07-11 11:40:18,324 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 197 in 62 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,324 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,324 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at CalEigenVector.scala:38) finished in 0.064 s
2014-07-11 11:40:18,324 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.067110917 s
2014-07-11 11:40:18,329 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,329 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,329 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 99(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,329 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,331 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,331 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 99 (MappedRDD[398] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,332 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 99 (MappedRDD[398] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,332 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 99.0 with 2 tasks
2014-07-11 11:40:18,333 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 99.0:0 as TID 198 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,333 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 99.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:18,333 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 99.0:1 as TID 199 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,334 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 99.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,334 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 198
2014-07-11 11:40:18,334 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 199
2014-07-11 11:40:18,335 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,335 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,336 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,336 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,344 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,345 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 199 is 678
2014-07-11 11:40:18,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 199 directly to driver
2014-07-11 11:40:18,402 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 199 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,402 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(99, 1)
2014-07-11 11:40:18,402 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 199
2014-07-11 11:40:18,404 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 198 is 678
2014-07-11 11:40:18,404 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 198 directly to driver
2014-07-11 11:40:18,404 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 198
2014-07-11 11:40:18,407 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 198 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,408 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,410 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(99, 0)
2014-07-11 11:40:18,410 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 99 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:40:18,411 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081962062 s
2014-07-11 11:40:18,417 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,421 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,421 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[402] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,422 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 100 (MappedRDD[402] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,422 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 2 tasks
2014-07-11 11:40:18,423 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 200 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,423 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:18,423 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:1 as TID 201 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,423 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:18,423 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 200
2014-07-11 11:40:18,424 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 201
2014-07-11 11:40:18,424 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,424 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,425 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,425 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,425 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,425 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,506 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 201 is 678
2014-07-11 11:40:18,506 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 201 directly to driver
2014-07-11 11:40:18,507 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 201
2014-07-11 11:40:18,507 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 201 in 84 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,507 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 1)
2014-07-11 11:40:18,523 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 200 is 678
2014-07-11 11:40:18,523 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 200 directly to driver
2014-07-11 11:40:18,523 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 200
2014-07-11 11:40:18,523 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-11 11:40:18,523 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 200 in 101 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,523 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,524 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at CalEigenVector.scala:38) finished in 0.101 s
2014-07-11 11:40:18,524 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.106751642 s
2014-07-11 11:40:18,530 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,531 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,531 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 101(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,531 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,532 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,533 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 101 (MappedRDD[406] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,534 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 101 (MappedRDD[406] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,534 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 101.0 with 2 tasks
2014-07-11 11:40:18,534 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 101.0:0 as TID 202 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,534 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 101.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:18,535 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 101.0:1 as TID 203 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,535 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 101.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:18,535 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 202
2014-07-11 11:40:18,536 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,537 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,537 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 203
2014-07-11 11:40:18,539 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,539 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,540 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,600 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 202 is 678
2014-07-11 11:40:18,600 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 202 directly to driver
2014-07-11 11:40:18,600 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 202
2014-07-11 11:40:18,601 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(101, 0)
2014-07-11 11:40:18,601 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 202 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 203 is 678
2014-07-11 11:40:18,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 203 directly to driver
2014-07-11 11:40:18,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 203
2014-07-11 11:40:18,605 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(101, 1)
2014-07-11 11:40:18,605 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 203 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,605 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 101.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,605 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 101 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:40:18,606 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075413008 s
2014-07-11 11:40:18,611 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,611 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,611 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,611 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,613 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,613 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[410] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,614 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 102 (MappedRDD[410] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,614 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 2 tasks
2014-07-11 11:40:18,614 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 204 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,615 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2296 bytes in 1 ms
2014-07-11 11:40:18,615 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:1 as TID 205 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,615 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:18,615 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 204
2014-07-11 11:40:18,616 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,617 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,617 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,619 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 205
2014-07-11 11:40:18,620 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,621 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,621 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 204 is 678
2014-07-11 11:40:18,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 204 directly to driver
2014-07-11 11:40:18,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 204
2014-07-11 11:40:18,679 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-11 11:40:18,679 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 204 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,684 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 205 is 678
2014-07-11 11:40:18,684 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 205 directly to driver
2014-07-11 11:40:18,684 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 205
2014-07-11 11:40:18,685 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 1)
2014-07-11 11:40:18,686 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:40:18,687 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076104641 s
2014-07-11 11:40:18,685 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 205 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,690 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,693 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,694 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,694 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 103(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,694 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,695 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,696 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 103 (MappedRDD[414] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,697 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 103 (MappedRDD[414] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,697 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 103.0 with 2 tasks
2014-07-11 11:40:18,697 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 103.0:0 as TID 206 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,698 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 103.0:0 as 2297 bytes in 1 ms
2014-07-11 11:40:18,698 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 103.0:1 as TID 207 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,698 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 103.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,698 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 206
2014-07-11 11:40:18,699 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 207
2014-07-11 11:40:18,699 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,699 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,700 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,700 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,700 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,700 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,760 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 206 is 678
2014-07-11 11:40:18,761 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 206 directly to driver
2014-07-11 11:40:18,761 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 206
2014-07-11 11:40:18,761 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 206 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,761 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(103, 0)
2014-07-11 11:40:18,763 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 207 is 678
2014-07-11 11:40:18,763 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 207 directly to driver
2014-07-11 11:40:18,763 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 207
2014-07-11 11:40:18,763 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(103, 1)
2014-07-11 11:40:18,763 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 207 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,764 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,764 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 103 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:40:18,764 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070910066 s
2014-07-11 11:40:18,769 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,769 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,769 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,769 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,771 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,771 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[418] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,772 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 104 (MappedRDD[418] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,772 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 2 tasks
2014-07-11 11:40:18,773 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 208 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,773 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:18,773 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:1 as TID 209 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,773 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:18,774 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 208
2014-07-11 11:40:18,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 209
2014-07-11 11:40:18,774 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,774 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,775 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,775 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,775 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,775 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,846 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 209 is 678
2014-07-11 11:40:18,846 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 209 directly to driver
2014-07-11 11:40:18,847 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 1)
2014-07-11 11:40:18,847 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 209 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,847 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 209
2014-07-11 11:40:18,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 208 is 678
2014-07-11 11:40:18,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 208 directly to driver
2014-07-11 11:40:18,848 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 208
2014-07-11 11:40:18,848 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-11 11:40:18,848 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 208 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,848 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,848 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:40:18,848 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079523681 s
2014-07-11 11:40:18,854 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,855 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,855 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 105(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,855 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,859 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,859 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 105 (MappedRDD[422] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,860 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 105 (MappedRDD[422] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,860 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 105.0 with 2 tasks
2014-07-11 11:40:18,861 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 105.0:0 as TID 210 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,861 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 105.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:18,861 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 105.0:1 as TID 211 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,861 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 105.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,865 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 211
2014-07-11 11:40:18,866 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,866 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 210
2014-07-11 11:40:18,867 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,867 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,868 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,868 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,868 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,928 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 211 is 678
2014-07-11 11:40:18,928 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 211 directly to driver
2014-07-11 11:40:18,928 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 210 is 678
2014-07-11 11:40:18,929 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 210 directly to driver
2014-07-11 11:40:18,929 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 210
2014-07-11 11:40:18,929 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 211 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:40:18,929 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(105, 1)
2014-07-11 11:40:18,929 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 210 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:40:18,929 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2014-07-11 11:40:18,929 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(105, 0)
2014-07-11 11:40:18,929 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 211
2014-07-11 11:40:18,930 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 105 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:40:18,930 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075696691 s
2014-07-11 11:40:18,939 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:18,940 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:18,940 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:18,940 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:18,943 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:18,943 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[426] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:18,944 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 106 (MappedRDD[426] at map at CalEigenVector.scala:38)
2014-07-11 11:40:18,944 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 2 tasks
2014-07-11 11:40:18,945 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 212 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,945 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:18,945 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:1 as TID 213 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:18,945 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:18,946 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 212
2014-07-11 11:40:18,946 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 213
2014-07-11 11:40:18,946 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,946 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:18,947 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,947 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:18,947 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:18,947 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,006 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 213 is 678
2014-07-11 11:40:19,006 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 213 directly to driver
2014-07-11 11:40:19,007 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 212 is 678
2014-07-11 11:40:19,007 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 212 directly to driver
2014-07-11 11:40:19,007 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 212
2014-07-11 11:40:19,007 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 213
2014-07-11 11:40:19,007 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 213 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,007 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 1)
2014-07-11 11:40:19,007 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 212 in 62 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,008 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-11 11:40:19,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at CalEigenVector.scala:38) finished in 0.064 s
2014-07-11 11:40:19,008 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.068734683 s
2014-07-11 11:40:19,013 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,013 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,013 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 107(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,013 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 107 (MappedRDD[430] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,016 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 107 (MappedRDD[430] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,016 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 107.0 with 2 tasks
2014-07-11 11:40:19,016 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 107.0:0 as TID 214 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 107.0:0 as 2296 bytes in 1 ms
2014-07-11 11:40:19,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 107.0:1 as TID 215 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 107.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:19,017 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 214
2014-07-11 11:40:19,017 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 215
2014-07-11 11:40:19,018 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,018 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,019 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,019 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,019 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,019 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 215 is 678
2014-07-11 11:40:19,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 215 directly to driver
2014-07-11 11:40:19,076 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 215 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,077 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(107, 1)
2014-07-11 11:40:19,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 215
2014-07-11 11:40:19,082 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 214 is 678
2014-07-11 11:40:19,082 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 214 directly to driver
2014-07-11 11:40:19,083 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 214
2014-07-11 11:40:19,083 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(107, 0)
2014-07-11 11:40:19,083 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 107 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:40:19,083 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 214 in 67 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,084 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 107.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,084 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070954913 s
2014-07-11 11:40:19,088 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,089 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,089 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,089 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,090 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,090 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[434] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,092 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 108 (MappedRDD[434] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,092 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 2 tasks
2014-07-11 11:40:19,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 216 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:1 as TID 217 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,093 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,093 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 216
2014-07-11 11:40:19,094 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,095 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,095 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,097 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 217
2014-07-11 11:40:19,098 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,099 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,099 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,150 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 216 is 678
2014-07-11 11:40:19,150 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 216 directly to driver
2014-07-11 11:40:19,150 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 216
2014-07-11 11:40:19,152 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 216 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,152 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-11 11:40:19,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 217 is 678
2014-07-11 11:40:19,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 217 directly to driver
2014-07-11 11:40:19,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 217
2014-07-11 11:40:19,154 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 1)
2014-07-11 11:40:19,154 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 217 in 62 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,154 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,154 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:40:19,154 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.066005023 s
2014-07-11 11:40:19,159 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 109(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,161 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,161 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 109 (MappedRDD[438] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,162 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 109 (MappedRDD[438] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,162 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 109.0 with 2 tasks
2014-07-11 11:40:19,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 109.0:0 as TID 218 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 109.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:19,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 109.0:1 as TID 219 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 109.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:19,166 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 219
2014-07-11 11:40:19,167 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,167 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,167 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 218
2014-07-11 11:40:19,173 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,174 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,174 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,213 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 219 is 678
2014-07-11 11:40:19,213 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 219 directly to driver
2014-07-11 11:40:19,214 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 219
2014-07-11 11:40:19,214 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(109, 1)
2014-07-11 11:40:19,214 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 219 in 51 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,226 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 218 is 678
2014-07-11 11:40:19,226 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 218 directly to driver
2014-07-11 11:40:19,226 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 218
2014-07-11 11:40:19,227 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 218 in 63 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,227 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,227 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(109, 0)
2014-07-11 11:40:19,227 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 109 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:40:19,227 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.068146439 s
2014-07-11 11:40:19,232 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,234 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,234 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[442] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,235 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 110 (MappedRDD[442] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,235 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 2 tasks
2014-07-11 11:40:19,236 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 220 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,236 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,236 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:1 as TID 221 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,236 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,236 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 220
2014-07-11 11:40:19,237 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 221
2014-07-11 11:40:19,237 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,238 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,238 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,242 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,243 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,243 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,292 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 221 is 678
2014-07-11 11:40:19,292 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 221 directly to driver
2014-07-11 11:40:19,293 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 221
2014-07-11 11:40:19,293 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 221 in 56 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,293 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 1)
2014-07-11 11:40:19,295 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 220 is 678
2014-07-11 11:40:19,295 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 220 directly to driver
2014-07-11 11:40:19,296 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 220
2014-07-11 11:40:19,296 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 220 in 60 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,296 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,296 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-11 11:40:19,296 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at CalEigenVector.scala:38) finished in 0.061 s
2014-07-11 11:40:19,297 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.06481141 s
2014-07-11 11:40:19,301 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,302 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,302 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 111(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,302 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,304 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,305 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 111 (MappedRDD[446] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,306 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 111 (MappedRDD[446] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,306 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 111.0 with 2 tasks
2014-07-11 11:40:19,306 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 111.0:0 as TID 222 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,306 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 111.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:19,307 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 111.0:1 as TID 223 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,307 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 111.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:19,307 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 222
2014-07-11 11:40:19,307 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 223
2014-07-11 11:40:19,308 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,308 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,309 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,309 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,309 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,309 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,368 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 223 is 678
2014-07-11 11:40:19,368 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 223 directly to driver
2014-07-11 11:40:19,369 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 223 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,369 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 222 is 678
2014-07-11 11:40:19,369 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 222 directly to driver
2014-07-11 11:40:19,369 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(111, 1)
2014-07-11 11:40:19,370 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 222
2014-07-11 11:40:19,370 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 222 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,370 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,370 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(111, 0)
2014-07-11 11:40:19,370 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 111 (reduce at CalEigenVector.scala:38) finished in 0.064 s
2014-07-11 11:40:19,371 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069087784 s
2014-07-11 11:40:19,371 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 223
2014-07-11 11:40:19,376 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,376 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,376 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,376 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,378 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,379 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[450] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,380 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 112 (MappedRDD[450] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,380 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 2 tasks
2014-07-11 11:40:19,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 224 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:1 as TID 225 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,382 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 224
2014-07-11 11:40:19,382 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,383 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,383 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,390 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 225
2014-07-11 11:40:19,391 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,392 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,392 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 224 is 678
2014-07-11 11:40:19,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 224 directly to driver
2014-07-11 11:40:19,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 224
2014-07-11 11:40:19,442 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-11 11:40:19,442 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 224 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,464 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 225 is 678
2014-07-11 11:40:19,464 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 225 directly to driver
2014-07-11 11:40:19,464 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 225
2014-07-11 11:40:19,465 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 1)
2014-07-11 11:40:19,465 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at CalEigenVector.scala:38) finished in 0.085 s
2014-07-11 11:40:19,465 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 225 in 84 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,465 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,465 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089429821 s
2014-07-11 11:40:19,470 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 113(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,472 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,473 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 113 (MappedRDD[454] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,474 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 113 (MappedRDD[454] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,474 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 113.0 with 2 tasks
2014-07-11 11:40:19,474 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 113.0:0 as TID 226 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,475 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 113.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,477 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 113.0:1 as TID 227 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,477 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 113.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,477 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 227
2014-07-11 11:40:19,477 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 226
2014-07-11 11:40:19,478 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,478 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,479 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,479 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,479 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,479 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,555 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 227 is 678
2014-07-11 11:40:19,555 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 227 directly to driver
2014-07-11 11:40:19,555 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 227
2014-07-11 11:40:19,556 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 227 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,556 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(113, 1)
2014-07-11 11:40:19,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 226 is 678
2014-07-11 11:40:19,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 226 directly to driver
2014-07-11 11:40:19,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 226
2014-07-11 11:40:19,557 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(113, 0)
2014-07-11 11:40:19,557 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 226 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,557 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 113.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,557 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 113 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:40:19,557 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086937853 s
2014-07-11 11:40:19,562 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,562 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,563 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,563 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,564 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,564 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[458] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,568 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 114 (MappedRDD[458] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,568 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 2 tasks
2014-07-11 11:40:19,569 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 228 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,569 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,569 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:1 as TID 229 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,569 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,570 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 228
2014-07-11 11:40:19,570 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 229
2014-07-11 11:40:19,571 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,571 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,572 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,572 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,572 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,572 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,627 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 229 is 678
2014-07-11 11:40:19,627 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 229 directly to driver
2014-07-11 11:40:19,628 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 229 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,628 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 1)
2014-07-11 11:40:19,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 229
2014-07-11 11:40:19,629 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 228 is 678
2014-07-11 11:40:19,629 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 228 directly to driver
2014-07-11 11:40:19,630 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 228
2014-07-11 11:40:19,630 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 228 in 61 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,630 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,630 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-11 11:40:19,631 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:40:19,631 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069010111 s
2014-07-11 11:40:19,636 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,637 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,637 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 115(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,637 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,638 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,639 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 115 (MappedRDD[462] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,640 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 115 (MappedRDD[462] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,640 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 115.0 with 2 tasks
2014-07-11 11:40:19,640 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 115.0:0 as TID 230 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,640 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 115.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,641 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 115.0:1 as TID 231 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,641 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 115.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,641 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 230
2014-07-11 11:40:19,642 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,643 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,643 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,647 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 231
2014-07-11 11:40:19,648 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,698 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 230 is 678
2014-07-11 11:40:19,698 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 230 directly to driver
2014-07-11 11:40:19,699 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 230 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,699 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(115, 0)
2014-07-11 11:40:19,699 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 230
2014-07-11 11:40:19,705 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 231 is 678
2014-07-11 11:40:19,705 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 231 directly to driver
2014-07-11 11:40:19,705 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 231
2014-07-11 11:40:19,706 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(115, 1)
2014-07-11 11:40:19,706 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 115 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:40:19,706 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 231 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,706 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,706 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069441767 s
2014-07-11 11:40:19,710 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,711 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,711 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,711 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,713 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,713 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[466] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,715 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 116 (MappedRDD[466] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,715 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 2 tasks
2014-07-11 11:40:19,715 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 232 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:1 as TID 233 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 232
2014-07-11 11:40:19,717 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 233
2014-07-11 11:40:19,718 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,718 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,718 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,718 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,718 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,718 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 233 is 678
2014-07-11 11:40:19,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 233 directly to driver
2014-07-11 11:40:19,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 233
2014-07-11 11:40:19,775 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 233 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,775 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 1)
2014-07-11 11:40:19,777 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 232 is 678
2014-07-11 11:40:19,777 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 232 directly to driver
2014-07-11 11:40:19,777 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 232
2014-07-11 11:40:19,779 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 232 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,779 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,780 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-11 11:40:19,780 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:40:19,780 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069429349 s
2014-07-11 11:40:19,785 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,786 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,786 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 117(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,786 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,788 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,788 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 117 (MappedRDD[470] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,789 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 117 (MappedRDD[470] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,789 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 117.0 with 2 tasks
2014-07-11 11:40:19,790 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 117.0:0 as TID 234 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,790 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 117.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,790 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 117.0:1 as TID 235 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,790 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 117.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,791 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 234
2014-07-11 11:40:19,792 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,792 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,792 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,794 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 235
2014-07-11 11:40:19,795 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,796 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,796 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 234 is 678
2014-07-11 11:40:19,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 234 directly to driver
2014-07-11 11:40:19,848 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 234 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,848 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(117, 0)
2014-07-11 11:40:19,849 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 234
2014-07-11 11:40:19,854 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 235 is 678
2014-07-11 11:40:19,854 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 235 directly to driver
2014-07-11 11:40:19,854 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 235
2014-07-11 11:40:19,855 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(117, 1)
2014-07-11 11:40:19,855 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 117 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:40:19,855 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 235 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,855 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,855 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070335212 s
2014-07-11 11:40:19,860 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,861 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,861 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,861 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,867 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,868 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[474] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,869 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 118 (MappedRDD[474] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,869 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 2 tasks
2014-07-11 11:40:19,869 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 236 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,870 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:19,870 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:1 as TID 237 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,870 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:19,870 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 236
2014-07-11 11:40:19,871 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 237
2014-07-11 11:40:19,871 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,872 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,872 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,875 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,876 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,876 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,930 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 236 is 678
2014-07-11 11:40:19,930 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 236 directly to driver
2014-07-11 11:40:19,931 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 236
2014-07-11 11:40:19,931 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 236 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:40:19,931 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-11 11:40:19,935 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 237 is 678
2014-07-11 11:40:19,935 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 237 directly to driver
2014-07-11 11:40:19,935 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 237
2014-07-11 11:40:19,936 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 1)
2014-07-11 11:40:19,936 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:40:19,936 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 237 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:40:19,936 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-11 11:40:19,936 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.0759862 s
2014-07-11 11:40:19,941 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:19,941 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:19,941 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 119(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:19,942 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:19,943 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:19,943 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 119 (MappedRDD[478] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:19,944 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 119 (MappedRDD[478] at map at CalEigenVector.scala:38)
2014-07-11 11:40:19,944 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 119.0 with 2 tasks
2014-07-11 11:40:19,945 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 119.0:0 as TID 238 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,945 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 119.0:0 as 2297 bytes in 0 ms
2014-07-11 11:40:19,945 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 119.0:1 as TID 239 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:19,945 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 119.0:1 as 2297 bytes in 0 ms
2014-07-11 11:40:19,945 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 238
2014-07-11 11:40:19,946 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,947 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 239
2014-07-11 11:40:19,947 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,947 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:19,948 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:19,949 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:19,949 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:20,001 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 238 is 678
2014-07-11 11:40:20,001 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 238 directly to driver
2014-07-11 11:40:20,002 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 238
2014-07-11 11:40:20,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(119, 0)
2014-07-11 11:40:20,002 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 238 in 57 ms on localhost (progress: 1/2)
2014-07-11 11:40:20,003 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 239 is 678
2014-07-11 11:40:20,003 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 239 directly to driver
2014-07-11 11:40:20,003 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 239
2014-07-11 11:40:20,004 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(119, 1)
2014-07-11 11:40:20,004 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 239 in 59 ms on localhost (progress: 2/2)
2014-07-11 11:40:20,004 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 119.0, whose tasks have all completed, from pool 
2014-07-11 11:40:20,004 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 119 (reduce at CalEigenVector.scala:38) finished in 0.060 s
2014-07-11 11:40:20,004 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.06322608 s
2014-07-11 11:40:20,009 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:20,009 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:20,009 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:20,009 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:20,011 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:20,011 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[482] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:20,012 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 120 (MappedRDD[482] at map at CalEigenVector.scala:38)
2014-07-11 11:40:20,012 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 2 tasks
2014-07-11 11:40:20,013 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 240 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:20,013 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:20,013 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:1 as TID 241 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:20,013 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:20,013 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 240
2014-07-11 11:40:20,014 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 241
2014-07-11 11:40:20,014 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:20,015 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:20,015 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:20,015 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:20,016 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:20,016 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:20,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 241 is 678
2014-07-11 11:40:20,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 241 directly to driver
2014-07-11 11:40:20,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 241
2014-07-11 11:40:20,064 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 1)
2014-07-11 11:40:20,064 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 241 in 51 ms on localhost (progress: 1/2)
2014-07-11 11:40:20,066 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 240 is 678
2014-07-11 11:40:20,066 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 240 directly to driver
2014-07-11 11:40:20,066 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 240 in 53 ms on localhost (progress: 2/2)
2014-07-11 11:40:20,067 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-11 11:40:20,067 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-11 11:40:20,068 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at CalEigenVector.scala:38) finished in 0.055 s
2014-07-11 11:40:20,068 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.059263626 s
2014-07-11 11:40:20,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 240
2014-07-11 11:40:20,075 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:40:20,076 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:40:20,076 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 121(reduce at CalEigenVector.scala:38)
2014-07-11 11:40:20,076 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:40:20,077 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:40:20,077 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 121 (MappedRDD[486] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:40:20,079 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 121 (MappedRDD[486] at map at CalEigenVector.scala:38)
2014-07-11 11:40:20,079 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 121.0 with 2 tasks
2014-07-11 11:40:20,079 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 121.0:0 as TID 242 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:20,080 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 121.0:0 as 2296 bytes in 0 ms
2014-07-11 11:40:20,080 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 121.0:1 as TID 243 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:40:20,080 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 121.0:1 as 2296 bytes in 0 ms
2014-07-11 11:40:20,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 243
2014-07-11 11:40:20,081 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:20,082 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:20,082 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:40:20,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 242
2014-07-11 11:40:20,091 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:40:20,092 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:20,092 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:40:20,135 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 243 is 678
2014-07-11 11:40:20,135 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 242 is 678
2014-07-11 11:40:20,135 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 243 directly to driver
2014-07-11 11:40:20,135 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 242 directly to driver
2014-07-11 11:40:20,135 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 242
2014-07-11 11:40:20,136 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 243 in 56 ms on localhost (progress: 1/2)
2014-07-11 11:40:20,136 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 242 in 57 ms on localhost (progress: 2/2)
2014-07-11 11:40:20,136 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 121.0, whose tasks have all completed, from pool 
2014-07-11 11:40:20,136 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(121, 1)
2014-07-11 11:40:20,135 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 243
2014-07-11 11:40:20,137 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(121, 0)
2014-07-11 11:40:20,137 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 121 (reduce at CalEigenVector.scala:38) finished in 0.055 s
2014-07-11 11:40:20,137 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.06213446 s
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/static,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2014-07-11 11:40:20,232 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2014-07-11 11:40:20,233 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages,null}
2014-07-11 11:40:20,286 [main] INFO  [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://10.74.147.155:4040
2014-07-11 11:40:20,287 [main] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stopping DAGScheduler
2014-07-11 11:40:21,342 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.MapOutputTrackerMasterActor] - MapOutputTrackerActor stopped!
2014-07-11 11:40:21,396 [connection-manager-thread] INFO  [org.apache.spark.network.ConnectionManager] - Selector thread was interrupted!
2014-07-11 11:40:21,396 [main] INFO  [org.apache.spark.network.ConnectionManager] - ConnectionManager stopped
2014-07-11 11:40:21,398 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore cleared
2014-07-11 11:40:21,399 [main] INFO  [org.apache.spark.storage.BlockManager] - BlockManager stopped
2014-07-11 11:40:21,400 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.storage.BlockManagerMasterActor] - Stopping BlockManagerMaster
2014-07-11 11:40:21,400 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2014-07-11 11:40:21,406 [spark-akka.actor.default-dispatcher-3] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Shutting down remote daemon.
2014-07-11 11:40:21,406 [main] INFO  [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2014-07-11 11:40:21,409 [spark-akka.actor.default-dispatcher-3] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Remote daemon shut down; proceeding with flushing remote transports.
2014-07-11 11:45:19,869 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.155 instead (on interface eth0)
2014-07-11 11:45:19,870 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-11 11:45:19,931 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-11 11:45:19,932 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-11 11:45:20,399 [spark-akka.actor.default-dispatcher-4] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-11 11:45:20,463 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Starting remoting
2014-07-11 11:45:20,632 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.155:47212]
2014-07-11 11:45:20,634 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.155:47212]
2014-07-11 11:45:20,661 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-11 11:45:20,665 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-11 11:45:20,678 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140711114520-e007
2014-07-11 11:45:20,682 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-11 11:45:20,711 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 39245 with id = ConnectionManagerId(10.74.147.155,39245)
2014-07-11 11:45:20,716 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-11 11:45:20,718 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.155:39245 with 1056.0 MB RAM
2014-07-11 11:45:20,719 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-11 11:45:20,735 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-11 11:45:20,851 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:45:20,872 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:46740
2014-07-11 11:45:20,873 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.155:46740
2014-07-11 11:45:20,880 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-96656bb7-4fc1-4a76-9a9a-42c8b10bfb15
2014-07-11 11:45:20,880 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-11 11:45:20,881 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:45:20,883 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:41905
2014-07-11 11:45:21,220 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:45:21,233 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-11 11:45:21,234 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.155:4040
2014-07-11 11:45:21,753 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-11 11:45:21,754 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-11 11:45:21,837 [main] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-11 11:45:21,837 [main] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-11 11:45:21,845 [main] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-11 11:45:21,854 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at CalEigenVector.scala:31
2014-07-11 11:45:21,866 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at CalEigenVector.scala:31) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:21,866 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at CalEigenVector.scala:31)
2014-07-11 11:45:21,867 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:21,871 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:21,876 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[2] at map at CalEigenVector.scala:25), which has no missing parents
2014-07-11 11:45:21,945 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 0 (MappedRDD[2] at map at CalEigenVector.scala:25)
2014-07-11 11:45:21,946 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2014-07-11 11:45:21,976 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:21,979 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 1797 bytes in 2 ms
2014-07-11 11:45:21,982 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:21,983 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:1 as 1797 bytes in 0 ms
2014-07-11 11:45:21,989 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-11 11:45:21,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-11 11:45:22,007 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:22,009 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:22,015 [Executor task launch worker-0] INFO  [org.apache.spark.CacheManager] - Partition rdd_2_0 not found, computing it
2014-07-11 11:45:22,015 [Executor task launch worker-1] INFO  [org.apache.spark.CacheManager] - Partition rdd_2_1 not found, computing it
2014-07-11 11:45:22,018 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-11 11:45:22,018 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-11 11:45:23,565 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85249276) called with curMem=32856, maxMem=1107296256
2014-07-11 11:45:23,567 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_2_0 stored as values to memory (estimated size 81.3 MB, free 974.7 MB)
2014-07-11 11:45:23,570 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_2_0 in memory on 10.74.147.155:39245 (size: 81.3 MB, free: 974.7 MB)
2014-07-11 11:45:23,571 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_2_0
2014-07-11 11:45:23,599 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85228305) called with curMem=85282132, maxMem=1107296256
2014-07-11 11:45:23,600 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_2_1 stored as values to memory (estimated size 81.3 MB, free 893.4 MB)
2014-07-11 11:45:23,600 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_2_1 in memory on 10.74.147.155:39245 (size: 81.3 MB, free: 893.4 MB)
2014-07-11 11:45:23,601 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_2_1
2014-07-11 11:45:23,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 1174
2014-07-11 11:45:23,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-11 11:45:23,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-11 11:45:23,608 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 1174
2014-07-11 11:45:23,608 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-11 11:45:23,608 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-11 11:45:23,616 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-11 11:45:23,618 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 1639 ms on localhost (progress: 1/2)
2014-07-11 11:45:23,619 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 1)
2014-07-11 11:45:23,619 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at CalEigenVector.scala:31) finished in 1.655 s
2014-07-11 11:45:23,630 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at CalEigenVector.scala:31, took 1.77553764 s
2014-07-11 11:45:23,633 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 1637 ms on localhost (progress: 2/2)
2014-07-11 11:45:23,634 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-11 11:45:23,672 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:23,674 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:23,674 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 1(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:23,674 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:23,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:23,678 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MappedRDD[6] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:23,691 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MappedRDD[6] at map at CalEigenVector.scala:38)
2014-07-11 11:45:23,691 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-11 11:45:23,693 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:23,694 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2291 bytes in 0 ms
2014-07-11 11:45:23,694 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:23,695 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2291 bytes in 0 ms
2014-07-11 11:45:23,695 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-11 11:45:23,695 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-11 11:45:23,698 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:23,700 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:23,711 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:23,711 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:23,714 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:23,715 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:23,892 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 678
2014-07-11 11:45:23,892 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-11 11:45:23,892 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-11 11:45:23,896 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(1, 1)
2014-07-11 11:45:23,896 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 201 ms on localhost (progress: 1/2)
2014-07-11 11:45:23,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 678
2014-07-11 11:45:23,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-11 11:45:23,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-11 11:45:23,905 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(1, 0)
2014-07-11 11:45:23,905 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 212 ms on localhost (progress: 2/2)
2014-07-11 11:45:23,905 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-11 11:45:23,906 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (reduce at CalEigenVector.scala:38) finished in 0.213 s
2014-07-11 11:45:23,906 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.233322568 s
2014-07-11 11:45:23,914 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:23,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:23,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:23,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:23,917 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:23,918 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[10] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:23,921 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 2 (MappedRDD[10] at map at CalEigenVector.scala:38)
2014-07-11 11:45:23,922 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2014-07-11 11:45:23,923 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:23,923 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:23,924 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:1 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:23,924 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:23,925 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-11 11:45:23,928 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:23,930 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:23,931 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:23,932 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-11 11:45:23,935 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:23,937 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:23,937 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,015 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 678
2014-07-11 11:45:24,015 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-11 11:45:24,016 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-11 11:45:24,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-11 11:45:24,017 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 94 ms on localhost (progress: 1/2)
2014-07-11 11:45:24,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 678
2014-07-11 11:45:24,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-11 11:45:24,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-11 11:45:24,019 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 1)
2014-07-11 11:45:24,019 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 95 ms on localhost (progress: 2/2)
2014-07-11 11:45:24,020 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-11 11:45:24,020 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at CalEigenVector.scala:38) finished in 0.097 s
2014-07-11 11:45:24,020 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.106245015 s
2014-07-11 11:45:24,029 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:24,031 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:24,031 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 3(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:24,031 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:24,033 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:24,033 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 3 (MappedRDD[14] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:24,037 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 3 (MappedRDD[14] at map at CalEigenVector.scala:38)
2014-07-11 11:45:24,037 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2014-07-11 11:45:24,038 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,038 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 3.0:0 as 2291 bytes in 0 ms
2014-07-11 11:45:24,039 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0:1 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,039 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 3.0:1 as 2291 bytes in 0 ms
2014-07-11 11:45:24,040 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-11 11:45:24,042 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-11 11:45:24,044 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,045 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,047 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,047 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,048 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,048 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,366 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-11 11:45:24,366 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-11 11:45:24,368 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 329 ms on localhost (progress: 1/2)
2014-07-11 11:45:24,369 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(3, 1)
2014-07-11 11:45:24,369 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-11 11:45:24,371 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-11 11:45:24,371 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-11 11:45:24,371 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-11 11:45:24,372 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(3, 0)
2014-07-11 11:45:24,372 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 334 ms on localhost (progress: 2/2)
2014-07-11 11:45:24,372 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2014-07-11 11:45:24,373 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 3 (reduce at CalEigenVector.scala:38) finished in 0.335 s
2014-07-11 11:45:24,373 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.343329589 s
2014-07-11 11:45:24,380 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:24,381 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:24,381 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:24,381 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:24,383 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:24,384 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[18] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:24,387 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 4 (MappedRDD[18] at map at CalEigenVector.scala:38)
2014-07-11 11:45:24,387 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2014-07-11 11:45:24,388 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,388 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2292 bytes in 0 ms
2014-07-11 11:45:24,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:1 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:24,390 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-11 11:45:24,391 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-11 11:45:24,393 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,393 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,396 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,396 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,396 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,396 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,463 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-11 11:45:24,463 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-11 11:45:24,464 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-11 11:45:24,464 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 1)
2014-07-11 11:45:24,464 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:45:24,465 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-11 11:45:24,465 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-11 11:45:24,465 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-11 11:45:24,466 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-11 11:45:24,466 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:45:24,466 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:45:24,467 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-11 11:45:24,467 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086793729 s
2014-07-11 11:45:24,474 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:24,475 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:24,475 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 5(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:24,475 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:24,478 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:24,478 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 5 (MappedRDD[22] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:24,482 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 5 (MappedRDD[22] at map at CalEigenVector.scala:38)
2014-07-11 11:45:24,482 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2014-07-11 11:45:24,486 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,486 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 5.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:24,487 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0:1 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,488 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 5.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:24,488 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-11 11:45:24,488 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-11 11:45:24,491 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,494 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,494 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,499 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,502 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,502 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,562 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-11 11:45:24,563 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-11 11:45:24,563 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-11 11:45:24,564 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(5, 1)
2014-07-11 11:45:24,564 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:45:24,571 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-11 11:45:24,571 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-11 11:45:24,571 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-11 11:45:24,573 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(5, 0)
2014-07-11 11:45:24,573 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 89 ms on localhost (progress: 2/2)
2014-07-11 11:45:24,573 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2014-07-11 11:45:24,573 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 5 (reduce at CalEigenVector.scala:38) finished in 0.090 s
2014-07-11 11:45:24,573 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.099039796 s
2014-07-11 11:45:24,581 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:24,583 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:24,583 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:24,583 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:24,585 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:24,586 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[26] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:24,589 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 6 (MappedRDD[26] at map at CalEigenVector.scala:38)
2014-07-11 11:45:24,589 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2014-07-11 11:45:24,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2292 bytes in 1 ms
2014-07-11 11:45:24,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:1 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,592 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:1 as 2292 bytes in 1 ms
2014-07-11 11:45:24,593 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-11 11:45:24,594 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-11 11:45:24,595 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,597 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,598 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,598 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,599 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,600 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-11 11:45:24,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-11 11:45:24,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-11 11:45:24,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-11 11:45:24,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-11 11:45:24,669 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 1)
2014-07-11 11:45:24,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-11 11:45:24,669 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:45:24,671 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-11 11:45:24,671 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 80 ms on localhost (progress: 2/2)
2014-07-11 11:45:24,671 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-11 11:45:24,671 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (reduce at CalEigenVector.scala:38) finished in 0.081 s
2014-07-11 11:45:24,671 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089973031 s
2014-07-11 11:45:24,679 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:24,681 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:24,681 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 7(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:24,681 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:24,687 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:24,688 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 7 (MappedRDD[30] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:24,691 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 7 (MappedRDD[30] at map at CalEigenVector.scala:38)
2014-07-11 11:45:24,691 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2014-07-11 11:45:24,692 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,692 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 7.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:24,693 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0:1 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:24,693 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 7.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:24,694 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-11 11:45:24,695 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-11 11:45:24,697 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,701 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:24,704 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,704 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:24,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:24,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,009 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-11 11:45:25,009 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-11 11:45:25,009 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-11 11:45:25,010 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(7, 1)
2014-07-11 11:45:25,010 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 318 ms on localhost (progress: 1/2)
2014-07-11 11:45:25,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-11 11:45:25,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-11 11:45:25,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-11 11:45:25,013 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(7, 0)
2014-07-11 11:45:25,013 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 321 ms on localhost (progress: 2/2)
2014-07-11 11:45:25,013 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2014-07-11 11:45:25,013 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 7 (reduce at CalEigenVector.scala:38) finished in 0.310 s
2014-07-11 11:45:25,013 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.334541885 s
2014-07-11 11:45:25,021 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:25,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:25,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:25,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:25,024 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:25,025 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[34] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:25,028 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 8 (MappedRDD[34] at map at CalEigenVector.scala:38)
2014-07-11 11:45:25,028 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2014-07-11 11:45:25,029 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,029 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:25,030 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:1 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,030 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:25,031 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-11 11:45:25,031 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-11 11:45:25,033 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,034 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,035 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,035 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,037 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,037 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,100 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-11 11:45:25,100 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-11 11:45:25,100 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-11 11:45:25,101 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-11 11:45:25,101 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:25,103 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-11 11:45:25,103 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-11 11:45:25,103 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-11 11:45:25,105 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 1)
2014-07-11 11:45:25,105 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:25,105 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-11 11:45:25,105 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:45:25,106 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.084592816 s
2014-07-11 11:45:25,113 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:25,116 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:25,116 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 9(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:25,116 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:25,123 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:25,123 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 9 (MappedRDD[38] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:25,126 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 9 (MappedRDD[38] at map at CalEigenVector.scala:38)
2014-07-11 11:45:25,126 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2014-07-11 11:45:25,127 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,128 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 9.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:25,128 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0:1 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,129 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 9.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:25,129 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-11 11:45:25,130 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-11 11:45:25,131 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,132 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,134 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,134 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,140 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,142 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,198 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-11 11:45:25,198 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-11 11:45:25,198 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-11 11:45:25,200 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:25,201 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(9, 1)
2014-07-11 11:45:25,233 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-11 11:45:25,233 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-11 11:45:25,235 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 107 ms on localhost (progress: 2/2)
2014-07-11 11:45:25,235 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2014-07-11 11:45:25,235 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(9, 0)
2014-07-11 11:45:25,235 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 9 (reduce at CalEigenVector.scala:38) finished in 0.108 s
2014-07-11 11:45:25,236 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.122891378 s
2014-07-11 11:45:25,237 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-11 11:45:25,243 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:25,244 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:25,244 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:25,244 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:25,247 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:25,248 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[42] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:25,251 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 10 (MappedRDD[42] at map at CalEigenVector.scala:38)
2014-07-11 11:45:25,252 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 2 tasks
2014-07-11 11:45:25,253 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,253 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2292 bytes in 0 ms
2014-07-11 11:45:25,253 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:1 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,254 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:25,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-11 11:45:25,255 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-11 11:45:25,257 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,257 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,262 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,262 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,262 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,263 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,382 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-11 11:45:25,383 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-11 11:45:25,383 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-11 11:45:25,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-11 11:45:25,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-11 11:45:25,384 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-11 11:45:25,384 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-11 11:45:25,384 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 132 ms on localhost (progress: 1/2)
2014-07-11 11:45:25,386 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 1)
2014-07-11 11:45:25,386 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 132 ms on localhost (progress: 2/2)
2014-07-11 11:45:25,386 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-11 11:45:25,386 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at CalEigenVector.scala:38) finished in 0.129 s
2014-07-11 11:45:25,386 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.143209727 s
2014-07-11 11:45:25,396 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:25,397 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:25,397 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 11(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:25,397 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:25,401 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:25,402 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 11 (MappedRDD[46] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:25,405 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 11 (MappedRDD[46] at map at CalEigenVector.scala:38)
2014-07-11 11:45:25,405 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2014-07-11 11:45:25,406 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 11.0:0 as 2292 bytes in 1 ms
2014-07-11 11:45:25,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0:1 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 11.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:25,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-11 11:45:25,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-11 11:45:25,410 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,411 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,414 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,414 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,418 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,421 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,493 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-11 11:45:25,493 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-11 11:45:25,494 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-11 11:45:25,494 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 87 ms on localhost (progress: 1/2)
2014-07-11 11:45:25,494 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(11, 1)
2014-07-11 11:45:25,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-11 11:45:25,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-11 11:45:25,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-11 11:45:25,514 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(11, 0)
2014-07-11 11:45:25,514 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 108 ms on localhost (progress: 2/2)
2014-07-11 11:45:25,514 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2014-07-11 11:45:25,514 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 11 (reduce at CalEigenVector.scala:38) finished in 0.106 s
2014-07-11 11:45:25,515 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.118654885 s
2014-07-11 11:45:25,522 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:25,523 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:25,523 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:25,523 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:25,527 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:25,527 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[50] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:25,530 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 12 (MappedRDD[50] at map at CalEigenVector.scala:38)
2014-07-11 11:45:25,530 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2014-07-11 11:45:25,531 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,532 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2290 bytes in 0 ms
2014-07-11 11:45:25,532 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:1 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,533 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:1 as 2290 bytes in 0 ms
2014-07-11 11:45:25,537 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-11 11:45:25,539 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,541 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,542 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,543 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-11 11:45:25,545 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,549 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,549 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,650 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-11 11:45:25,652 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-11 11:45:25,652 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-11 11:45:25,652 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-11 11:45:25,652 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-11 11:45:25,655 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-11 11:45:25,656 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-11 11:45:25,659 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 123 ms on localhost (progress: 1/2)
2014-07-11 11:45:25,659 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 127 ms on localhost (progress: 2/2)
2014-07-11 11:45:25,659 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-11 11:45:25,660 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 1)
2014-07-11 11:45:25,660 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at CalEigenVector.scala:38) finished in 0.105 s
2014-07-11 11:45:25,660 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.137970092 s
2014-07-11 11:45:25,667 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:25,668 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:25,669 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 13(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:25,669 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:25,671 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:25,672 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 13 (MappedRDD[54] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:25,675 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 13 (MappedRDD[54] at map at CalEigenVector.scala:38)
2014-07-11 11:45:25,675 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2014-07-11 11:45:25,676 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 13.0:0 as 2292 bytes in 0 ms
2014-07-11 11:45:25,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0:1 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:25,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 13.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:25,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-11 11:45:25,680 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,682 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,682 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:25,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-11 11:45:25,687 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:25,689 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:25,689 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,123 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-11 11:45:27,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-11 11:45:27,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-11 11:45:27,125 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 1449 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,126 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(13, 0)
2014-07-11 11:45:27,127 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-11 11:45:27,127 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-11 11:45:27,128 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-11 11:45:27,128 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(13, 1)
2014-07-11 11:45:27,128 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 1451 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,128 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,128 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 13 (reduce at CalEigenVector.scala:38) finished in 1.433 s
2014-07-11 11:45:27,129 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 1.461814844 s
2014-07-11 11:45:27,137 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,138 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,138 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,138 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,140 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,141 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[58] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,144 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 14 (MappedRDD[58] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,144 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2014-07-11 11:45:27,145 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,146 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:27,146 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:1 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,146 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:27,147 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-11 11:45:27,147 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-11 11:45:27,149 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,149 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,151 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,152 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,156 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,157 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,225 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-11 11:45:27,225 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-11 11:45:27,227 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,228 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-11 11:45:27,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-11 11:45:27,247 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-11 11:45:27,247 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-11 11:45:27,249 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 102 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,249 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,249 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 1)
2014-07-11 11:45:27,249 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at CalEigenVector.scala:38) finished in 0.104 s
2014-07-11 11:45:27,250 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.11307189 s
2014-07-11 11:45:27,259 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-11 11:45:27,259 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,260 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,260 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 15(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,260 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,263 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,263 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 15 (MappedRDD[62] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,266 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 15 (MappedRDD[62] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,267 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2014-07-11 11:45:27,267 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,268 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 15.0:0 as 2294 bytes in 1 ms
2014-07-11 11:45:27,268 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0:1 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,269 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 15.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:27,269 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-11 11:45:27,271 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-11 11:45:27,271 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,272 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,274 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,274 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,275 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,275 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-11 11:45:27,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-11 11:45:27,340 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-11 11:45:27,341 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,341 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(15, 0)
2014-07-11 11:45:27,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-11 11:45:27,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-11 11:45:27,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-11 11:45:27,343 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,344 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,344 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(15, 1)
2014-07-11 11:45:27,344 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 15 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:45:27,345 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085276309 s
2014-07-11 11:45:27,351 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,352 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,352 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,352 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,355 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,355 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[66] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,358 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 16 (MappedRDD[66] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,358 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2014-07-11 11:45:27,359 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,359 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:27,359 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:1 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,360 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:1 as 2294 bytes in 1 ms
2014-07-11 11:45:27,360 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-11 11:45:27,361 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-11 11:45:27,362 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,362 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,364 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,364 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,364 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,364 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,434 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-11 11:45:27,434 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-11 11:45:27,434 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-11 11:45:27,435 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-11 11:45:27,435 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,436 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-11 11:45:27,436 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-11 11:45:27,436 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-11 11:45:27,437 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 1)
2014-07-11 11:45:27,437 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,437 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,437 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:45:27,438 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086423662 s
2014-07-11 11:45:27,444 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,446 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,447 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 17(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,447 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,452 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,452 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 17 (MappedRDD[70] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,455 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 17 (MappedRDD[70] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,455 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 17.0 with 2 tasks
2014-07-11 11:45:27,456 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,456 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 17.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:27,457 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0:1 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,457 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 17.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:27,457 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-11 11:45:27,458 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-11 11:45:27,459 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,462 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,462 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,462 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,465 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,465 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,534 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-11 11:45:27,534 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-11 11:45:27,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-11 11:45:27,536 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-11 11:45:27,536 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 79 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,536 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-11 11:45:27,536 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(17, 1)
2014-07-11 11:45:27,537 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,537 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,538 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(17, 0)
2014-07-11 11:45:27,538 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 17 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:45:27,536 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-11 11:45:27,539 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094515527 s
2014-07-11 11:45:27,545 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,546 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,546 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,546 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,549 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,550 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[74] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,553 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 18 (MappedRDD[74] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,553 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2014-07-11 11:45:27,554 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,555 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:27,555 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:1 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,555 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:27,556 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-11 11:45:27,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-11 11:45:27,558 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,560 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,560 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,560 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,628 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-11 11:45:27,629 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-11 11:45:27,630 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-11 11:45:27,630 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-11 11:45:27,630 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-11 11:45:27,630 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-11 11:45:27,631 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 1)
2014-07-11 11:45:27,631 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,632 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,632 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,632 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-11 11:45:27,633 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:45:27,633 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088175974 s
2014-07-11 11:45:27,640 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,641 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,641 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 19(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,641 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,643 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,644 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 19 (MappedRDD[78] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,646 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 19 (MappedRDD[78] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,646 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 19.0 with 2 tasks
2014-07-11 11:45:27,647 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,648 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 19.0:0 as 2292 bytes in 0 ms
2014-07-11 11:45:27,648 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0:1 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,648 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 19.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:27,649 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-11 11:45:27,649 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-11 11:45:27,651 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,651 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,653 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,653 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,653 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,653 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,723 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-11 11:45:27,723 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-11 11:45:27,724 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-11 11:45:27,724 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-11 11:45:27,724 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-11 11:45:27,725 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(19, 1)
2014-07-11 11:45:27,725 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 76 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-11 11:45:27,726 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(19, 0)
2014-07-11 11:45:27,726 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,726 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,726 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 19 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:45:27,726 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086691028 s
2014-07-11 11:45:27,732 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,733 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,734 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,734 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,735 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,736 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[82] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,739 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 20 (MappedRDD[82] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,739 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2014-07-11 11:45:27,740 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,740 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:27,741 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:1 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,741 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:27,741 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-11 11:45:27,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-11 11:45:27,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,744 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,745 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,745 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,745 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,746 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,809 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-11 11:45:27,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-11 11:45:27,809 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-11 11:45:27,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-11 11:45:27,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-11 11:45:27,811 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-11 11:45:27,811 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,811 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-11 11:45:27,811 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 1)
2014-07-11 11:45:27,811 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,811 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,811 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:27,812 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080123144 s
2014-07-11 11:45:27,818 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,819 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,819 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 21(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,819 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,824 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,824 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 21 (MappedRDD[86] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,827 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 21 (MappedRDD[86] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,827 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2014-07-11 11:45:27,828 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,828 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 21.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:27,829 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0:1 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,829 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 21.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:27,829 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-11 11:45:27,829 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-11 11:45:27,831 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,832 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,833 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,834 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,834 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,835 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,900 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-11 11:45:27,900 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-11 11:45:27,901 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-11 11:45:27,901 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(21, 1)
2014-07-11 11:45:27,901 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-11 11:45:27,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-11 11:45:27,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-11 11:45:27,905 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(21, 0)
2014-07-11 11:45:27,905 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,905 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,905 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 21 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:45:27,906 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.087818412 s
2014-07-11 11:45:27,911 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,912 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,912 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,912 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,914 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,914 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[90] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:27,917 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 22 (MappedRDD[90] at map at CalEigenVector.scala:38)
2014-07-11 11:45:27,917 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 2 tasks
2014-07-11 11:45:27,918 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,918 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:27,918 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:1 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:27,919 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:1 as 2294 bytes in 1 ms
2014-07-11 11:45:27,919 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-11 11:45:27,921 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-11 11:45:27,923 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,923 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:27,925 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,925 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,925 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:27,925 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:27,985 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-11 11:45:27,985 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-11 11:45:27,986 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-11 11:45:27,986 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-11 11:45:27,986 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:45:27,987 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-11 11:45:27,987 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-11 11:45:27,987 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-11 11:45:27,988 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:27,988 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-11 11:45:27,989 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 1)
2014-07-11 11:45:27,989 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:27,989 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078103485 s
2014-07-11 11:45:27,995 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:27,996 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:27,996 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 23(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:27,996 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:27,997 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:27,998 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 23 (MappedRDD[94] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,001 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 23 (MappedRDD[94] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,001 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 23.0 with 2 tasks
2014-07-11 11:45:28,002 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 23.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,003 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 23.0:0 as 2292 bytes in 1 ms
2014-07-11 11:45:28,003 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 23.0:1 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,003 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 23.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:28,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-11 11:45:28,006 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,008 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,008 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,011 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-11 11:45:28,013 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,014 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,015 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,076 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-11 11:45:28,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-11 11:45:28,076 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-11 11:45:28,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-11 11:45:28,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-11 11:45:28,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-11 11:45:28,077 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(23, 1)
2014-07-11 11:45:28,077 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,078 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(23, 0)
2014-07-11 11:45:28,078 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,078 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,078 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 23 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:45:28,078 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083557298 s
2014-07-11 11:45:28,084 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,085 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,085 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,085 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,087 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,087 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[98] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,090 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 24 (MappedRDD[98] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,090 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 2 tasks
2014-07-11 11:45:28,091 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,091 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2292 bytes in 0 ms
2014-07-11 11:45:28,091 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:1 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,092 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:1 as 2292 bytes in 1 ms
2014-07-11 11:45:28,092 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-11 11:45:28,094 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,096 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,097 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,101 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-11 11:45:28,103 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,105 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,106 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-11 11:45:28,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-11 11:45:28,154 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-11 11:45:28,154 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-11 11:45:28,154 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,163 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-11 11:45:28,163 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-11 11:45:28,164 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-11 11:45:28,164 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 1)
2014-07-11 11:45:28,164 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,164 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,164 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:28,164 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080423232 s
2014-07-11 11:45:28,170 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,171 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,171 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 25(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,171 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,172 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,173 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 25 (MappedRDD[102] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,175 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 25 (MappedRDD[102] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,175 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 25.0 with 2 tasks
2014-07-11 11:45:28,176 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 25.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,176 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 25.0:0 as 2291 bytes in 0 ms
2014-07-11 11:45:28,177 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 25.0:1 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,177 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 25.0:1 as 2291 bytes in 0 ms
2014-07-11 11:45:28,177 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-11 11:45:28,178 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-11 11:45:28,179 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,179 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,181 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,181 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,181 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,181 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-11 11:45:28,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-11 11:45:28,230 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-11 11:45:28,231 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(25, 1)
2014-07-11 11:45:28,231 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 53 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,231 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-11 11:45:28,231 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-11 11:45:28,231 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-11 11:45:28,232 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(25, 0)
2014-07-11 11:45:28,232 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 56 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,232 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,232 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 25 (reduce at CalEigenVector.scala:38) finished in 0.056 s
2014-07-11 11:45:28,232 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.062561166 s
2014-07-11 11:45:28,238 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,239 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,239 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,239 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,241 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,242 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[106] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,244 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 26 (MappedRDD[106] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,245 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2014-07-11 11:45:28,245 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,246 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2292 bytes in 1 ms
2014-07-11 11:45:28,246 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:1 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,246 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:28,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-11 11:45:28,248 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,250 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,251 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,251 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-11 11:45:28,253 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,255 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,255 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,334 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-11 11:45:28,334 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-11 11:45:28,334 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-11 11:45:28,335 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 89 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,335 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-11 11:45:28,335 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-11 11:45:28,335 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-11 11:45:28,335 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 1)
2014-07-11 11:45:28,336 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-11 11:45:28,336 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 91 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,336 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,336 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at CalEigenVector.scala:38) finished in 0.091 s
2014-07-11 11:45:28,337 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.098813693 s
2014-07-11 11:45:28,343 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,344 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,344 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 27(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,344 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,346 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,346 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 27 (MappedRDD[110] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,349 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 27 (MappedRDD[110] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,349 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 2 tasks
2014-07-11 11:45:28,350 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 27.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,350 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 27.0:0 as 2291 bytes in 0 ms
2014-07-11 11:45:28,350 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 27.0:1 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,351 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 27.0:1 as 2291 bytes in 0 ms
2014-07-11 11:45:28,351 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-11 11:45:28,351 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-11 11:45:28,353 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,355 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,355 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,357 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,359 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,359 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,424 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-11 11:45:28,424 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-11 11:45:28,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-11 11:45:28,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-11 11:45:28,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-11 11:45:28,426 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 76 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,426 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(27, 0)
2014-07-11 11:45:28,426 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-11 11:45:28,427 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(27, 1)
2014-07-11 11:45:28,427 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,427 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,428 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 27 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:45:28,428 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08456018 s
2014-07-11 11:45:28,434 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,435 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,435 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,435 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,437 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,437 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[114] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,440 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 28 (MappedRDD[114] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,440 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 2 tasks
2014-07-11 11:45:28,441 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,441 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2291 bytes in 0 ms
2014-07-11 11:45:28,442 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:1 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,442 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:1 as 2291 bytes in 0 ms
2014-07-11 11:45:28,442 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-11 11:45:28,444 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-11 11:45:28,446 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,447 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,451 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,451 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,452 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,452 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,516 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-11 11:45:28,516 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-11 11:45:28,516 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-11 11:45:28,517 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 76 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,518 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-11 11:45:28,528 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-11 11:45:28,528 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-11 11:45:28,528 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-11 11:45:28,529 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 1)
2014-07-11 11:45:28,529 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,529 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,529 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at CalEigenVector.scala:38) finished in 0.089 s
2014-07-11 11:45:28,529 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094905002 s
2014-07-11 11:45:28,535 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,536 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,536 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 29(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,536 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,537 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,538 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 29 (MappedRDD[118] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,540 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 29 (MappedRDD[118] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,540 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 29.0 with 2 tasks
2014-07-11 11:45:28,541 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 29.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,542 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 29.0:0 as 2290 bytes in 0 ms
2014-07-11 11:45:28,542 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 29.0:1 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,542 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 29.0:1 as 2290 bytes in 0 ms
2014-07-11 11:45:28,543 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-11 11:45:28,544 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-11 11:45:28,546 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,546 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,548 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,548 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,549 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,549 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,615 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-11 11:45:28,616 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-11 11:45:28,616 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-11 11:45:28,617 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(29, 0)
2014-07-11 11:45:28,617 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,619 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-11 11:45:28,620 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-11 11:45:28,620 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-11 11:45:28,621 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(29, 1)
2014-07-11 11:45:28,621 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,621 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,621 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 29 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:45:28,621 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086196093 s
2014-07-11 11:45:28,626 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,627 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,627 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,627 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,629 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,629 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[122] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,632 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 30 (MappedRDD[122] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,632 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 2 tasks
2014-07-11 11:45:28,633 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,633 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2292 bytes in 0 ms
2014-07-11 11:45:28,633 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:1 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,633 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:1 as 2292 bytes in 0 ms
2014-07-11 11:45:28,634 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-11 11:45:28,635 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-11 11:45:28,636 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,636 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,637 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,637 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,639 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,639 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,702 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-11 11:45:28,702 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-11 11:45:28,704 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,704 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-11 11:45:28,705 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-11 11:45:28,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-11 11:45:28,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-11 11:45:28,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-11 11:45:28,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 1)
2014-07-11 11:45:28,716 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,716 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:45:28,716 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089883346 s
2014-07-11 11:45:28,725 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,726 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,726 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 31(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,726 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,728 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,728 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 31 (MappedRDD[126] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,731 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 31 (MappedRDD[126] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,731 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2014-07-11 11:45:28,731 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 31.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,732 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 31.0:0 as 2293 bytes in 1 ms
2014-07-11 11:45:28,732 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 31.0:1 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,732 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 31.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:28,733 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-11 11:45:28,733 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-11 11:45:28,734 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,735 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,736 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,736 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,736 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,737 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,802 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-11 11:45:28,802 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-11 11:45:28,802 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-11 11:45:28,803 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(31, 0)
2014-07-11 11:45:28,803 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-11 11:45:28,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-11 11:45:28,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-11 11:45:28,805 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(31, 1)
2014-07-11 11:45:28,805 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,805 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,805 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 31 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:45:28,806 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080657118 s
2014-07-11 11:45:28,811 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,812 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,812 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,812 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,814 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,814 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[130] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,816 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 32 (MappedRDD[130] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,816 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 2 tasks
2014-07-11 11:45:28,817 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,818 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:28,818 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:1 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,818 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:28,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-11 11:45:28,820 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,822 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,822 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,825 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-11 11:45:28,828 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,830 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,830 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-11 11:45:28,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-11 11:45:28,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-11 11:45:28,886 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:45:28,886 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-11 11:45:28,893 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-11 11:45:28,893 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-11 11:45:28,893 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-11 11:45:28,894 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 1)
2014-07-11 11:45:28,894 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:28,894 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-11 11:45:28,895 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:45:28,895 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083632351 s
2014-07-11 11:45:28,900 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:28,901 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:28,901 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 33(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:28,901 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:28,902 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:28,903 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 33 (MappedRDD[134] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:28,905 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 33 (MappedRDD[134] at map at CalEigenVector.scala:38)
2014-07-11 11:45:28,906 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2014-07-11 11:45:28,906 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 33.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,907 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 33.0:0 as 2294 bytes in 1 ms
2014-07-11 11:45:28,907 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 33.0:1 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:28,907 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 33.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:28,908 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-11 11:45:28,910 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,911 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-11 11:45:28,914 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:28,916 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,916 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:28,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:28,980 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-11 11:45:28,980 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-11 11:45:28,980 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-11 11:45:28,981 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(33, 1)
2014-07-11 11:45:28,981 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,000 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-11 11:45:29,000 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-11 11:45:29,000 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-11 11:45:29,001 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 94 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,001 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,001 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(33, 0)
2014-07-11 11:45:29,001 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 33 (reduce at CalEigenVector.scala:38) finished in 0.095 s
2014-07-11 11:45:29,002 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.101783874 s
2014-07-11 11:45:29,007 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,010 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,010 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[138] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,013 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 34 (MappedRDD[138] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,013 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 2 tasks
2014-07-11 11:45:29,014 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,014 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:29,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:1 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:29,015 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-11 11:45:29,017 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,019 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,019 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-11 11:45:29,019 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,021 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,022 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,023 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,085 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-11 11:45:29,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-11 11:45:29,085 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-11 11:45:29,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-11 11:45:29,085 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-11 11:45:29,086 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-11 11:45:29,087 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-11 11:45:29,087 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,088 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 1)
2014-07-11 11:45:29,088 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,088 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,088 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:45:29,088 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080714091 s
2014-07-11 11:45:29,093 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 35(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,096 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,096 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 35 (MappedRDD[142] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,098 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 35 (MappedRDD[142] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,099 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 2 tasks
2014-07-11 11:45:29,099 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 35.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,100 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 35.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:29,100 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 35.0:1 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,100 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 35.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:29,101 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-11 11:45:29,101 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-11 11:45:29,103 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,103 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,107 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,107 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,111 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,111 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-11 11:45:29,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-11 11:45:29,166 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-11 11:45:29,166 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(35, 1)
2014-07-11 11:45:29,166 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,170 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-11 11:45:29,171 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-11 11:45:29,171 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-11 11:45:29,171 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(35, 0)
2014-07-11 11:45:29,172 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,172 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,172 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 35 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:29,172 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078565792 s
2014-07-11 11:45:29,177 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,178 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,178 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,178 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,180 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,180 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[146] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,182 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 36 (MappedRDD[146] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,182 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2014-07-11 11:45:29,183 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,184 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:29,184 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:1 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,184 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:29,184 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-11 11:45:29,185 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-11 11:45:29,186 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,186 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,188 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,188 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,189 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,189 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,244 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-11 11:45:29,245 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-11 11:45:29,245 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-11 11:45:29,245 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-11 11:45:29,246 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,246 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-11 11:45:29,246 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-11 11:45:29,246 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-11 11:45:29,247 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 1)
2014-07-11 11:45:29,247 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 63 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,247 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,247 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at CalEigenVector.scala:38) finished in 0.057 s
2014-07-11 11:45:29,247 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070345777 s
2014-07-11 11:45:29,253 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,254 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,254 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 37(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,254 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,255 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,256 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 37 (MappedRDD[150] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,258 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 37 (MappedRDD[150] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,258 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2014-07-11 11:45:29,259 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 37.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,259 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 37.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:29,259 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 37.0:1 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,259 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 37.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:29,260 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-11 11:45:29,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-11 11:45:29,261 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,262 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,263 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,264 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,271 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,271 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,311 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-11 11:45:29,311 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-11 11:45:29,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-11 11:45:29,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(37, 1)
2014-07-11 11:45:29,312 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 53 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,319 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-11 11:45:29,319 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-11 11:45:29,319 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-11 11:45:29,320 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(37, 0)
2014-07-11 11:45:29,320 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 62 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,320 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,320 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 37 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:45:29,321 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.067625902 s
2014-07-11 11:45:29,327 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,328 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,328 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,328 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,330 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,330 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[154] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,333 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 38 (MappedRDD[154] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,333 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 2 tasks
2014-07-11 11:45:29,334 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,334 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:29,334 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:1 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,335 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:1 as 2294 bytes in 1 ms
2014-07-11 11:45:29,335 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-11 11:45:29,336 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-11 11:45:29,337 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,337 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,339 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,339 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,342 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,343 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,395 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-11 11:45:29,395 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-11 11:45:29,396 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-11 11:45:29,396 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-11 11:45:29,396 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,429 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-11 11:45:29,429 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-11 11:45:29,429 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-11 11:45:29,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 1)
2014-07-11 11:45:29,430 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 96 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,430 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,430 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at CalEigenVector.scala:38) finished in 0.091 s
2014-07-11 11:45:29,430 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.103731221 s
2014-07-11 11:45:29,437 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,438 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,438 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 39(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,438 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,440 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,440 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 39 (MappedRDD[158] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,443 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 39 (MappedRDD[158] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,443 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2014-07-11 11:45:29,443 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 39.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,444 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 39.0:0 as 2294 bytes in 1 ms
2014-07-11 11:45:29,444 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 39.0:1 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,444 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 39.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:29,445 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-11 11:45:29,445 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-11 11:45:29,446 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,447 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,448 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,448 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,451 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,451 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-11 11:45:29,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-11 11:45:29,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-11 11:45:29,532 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(39, 0)
2014-07-11 11:45:29,532 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 88 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-11 11:45:29,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-11 11:45:29,557 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 113 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,557 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,558 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(39, 1)
2014-07-11 11:45:29,558 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 39 (reduce at CalEigenVector.scala:38) finished in 0.115 s
2014-07-11 11:45:29,558 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.120625571 s
2014-07-11 11:45:29,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-11 11:45:29,564 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,565 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,565 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,565 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,568 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,569 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[162] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,572 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 40 (MappedRDD[162] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,573 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 2 tasks
2014-07-11 11:45:29,574 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,574 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:29,575 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:1 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,575 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:29,575 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-11 11:45:29,576 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-11 11:45:29,577 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,577 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,579 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,579 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,580 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,580 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,654 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-11 11:45:29,654 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-11 11:45:29,654 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-11 11:45:29,654 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-11 11:45:29,654 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-11 11:45:29,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-11 11:45:29,655 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,655 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 1)
2014-07-11 11:45:29,656 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-11 11:45:29,656 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,656 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,656 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:45:29,656 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092064371 s
2014-07-11 11:45:29,661 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,662 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,662 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 41(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,662 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,664 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,664 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 41 (MappedRDD[166] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,666 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 41 (MappedRDD[166] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,667 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 2 tasks
2014-07-11 11:45:29,667 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 41.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,668 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 41.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:29,668 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 41.0:1 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,668 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 41.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:29,668 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-11 11:45:29,670 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,670 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-11 11:45:29,671 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,676 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,676 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,682 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,682 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,752 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-11 11:45:29,752 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-11 11:45:29,754 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 86 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,754 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(41, 0)
2014-07-11 11:45:29,754 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-11 11:45:29,777 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-11 11:45:29,777 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-11 11:45:29,777 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-11 11:45:29,778 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(41, 1)
2014-07-11 11:45:29,778 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 109 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,778 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,778 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 41 (reduce at CalEigenVector.scala:38) finished in 0.111 s
2014-07-11 11:45:29,778 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.116616853 s
2014-07-11 11:45:29,784 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,785 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,785 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,785 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,786 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,787 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[170] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,789 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 42 (MappedRDD[170] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,789 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 2 tasks
2014-07-11 11:45:29,790 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,790 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:29,790 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:1 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,791 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:1 as 2294 bytes in 1 ms
2014-07-11 11:45:29,791 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-11 11:45:29,791 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-11 11:45:29,795 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,797 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,797 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,800 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,804 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,804 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,873 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-11 11:45:29,873 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-11 11:45:29,874 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 83 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,874 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 1)
2014-07-11 11:45:29,874 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-11 11:45:29,901 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-11 11:45:29,901 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-11 11:45:29,901 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-11 11:45:29,902 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-11 11:45:29,902 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 112 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,902 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,902 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at CalEigenVector.scala:38) finished in 0.113 s
2014-07-11 11:45:29,902 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.118567681 s
2014-07-11 11:45:29,907 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:29,909 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:29,909 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 43(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:29,909 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:29,911 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:29,912 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 43 (MappedRDD[174] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:29,914 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 43 (MappedRDD[174] at map at CalEigenVector.scala:38)
2014-07-11 11:45:29,914 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 2 tasks
2014-07-11 11:45:29,915 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 43.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,915 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 43.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:29,915 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 43.0:1 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:29,915 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 43.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:29,916 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-11 11:45:29,917 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-11 11:45:29,918 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,919 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:29,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:29,925 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,925 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:29,979 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-11 11:45:29,979 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-11 11:45:29,979 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-11 11:45:29,981 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(43, 1)
2014-07-11 11:45:29,981 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:29,989 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-11 11:45:29,989 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-11 11:45:29,989 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-11 11:45:29,990 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(43, 0)
2014-07-11 11:45:29,990 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:29,990 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2014-07-11 11:45:29,990 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 43 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:45:29,993 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085997084 s
2014-07-11 11:45:29,999 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,000 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,000 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,000 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,001 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,002 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[178] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,004 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 44 (MappedRDD[178] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,004 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 2 tasks
2014-07-11 11:45:30,005 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,005 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,006 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:1 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,006 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-11 11:45:30,006 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-11 11:45:30,008 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,008 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,009 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,009 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,009 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,009 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,065 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-11 11:45:30,065 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-11 11:45:30,066 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,066 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 1)
2014-07-11 11:45:30,067 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-11 11:45:30,068 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-11 11:45:30,068 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-11 11:45:30,069 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-11 11:45:30,069 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-11 11:45:30,069 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,069 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,069 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:45:30,070 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071022706 s
2014-07-11 11:45:30,075 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,076 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,076 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 45(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,076 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,077 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,078 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 45 (MappedRDD[182] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,080 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 45 (MappedRDD[182] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,080 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2014-07-11 11:45:30,080 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 45.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,081 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 45.0:0 as 2293 bytes in 1 ms
2014-07-11 11:45:30,081 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 45.0:1 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,081 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 45.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:30,082 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-11 11:45:30,083 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,085 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,085 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-11 11:45:30,086 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,087 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,088 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,166 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-11 11:45:30,166 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-11 11:45:30,166 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-11 11:45:30,166 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-11 11:45:30,166 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-11 11:45:30,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-11 11:45:30,167 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 87 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,167 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(45, 0)
2014-07-11 11:45:30,168 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(45, 1)
2014-07-11 11:45:30,168 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 86 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,168 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,168 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 45 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:45:30,168 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.093234312 s
2014-07-11 11:45:30,173 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,174 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,174 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,174 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,176 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,176 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[186] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,178 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 46 (MappedRDD[186] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,178 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2014-07-11 11:45:30,179 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,179 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,179 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:1 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,180 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,180 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-11 11:45:30,180 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-11 11:45:30,181 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,183 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,183 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,187 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,189 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,189 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,247 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-11 11:45:30,248 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-11 11:45:30,248 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-11 11:45:30,248 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-11 11:45:30,248 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-11 11:45:30,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-11 11:45:30,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-11 11:45:30,255 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 1)
2014-07-11 11:45:30,255 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,255 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,255 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:45:30,255 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082075337 s
2014-07-11 11:45:30,261 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,262 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,262 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 47(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,262 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,263 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,264 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 47 (MappedRDD[190] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,271 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 47 (MappedRDD[190] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,271 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 47.0 with 2 tasks
2014-07-11 11:45:30,271 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 47.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,272 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 47.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,274 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 47.0:1 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,274 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 47.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,275 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-11 11:45:30,275 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-11 11:45:30,276 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,277 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,278 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,278 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,337 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-11 11:45:30,337 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-11 11:45:30,338 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,339 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(47, 0)
2014-07-11 11:45:30,339 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-11 11:45:30,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-11 11:45:30,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-11 11:45:30,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-11 11:45:30,340 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(47, 1)
2014-07-11 11:45:30,340 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,340 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,340 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 47 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:45:30,340 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079315267 s
2014-07-11 11:45:30,345 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,346 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,346 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,346 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,348 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,348 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[194] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,350 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 48 (MappedRDD[194] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,350 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2014-07-11 11:45:30,351 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,351 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,351 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:1 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,352 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,352 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-11 11:45:30,353 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-11 11:45:30,354 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,355 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,355 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,356 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,357 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,357 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,410 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-11 11:45:30,410 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-11 11:45:30,411 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-11 11:45:30,411 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 60 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,415 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 1)
2014-07-11 11:45:30,416 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-11 11:45:30,416 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-11 11:45:30,416 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-11 11:45:30,417 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-11 11:45:30,417 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,417 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,417 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:45:30,417 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071955637 s
2014-07-11 11:45:30,422 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,423 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,423 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 49(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,423 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,425 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,425 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 49 (MappedRDD[198] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,427 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 49 (MappedRDD[198] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,427 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 49.0 with 2 tasks
2014-07-11 11:45:30,428 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 49.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,428 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 49.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:30,428 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 49.0:1 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,429 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 49.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:30,429 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-11 11:45:30,429 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-11 11:45:30,430 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,430 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,431 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,432 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,432 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,432 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,480 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-11 11:45:30,481 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-11 11:45:30,482 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 53 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,489 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(49, 1)
2014-07-11 11:45:30,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-11 11:45:30,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-11 11:45:30,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-11 11:45:30,500 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(49, 0)
2014-07-11 11:45:30,500 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 49 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:30,500 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078244594 s
2014-07-11 11:45:30,500 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,501 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,506 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,507 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,507 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,507 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,508 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-11 11:45:30,509 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,509 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[202] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,511 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 50 (MappedRDD[202] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,512 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2014-07-11 11:45:30,512 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,513 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,513 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:1 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,513 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,513 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-11 11:45:30,515 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,516 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,516 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,519 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-11 11:45:30,521 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,522 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,522 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,572 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-11 11:45:30,572 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-11 11:45:30,573 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-11 11:45:30,573 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,574 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-11 11:45:30,610 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-11 11:45:30,610 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-11 11:45:30,610 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-11 11:45:30,611 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 1)
2014-07-11 11:45:30,611 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 97 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,611 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,611 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at CalEigenVector.scala:38) finished in 0.099 s
2014-07-11 11:45:30,611 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.10459679 s
2014-07-11 11:45:30,619 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,620 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,620 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 51(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,620 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,622 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,623 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 51 (MappedRDD[206] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,625 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 51 (MappedRDD[206] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,625 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 2 tasks
2014-07-11 11:45:30,626 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 51.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,626 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 51.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,626 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 51.0:1 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,626 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 51.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,627 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-11 11:45:30,628 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,628 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-11 11:45:30,629 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,629 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,629 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,633 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,633 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,735 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-11 11:45:30,736 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-11 11:45:30,736 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-11 11:45:30,736 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(51, 1)
2014-07-11 11:45:30,736 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 110 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,741 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-11 11:45:30,741 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-11 11:45:30,741 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-11 11:45:30,742 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(51, 0)
2014-07-11 11:45:30,742 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 117 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,742 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,742 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 51 (reduce at CalEigenVector.scala:38) finished in 0.105 s
2014-07-11 11:45:30,743 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.123491089 s
2014-07-11 11:45:30,748 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,748 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,748 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,748 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,750 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,751 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[210] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,752 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 52 (MappedRDD[210] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,753 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 2 tasks
2014-07-11 11:45:30,753 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,754 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,755 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:1 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,755 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,756 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-11 11:45:30,756 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-11 11:45:30,757 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,758 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,759 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,759 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,759 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,759 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-11 11:45:30,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-11 11:45:30,823 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,823 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-11 11:45:30,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-11 11:45:30,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-11 11:45:30,824 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-11 11:45:30,824 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 1)
2014-07-11 11:45:30,825 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:30,825 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077329262 s
2014-07-11 11:45:30,824 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,827 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,827 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-11 11:45:30,830 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,831 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,831 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 53(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,831 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,833 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,833 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 53 (MappedRDD[214] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,835 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 53 (MappedRDD[214] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,836 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 2 tasks
2014-07-11 11:45:30,836 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 53.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,837 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 53.0:0 as 2294 bytes in 1 ms
2014-07-11 11:45:30,837 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 53.0:1 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,837 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 53.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:30,838 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-11 11:45:30,838 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-11 11:45:30,839 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,839 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,840 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,840 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,840 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,840 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-11 11:45:30,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-11 11:45:30,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-11 11:45:30,904 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,904 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(53, 0)
2014-07-11 11:45:30,909 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-11 11:45:30,909 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-11 11:45:30,909 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-11 11:45:30,909 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(53, 1)
2014-07-11 11:45:30,909 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,910 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,910 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 53 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:30,910 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079688901 s
2014-07-11 11:45:30,915 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,916 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,916 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,916 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:30,918 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:30,918 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[218] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:30,920 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 54 (MappedRDD[218] at map at CalEigenVector.scala:38)
2014-07-11 11:45:30,920 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2014-07-11 11:45:30,921 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,921 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:30,921 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:1 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:30,922 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:1 as 2294 bytes in 1 ms
2014-07-11 11:45:30,922 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-11 11:45:30,922 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-11 11:45:30,923 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,923 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:30,924 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,924 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,924 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:30,924 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:30,989 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-11 11:45:30,989 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-11 11:45:30,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-11 11:45:30,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-11 11:45:30,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-11 11:45:30,990 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 1)
2014-07-11 11:45:30,990 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:45:30,991 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-11 11:45:30,991 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-11 11:45:30,991 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:30,991 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-11 11:45:30,991 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:30,991 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076481253 s
2014-07-11 11:45:30,997 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:30,998 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:30,998 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 55(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:30,998 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,003 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,004 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 55 (MappedRDD[222] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,006 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 55 (MappedRDD[222] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,006 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2014-07-11 11:45:31,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 55.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 55.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:31,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 55.0:1 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 55.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:31,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-11 11:45:31,011 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-11 11:45:31,013 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,013 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,014 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,014 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,014 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,017 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-11 11:45:31,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-11 11:45:31,078 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-11 11:45:31,078 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,078 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(55, 1)
2014-07-11 11:45:31,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-11 11:45:31,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-11 11:45:31,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-11 11:45:31,080 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(55, 0)
2014-07-11 11:45:31,080 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,080 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,080 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 55 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:45:31,081 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083628212 s
2014-07-11 11:45:31,086 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,088 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,089 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[226] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 56 (MappedRDD[226] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 2 tasks
2014-07-11 11:45:31,091 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2293 bytes in 1 ms
2014-07-11 11:45:31,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:1 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,092 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:31,092 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-11 11:45:31,093 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-11 11:45:31,094 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,094 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,094 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,095 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,095 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,096 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,160 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-11 11:45:31,160 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-11 11:45:31,160 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-11 11:45:31,161 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-11 11:45:31,161 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-11 11:45:31,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-11 11:45:31,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-11 11:45:31,166 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 1)
2014-07-11 11:45:31,166 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,166 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,166 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:45:31,166 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080378533 s
2014-07-11 11:45:31,171 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,172 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,172 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 57(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,172 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,174 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,174 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 57 (MappedRDD[230] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,179 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 57 (MappedRDD[230] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,179 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 2 tasks
2014-07-11 11:45:31,180 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 57.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,180 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 57.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:31,180 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 57.0:1 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,181 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 57.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:31,182 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-11 11:45:31,182 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-11 11:45:31,184 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,190 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,191 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,191 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,193 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,193 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-11 11:45:31,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-11 11:45:31,260 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-11 11:45:31,260 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-11 11:45:31,260 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-11 11:45:31,261 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-11 11:45:31,261 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,261 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(57, 1)
2014-07-11 11:45:31,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(57, 0)
2014-07-11 11:45:31,261 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,261 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 57 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:45:31,262 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.090679486 s
2014-07-11 11:45:31,267 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,270 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,271 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[234] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,273 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 58 (MappedRDD[234] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,273 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 2 tasks
2014-07-11 11:45:31,273 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,274 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2293 bytes in 1 ms
2014-07-11 11:45:31,274 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:1 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,274 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:31,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-11 11:45:31,275 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-11 11:45:31,275 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,276 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,276 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,279 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,279 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,339 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-11 11:45:31,339 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-11 11:45:31,341 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,341 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 1)
2014-07-11 11:45:31,341 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-11 11:45:31,342 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-11 11:45:31,343 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-11 11:45:31,343 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-11 11:45:31,344 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-11 11:45:31,344 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,344 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,344 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:31,344 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077081377 s
2014-07-11 11:45:31,349 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,350 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,350 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 59(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,350 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,351 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,352 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 59 (MappedRDD[238] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,354 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 59 (MappedRDD[238] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,354 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 2 tasks
2014-07-11 11:45:31,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 59.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 59.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:31,355 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 59.0:1 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,355 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 59.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:31,355 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-11 11:45:31,357 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,356 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-11 11:45:31,358 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,359 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,359 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,359 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,359 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-11 11:45:31,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-11 11:45:31,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-11 11:45:31,423 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,424 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(59, 1)
2014-07-11 11:45:31,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-11 11:45:31,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-11 11:45:31,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-11 11:45:31,426 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(59, 0)
2014-07-11 11:45:31,426 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,426 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,426 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 59 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:31,426 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077283513 s
2014-07-11 11:45:31,432 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,433 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,433 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,433 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,434 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,434 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[242] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,436 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 60 (MappedRDD[242] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,436 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 2 tasks
2014-07-11 11:45:31,437 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,437 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:31,438 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:1 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,438 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:31,439 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-11 11:45:31,440 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,441 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,441 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,444 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-11 11:45:31,446 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,447 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,447 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,492 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-11 11:45:31,492 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-11 11:45:31,493 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 55 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,494 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 1)
2014-07-11 11:45:31,494 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-11 11:45:31,524 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-11 11:45:31,525 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-11 11:45:31,525 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 88 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,526 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,526 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-11 11:45:31,526 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-11 11:45:31,526 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at CalEigenVector.scala:38) finished in 0.089 s
2014-07-11 11:45:31,527 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094729275 s
2014-07-11 11:45:31,532 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,533 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,533 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 61(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,533 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,534 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,535 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 61 (MappedRDD[246] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,536 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 61 (MappedRDD[246] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,537 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 2 tasks
2014-07-11 11:45:31,537 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 61.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,538 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 61.0:0 as 2293 bytes in 1 ms
2014-07-11 11:45:31,538 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 61.0:1 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,538 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 61.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:31,538 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-11 11:45:31,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-11 11:45:31,539 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,539 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,540 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,540 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,540 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,540 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,587 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-11 11:45:31,587 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-11 11:45:31,588 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 50 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(61, 1)
2014-07-11 11:45:31,588 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-11 11:45:31,590 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-11 11:45:31,590 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-11 11:45:31,590 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-11 11:45:31,590 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(61, 0)
2014-07-11 11:45:31,590 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 53 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,591 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 61 (reduce at CalEigenVector.scala:38) finished in 0.054 s
2014-07-11 11:45:31,591 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,591 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.058920244 s
2014-07-11 11:45:31,596 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,597 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,597 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,597 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,598 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,599 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[250] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,600 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 62 (MappedRDD[250] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,601 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 2 tasks
2014-07-11 11:45:31,601 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 124 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,601 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:31,602 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:1 as TID 125 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,602 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:31,602 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 124
2014-07-11 11:45:31,603 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 125
2014-07-11 11:45:31,603 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,604 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,604 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,604 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,604 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,605 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 124 is 678
2014-07-11 11:45:31,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 124 directly to driver
2014-07-11 11:45:31,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 124
2014-07-11 11:45:31,664 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-11 11:45:31,664 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 124 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,665 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 125 is 678
2014-07-11 11:45:31,665 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 125 directly to driver
2014-07-11 11:45:31,665 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 125
2014-07-11 11:45:31,665 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 125 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,666 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,666 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 1)
2014-07-11 11:45:31,666 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:45:31,666 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069962725 s
2014-07-11 11:45:31,671 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,672 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,672 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 63(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,672 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,673 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,674 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 63 (MappedRDD[254] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,675 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 63 (MappedRDD[254] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,676 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 2 tasks
2014-07-11 11:45:31,676 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 63.0:0 as TID 126 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,677 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 63.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:31,677 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 63.0:1 as TID 127 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,677 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 63.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:31,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 127
2014-07-11 11:45:31,679 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,680 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,680 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,682 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 126
2014-07-11 11:45:31,684 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,688 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,688 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,739 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 127 is 678
2014-07-11 11:45:31,739 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 127 directly to driver
2014-07-11 11:45:31,740 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 127 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,743 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(63, 1)
2014-07-11 11:45:31,745 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 127
2014-07-11 11:45:31,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 126 is 678
2014-07-11 11:45:31,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 126 directly to driver
2014-07-11 11:45:31,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 126
2014-07-11 11:45:31,774 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(63, 0)
2014-07-11 11:45:31,775 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 63 (reduce at CalEigenVector.scala:38) finished in 0.099 s
2014-07-11 11:45:31,775 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 126 in 98 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,775 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,775 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.103771518 s
2014-07-11 11:45:31,780 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,781 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,781 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,781 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,783 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,783 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[258] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,784 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 64 (MappedRDD[258] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,785 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 2 tasks
2014-07-11 11:45:31,785 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 128 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,785 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2294 bytes in 0 ms
2014-07-11 11:45:31,786 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:1 as TID 129 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,786 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:31,786 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 128
2014-07-11 11:45:31,787 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 129
2014-07-11 11:45:31,787 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,788 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,788 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,788 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,789 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,789 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,860 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 128 is 678
2014-07-11 11:45:31,860 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 128 directly to driver
2014-07-11 11:45:31,860 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 128
2014-07-11 11:45:31,862 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 128 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,862 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-11 11:45:31,875 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 129 is 678
2014-07-11 11:45:31,875 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 129 directly to driver
2014-07-11 11:45:31,875 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 129
2014-07-11 11:45:31,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 1)
2014-07-11 11:45:31,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at CalEigenVector.scala:38) finished in 0.091 s
2014-07-11 11:45:31,876 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 129 in 91 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,876 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,876 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.096002558 s
2014-07-11 11:45:31,881 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,882 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,882 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 65(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,882 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,884 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,884 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 65 (MappedRDD[262] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,885 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 65 (MappedRDD[262] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,886 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 2 tasks
2014-07-11 11:45:31,886 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 65.0:0 as TID 130 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,886 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 65.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:31,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 65.0:1 as TID 131 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 65.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:31,887 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 130
2014-07-11 11:45:31,887 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 131
2014-07-11 11:45:31,888 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,888 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,889 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,889 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,952 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 131 is 678
2014-07-11 11:45:31,952 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 131 directly to driver
2014-07-11 11:45:31,953 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 131
2014-07-11 11:45:31,953 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 131 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:45:31,953 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(65, 1)
2014-07-11 11:45:31,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 130 is 678
2014-07-11 11:45:31,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 130 directly to driver
2014-07-11 11:45:31,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 130
2014-07-11 11:45:31,957 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 130 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:31,957 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2014-07-11 11:45:31,957 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(65, 0)
2014-07-11 11:45:31,957 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 65 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:31,957 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076019746 s
2014-07-11 11:45:31,962 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:31,963 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:31,963 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:31,963 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:31,965 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:31,965 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[266] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:31,967 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 66 (MappedRDD[266] at map at CalEigenVector.scala:38)
2014-07-11 11:45:31,967 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 2 tasks
2014-07-11 11:45:31,968 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 132 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,968 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:31,968 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:1 as TID 133 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:31,968 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:31,969 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 132
2014-07-11 11:45:31,969 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 133
2014-07-11 11:45:31,970 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,971 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,971 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:31,973 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:31,974 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:31,974 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,031 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 133 is 678
2014-07-11 11:45:32,032 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 133 directly to driver
2014-07-11 11:45:32,032 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 133
2014-07-11 11:45:32,032 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 1)
2014-07-11 11:45:32,032 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 133 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,038 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 132 is 678
2014-07-11 11:45:32,038 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 132 directly to driver
2014-07-11 11:45:32,038 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 132
2014-07-11 11:45:32,039 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-11 11:45:32,039 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:32,039 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 132 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,039 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,039 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076822254 s
2014-07-11 11:45:32,044 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,045 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,045 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 67(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,045 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,047 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,047 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 67 (MappedRDD[270] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,049 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 67 (MappedRDD[270] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,049 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 67.0 with 2 tasks
2014-07-11 11:45:32,049 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 67.0:0 as TID 134 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,050 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 67.0:0 as 2294 bytes in 1 ms
2014-07-11 11:45:32,050 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 67.0:1 as TID 135 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,050 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 67.0:1 as 2294 bytes in 0 ms
2014-07-11 11:45:32,050 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 134
2014-07-11 11:45:32,050 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 135
2014-07-11 11:45:32,051 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,051 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,052 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,052 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,052 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,052 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,119 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 135 is 678
2014-07-11 11:45:32,119 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 135 directly to driver
2014-07-11 11:45:32,120 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 135
2014-07-11 11:45:32,120 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(67, 1)
2014-07-11 11:45:32,120 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 135 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,123 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 134 is 678
2014-07-11 11:45:32,123 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 134 directly to driver
2014-07-11 11:45:32,123 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 134
2014-07-11 11:45:32,124 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(67, 0)
2014-07-11 11:45:32,125 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 67 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:45:32,124 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 134 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,125 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,125 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080579038 s
2014-07-11 11:45:32,130 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,131 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,131 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,131 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,132 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,133 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[274] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,134 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 68 (MappedRDD[274] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,134 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 2 tasks
2014-07-11 11:45:32,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 136 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:1 as TID 137 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,136 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 136
2014-07-11 11:45:32,136 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 137
2014-07-11 11:45:32,137 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,137 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,138 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,138 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,145 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,145 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,212 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 137 is 678
2014-07-11 11:45:32,212 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 137 directly to driver
2014-07-11 11:45:32,212 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 137
2014-07-11 11:45:32,213 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 137 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,213 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 1)
2014-07-11 11:45:32,218 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 136 is 678
2014-07-11 11:45:32,218 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 136 directly to driver
2014-07-11 11:45:32,218 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 136
2014-07-11 11:45:32,219 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-11 11:45:32,219 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 136 in 84 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,219 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,219 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at CalEigenVector.scala:38) finished in 0.085 s
2014-07-11 11:45:32,219 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089595378 s
2014-07-11 11:45:32,225 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,225 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,225 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 69(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,225 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,227 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,227 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 69 (MappedRDD[278] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,229 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 69 (MappedRDD[278] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,229 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 69.0 with 2 tasks
2014-07-11 11:45:32,230 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 69.0:0 as TID 138 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,230 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 69.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,230 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 69.0:1 as TID 139 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,230 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 69.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,231 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 138
2014-07-11 11:45:32,232 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,233 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,233 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,233 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 139
2014-07-11 11:45:32,234 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,235 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,235 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,298 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 138 is 678
2014-07-11 11:45:32,298 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 139 is 678
2014-07-11 11:45:32,298 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 138 directly to driver
2014-07-11 11:45:32,298 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 139 directly to driver
2014-07-11 11:45:32,298 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 139
2014-07-11 11:45:32,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 138
2014-07-11 11:45:32,299 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 138 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,300 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(69, 0)
2014-07-11 11:45:32,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(69, 1)
2014-07-11 11:45:32,301 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 139 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,301 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 69 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:32,301 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076237476 s
2014-07-11 11:45:32,306 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,309 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,309 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[282] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,310 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 70 (MappedRDD[282] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,311 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 2 tasks
2014-07-11 11:45:32,311 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 140 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,311 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:1 as TID 141 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 140
2014-07-11 11:45:32,312 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 141
2014-07-11 11:45:32,313 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,313 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,314 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,314 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,314 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,314 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,376 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 140 is 678
2014-07-11 11:45:32,376 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 140 directly to driver
2014-07-11 11:45:32,376 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 140
2014-07-11 11:45:32,377 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-11 11:45:32,378 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 141 is 678
2014-07-11 11:45:32,378 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 141 directly to driver
2014-07-11 11:45:32,378 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 141
2014-07-11 11:45:32,377 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 140 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,384 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 1)
2014-07-11 11:45:32,384 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 141 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,384 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,384 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:32,384 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.07811262 s
2014-07-11 11:45:32,390 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,391 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,391 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 71(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,391 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,393 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,393 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 71 (MappedRDD[286] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,395 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 71 (MappedRDD[286] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,395 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 71.0 with 2 tasks
2014-07-11 11:45:32,396 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 71.0:0 as TID 142 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,396 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 71.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:32,396 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 71.0:1 as TID 143 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,396 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 71.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:32,397 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 143
2014-07-11 11:45:32,397 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 142
2014-07-11 11:45:32,398 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,399 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,400 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,400 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,406 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,408 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,467 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 142 is 678
2014-07-11 11:45:32,467 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 142 directly to driver
2014-07-11 11:45:32,467 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 142
2014-07-11 11:45:32,468 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(71, 0)
2014-07-11 11:45:32,468 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 142 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 143 is 678
2014-07-11 11:45:32,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 143 directly to driver
2014-07-11 11:45:32,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 143
2014-07-11 11:45:32,498 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(71, 1)
2014-07-11 11:45:32,498 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 143 in 102 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,498 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 71 (reduce at CalEigenVector.scala:38) finished in 0.100 s
2014-07-11 11:45:32,499 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.108617948 s
2014-07-11 11:45:32,501 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,506 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,506 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,507 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,507 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,508 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,508 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[290] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,510 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 72 (MappedRDD[290] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,510 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 2 tasks
2014-07-11 11:45:32,511 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 144 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,511 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:32,511 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:1 as TID 145 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,511 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:32,512 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 145
2014-07-11 11:45:32,513 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,513 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,513 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,519 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 144
2014-07-11 11:45:32,520 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,521 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,521 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,575 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 145 is 678
2014-07-11 11:45:32,575 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 144 is 678
2014-07-11 11:45:32,575 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 145 directly to driver
2014-07-11 11:45:32,575 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 144 directly to driver
2014-07-11 11:45:32,575 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 144
2014-07-11 11:45:32,576 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 145
2014-07-11 11:45:32,576 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 145 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,576 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 1)
2014-07-11 11:45:32,577 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-11 11:45:32,577 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 144 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,577 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,577 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:45:32,577 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071321253 s
2014-07-11 11:45:32,583 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,583 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,583 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 73(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,583 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,585 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,585 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 73 (MappedRDD[294] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,587 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 73 (MappedRDD[294] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,587 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 2 tasks
2014-07-11 11:45:32,587 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 73.0:0 as TID 146 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 73.0:0 as 2295 bytes in 1 ms
2014-07-11 11:45:32,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 73.0:1 as TID 147 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 73.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:32,588 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 146
2014-07-11 11:45:32,589 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 147
2014-07-11 11:45:32,590 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,590 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,590 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,590 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,590 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,591 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,638 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 147 is 678
2014-07-11 11:45:32,638 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 147 directly to driver
2014-07-11 11:45:32,639 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 147 in 51 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,640 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(73, 1)
2014-07-11 11:45:32,640 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 147
2014-07-11 11:45:32,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 146 is 678
2014-07-11 11:45:32,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 146 directly to driver
2014-07-11 11:45:32,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 146
2014-07-11 11:45:32,641 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(73, 0)
2014-07-11 11:45:32,641 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 146 in 54 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,641 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,641 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 73 (reduce at CalEigenVector.scala:38) finished in 0.054 s
2014-07-11 11:45:32,641 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.058836424 s
2014-07-11 11:45:32,647 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,648 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,648 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,648 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,649 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,650 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[298] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,651 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 74 (MappedRDD[298] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,651 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 2 tasks
2014-07-11 11:45:32,652 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 148 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,652 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,653 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:1 as TID 149 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,653 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,654 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 149
2014-07-11 11:45:32,654 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 148
2014-07-11 11:45:32,655 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,655 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,656 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,656 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,656 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,656 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 149 is 678
2014-07-11 11:45:32,714 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 149 directly to driver
2014-07-11 11:45:32,715 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 149 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 148 is 678
2014-07-11 11:45:32,715 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 1)
2014-07-11 11:45:32,715 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 149
2014-07-11 11:45:32,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 148 directly to driver
2014-07-11 11:45:32,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 148
2014-07-11 11:45:32,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-11 11:45:32,716 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at CalEigenVector.scala:38) finished in 0.064 s
2014-07-11 11:45:32,716 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 148 in 63 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,716 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,716 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.068994399 s
2014-07-11 11:45:32,722 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,723 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,723 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 75(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,723 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,725 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,725 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 75 (MappedRDD[302] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,727 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 75 (MappedRDD[302] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,727 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 75.0 with 2 tasks
2014-07-11 11:45:32,728 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 75.0:0 as TID 150 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,728 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 75.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,728 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 75.0:1 as TID 151 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,728 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 75.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,729 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 151
2014-07-11 11:45:32,730 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,731 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,731 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,731 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 150
2014-07-11 11:45:32,734 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,735 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,735 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,792 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 151 is 678
2014-07-11 11:45:32,792 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 151 directly to driver
2014-07-11 11:45:32,793 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 151 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,793 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(75, 1)
2014-07-11 11:45:32,793 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 151
2014-07-11 11:45:32,799 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 150 is 678
2014-07-11 11:45:32,799 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 150 directly to driver
2014-07-11 11:45:32,799 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 150
2014-07-11 11:45:32,800 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(75, 0)
2014-07-11 11:45:32,800 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 75 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:32,800 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 150 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,800 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,800 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078474724 s
2014-07-11 11:45:32,806 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,807 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,807 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,807 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,808 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,808 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[306] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,810 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 76 (MappedRDD[306] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,810 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 2 tasks
2014-07-11 11:45:32,810 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 152 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2295 bytes in 1 ms
2014-07-11 11:45:32,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:1 as TID 153 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:32,811 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 152
2014-07-11 11:45:32,812 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 153
2014-07-11 11:45:32,812 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,813 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,813 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,813 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,813 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 152 is 678
2014-07-11 11:45:32,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 152 directly to driver
2014-07-11 11:45:32,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 152
2014-07-11 11:45:32,878 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-11 11:45:32,878 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 152 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,879 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 153 is 678
2014-07-11 11:45:32,879 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 153 directly to driver
2014-07-11 11:45:32,879 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 153
2014-07-11 11:45:32,880 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 1)
2014-07-11 11:45:32,880 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:45:32,881 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.074722184 s
2014-07-11 11:45:32,880 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 153 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,881 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,886 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,887 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,887 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 77(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,887 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,889 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,889 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 77 (MappedRDD[310] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,891 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 77 (MappedRDD[310] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,891 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 77.0 with 2 tasks
2014-07-11 11:45:32,891 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 77.0:0 as TID 154 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,891 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 77.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,892 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 77.0:1 as TID 155 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,892 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 77.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,892 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 154
2014-07-11 11:45:32,894 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,895 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,895 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,896 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 155
2014-07-11 11:45:32,898 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,899 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,899 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,958 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 154 is 678
2014-07-11 11:45:32,958 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 154 directly to driver
2014-07-11 11:45:32,958 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 154
2014-07-11 11:45:32,959 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(77, 0)
2014-07-11 11:45:32,959 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 154 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:32,960 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 155 is 678
2014-07-11 11:45:32,960 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 155 directly to driver
2014-07-11 11:45:32,960 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 155
2014-07-11 11:45:32,961 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(77, 1)
2014-07-11 11:45:32,961 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 155 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:32,962 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2014-07-11 11:45:32,962 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 77 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:45:32,962 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075105322 s
2014-07-11 11:45:32,967 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:32,968 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:32,968 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:32,968 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:32,969 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:32,970 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[314] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:32,971 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 78 (MappedRDD[314] at map at CalEigenVector.scala:38)
2014-07-11 11:45:32,971 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 2 tasks
2014-07-11 11:45:32,972 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 156 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,972 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:32,972 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:1 as TID 157 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:32,972 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:32,973 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 156
2014-07-11 11:45:32,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,975 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:32,975 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 157
2014-07-11 11:45:32,976 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:32,976 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:32,977 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,039 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 157 is 678
2014-07-11 11:45:33,039 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 157 directly to driver
2014-07-11 11:45:33,039 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 157
2014-07-11 11:45:33,040 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 157 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,040 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 1)
2014-07-11 11:45:33,041 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 156 is 678
2014-07-11 11:45:33,042 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 156 directly to driver
2014-07-11 11:45:33,042 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 156
2014-07-11 11:45:33,042 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-11 11:45:33,042 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:33,042 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 156 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,043 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,043 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075482644 s
2014-07-11 11:45:33,048 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,048 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,048 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 79(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,048 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,050 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,050 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 79 (MappedRDD[318] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,052 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 79 (MappedRDD[318] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,052 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 79.0 with 2 tasks
2014-07-11 11:45:33,053 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 79.0:0 as TID 158 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,053 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 79.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:33,053 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 79.0:1 as TID 159 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,053 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 79.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:33,054 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 159
2014-07-11 11:45:33,055 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,056 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,056 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,061 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 158
2014-07-11 11:45:33,062 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,063 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,063 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,120 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 159 is 678
2014-07-11 11:45:33,121 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 159 directly to driver
2014-07-11 11:45:33,121 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 159
2014-07-11 11:45:33,121 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(79, 1)
2014-07-11 11:45:33,121 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 159 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,126 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 158 is 678
2014-07-11 11:45:33,126 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 158 directly to driver
2014-07-11 11:45:33,126 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 158
2014-07-11 11:45:33,127 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(79, 0)
2014-07-11 11:45:33,127 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 79 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:45:33,127 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 158 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,127 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,127 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.0798033 s
2014-07-11 11:45:33,132 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[322] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,136 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 80 (MappedRDD[322] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,136 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 2 tasks
2014-07-11 11:45:33,137 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 160 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,137 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:33,137 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:1 as TID 161 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,137 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:33,138 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 160
2014-07-11 11:45:33,139 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 161
2014-07-11 11:45:33,140 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,140 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,140 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,140 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,141 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,141 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 161 is 678
2014-07-11 11:45:33,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 161 directly to driver
2014-07-11 11:45:33,205 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 161
2014-07-11 11:45:33,205 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 161 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,205 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 1)
2014-07-11 11:45:33,206 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 160 is 678
2014-07-11 11:45:33,206 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 160 directly to driver
2014-07-11 11:45:33,207 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 160
2014-07-11 11:45:33,207 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-11 11:45:33,207 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 160 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,208 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,208 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:45:33,208 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075300568 s
2014-07-11 11:45:33,213 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,214 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,214 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 81(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,214 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,217 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,217 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 81 (MappedRDD[326] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,219 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 81 (MappedRDD[326] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,219 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 81.0 with 2 tasks
2014-07-11 11:45:33,219 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 81.0:0 as TID 162 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,220 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 81.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:33,220 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 81.0:1 as TID 163 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,220 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 81.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:33,220 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 162
2014-07-11 11:45:33,221 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 163
2014-07-11 11:45:33,221 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,222 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,222 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,222 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,223 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,223 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,286 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 162 is 678
2014-07-11 11:45:33,286 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 163 is 678
2014-07-11 11:45:33,286 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 162 directly to driver
2014-07-11 11:45:33,286 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 163 directly to driver
2014-07-11 11:45:33,287 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 162
2014-07-11 11:45:33,287 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 163
2014-07-11 11:45:33,287 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 162 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,287 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(81, 0)
2014-07-11 11:45:33,288 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(81, 1)
2014-07-11 11:45:33,288 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 163 in 68 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,288 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,288 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 81 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:45:33,288 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075444546 s
2014-07-11 11:45:33,293 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,294 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,294 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,294 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,296 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,296 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[330] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,297 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 82 (MappedRDD[330] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,297 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 2 tasks
2014-07-11 11:45:33,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 164 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:33,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:1 as TID 165 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,299 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:33,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 164
2014-07-11 11:45:33,299 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 165
2014-07-11 11:45:33,300 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,300 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,301 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,301 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,301 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,301 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 165 is 678
2014-07-11 11:45:33,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 165 directly to driver
2014-07-11 11:45:33,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 165
2014-07-11 11:45:33,364 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 1)
2014-07-11 11:45:33,364 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 165 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 164 is 678
2014-07-11 11:45:33,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 164 directly to driver
2014-07-11 11:45:33,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 164
2014-07-11 11:45:33,365 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 164 in 67 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,365 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,365 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-11 11:45:33,365 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:45:33,366 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072167631 s
2014-07-11 11:45:33,374 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 83(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,376 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,376 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 83 (MappedRDD[334] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 83 (MappedRDD[334] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 83.0 with 2 tasks
2014-07-11 11:45:33,381 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 83.0:0 as TID 166 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,381 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 83.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:33,381 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 83.0:1 as TID 167 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,381 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 83.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:33,382 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 166
2014-07-11 11:45:33,382 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 167
2014-07-11 11:45:33,383 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,383 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,383 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,384 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,384 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,385 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 166 is 678
2014-07-11 11:45:33,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 166 directly to driver
2014-07-11 11:45:33,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 166
2014-07-11 11:45:33,440 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 166 in 60 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,440 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(83, 0)
2014-07-11 11:45:33,473 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 167 is 678
2014-07-11 11:45:33,473 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 167 directly to driver
2014-07-11 11:45:33,473 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 167
2014-07-11 11:45:33,474 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(83, 1)
2014-07-11 11:45:33,474 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 83 (reduce at CalEigenVector.scala:38) finished in 0.094 s
2014-07-11 11:45:33,474 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 167 in 92 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,474 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,474 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.100285067 s
2014-07-11 11:45:33,481 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,482 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,482 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,482 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,485 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,485 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[338] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,495 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 84 (MappedRDD[338] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,496 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 2 tasks
2014-07-11 11:45:33,496 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 168 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,497 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:33,497 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:1 as TID 169 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,497 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:33,497 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 168
2014-07-11 11:45:33,498 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,499 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,499 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 169
2014-07-11 11:45:33,503 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,504 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,504 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,553 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 168 is 678
2014-07-11 11:45:33,553 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 168 directly to driver
2014-07-11 11:45:33,554 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 168 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,554 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-11 11:45:33,554 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 168
2014-07-11 11:45:33,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 169 is 678
2014-07-11 11:45:33,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 169 directly to driver
2014-07-11 11:45:33,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 169
2014-07-11 11:45:33,579 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 1)
2014-07-11 11:45:33,579 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:45:33,579 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 169 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,579 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,579 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.09837345 s
2014-07-11 11:45:33,584 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,585 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,585 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 85(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,585 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,588 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,588 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 85 (MappedRDD[342] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,591 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 85 (MappedRDD[342] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,591 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 85.0 with 2 tasks
2014-07-11 11:45:33,592 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 85.0:0 as TID 170 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,592 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 85.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:33,592 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 85.0:1 as TID 171 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,592 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 85.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:33,593 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 170
2014-07-11 11:45:33,593 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 171
2014-07-11 11:45:33,594 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,595 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,595 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,601 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,602 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,602 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,657 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 170 is 678
2014-07-11 11:45:33,657 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 170 directly to driver
2014-07-11 11:45:33,658 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 170
2014-07-11 11:45:33,658 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(85, 0)
2014-07-11 11:45:33,658 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 170 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 171 is 678
2014-07-11 11:45:33,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 171 directly to driver
2014-07-11 11:45:33,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 171
2014-07-11 11:45:33,669 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 171 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,669 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,669 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(85, 1)
2014-07-11 11:45:33,669 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 85 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:45:33,670 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085208684 s
2014-07-11 11:45:33,674 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,675 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,675 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,675 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,676 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,677 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[346] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,678 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 86 (MappedRDD[346] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,678 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 2 tasks
2014-07-11 11:45:33,679 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 172 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,679 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:33,679 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:1 as TID 173 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,679 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:33,679 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 172
2014-07-11 11:45:33,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 173
2014-07-11 11:45:33,681 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,681 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,681 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,682 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,681 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,685 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,740 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 172 is 678
2014-07-11 11:45:33,740 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 172 directly to driver
2014-07-11 11:45:33,741 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 172
2014-07-11 11:45:33,741 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 172 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,741 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-11 11:45:33,749 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 173 is 678
2014-07-11 11:45:33,749 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 173 directly to driver
2014-07-11 11:45:33,749 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 173
2014-07-11 11:45:33,750 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 173 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,750 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,750 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 1)
2014-07-11 11:45:33,751 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:33,751 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076373267 s
2014-07-11 11:45:33,756 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,757 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,757 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 87(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,757 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,758 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,758 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 87 (MappedRDD[350] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,759 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 87 (MappedRDD[350] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,760 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 87.0 with 2 tasks
2014-07-11 11:45:33,760 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 87.0:0 as TID 174 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,760 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 87.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:33,761 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 87.0:1 as TID 175 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,761 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 87.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:33,761 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 174
2014-07-11 11:45:33,761 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 175
2014-07-11 11:45:33,763 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,763 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,763 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,764 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,764 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,764 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 175 is 678
2014-07-11 11:45:33,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 175 directly to driver
2014-07-11 11:45:33,824 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 174 is 678
2014-07-11 11:45:33,824 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 174 directly to driver
2014-07-11 11:45:33,824 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 175 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,824 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(87, 1)
2014-07-11 11:45:33,824 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 174
2014-07-11 11:45:33,825 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(87, 0)
2014-07-11 11:45:33,825 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 174 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,825 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 87 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:45:33,825 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,825 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069257164 s
2014-07-11 11:45:33,827 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 175
2014-07-11 11:45:33,830 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,831 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,831 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,831 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[354] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,834 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 88 (MappedRDD[354] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,834 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 2 tasks
2014-07-11 11:45:33,835 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 176 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,835 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:33,835 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:1 as TID 177 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,835 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:33,836 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 176
2014-07-11 11:45:33,836 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 177
2014-07-11 11:45:33,837 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,838 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,838 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,839 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,840 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,841 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,894 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 177 is 678
2014-07-11 11:45:33,894 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 177 directly to driver
2014-07-11 11:45:33,894 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 177
2014-07-11 11:45:33,895 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 1)
2014-07-11 11:45:33,895 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 177 in 60 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,899 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 176 is 678
2014-07-11 11:45:33,899 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 176 directly to driver
2014-07-11 11:45:33,899 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 176
2014-07-11 11:45:33,900 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-11 11:45:33,900 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:45:33,900 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 176 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,900 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,900 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070087948 s
2014-07-11 11:45:33,909 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,909 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,910 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 89(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,910 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,911 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,911 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 89 (MappedRDD[358] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,912 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 89 (MappedRDD[358] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,912 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 89.0 with 2 tasks
2014-07-11 11:45:33,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 89.0:0 as TID 178 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 89.0:0 as 2293 bytes in 0 ms
2014-07-11 11:45:33,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 89.0:1 as TID 179 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,914 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 89.0:1 as 2293 bytes in 0 ms
2014-07-11 11:45:33,914 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 178
2014-07-11 11:45:33,915 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 179
2014-07-11 11:45:33,916 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,917 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,917 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,917 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,921 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,921 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,981 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 178 is 678
2014-07-11 11:45:33,981 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 178 directly to driver
2014-07-11 11:45:33,981 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 178
2014-07-11 11:45:33,982 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(89, 0)
2014-07-11 11:45:33,982 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 178 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:33,985 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 179 is 678
2014-07-11 11:45:33,985 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 179 directly to driver
2014-07-11 11:45:33,985 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 179
2014-07-11 11:45:33,986 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(89, 1)
2014-07-11 11:45:33,986 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 179 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:33,986 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 89 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:33,986 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 89.0, whose tasks have all completed, from pool 
2014-07-11 11:45:33,986 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077578755 s
2014-07-11 11:45:33,991 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:33,992 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:33,992 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:33,992 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:33,993 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:33,994 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[362] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:33,995 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 90 (MappedRDD[362] at map at CalEigenVector.scala:38)
2014-07-11 11:45:33,995 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 2 tasks
2014-07-11 11:45:33,996 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 180 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,996 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:33,996 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:1 as TID 181 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:33,996 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:33,996 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 180
2014-07-11 11:45:33,996 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 181
2014-07-11 11:45:33,997 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,998 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:33,998 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,998 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:33,998 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:33,998 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,062 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 181 is 678
2014-07-11 11:45:34,062 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 181 directly to driver
2014-07-11 11:45:34,063 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 181 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,063 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 1)
2014-07-11 11:45:34,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 180 is 678
2014-07-11 11:45:34,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 180 directly to driver
2014-07-11 11:45:34,063 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 181
2014-07-11 11:45:34,064 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-11 11:45:34,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 180
2014-07-11 11:45:34,064 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 180 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,064 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:45:34,064 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,064 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072980798 s
2014-07-11 11:45:34,069 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,070 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,070 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 91(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,070 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,071 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,072 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 91 (MappedRDD[366] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,073 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 91 (MappedRDD[366] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,073 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 91.0 with 2 tasks
2014-07-11 11:45:34,074 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 91.0:0 as TID 182 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,074 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 91.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:34,074 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 91.0:1 as TID 183 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,075 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 91.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:34,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 183
2014-07-11 11:45:34,076 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 182
2014-07-11 11:45:34,077 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,077 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,077 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,078 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,079 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,141 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 183 is 678
2014-07-11 11:45:34,141 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 183 directly to driver
2014-07-11 11:45:34,141 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 183
2014-07-11 11:45:34,142 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(91, 1)
2014-07-11 11:45:34,142 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 183 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,146 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 182 is 678
2014-07-11 11:45:34,146 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 182 directly to driver
2014-07-11 11:45:34,147 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 182
2014-07-11 11:45:34,147 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(91, 0)
2014-07-11 11:45:34,147 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 91 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:34,147 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 182 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,149 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079988884 s
2014-07-11 11:45:34,157 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,161 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,162 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,162 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,162 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,163 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,164 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[370] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 92 (MappedRDD[370] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 2 tasks
2014-07-11 11:45:34,165 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 184 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,166 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:34,166 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:1 as TID 185 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,166 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:34,166 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 184
2014-07-11 11:45:34,168 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,169 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,169 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,169 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 185
2014-07-11 11:45:34,170 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,171 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,171 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 184 is 678
2014-07-11 11:45:34,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 184 directly to driver
2014-07-11 11:45:34,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 184
2014-07-11 11:45:34,233 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 184 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,233 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-11 11:45:34,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 185 is 678
2014-07-11 11:45:34,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 185 directly to driver
2014-07-11 11:45:34,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 185
2014-07-11 11:45:34,242 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 185 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,242 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,245 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 1)
2014-07-11 11:45:34,245 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:45:34,245 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.0840485 s
2014-07-11 11:45:34,250 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,251 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,251 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 93(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,251 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,252 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,253 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 93 (MappedRDD[374] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,254 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 93 (MappedRDD[374] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,254 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 93.0 with 2 tasks
2014-07-11 11:45:34,255 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 93.0:0 as TID 186 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,255 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 93.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:34,255 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 93.0:1 as TID 187 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,255 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 93.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:34,256 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 187
2014-07-11 11:45:34,256 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 186
2014-07-11 11:45:34,257 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,258 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,258 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,260 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,261 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,261 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,332 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 187 is 678
2014-07-11 11:45:34,333 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 187 directly to driver
2014-07-11 11:45:34,333 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 187
2014-07-11 11:45:34,333 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(93, 1)
2014-07-11 11:45:34,333 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 187 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,371 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 186 is 678
2014-07-11 11:45:34,371 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 186 directly to driver
2014-07-11 11:45:34,373 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 186 in 119 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,373 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,373 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(93, 0)
2014-07-11 11:45:34,374 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 93 (reduce at CalEigenVector.scala:38) finished in 0.119 s
2014-07-11 11:45:34,374 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.123752357 s
2014-07-11 11:45:34,384 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 186
2014-07-11 11:45:34,385 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,385 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,386 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,386 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,388 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,389 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[378] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,392 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 94 (MappedRDD[378] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,393 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 2 tasks
2014-07-11 11:45:34,393 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 188 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,394 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2296 bytes in 1 ms
2014-07-11 11:45:34,394 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:1 as TID 189 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,394 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:34,394 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 189
2014-07-11 11:45:34,396 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,397 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,397 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,399 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 188
2014-07-11 11:45:34,401 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,404 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,404 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,467 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 189 is 678
2014-07-11 11:45:34,467 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 189 directly to driver
2014-07-11 11:45:34,467 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 189
2014-07-11 11:45:34,468 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 1)
2014-07-11 11:45:34,468 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 189 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,474 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 188 is 678
2014-07-11 11:45:34,474 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 188 directly to driver
2014-07-11 11:45:34,475 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 188
2014-07-11 11:45:34,475 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-11 11:45:34,475 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 188 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,475 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,475 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:45:34,475 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.090539854 s
2014-07-11 11:45:34,481 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,482 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,482 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 95(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,482 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,486 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,487 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 95 (MappedRDD[382] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,489 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 95 (MappedRDD[382] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,489 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 95.0 with 2 tasks
2014-07-11 11:45:34,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 95.0:0 as TID 190 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 95.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:34,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 95.0:1 as TID 191 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 95.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:34,491 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 190
2014-07-11 11:45:34,491 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 191
2014-07-11 11:45:34,492 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,493 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,493 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,497 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,499 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,499 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 190 is 678
2014-07-11 11:45:34,559 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 190 directly to driver
2014-07-11 11:45:34,559 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 190
2014-07-11 11:45:34,571 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(95, 0)
2014-07-11 11:45:34,571 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 190 in 82 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,576 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 191 is 678
2014-07-11 11:45:34,576 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 191 directly to driver
2014-07-11 11:45:34,577 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(95, 1)
2014-07-11 11:45:34,577 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 95 (reduce at CalEigenVector.scala:38) finished in 0.087 s
2014-07-11 11:45:34,577 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 191 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,577 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 95.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,578 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.096364493 s
2014-07-11 11:45:34,579 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 191
2014-07-11 11:45:34,582 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,583 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,583 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,583 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,585 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,586 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[386] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,587 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 96 (MappedRDD[386] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,587 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 2 tasks
2014-07-11 11:45:34,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 192 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:34,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:1 as TID 193 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:34,589 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 192
2014-07-11 11:45:34,589 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 193
2014-07-11 11:45:34,590 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,590 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,591 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,591 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,592 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,592 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 192 is 678
2014-07-11 11:45:34,670 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 192 directly to driver
2014-07-11 11:45:34,671 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 192
2014-07-11 11:45:34,675 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 192 in 87 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,675 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-11 11:45:34,711 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 193 is 678
2014-07-11 11:45:34,711 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 193 directly to driver
2014-07-11 11:45:34,711 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 193
2014-07-11 11:45:34,712 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 193 in 124 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,712 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,712 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 1)
2014-07-11 11:45:34,712 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at CalEigenVector.scala:38) finished in 0.123 s
2014-07-11 11:45:34,713 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.130304562 s
2014-07-11 11:45:34,719 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,721 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,721 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 97(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,721 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,723 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,723 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 97 (MappedRDD[390] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,725 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 97 (MappedRDD[390] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,725 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 97.0 with 2 tasks
2014-07-11 11:45:34,725 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 97.0:0 as TID 194 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,725 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 97.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:34,726 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 97.0:1 as TID 195 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,726 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 97.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:34,726 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 195
2014-07-11 11:45:34,727 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,728 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,728 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,736 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 194
2014-07-11 11:45:34,737 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,738 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,738 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,795 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 195 is 678
2014-07-11 11:45:34,797 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 195 directly to driver
2014-07-11 11:45:34,798 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 195 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,798 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(97, 1)
2014-07-11 11:45:34,798 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 195
2014-07-11 11:45:34,804 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 194 is 678
2014-07-11 11:45:34,804 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 194 directly to driver
2014-07-11 11:45:34,805 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 194 in 80 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,805 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 97.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,805 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(97, 0)
2014-07-11 11:45:34,806 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 97 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:45:34,806 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086409625 s
2014-07-11 11:45:34,811 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,812 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,812 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,812 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,814 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,815 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[394] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,823 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 98 (MappedRDD[394] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,824 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 2 tasks
2014-07-11 11:45:34,824 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 196 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,825 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2297 bytes in 1 ms
2014-07-11 11:45:34,825 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:1 as TID 197 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,825 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:34,825 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 196
2014-07-11 11:45:34,826 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,827 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,827 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,830 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 197
2014-07-11 11:45:34,833 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,834 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,834 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 194
2014-07-11 11:45:34,902 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 196 is 678
2014-07-11 11:45:34,902 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 196 directly to driver
2014-07-11 11:45:34,902 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-11 11:45:34,902 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 196 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:45:34,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 196
2014-07-11 11:45:34,936 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 197 is 678
2014-07-11 11:45:34,937 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 197 directly to driver
2014-07-11 11:45:34,937 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 197
2014-07-11 11:45:34,937 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 1)
2014-07-11 11:45:34,937 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at CalEigenVector.scala:38) finished in 0.105 s
2014-07-11 11:45:34,937 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 197 in 112 ms on localhost (progress: 2/2)
2014-07-11 11:45:34,938 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-11 11:45:34,938 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.126100718 s
2014-07-11 11:45:34,942 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:34,943 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:34,943 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 99(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:34,943 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:34,946 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:34,946 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 99 (MappedRDD[398] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:34,947 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 99 (MappedRDD[398] at map at CalEigenVector.scala:38)
2014-07-11 11:45:34,947 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 99.0 with 2 tasks
2014-07-11 11:45:34,948 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 99.0:0 as TID 198 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,948 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 99.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:34,948 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 99.0:1 as TID 199 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:34,948 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 99.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:34,949 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 198
2014-07-11 11:45:34,949 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 199
2014-07-11 11:45:34,949 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,950 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:34,950 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,950 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:34,950 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:34,950 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,005 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 198 is 678
2014-07-11 11:45:35,006 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 198 directly to driver
2014-07-11 11:45:35,006 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 198
2014-07-11 11:45:35,006 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(99, 0)
2014-07-11 11:45:35,006 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 198 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,016 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 199 is 678
2014-07-11 11:45:35,016 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 199 directly to driver
2014-07-11 11:45:35,017 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 199
2014-07-11 11:45:35,017 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(99, 1)
2014-07-11 11:45:35,017 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 199 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,017 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,017 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 99 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:45:35,019 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076815532 s
2014-07-11 11:45:35,025 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,026 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,026 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,026 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,027 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,027 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[402] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,028 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 100 (MappedRDD[402] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,029 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 2 tasks
2014-07-11 11:45:35,029 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 200 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,029 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:35,029 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:1 as TID 201 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,030 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:1 as 2295 bytes in 1 ms
2014-07-11 11:45:35,030 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 200
2014-07-11 11:45:35,030 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 201
2014-07-11 11:45:35,032 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,033 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,033 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,038 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,042 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,042 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,124 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 201 is 678
2014-07-11 11:45:35,124 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 201 directly to driver
2014-07-11 11:45:35,125 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 201 in 96 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 200 is 678
2014-07-11 11:45:35,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 200 directly to driver
2014-07-11 11:45:35,125 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 1)
2014-07-11 11:45:35,126 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 201
2014-07-11 11:45:35,126 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-11 11:45:35,126 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 200 in 97 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,126 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,126 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at CalEigenVector.scala:38) finished in 0.097 s
2014-07-11 11:45:35,126 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 200
2014-07-11 11:45:35,127 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.101271472 s
2014-07-11 11:45:35,133 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,133 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,133 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 101(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,133 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,135 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,135 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 101 (MappedRDD[406] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,137 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 101 (MappedRDD[406] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,137 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 101.0 with 2 tasks
2014-07-11 11:45:35,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 101.0:0 as TID 202 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 101.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:35,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 101.0:1 as TID 203 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 101.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,138 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 203
2014-07-11 11:45:35,139 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 202
2014-07-11 11:45:35,139 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,140 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,140 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,140 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,141 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,141 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,202 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 202 is 678
2014-07-11 11:45:35,202 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 202 directly to driver
2014-07-11 11:45:35,203 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 202 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,203 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(101, 0)
2014-07-11 11:45:35,203 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 202
2014-07-11 11:45:35,214 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 203 is 678
2014-07-11 11:45:35,214 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 203 directly to driver
2014-07-11 11:45:35,214 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 203
2014-07-11 11:45:35,214 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(101, 1)
2014-07-11 11:45:35,215 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 101 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:45:35,214 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 203 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,215 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 101.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,215 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081959648 s
2014-07-11 11:45:35,221 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,222 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,222 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,222 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,224 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,225 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[410] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,230 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 102 (MappedRDD[410] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,231 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 2 tasks
2014-07-11 11:45:35,231 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 204 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,232 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:35,232 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:1 as TID 205 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,232 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:35,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 205
2014-07-11 11:45:35,233 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 204
2014-07-11 11:45:35,233 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,233 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,234 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,234 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,234 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,234 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,303 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 204 is 678
2014-07-11 11:45:35,303 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 204 directly to driver
2014-07-11 11:45:35,304 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 204 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,304 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-11 11:45:35,304 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 204
2014-07-11 11:45:35,321 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 205 is 678
2014-07-11 11:45:35,321 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 205 directly to driver
2014-07-11 11:45:35,321 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 205
2014-07-11 11:45:35,322 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 1)
2014-07-11 11:45:35,322 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 205 in 90 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,323 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,323 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at CalEigenVector.scala:38) finished in 0.091 s
2014-07-11 11:45:35,323 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.101647749 s
2014-07-11 11:45:35,329 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,330 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,330 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 103(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,330 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,332 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,332 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 103 (MappedRDD[414] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,334 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 103 (MappedRDD[414] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,334 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 103.0 with 2 tasks
2014-07-11 11:45:35,334 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 103.0:0 as TID 206 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,335 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 103.0:0 as 2296 bytes in 1 ms
2014-07-11 11:45:35,335 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 103.0:1 as TID 207 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,335 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 103.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,335 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 206
2014-07-11 11:45:35,336 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 207
2014-07-11 11:45:35,336 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,337 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,337 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,337 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,337 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,337 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,398 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 206 is 678
2014-07-11 11:45:35,398 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 206 directly to driver
2014-07-11 11:45:35,399 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 206 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,399 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(103, 0)
2014-07-11 11:45:35,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 206
2014-07-11 11:45:35,406 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 207 is 678
2014-07-11 11:45:35,406 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 207 directly to driver
2014-07-11 11:45:35,406 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 207
2014-07-11 11:45:35,407 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 207 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,407 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,407 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(103, 1)
2014-07-11 11:45:35,407 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 103 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:35,408 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078232162 s
2014-07-11 11:45:35,413 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,414 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,414 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,414 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,415 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,415 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[418] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,416 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 104 (MappedRDD[418] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,416 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 2 tasks
2014-07-11 11:45:35,417 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 208 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,417 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:35,417 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:1 as TID 209 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,417 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,418 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 208
2014-07-11 11:45:35,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 209
2014-07-11 11:45:35,418 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,419 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,419 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,419 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,419 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,419 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,481 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 208 is 678
2014-07-11 11:45:35,481 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 208 directly to driver
2014-07-11 11:45:35,481 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 208
2014-07-11 11:45:35,482 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 208 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,482 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-11 11:45:35,485 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 209 is 678
2014-07-11 11:45:35,485 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 209 directly to driver
2014-07-11 11:45:35,486 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 209
2014-07-11 11:45:35,486 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 1)
2014-07-11 11:45:35,486 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:45:35,486 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 209 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,486 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,487 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.073642974 s
2014-07-11 11:45:35,492 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,493 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,493 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 105(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,493 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,494 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,495 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 105 (MappedRDD[422] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,496 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 105 (MappedRDD[422] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,496 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 105.0 with 2 tasks
2014-07-11 11:45:35,496 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 105.0:0 as TID 210 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,497 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 105.0:0 as 2296 bytes in 1 ms
2014-07-11 11:45:35,497 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 105.0:1 as TID 211 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,497 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 105.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 210
2014-07-11 11:45:35,498 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,499 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,499 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,500 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 211
2014-07-11 11:45:35,500 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,501 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,502 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,576 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 210 is 678
2014-07-11 11:45:35,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 210 directly to driver
2014-07-11 11:45:35,578 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 210 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(105, 0)
2014-07-11 11:45:35,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 210
2014-07-11 11:45:35,582 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 211 is 678
2014-07-11 11:45:35,583 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 211 directly to driver
2014-07-11 11:45:35,583 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 211
2014-07-11 11:45:35,583 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(105, 1)
2014-07-11 11:45:35,583 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 211 in 86 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,583 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,583 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 105 (reduce at CalEigenVector.scala:38) finished in 0.086 s
2014-07-11 11:45:35,584 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.091369555 s
2014-07-11 11:45:35,593 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,593 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,593 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,594 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,595 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,595 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[426] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,596 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 106 (MappedRDD[426] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,596 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 2 tasks
2014-07-11 11:45:35,597 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 212 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,597 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:35,597 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:1 as TID 213 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,597 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,598 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 212
2014-07-11 11:45:35,598 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,599 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 213
2014-07-11 11:45:35,599 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,600 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,600 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,601 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,601 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,659 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 213 is 678
2014-07-11 11:45:35,660 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 213 directly to driver
2014-07-11 11:45:35,660 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 213
2014-07-11 11:45:35,660 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 1)
2014-07-11 11:45:35,660 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 213 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,661 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 212 is 678
2014-07-11 11:45:35,661 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 212 directly to driver
2014-07-11 11:45:35,661 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 212
2014-07-11 11:45:35,661 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-11 11:45:35,661 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 212 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,661 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,661 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:45:35,662 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.068834598 s
2014-07-11 11:45:35,667 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,667 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,667 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 107(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,668 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,669 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,669 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 107 (MappedRDD[430] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,670 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 107 (MappedRDD[430] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,670 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 107.0 with 2 tasks
2014-07-11 11:45:35,671 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 107.0:0 as TID 214 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,671 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 107.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:35,671 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 107.0:1 as TID 215 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,671 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 107.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,671 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 214
2014-07-11 11:45:35,672 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 215
2014-07-11 11:45:35,672 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,672 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,673 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,673 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,729 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 214 is 678
2014-07-11 11:45:35,729 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 214 directly to driver
2014-07-11 11:45:35,729 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 214
2014-07-11 11:45:35,730 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(107, 0)
2014-07-11 11:45:35,730 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 214 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,731 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 215 is 678
2014-07-11 11:45:35,731 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 215 directly to driver
2014-07-11 11:45:35,731 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 215
2014-07-11 11:45:35,732 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(107, 1)
2014-07-11 11:45:35,732 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 215 in 60 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,732 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 107.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,732 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 107 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:45:35,732 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.06504334 s
2014-07-11 11:45:35,737 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,737 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,737 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,737 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,739 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,739 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[434] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,740 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 108 (MappedRDD[434] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,740 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 2 tasks
2014-07-11 11:45:35,741 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 216 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,741 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:35,741 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:1 as TID 217 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,741 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 216
2014-07-11 11:45:35,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,745 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 217
2014-07-11 11:45:35,747 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,748 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,748 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,797 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 216 is 678
2014-07-11 11:45:35,797 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 216 directly to driver
2014-07-11 11:45:35,797 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 216
2014-07-11 11:45:35,797 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-11 11:45:35,797 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 216 in 57 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,804 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 217 is 678
2014-07-11 11:45:35,805 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 217 directly to driver
2014-07-11 11:45:35,806 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 217
2014-07-11 11:45:35,806 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 217 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,806 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 1)
2014-07-11 11:45:35,807 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,807 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:45:35,807 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070617399 s
2014-07-11 11:45:35,812 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,813 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,813 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 109(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,813 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,814 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,815 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 109 (MappedRDD[438] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,816 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 109 (MappedRDD[438] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,816 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 109.0 with 2 tasks
2014-07-11 11:45:35,816 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 109.0:0 as TID 218 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,816 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 109.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:35,817 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 109.0:1 as TID 219 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,817 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 109.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:35,817 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 219
2014-07-11 11:45:35,818 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,819 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,819 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,824 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 218
2014-07-11 11:45:35,830 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,831 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,831 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,863 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 219 is 678
2014-07-11 11:45:35,863 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 219 directly to driver
2014-07-11 11:45:35,863 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 219
2014-07-11 11:45:35,864 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(109, 1)
2014-07-11 11:45:35,864 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 219 in 47 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,882 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 218 is 678
2014-07-11 11:45:35,882 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 218 directly to driver
2014-07-11 11:45:35,882 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 218
2014-07-11 11:45:35,883 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 218 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,883 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,883 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(109, 0)
2014-07-11 11:45:35,883 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 109 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:45:35,883 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070659283 s
2014-07-11 11:45:35,888 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,888 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,888 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,888 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,890 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,890 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[442] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,891 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 110 (MappedRDD[442] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,891 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 2 tasks
2014-07-11 11:45:35,892 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 220 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,892 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:35,892 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:1 as TID 221 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:35,892 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:35,892 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 220
2014-07-11 11:45:35,893 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 221
2014-07-11 11:45:35,893 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,894 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,894 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:35,896 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:35,897 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,897 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:35,944 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 221 is 678
2014-07-11 11:45:35,945 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 221 directly to driver
2014-07-11 11:45:35,945 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 221
2014-07-11 11:45:35,945 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 221 in 53 ms on localhost (progress: 1/2)
2014-07-11 11:45:35,946 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 1)
2014-07-11 11:45:35,979 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 220 is 678
2014-07-11 11:45:35,979 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 220 directly to driver
2014-07-11 11:45:35,980 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 220 in 88 ms on localhost (progress: 2/2)
2014-07-11 11:45:35,980 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-11 11:45:35,980 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-11 11:45:35,980 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at CalEigenVector.scala:38) finished in 0.089 s
2014-07-11 11:45:35,981 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092858196 s
2014-07-11 11:45:35,988 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:35,988 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 220
2014-07-11 11:45:35,989 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:35,989 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 111(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:35,989 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:35,993 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:35,994 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 111 (MappedRDD[446] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:35,998 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 111 (MappedRDD[446] at map at CalEigenVector.scala:38)
2014-07-11 11:45:35,999 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 111.0 with 2 tasks
2014-07-11 11:45:36,000 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 111.0:0 as TID 222 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,000 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 111.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:36,000 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 111.0:1 as TID 223 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,001 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 111.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:36,001 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 222
2014-07-11 11:45:36,002 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,002 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 223
2014-07-11 11:45:36,003 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,003 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,003 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,004 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,004 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,061 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 222 is 678
2014-07-11 11:45:36,061 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 222 directly to driver
2014-07-11 11:45:36,062 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 222
2014-07-11 11:45:36,062 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 222 in 62 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,062 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(111, 0)
2014-07-11 11:45:36,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 223 is 678
2014-07-11 11:45:36,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 223 directly to driver
2014-07-11 11:45:36,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 223
2014-07-11 11:45:36,081 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(111, 1)
2014-07-11 11:45:36,081 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 223 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,081 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,081 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 111 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:45:36,081 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092965791 s
2014-07-11 11:45:36,086 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,092 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,093 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[450] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,095 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 112 (MappedRDD[450] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,095 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 2 tasks
2014-07-11 11:45:36,096 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 224 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,096 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,096 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:1 as TID 225 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,096 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,097 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 224
2014-07-11 11:45:36,098 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,098 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,099 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,099 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 225
2014-07-11 11:45:36,100 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,101 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,101 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,172 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 225 is 678
2014-07-11 11:45:36,172 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 225 directly to driver
2014-07-11 11:45:36,172 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 224 is 678
2014-07-11 11:45:36,172 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 224 directly to driver
2014-07-11 11:45:36,173 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 1)
2014-07-11 11:45:36,173 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 224
2014-07-11 11:45:36,172 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 225
2014-07-11 11:45:36,173 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 225 in 76 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,173 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-11 11:45:36,173 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 224 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,173 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:45:36,174 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,174 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.087602703 s
2014-07-11 11:45:36,178 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,179 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,179 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 113(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,179 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,180 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,181 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 113 (MappedRDD[454] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,182 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 113 (MappedRDD[454] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,182 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 113.0 with 2 tasks
2014-07-11 11:45:36,182 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 113.0:0 as TID 226 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,183 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 113.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,183 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 113.0:1 as TID 227 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,183 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 113.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,184 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 227
2014-07-11 11:45:36,184 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 226
2014-07-11 11:45:36,185 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,185 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,186 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,189 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,189 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,190 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,254 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 227 is 678
2014-07-11 11:45:36,254 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 227 directly to driver
2014-07-11 11:45:36,255 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 227 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,255 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 226 is 678
2014-07-11 11:45:36,255 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 226 directly to driver
2014-07-11 11:45:36,255 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(113, 1)
2014-07-11 11:45:36,255 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 227
2014-07-11 11:45:36,256 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 226 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,256 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 113.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,256 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(113, 0)
2014-07-11 11:45:36,256 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 113 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:45:36,256 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077611974 s
2014-07-11 11:45:36,256 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 226
2014-07-11 11:45:36,261 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,261 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,261 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,261 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,263 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,263 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[458] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,266 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 114 (MappedRDD[458] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,266 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 2 tasks
2014-07-11 11:45:36,266 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 228 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:1 as TID 229 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,267 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 228
2014-07-11 11:45:36,267 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 229
2014-07-11 11:45:36,268 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,268 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,269 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,269 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,269 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,269 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 229 is 678
2014-07-11 11:45:36,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 229 directly to driver
2014-07-11 11:45:36,348 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 229 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,348 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 1)
2014-07-11 11:45:36,349 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 229
2014-07-11 11:45:36,355 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 228 is 678
2014-07-11 11:45:36,355 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 228 directly to driver
2014-07-11 11:45:36,355 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 228
2014-07-11 11:45:36,356 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-11 11:45:36,356 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 228 in 90 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,356 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,356 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at CalEigenVector.scala:38) finished in 0.090 s
2014-07-11 11:45:36,356 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.095438811 s
2014-07-11 11:45:36,363 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,364 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,364 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 115(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,364 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,366 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,366 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 115 (MappedRDD[462] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,367 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 115 (MappedRDD[462] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,367 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 115.0 with 2 tasks
2014-07-11 11:45:36,368 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 115.0:0 as TID 230 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,368 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 115.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,368 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 115.0:1 as TID 231 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,368 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 115.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,369 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 230
2014-07-11 11:45:36,370 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,370 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 231
2014-07-11 11:45:36,370 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,371 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,371 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,372 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,372 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,434 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 230 is 678
2014-07-11 11:45:36,434 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 230 directly to driver
2014-07-11 11:45:36,434 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 230
2014-07-11 11:45:36,435 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(115, 0)
2014-07-11 11:45:36,435 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 230 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,436 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 231 is 678
2014-07-11 11:45:36,436 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 231 directly to driver
2014-07-11 11:45:36,436 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 231
2014-07-11 11:45:36,437 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(115, 1)
2014-07-11 11:45:36,437 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 231 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,437 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,437 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 115 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:45:36,437 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.073741407 s
2014-07-11 11:45:36,443 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,444 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,444 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,444 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,446 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,447 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[466] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,448 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 116 (MappedRDD[466] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,448 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 2 tasks
2014-07-11 11:45:36,449 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 232 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,450 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2296 bytes in 1 ms
2014-07-11 11:45:36,450 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:1 as TID 233 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,450 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,450 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 232
2014-07-11 11:45:36,451 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 233
2014-07-11 11:45:36,451 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,452 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,453 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,457 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,459 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,459 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,520 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 232 is 678
2014-07-11 11:45:36,520 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 232 directly to driver
2014-07-11 11:45:36,521 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 232 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,521 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-11 11:45:36,522 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 232
2014-07-11 11:45:36,525 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 233 is 678
2014-07-11 11:45:36,525 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 233 directly to driver
2014-07-11 11:45:36,525 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 233
2014-07-11 11:45:36,525 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 1)
2014-07-11 11:45:36,526 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:45:36,525 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 233 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,526 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,526 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082702172 s
2014-07-11 11:45:36,531 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,532 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,532 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 117(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,532 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,533 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,533 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 117 (MappedRDD[470] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,534 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 117 (MappedRDD[470] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,534 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 117.0 with 2 tasks
2014-07-11 11:45:36,535 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 117.0:0 as TID 234 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,535 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 117.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,535 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 117.0:1 as TID 235 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,536 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 117.0:1 as 2296 bytes in 1 ms
2014-07-11 11:45:36,536 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 235
2014-07-11 11:45:36,537 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 234
2014-07-11 11:45:36,537 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,537 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,538 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,538 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,538 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,538 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,598 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 234 is 678
2014-07-11 11:45:36,598 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 234 directly to driver
2014-07-11 11:45:36,598 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 234
2014-07-11 11:45:36,599 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(117, 0)
2014-07-11 11:45:36,599 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 234 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,606 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 235 is 678
2014-07-11 11:45:36,606 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 235 directly to driver
2014-07-11 11:45:36,606 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 235
2014-07-11 11:45:36,607 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 235 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,607 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(117, 1)
2014-07-11 11:45:36,607 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,607 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 117 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:45:36,607 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075937846 s
2014-07-11 11:45:36,612 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,613 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,613 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,613 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,615 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,615 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[474] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,617 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 118 (MappedRDD[474] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,617 [spark-akka.actor.default-dispatcher-12] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 2 tasks
2014-07-11 11:45:36,618 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 236 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,618 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,618 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:1 as TID 237 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,618 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,619 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 236
2014-07-11 11:45:36,620 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,620 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,621 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,622 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 237
2014-07-11 11:45:36,623 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,624 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,624 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 236 is 678
2014-07-11 11:45:36,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 236 directly to driver
2014-07-11 11:45:36,686 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 236 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,686 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-11 11:45:36,686 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 236
2014-07-11 11:45:36,691 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 237 is 678
2014-07-11 11:45:36,691 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 237 directly to driver
2014-07-11 11:45:36,691 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 237
2014-07-11 11:45:36,691 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 1)
2014-07-11 11:45:36,691 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 237 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,692 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,692 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:45:36,692 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079331349 s
2014-07-11 11:45:36,697 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,698 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,698 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 119(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,698 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,699 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,700 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 119 (MappedRDD[478] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,701 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 119 (MappedRDD[478] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,701 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 119.0 with 2 tasks
2014-07-11 11:45:36,701 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 119.0:0 as TID 238 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,701 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 119.0:0 as 2297 bytes in 0 ms
2014-07-11 11:45:36,702 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 119.0:1 as TID 239 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,702 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 119.0:1 as 2297 bytes in 0 ms
2014-07-11 11:45:36,702 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 239
2014-07-11 11:45:36,704 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,704 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 238
2014-07-11 11:45:36,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,705 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,706 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,706 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,759 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 238 is 678
2014-07-11 11:45:36,759 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 238 directly to driver
2014-07-11 11:45:36,760 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 238 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,760 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(119, 0)
2014-07-11 11:45:36,761 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 238
2014-07-11 11:45:36,767 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 239 is 678
2014-07-11 11:45:36,768 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 239 directly to driver
2014-07-11 11:45:36,768 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 239
2014-07-11 11:45:36,769 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(119, 1)
2014-07-11 11:45:36,769 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 239 in 67 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,769 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 119.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,769 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 119 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:45:36,769 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071976058 s
2014-07-11 11:45:36,774 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,774 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,774 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,774 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,776 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,777 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[482] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,778 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 120 (MappedRDD[482] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,778 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 2 tasks
2014-07-11 11:45:36,778 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 240 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,779 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2296 bytes in 0 ms
2014-07-11 11:45:36,779 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:1 as TID 241 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,779 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:1 as 2296 bytes in 0 ms
2014-07-11 11:45:36,779 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 240
2014-07-11 11:45:36,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,780 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 241
2014-07-11 11:45:36,781 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,782 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,782 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,783 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,784 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,833 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 241 is 678
2014-07-11 11:45:36,833 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 241 directly to driver
2014-07-11 11:45:36,833 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 241
2014-07-11 11:45:36,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 1)
2014-07-11 11:45:36,833 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 241 in 54 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,845 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 240 is 678
2014-07-11 11:45:36,845 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 240 directly to driver
2014-07-11 11:45:36,846 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 240
2014-07-11 11:45:36,846 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 240 in 67 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,846 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,846 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-11 11:45:36,846 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:45:36,846 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072287481 s
2014-07-11 11:45:36,851 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:45:36,852 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:45:36,852 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 121(reduce at CalEigenVector.scala:38)
2014-07-11 11:45:36,852 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:45:36,854 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:45:36,854 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 121 (MappedRDD[486] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:45:36,856 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 121 (MappedRDD[486] at map at CalEigenVector.scala:38)
2014-07-11 11:45:36,856 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 121.0 with 2 tasks
2014-07-11 11:45:36,857 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 121.0:0 as TID 242 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,857 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 121.0:0 as 2295 bytes in 0 ms
2014-07-11 11:45:36,857 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 121.0:1 as TID 243 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:45:36,857 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 121.0:1 as 2295 bytes in 0 ms
2014-07-11 11:45:36,857 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 242
2014-07-11 11:45:36,858 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 243
2014-07-11 11:45:36,858 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,858 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:45:36,859 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,859 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,859 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:45:36,859 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:45:36,905 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 243 is 678
2014-07-11 11:45:36,905 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 243 directly to driver
2014-07-11 11:45:36,906 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 243 in 48 ms on localhost (progress: 1/2)
2014-07-11 11:45:36,906 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(121, 1)
2014-07-11 11:45:36,906 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 243
2014-07-11 11:45:36,913 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 242 is 678
2014-07-11 11:45:36,913 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 242 directly to driver
2014-07-11 11:45:36,913 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 242
2014-07-11 11:45:36,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(121, 0)
2014-07-11 11:45:36,913 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 242 in 56 ms on localhost (progress: 2/2)
2014-07-11 11:45:36,913 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 121.0, whose tasks have all completed, from pool 
2014-07-11 11:45:36,913 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 121 (reduce at CalEigenVector.scala:38) finished in 0.057 s
2014-07-11 11:45:36,914 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.062137502 s
2014-07-11 11:45:37,020 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/static,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2014-07-11 11:45:37,021 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2014-07-11 11:45:37,022 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages,null}
2014-07-11 11:45:37,074 [main] INFO  [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://10.74.147.155:4040
2014-07-11 11:45:37,075 [main] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stopping DAGScheduler
2014-07-11 11:45:38,130 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.MapOutputTrackerMasterActor] - MapOutputTrackerActor stopped!
2014-07-11 11:45:38,184 [connection-manager-thread] INFO  [org.apache.spark.network.ConnectionManager] - Selector thread was interrupted!
2014-07-11 11:45:38,186 [main] INFO  [org.apache.spark.network.ConnectionManager] - ConnectionManager stopped
2014-07-11 11:45:38,188 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore cleared
2014-07-11 11:45:38,188 [main] INFO  [org.apache.spark.storage.BlockManager] - BlockManager stopped
2014-07-11 11:45:38,189 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.storage.BlockManagerMasterActor] - Stopping BlockManagerMaster
2014-07-11 11:45:38,189 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2014-07-11 11:45:38,191 [main] INFO  [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2014-07-11 11:45:38,194 [spark-akka.actor.default-dispatcher-13] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Shutting down remote daemon.
2014-07-11 11:45:38,197 [spark-akka.actor.default-dispatcher-13] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Remote daemon shut down; proceeding with flushing remote transports.
2014-07-11 11:48:47,962 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.155 instead (on interface eth0)
2014-07-11 11:48:47,963 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-11 11:48:48,025 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-11 11:48:48,026 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-11 11:48:48,477 [spark-akka.actor.default-dispatcher-4] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-11 11:48:48,542 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Starting remoting
2014-07-11 11:48:48,720 [spark-akka.actor.default-dispatcher-6] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.155:50093]
2014-07-11 11:48:48,723 [spark-akka.actor.default-dispatcher-6] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.155:50093]
2014-07-11 11:48:48,748 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-11 11:48:48,751 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-11 11:48:48,764 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140711114848-692a
2014-07-11 11:48:48,768 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-11 11:48:48,798 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 46117 with id = ConnectionManagerId(10.74.147.155,46117)
2014-07-11 11:48:48,802 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-11 11:48:48,804 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.155:46117 with 1056.0 MB RAM
2014-07-11 11:48:48,805 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-11 11:48:48,820 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-11 11:48:48,949 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:48:48,966 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:42931
2014-07-11 11:48:48,966 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.155:42931
2014-07-11 11:48:48,986 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-85e05146-54f6-4fcb-a3b0-6c9123155c45
2014-07-11 11:48:48,986 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-11 11:48:48,987 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:48:48,988 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:54045
2014-07-11 11:48:49,305 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-11 11:48:49,317 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-11 11:48:49,319 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.155:4040
2014-07-11 11:48:49,854 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-11 11:48:49,856 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-11 11:48:49,944 [main] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-11 11:48:49,944 [main] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-11 11:48:49,952 [main] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-11 11:48:49,962 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at CalEigenVector.scala:31
2014-07-11 11:48:49,972 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at CalEigenVector.scala:31) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:49,973 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at CalEigenVector.scala:31)
2014-07-11 11:48:49,973 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:49,978 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:49,983 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[2] at map at CalEigenVector.scala:25), which has no missing parents
2014-07-11 11:48:50,053 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 0 (MappedRDD[2] at map at CalEigenVector.scala:25)
2014-07-11 11:48:50,054 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2014-07-11 11:48:50,072 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:50,076 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 1798 bytes in 2 ms
2014-07-11 11:48:50,079 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:50,080 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:1 as 1798 bytes in 0 ms
2014-07-11 11:48:50,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-11 11:48:50,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-11 11:48:50,103 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:50,104 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:50,111 [Executor task launch worker-1] INFO  [org.apache.spark.CacheManager] - Partition rdd_2_1 not found, computing it
2014-07-11 11:48:50,111 [Executor task launch worker-0] INFO  [org.apache.spark.CacheManager] - Partition rdd_2_0 not found, computing it
2014-07-11 11:48:50,115 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-11 11:48:50,115 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-11 11:48:51,728 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85228305) called with curMem=32856, maxMem=1107296256
2014-07-11 11:48:51,728 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_2_1 stored as values to memory (estimated size 81.3 MB, free 974.7 MB)
2014-07-11 11:48:51,732 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_2_1 in memory on 10.74.147.155:46117 (size: 81.3 MB, free: 974.7 MB)
2014-07-11 11:48:51,733 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_2_1
2014-07-11 11:48:51,795 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85249276) called with curMem=85261161, maxMem=1107296256
2014-07-11 11:48:51,796 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_2_0 stored as values to memory (estimated size 81.3 MB, free 893.4 MB)
2014-07-11 11:48:51,796 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_2_0 in memory on 10.74.147.155:46117 (size: 81.3 MB, free: 893.4 MB)
2014-07-11 11:48:51,799 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_2_0
2014-07-11 11:48:51,821 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 1174
2014-07-11 11:48:51,822 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-11 11:48:51,822 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-11 11:48:51,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 1174
2014-07-11 11:48:51,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-11 11:48:51,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-11 11:48:51,835 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 1)
2014-07-11 11:48:51,843 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 1754 ms on localhost (progress: 1/2)
2014-07-11 11:48:51,843 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-11 11:48:51,844 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at CalEigenVector.scala:31) finished in 1.783 s
2014-07-11 11:48:51,850 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 1773 ms on localhost (progress: 2/2)
2014-07-11 11:48:51,851 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-11 11:48:51,862 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at CalEigenVector.scala:31, took 1.899773771 s
2014-07-11 11:48:51,927 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:51,929 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:51,929 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 1(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:51,929 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:51,932 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:51,933 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MappedRDD[6] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:51,951 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MappedRDD[6] at map at CalEigenVector.scala:38)
2014-07-11 11:48:51,952 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-11 11:48:51,954 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:51,955 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2291 bytes in 1 ms
2014-07-11 11:48:51,955 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:51,956 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2291 bytes in 1 ms
2014-07-11 11:48:51,957 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-11 11:48:51,957 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-11 11:48:51,964 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:51,966 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:51,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:51,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:51,975 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:51,975 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,145 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 678
2014-07-11 11:48:52,145 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-11 11:48:52,145 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-11 11:48:52,148 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(1, 0)
2014-07-11 11:48:52,149 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 194 ms on localhost (progress: 1/2)
2014-07-11 11:48:52,183 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 678
2014-07-11 11:48:52,183 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-11 11:48:52,183 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-11 11:48:52,185 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(1, 1)
2014-07-11 11:48:52,185 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (reduce at CalEigenVector.scala:38) finished in 0.232 s
2014-07-11 11:48:52,186 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.258660828 s
2014-07-11 11:48:52,192 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 230 ms on localhost (progress: 2/2)
2014-07-11 11:48:52,192 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-11 11:48:52,195 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:52,196 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:52,196 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:52,196 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:52,198 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:52,199 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[10] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:52,215 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 2 (MappedRDD[10] at map at CalEigenVector.scala:38)
2014-07-11 11:48:52,219 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2014-07-11 11:48:52,220 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,220 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:52,221 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:1 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,221 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:52,222 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-11 11:48:52,225 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,227 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-11 11:48:52,229 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,235 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,236 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,237 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,237 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 678
2014-07-11 11:48:52,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-11 11:48:52,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-11 11:48:52,366 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 678
2014-07-11 11:48:52,366 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-11 11:48:52,367 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 1)
2014-07-11 11:48:52,367 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 145 ms on localhost (progress: 1/2)
2014-07-11 11:48:52,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-11 11:48:52,369 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-11 11:48:52,369 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 148 ms on localhost (progress: 2/2)
2014-07-11 11:48:52,369 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at CalEigenVector.scala:38) finished in 0.126 s
2014-07-11 11:48:52,369 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-11 11:48:52,369 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.174196092 s
2014-07-11 11:48:52,379 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:52,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:52,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 3(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:52,380 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:52,383 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:52,383 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 3 (MappedRDD[14] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:52,387 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 3 (MappedRDD[14] at map at CalEigenVector.scala:38)
2014-07-11 11:48:52,387 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 2 tasks
2014-07-11 11:48:52,388 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 3.0:0 as 2291 bytes in 0 ms
2014-07-11 11:48:52,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 3.0:1 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 3.0:1 as 2291 bytes in 0 ms
2014-07-11 11:48:52,390 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-11 11:48:52,390 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-11 11:48:52,393 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,396 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,399 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,399 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,402 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,403 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,765 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-11 11:48:52,765 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-11 11:48:52,765 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-11 11:48:52,767 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 379 ms on localhost (progress: 1/2)
2014-07-11 11:48:52,767 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(3, 0)
2014-07-11 11:48:52,775 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-11 11:48:52,775 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-11 11:48:52,775 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-11 11:48:52,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(3, 1)
2014-07-11 11:48:52,777 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 387 ms on localhost (progress: 2/2)
2014-07-11 11:48:52,777 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2014-07-11 11:48:52,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 3 (reduce at CalEigenVector.scala:38) finished in 0.389 s
2014-07-11 11:48:52,777 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.39812805 s
2014-07-11 11:48:52,784 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:52,786 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:52,786 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:52,786 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:52,788 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:52,788 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[18] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:52,792 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 4 (MappedRDD[18] at map at CalEigenVector.scala:38)
2014-07-11 11:48:52,792 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2014-07-11 11:48:52,793 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,793 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:52,793 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:1 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,794 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:1 as 2292 bytes in 1 ms
2014-07-11 11:48:52,794 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-11 11:48:52,797 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-11 11:48:52,798 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,801 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,801 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,801 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,805 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,806 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,872 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-11 11:48:52,872 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-11 11:48:52,872 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-11 11:48:52,873 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 1)
2014-07-11 11:48:52,874 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:48:52,878 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-11 11:48:52,878 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-11 11:48:52,878 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-11 11:48:52,880 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-11 11:48:52,880 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:48:52,880 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-11 11:48:52,880 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:48:52,881 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.096179954 s
2014-07-11 11:48:52,888 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:52,889 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:52,889 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 5(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:52,889 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:52,891 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:52,892 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 5 (MappedRDD[22] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:52,895 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 5 (MappedRDD[22] at map at CalEigenVector.scala:38)
2014-07-11 11:48:52,895 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 5.0 with 2 tasks
2014-07-11 11:48:52,896 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,897 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 5.0:0 as 2293 bytes in 1 ms
2014-07-11 11:48:52,897 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 5.0:1 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,898 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 5.0:1 as 2293 bytes in 1 ms
2014-07-11 11:48:52,898 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-11 11:48:52,898 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-11 11:48:52,901 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,903 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:52,905 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,905 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:52,906 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,907 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:52,978 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-11 11:48:52,978 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-11 11:48:52,978 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-11 11:48:52,979 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(5, 0)
2014-07-11 11:48:52,979 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 83 ms on localhost (progress: 1/2)
2014-07-11 11:48:52,979 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-11 11:48:52,980 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-11 11:48:52,980 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-11 11:48:52,981 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:48:52,981 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2014-07-11 11:48:52,981 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(5, 1)
2014-07-11 11:48:52,981 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 5 (reduce at CalEigenVector.scala:38) finished in 0.085 s
2014-07-11 11:48:52,981 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.09371031 s
2014-07-11 11:48:52,989 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:52,990 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:52,990 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:52,990 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:52,992 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:52,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[26] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:52,996 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 6 (MappedRDD[26] at map at CalEigenVector.scala:38)
2014-07-11 11:48:52,996 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2014-07-11 11:48:52,997 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,998 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2292 bytes in 1 ms
2014-07-11 11:48:52,998 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:1 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:52,999 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:1 as 2292 bytes in 1 ms
2014-07-11 11:48:52,999 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-11 11:48:53,002 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,003 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-11 11:48:53,004 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,004 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,007 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,009 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,010 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-11 11:48:53,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-11 11:48:53,079 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-11 11:48:53,081 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 1)
2014-07-11 11:48:53,081 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 83 ms on localhost (progress: 1/2)
2014-07-11 11:48:53,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-11 11:48:53,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-11 11:48:53,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-11 11:48:53,089 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-11 11:48:53,089 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 91 ms on localhost (progress: 2/2)
2014-07-11 11:48:53,089 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-11 11:48:53,089 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (reduce at CalEigenVector.scala:38) finished in 0.092 s
2014-07-11 11:48:53,090 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.100783288 s
2014-07-11 11:48:53,101 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:53,103 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:53,103 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 7(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:53,103 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:53,107 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:53,107 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 7 (MappedRDD[30] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:53,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 7 (MappedRDD[30] at map at CalEigenVector.scala:38)
2014-07-11 11:48:53,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 7.0 with 2 tasks
2014-07-11 11:48:53,113 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,113 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 7.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:53,114 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 7.0:1 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,114 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 7.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:53,115 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-11 11:48:53,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-11 11:48:53,117 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,118 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,120 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,120 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,126 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,126 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,440 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-11 11:48:53,440 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-11 11:48:53,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-11 11:48:53,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-11 11:48:53,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-11 11:48:53,443 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(7, 0)
2014-07-11 11:48:53,443 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 330 ms on localhost (progress: 1/2)
2014-07-11 11:48:53,443 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-11 11:48:53,444 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 330 ms on localhost (progress: 2/2)
2014-07-11 11:48:53,444 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2014-07-11 11:48:53,444 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(7, 1)
2014-07-11 11:48:53,444 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 7 (reduce at CalEigenVector.scala:38) finished in 0.319 s
2014-07-11 11:48:53,444 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.34312511 s
2014-07-11 11:48:53,452 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:53,453 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:53,453 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:53,453 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:53,455 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:53,456 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[34] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:53,459 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 8 (MappedRDD[34] at map at CalEigenVector.scala:38)
2014-07-11 11:48:53,459 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2014-07-11 11:48:53,460 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,460 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:53,460 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:1 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:1 as 2293 bytes in 1 ms
2014-07-11 11:48:53,461 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-11 11:48:53,462 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-11 11:48:53,465 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,465 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,468 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,468 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,468 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,468 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,537 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-11 11:48:53,537 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-11 11:48:53,539 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-11 11:48:53,539 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:48:53,539 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-11 11:48:53,539 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-11 11:48:53,539 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-11 11:48:53,541 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 1)
2014-07-11 11:48:53,541 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:48:53,542 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08980694 s
2014-07-11 11:48:53,541 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:48:53,542 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-11 11:48:53,542 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-11 11:48:53,549 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:53,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:53,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 9(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:53,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:53,553 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:53,554 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 9 (MappedRDD[38] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:53,557 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 9 (MappedRDD[38] at map at CalEigenVector.scala:38)
2014-07-11 11:48:53,557 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 2 tasks
2014-07-11 11:48:53,558 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,558 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 9.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:53,559 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 9.0:1 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,559 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 9.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:53,560 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-11 11:48:53,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,560 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-11 11:48:53,565 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,565 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,565 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,569 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,570 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,637 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-11 11:48:53,637 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-11 11:48:53,638 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 79 ms on localhost (progress: 1/2)
2014-07-11 11:48:53,638 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(9, 1)
2014-07-11 11:48:53,639 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-11 11:48:53,671 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-11 11:48:53,671 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-11 11:48:53,673 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 114 ms on localhost (progress: 2/2)
2014-07-11 11:48:53,673 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2014-07-11 11:48:53,673 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(9, 0)
2014-07-11 11:48:53,674 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 9 (reduce at CalEigenVector.scala:38) finished in 0.113 s
2014-07-11 11:48:53,674 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.125741054 s
2014-07-11 11:48:53,683 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:53,683 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-11 11:48:53,684 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:53,684 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:53,684 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:53,686 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:53,687 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[42] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:53,692 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 10 (MappedRDD[42] at map at CalEigenVector.scala:38)
2014-07-11 11:48:53,692 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 2 tasks
2014-07-11 11:48:53,693 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,693 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:53,694 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:1 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,694 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:53,695 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-11 11:48:53,695 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-11 11:48:53,697 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,697 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,699 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,699 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,699 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,699 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,769 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-11 11:48:53,769 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-11 11:48:53,771 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:48:53,771 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-11 11:48:53,771 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-11 11:48:53,803 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-11 11:48:53,803 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-11 11:48:53,806 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 111 ms on localhost (progress: 2/2)
2014-07-11 11:48:53,806 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-11 11:48:53,806 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 1)
2014-07-11 11:48:53,806 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at CalEigenVector.scala:38) finished in 0.114 s
2014-07-11 11:48:53,807 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.124096239 s
2014-07-11 11:48:53,815 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-11 11:48:53,816 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:53,817 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:53,817 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 11(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:53,817 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:53,820 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:53,821 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 11 (MappedRDD[46] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:53,824 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 11 (MappedRDD[46] at map at CalEigenVector.scala:38)
2014-07-11 11:48:53,825 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 11.0 with 2 tasks
2014-07-11 11:48:53,826 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,826 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 11.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:53,827 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 11.0:1 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,827 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 11.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:53,828 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-11 11:48:53,828 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-11 11:48:53,830 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,832 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,832 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,834 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,840 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,840 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,933 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-11 11:48:53,933 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-11 11:48:53,935 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(11, 0)
2014-07-11 11:48:53,936 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 109 ms on localhost (progress: 1/2)
2014-07-11 11:48:53,936 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-11 11:48:53,949 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-11 11:48:53,949 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-11 11:48:53,950 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-11 11:48:53,950 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(11, 1)
2014-07-11 11:48:53,950 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 124 ms on localhost (progress: 2/2)
2014-07-11 11:48:53,951 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 11 (reduce at CalEigenVector.scala:38) finished in 0.122 s
2014-07-11 11:48:53,951 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.135469144 s
2014-07-11 11:48:53,951 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2014-07-11 11:48:53,960 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:53,961 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:53,962 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:53,962 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:53,964 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:53,964 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[50] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:53,967 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 12 (MappedRDD[50] at map at CalEigenVector.scala:38)
2014-07-11 11:48:53,967 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2014-07-11 11:48:53,968 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,969 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2291 bytes in 1 ms
2014-07-11 11:48:53,969 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:1 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:53,970 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:1 as 2291 bytes in 0 ms
2014-07-11 11:48:53,970 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-11 11:48:53,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,974 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-11 11:48:53,976 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:53,979 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,979 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:53,987 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:53,988 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:54,081 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-11 11:48:54,081 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-11 11:48:54,084 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-11 11:48:54,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-11 11:48:54,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-11 11:48:54,087 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 117 ms on localhost (progress: 1/2)
2014-07-11 11:48:54,087 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 1)
2014-07-11 11:48:54,087 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-11 11:48:54,087 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 119 ms on localhost (progress: 2/2)
2014-07-11 11:48:54,088 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at CalEigenVector.scala:38) finished in 0.100 s
2014-07-11 11:48:54,088 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-11 11:48:54,089 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.128291627 s
2014-07-11 11:48:54,088 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-11 11:48:54,100 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:54,101 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:54,101 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 13(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:54,101 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:54,104 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:54,107 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 13 (MappedRDD[54] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:54,111 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 13 (MappedRDD[54] at map at CalEigenVector.scala:38)
2014-07-11 11:48:54,111 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2014-07-11 11:48:54,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:54,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 13.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:54,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 13.0:1 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:54,113 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 13.0:1 as 2293 bytes in 1 ms
2014-07-11 11:48:54,113 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-11 11:48:54,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-11 11:48:54,115 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:54,118 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:54,118 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:54,119 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:54,122 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:54,122 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,456 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-11 11:48:55,456 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-11 11:48:55,458 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 1346 ms on localhost (progress: 1/2)
2014-07-11 11:48:55,458 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(13, 0)
2014-07-11 11:48:55,466 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-11 11:48:55,474 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-11 11:48:55,474 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-11 11:48:55,475 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-11 11:48:55,475 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 1363 ms on localhost (progress: 2/2)
2014-07-11 11:48:55,475 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2014-07-11 11:48:55,476 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(13, 1)
2014-07-11 11:48:55,476 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 13 (reduce at CalEigenVector.scala:38) finished in 1.365 s
2014-07-11 11:48:55,476 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 1.376226946 s
2014-07-11 11:48:55,502 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:55,503 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:55,503 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:55,503 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:55,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:55,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[58] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:55,513 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 14 (MappedRDD[58] at map at CalEigenVector.scala:38)
2014-07-11 11:48:55,514 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2014-07-11 11:48:55,515 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,516 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2294 bytes in 1 ms
2014-07-11 11:48:55,516 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:1 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,517 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:55,518 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-11 11:48:55,521 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,523 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-11 11:48:55,524 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,524 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,525 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,528 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,528 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,588 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-11 11:48:55,588 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-11 11:48:55,590 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:48:55,591 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-11 11:48:55,592 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-11 11:48:55,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-11 11:48:55,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-11 11:48:55,623 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 107 ms on localhost (progress: 2/2)
2014-07-11 11:48:55,623 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-11 11:48:55,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 1)
2014-07-11 11:48:55,624 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at CalEigenVector.scala:38) finished in 0.096 s
2014-07-11 11:48:55,624 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.12251744 s
2014-07-11 11:48:55,631 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:55,631 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-11 11:48:55,632 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:55,632 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 15(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:55,632 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:55,635 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:55,636 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 15 (MappedRDD[62] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:55,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 15 (MappedRDD[62] at map at CalEigenVector.scala:38)
2014-07-11 11:48:55,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 2 tasks
2014-07-11 11:48:55,640 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,641 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 15.0:0 as 2294 bytes in 1 ms
2014-07-11 11:48:55,641 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 15.0:1 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,641 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 15.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:55,645 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-11 11:48:55,646 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,650 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-11 11:48:55,652 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,661 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,661 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,783 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-11 11:48:55,783 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-11 11:48:55,784 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 142 ms on localhost (progress: 1/2)
2014-07-11 11:48:55,784 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(15, 1)
2014-07-11 11:48:55,784 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-11 11:48:55,786 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-11 11:48:55,786 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-11 11:48:55,788 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 147 ms on localhost (progress: 2/2)
2014-07-11 11:48:55,788 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2014-07-11 11:48:55,788 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(15, 0)
2014-07-11 11:48:55,788 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 15 (reduce at CalEigenVector.scala:38) finished in 0.133 s
2014-07-11 11:48:55,789 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.157442439 s
2014-07-11 11:48:55,796 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-11 11:48:55,797 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:55,798 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:55,798 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:55,798 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:55,801 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:55,802 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[66] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:55,805 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 16 (MappedRDD[66] at map at CalEigenVector.scala:38)
2014-07-11 11:48:55,805 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2014-07-11 11:48:55,806 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,806 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:55,807 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:1 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,807 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:55,808 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-11 11:48:55,808 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-11 11:48:55,810 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,816 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,818 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,819 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,892 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-11 11:48:55,892 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-11 11:48:55,892 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-11 11:48:55,893 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 87 ms on localhost (progress: 1/2)
2014-07-11 11:48:55,893 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-11 11:48:55,924 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-11 11:48:55,924 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-11 11:48:55,924 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-11 11:48:55,925 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 1)
2014-07-11 11:48:55,925 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 118 ms on localhost (progress: 2/2)
2014-07-11 11:48:55,925 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-11 11:48:55,925 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at CalEigenVector.scala:38) finished in 0.120 s
2014-07-11 11:48:55,926 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.128650919 s
2014-07-11 11:48:55,934 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:55,936 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:55,936 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 17(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:55,936 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:55,938 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:55,939 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 17 (MappedRDD[70] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:55,942 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 17 (MappedRDD[70] at map at CalEigenVector.scala:38)
2014-07-11 11:48:55,942 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 17.0 with 2 tasks
2014-07-11 11:48:55,943 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,943 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 17.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:55,945 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 17.0:1 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:55,946 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 17.0:1 as 2293 bytes in 1 ms
2014-07-11 11:48:55,946 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-11 11:48:55,946 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-11 11:48:55,948 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,948 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:55,950 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,950 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:55,951 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:55,951 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,022 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-11 11:48:56,022 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-11 11:48:56,022 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-11 11:48:56,023 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(17, 0)
2014-07-11 11:48:56,023 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 80 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,026 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-11 11:48:56,026 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-11 11:48:56,026 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-11 11:48:56,027 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(17, 1)
2014-07-11 11:48:56,027 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,028 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,028 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 17 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:48:56,028 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.093269492 s
2014-07-11 11:48:56,034 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,038 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,039 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[74] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,042 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 18 (MappedRDD[74] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,042 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2014-07-11 11:48:56,042 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,043 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2293 bytes in 1 ms
2014-07-11 11:48:56,043 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:1 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,043 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:56,044 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-11 11:48:56,046 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,047 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-11 11:48:56,050 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,050 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,052 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,054 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,054 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,120 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-11 11:48:56,120 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-11 11:48:56,120 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-11 11:48:56,121 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,122 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 1)
2014-07-11 11:48:56,129 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-11 11:48:56,129 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-11 11:48:56,129 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-11 11:48:56,130 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-11 11:48:56,130 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 88 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,130 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,130 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:48:56,131 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.096688988 s
2014-07-11 11:48:56,137 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 19(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,140 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,140 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 19 (MappedRDD[78] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,143 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 19 (MappedRDD[78] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,143 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 19.0 with 2 tasks
2014-07-11 11:48:56,144 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,144 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 19.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:56,145 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 19.0:1 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,145 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 19.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:56,145 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-11 11:48:56,146 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-11 11:48:56,147 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,148 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,150 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,150 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,150 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,150 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-11 11:48:56,230 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-11 11:48:56,230 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-11 11:48:56,231 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(19, 0)
2014-07-11 11:48:56,231 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 86 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-11 11:48:56,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-11 11:48:56,232 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-11 11:48:56,233 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 89 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,233 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,233 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(19, 1)
2014-07-11 11:48:56,234 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 19 (reduce at CalEigenVector.scala:38) finished in 0.090 s
2014-07-11 11:48:56,234 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.097169115 s
2014-07-11 11:48:56,240 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,243 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,243 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[82] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,246 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 20 (MappedRDD[82] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,246 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2014-07-11 11:48:56,247 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,247 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:56,248 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:1 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,248 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:56,249 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-11 11:48:56,249 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-11 11:48:56,251 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,252 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,253 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,253 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,254 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,254 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,323 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-11 11:48:56,323 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-11 11:48:56,323 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-11 11:48:56,324 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-11 11:48:56,324 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-11 11:48:56,325 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-11 11:48:56,325 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-11 11:48:56,325 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,326 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 1)
2014-07-11 11:48:56,326 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,326 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,326 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:48:56,326 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086816195 s
2014-07-11 11:48:56,332 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,333 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,333 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 21(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,333 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,339 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,340 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 21 (MappedRDD[86] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,343 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 21 (MappedRDD[86] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,343 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 2 tasks
2014-07-11 11:48:56,344 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,344 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 21.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:56,345 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 21.0:1 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,345 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 21.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:56,346 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-11 11:48:56,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-11 11:48:56,348 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,349 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,350 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,350 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,351 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,351 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-11 11:48:56,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-11 11:48:56,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-11 11:48:56,421 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(21, 1)
2014-07-11 11:48:56,421 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 76 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,421 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-11 11:48:56,421 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-11 11:48:56,422 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-11 11:48:56,423 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,424 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,424 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(21, 0)
2014-07-11 11:48:56,424 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 21 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:48:56,424 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092035676 s
2014-07-11 11:48:56,430 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,431 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,431 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,431 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,433 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,433 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[90] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,436 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 22 (MappedRDD[90] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,436 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 2 tasks
2014-07-11 11:48:56,437 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,437 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:56,437 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:1 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,438 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:1 as 2294 bytes in 1 ms
2014-07-11 11:48:56,438 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-11 11:48:56,440 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,441 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-11 11:48:56,442 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,442 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,442 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,445 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,445 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,507 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-11 11:48:56,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-11 11:48:56,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-11 11:48:56,509 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-11 11:48:56,509 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,513 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-11 11:48:56,513 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-11 11:48:56,513 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-11 11:48:56,514 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,515 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,515 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 1)
2014-07-11 11:48:56,515 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at CalEigenVector.scala:38) finished in 0.079 s
2014-07-11 11:48:56,515 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085670443 s
2014-07-11 11:48:56,521 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,522 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,522 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 23(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,522 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,524 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,524 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 23 (MappedRDD[94] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,528 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 23 (MappedRDD[94] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,528 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 23.0 with 2 tasks
2014-07-11 11:48:56,529 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 23.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,529 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 23.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:56,529 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 23.0:1 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,530 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 23.0:1 as 2292 bytes in 1 ms
2014-07-11 11:48:56,530 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-11 11:48:56,530 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-11 11:48:56,532 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,532 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,534 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,534 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,534 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,535 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,596 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-11 11:48:56,596 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-11 11:48:56,596 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-11 11:48:56,597 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(23, 0)
2014-07-11 11:48:56,598 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,601 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-11 11:48:56,601 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-11 11:48:56,601 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-11 11:48:56,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(23, 1)
2014-07-11 11:48:56,602 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,602 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 23 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:48:56,602 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081344918 s
2014-07-11 11:48:56,608 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,609 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,609 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,609 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,611 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,611 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[98] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,614 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 24 (MappedRDD[98] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,614 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 2 tasks
2014-07-11 11:48:56,615 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,616 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:56,616 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:1 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,616 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:56,617 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-11 11:48:56,619 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,621 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,621 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,624 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-11 11:48:56,626 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,628 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,628 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,682 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-11 11:48:56,682 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-11 11:48:56,682 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-11 11:48:56,683 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-11 11:48:56,683 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,688 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-11 11:48:56,688 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-11 11:48:56,688 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-11 11:48:56,689 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 1)
2014-07-11 11:48:56,689 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,689 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,689 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:48:56,690 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081588331 s
2014-07-11 11:48:56,695 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,696 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,696 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 25(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,696 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 25 (MappedRDD[102] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 25 (MappedRDD[102] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 25.0 with 2 tasks
2014-07-11 11:48:56,702 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 25.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,702 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 25.0:0 as 2291 bytes in 0 ms
2014-07-11 11:48:56,703 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 25.0:1 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,703 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 25.0:1 as 2291 bytes in 0 ms
2014-07-11 11:48:56,703 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-11 11:48:56,704 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-11 11:48:56,705 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,706 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,707 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,707 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,708 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,708 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,758 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-11 11:48:56,758 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-11 11:48:56,758 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-11 11:48:56,759 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-11 11:48:56,759 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-11 11:48:56,760 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-11 11:48:56,761 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(25, 1)
2014-07-11 11:48:56,761 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,761 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 59 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,762 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,762 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(25, 0)
2014-07-11 11:48:56,762 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 25 (reduce at CalEigenVector.scala:38) finished in 0.061 s
2014-07-11 11:48:56,762 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.06695389 s
2014-07-11 11:48:56,767 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,768 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,768 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,768 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,770 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,771 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[106] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,774 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 26 (MappedRDD[106] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,774 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2014-07-11 11:48:56,775 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,775 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:56,775 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:1 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,776 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:56,776 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-11 11:48:56,778 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,781 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,781 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-11 11:48:56,783 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,791 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,791 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,861 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-11 11:48:56,862 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-11 11:48:56,862 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-11 11:48:56,863 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 1)
2014-07-11 11:48:56,863 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 87 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,867 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-11 11:48:56,867 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-11 11:48:56,867 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-11 11:48:56,868 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-11 11:48:56,868 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 94 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,868 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,868 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at CalEigenVector.scala:38) finished in 0.094 s
2014-07-11 11:48:56,869 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.101073117 s
2014-07-11 11:48:56,875 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,876 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,876 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 27(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,876 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,878 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,879 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 27 (MappedRDD[110] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,881 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 27 (MappedRDD[110] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,881 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 2 tasks
2014-07-11 11:48:56,882 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 27.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,882 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 27.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:56,882 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 27.0:1 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,883 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 27.0:1 as 2292 bytes in 1 ms
2014-07-11 11:48:56,883 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-11 11:48:56,885 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,886 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-11 11:48:56,888 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,893 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,893 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,962 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-11 11:48:56,962 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-11 11:48:56,962 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-11 11:48:56,963 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(27, 0)
2014-07-11 11:48:56,963 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:48:56,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-11 11:48:56,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-11 11:48:56,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-11 11:48:56,964 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(27, 1)
2014-07-11 11:48:56,964 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:48:56,964 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2014-07-11 11:48:56,965 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 27 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:48:56,965 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08929023 s
2014-07-11 11:48:56,970 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:56,971 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:56,971 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:56,971 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:56,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:56,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[114] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:56,976 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 28 (MappedRDD[114] at map at CalEigenVector.scala:38)
2014-07-11 11:48:56,976 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 2 tasks
2014-07-11 11:48:56,977 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,977 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2291 bytes in 0 ms
2014-07-11 11:48:56,977 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:1 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:56,978 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:1 as 2291 bytes in 1 ms
2014-07-11 11:48:56,978 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-11 11:48:56,978 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-11 11:48:56,980 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,980 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:56,982 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,982 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:56,983 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:56,984 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,050 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-11 11:48:57,050 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-11 11:48:57,051 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-11 11:48:57,051 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 1)
2014-07-11 11:48:57,051 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-11 11:48:57,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-11 11:48:57,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-11 11:48:57,056 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-11 11:48:57,056 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,056 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,056 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:48:57,057 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08642585 s
2014-07-11 11:48:57,062 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,063 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,063 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 29(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,063 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,065 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,065 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 29 (MappedRDD[118] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,068 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 29 (MappedRDD[118] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,068 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 29.0 with 2 tasks
2014-07-11 11:48:57,069 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 29.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,069 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 29.0:0 as 2290 bytes in 0 ms
2014-07-11 11:48:57,069 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 29.0:1 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,070 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 29.0:1 as 2290 bytes in 0 ms
2014-07-11 11:48:57,070 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-11 11:48:57,070 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-11 11:48:57,072 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,072 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,074 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,074 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,074 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,074 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,149 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-11 11:48:57,149 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-11 11:48:57,151 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,152 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-11 11:48:57,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-11 11:48:57,153 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(29, 1)
2014-07-11 11:48:57,154 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-11 11:48:57,154 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(29, 0)
2014-07-11 11:48:57,154 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 86 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,154 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,154 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 29 (reduce at CalEigenVector.scala:38) finished in 0.086 s
2014-07-11 11:48:57,155 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092812929 s
2014-07-11 11:48:57,155 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-11 11:48:57,160 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,161 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,161 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,161 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,163 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,164 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[122] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,166 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 30 (MappedRDD[122] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,166 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 2 tasks
2014-07-11 11:48:57,167 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,167 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:57,168 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:1 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,168 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:57,169 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-11 11:48:57,169 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-11 11:48:57,170 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,170 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,172 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,172 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,172 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,172 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-11 11:48:57,247 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-11 11:48:57,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-11 11:48:57,247 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-11 11:48:57,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-11 11:48:57,248 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-11 11:48:57,248 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-11 11:48:57,248 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 81 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,249 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 1)
2014-07-11 11:48:57,249 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,249 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,249 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:48:57,250 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.089114938 s
2014-07-11 11:48:57,259 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,260 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,260 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 31(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,260 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,262 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,262 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 31 (MappedRDD[126] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,265 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 31 (MappedRDD[126] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,265 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2014-07-11 11:48:57,266 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 31.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,266 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 31.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:57,266 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 31.0:1 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,267 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 31.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:57,268 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-11 11:48:57,269 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-11 11:48:57,270 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,271 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,273 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,273 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,277 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,277 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-11 11:48:57,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-11 11:48:57,347 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-11 11:48:57,348 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 83 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,348 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(31, 0)
2014-07-11 11:48:57,352 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-11 11:48:57,352 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-11 11:48:57,352 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-11 11:48:57,353 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(31, 1)
2014-07-11 11:48:57,353 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 86 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,353 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,353 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 31 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:48:57,353 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.09368407 s
2014-07-11 11:48:57,359 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,360 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,360 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,360 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,364 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,365 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[130] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,367 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 32 (MappedRDD[130] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,367 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 2 tasks
2014-07-11 11:48:57,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:57,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:1 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,369 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:57,369 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-11 11:48:57,371 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-11 11:48:57,371 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,372 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,373 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,373 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,375 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,376 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-11 11:48:57,441 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-11 11:48:57,442 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-11 11:48:57,442 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 1)
2014-07-11 11:48:57,442 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,448 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-11 11:48:57,448 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-11 11:48:57,448 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-11 11:48:57,449 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-11 11:48:57,449 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,449 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,449 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:48:57,450 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.090385037 s
2014-07-11 11:48:57,455 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,456 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,456 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 33(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,456 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,457 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,458 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 33 (MappedRDD[134] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,462 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 33 (MappedRDD[134] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,462 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 2 tasks
2014-07-11 11:48:57,463 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 33.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,463 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 33.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:57,463 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 33.0:1 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,464 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 33.0:1 as 2294 bytes in 1 ms
2014-07-11 11:48:57,464 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-11 11:48:57,464 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-11 11:48:57,466 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,466 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,473 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,473 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,474 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,474 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,547 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-11 11:48:57,547 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-11 11:48:57,547 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-11 11:48:57,548 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(33, 0)
2014-07-11 11:48:57,548 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 85 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,564 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-11 11:48:57,565 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-11 11:48:57,565 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-11 11:48:57,565 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(33, 1)
2014-07-11 11:48:57,566 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 102 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,566 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,566 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 33 (reduce at CalEigenVector.scala:38) finished in 0.104 s
2014-07-11 11:48:57,566 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.111094817 s
2014-07-11 11:48:57,572 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,573 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,573 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,573 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,575 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,576 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[138] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 34 (MappedRDD[138] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 2 tasks
2014-07-11 11:48:57,579 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,579 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2292 bytes in 0 ms
2014-07-11 11:48:57,580 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:1 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,580 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:1 as 2292 bytes in 0 ms
2014-07-11 11:48:57,581 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-11 11:48:57,583 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,583 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-11 11:48:57,585 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,585 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,587 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,594 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,594 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,649 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-11 11:48:57,649 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-11 11:48:57,650 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-11 11:48:57,650 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-11 11:48:57,650 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-11 11:48:57,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-11 11:48:57,668 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-11 11:48:57,669 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 1)
2014-07-11 11:48:57,669 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 89 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,669 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,669 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at CalEigenVector.scala:38) finished in 0.091 s
2014-07-11 11:48:57,669 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.097437256 s
2014-07-11 11:48:57,675 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,676 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,676 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 35(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,676 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,678 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 35 (MappedRDD[142] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,681 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 35 (MappedRDD[142] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,681 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 35.0 with 2 tasks
2014-07-11 11:48:57,682 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 35.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,682 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 35.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:57,683 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 35.0:1 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,683 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 35.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:57,684 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-11 11:48:57,684 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-11 11:48:57,685 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,685 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,687 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,688 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,698 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,698 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,747 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-11 11:48:57,747 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-11 11:48:57,749 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,751 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(35, 1)
2014-07-11 11:48:57,752 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-11 11:48:57,768 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-11 11:48:57,769 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-11 11:48:57,769 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-11 11:48:57,769 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(35, 0)
2014-07-11 11:48:57,770 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,770 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,770 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 35 (reduce at CalEigenVector.scala:38) finished in 0.089 s
2014-07-11 11:48:57,770 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.095458465 s
2014-07-11 11:48:57,776 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,778 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,778 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,778 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,780 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,780 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[146] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,785 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 36 (MappedRDD[146] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,785 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2014-07-11 11:48:57,786 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,787 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:57,787 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:1 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,787 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:57,788 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-11 11:48:57,788 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-11 11:48:57,789 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,791 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,791 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,793 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,798 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,799 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,854 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-11 11:48:57,854 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-11 11:48:57,856 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,856 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-11 11:48:57,856 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-11 11:48:57,871 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-11 11:48:57,871 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-11 11:48:57,871 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-11 11:48:57,872 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 1)
2014-07-11 11:48:57,872 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 85 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,872 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,872 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:48:57,872 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.096639825 s
2014-07-11 11:48:57,878 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 37(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,880 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,881 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 37 (MappedRDD[150] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,883 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 37 (MappedRDD[150] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,883 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2014-07-11 11:48:57,884 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 37.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,884 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 37.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:57,884 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 37.0:1 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,885 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 37.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:57,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-11 11:48:57,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-11 11:48:57,887 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,887 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,888 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,888 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,896 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,896 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,936 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-11 11:48:57,937 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-11 11:48:57,937 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-11 11:48:57,938 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(37, 0)
2014-07-11 11:48:57,938 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 53 ms on localhost (progress: 1/2)
2014-07-11 11:48:57,947 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-11 11:48:57,947 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-11 11:48:57,949 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(37, 1)
2014-07-11 11:48:57,949 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 64 ms on localhost (progress: 2/2)
2014-07-11 11:48:57,949 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2014-07-11 11:48:57,949 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 37 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:48:57,949 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071151564 s
2014-07-11 11:48:57,954 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:57,954 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-11 11:48:57,955 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:57,955 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:57,955 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:57,957 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:57,957 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[154] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:57,959 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 38 (MappedRDD[154] at map at CalEigenVector.scala:38)
2014-07-11 11:48:57,959 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 2 tasks
2014-07-11 11:48:57,960 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,960 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:57,961 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:1 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:57,961 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:57,961 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-11 11:48:57,962 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-11 11:48:57,963 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,963 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:57,965 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,965 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:57,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:57,973 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,024 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-11 11:48:58,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-11 11:48:58,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-11 11:48:58,025 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-11 11:48:58,025 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,059 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-11 11:48:58,059 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-11 11:48:58,061 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 99 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,061 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,061 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 1)
2014-07-11 11:48:58,061 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at CalEigenVector.scala:38) finished in 0.101 s
2014-07-11 11:48:58,062 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.107757559 s
2014-07-11 11:48:58,068 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-11 11:48:58,069 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,070 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,070 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 39(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,070 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,071 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,072 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 39 (MappedRDD[158] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,074 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 39 (MappedRDD[158] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,074 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 2 tasks
2014-07-11 11:48:58,075 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 39.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,076 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 39.0:0 as 2294 bytes in 1 ms
2014-07-11 11:48:58,076 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 39.0:1 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,076 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 39.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:58,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-11 11:48:58,077 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-11 11:48:58,079 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,079 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,081 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,081 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,087 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,087 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,174 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-11 11:48:58,174 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-11 11:48:58,174 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-11 11:48:58,175 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(39, 1)
2014-07-11 11:48:58,175 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 99 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,175 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-11 11:48:58,176 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-11 11:48:58,176 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-11 11:48:58,177 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(39, 0)
2014-07-11 11:48:58,177 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 101 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,177 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,177 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 39 (reduce at CalEigenVector.scala:38) finished in 0.102 s
2014-07-11 11:48:58,177 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.108184938 s
2014-07-11 11:48:58,182 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,184 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,184 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,184 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,185 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,186 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[162] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,188 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 40 (MappedRDD[162] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,188 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 2 tasks
2014-07-11 11:48:58,189 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,189 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:58,190 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:1 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,190 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:58,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-11 11:48:58,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-11 11:48:58,192 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,192 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,194 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,194 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,199 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,199 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,266 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-11 11:48:58,266 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-11 11:48:58,267 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 1)
2014-07-11 11:48:58,268 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-11 11:48:58,273 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-11 11:48:58,273 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-11 11:48:58,273 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-11 11:48:58,274 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-11 11:48:58,274 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 85 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,274 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,274 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at CalEigenVector.scala:38) finished in 0.086 s
2014-07-11 11:48:58,274 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.091887532 s
2014-07-11 11:48:58,279 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 41(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,282 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,282 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 41 (MappedRDD[166] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,284 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 41 (MappedRDD[166] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,284 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 41.0 with 2 tasks
2014-07-11 11:48:58,285 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 41.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,285 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 41.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:58,286 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 41.0:1 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,286 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 41.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:58,286 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-11 11:48:58,287 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-11 11:48:58,288 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,289 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,290 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,305 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,312 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,313 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,367 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-11 11:48:58,367 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-11 11:48:58,367 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-11 11:48:58,368 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 83 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,368 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(41, 1)
2014-07-11 11:48:58,409 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-11 11:48:58,409 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-11 11:48:58,409 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-11 11:48:58,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(41, 0)
2014-07-11 11:48:58,410 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 125 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,410 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 41 (reduce at CalEigenVector.scala:38) finished in 0.125 s
2014-07-11 11:48:58,411 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.131132969 s
2014-07-11 11:48:58,416 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,419 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,419 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[170] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 42 (MappedRDD[170] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 2 tasks
2014-07-11 11:48:58,422 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,422 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:58,423 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:1 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,423 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:58,423 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-11 11:48:58,424 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-11 11:48:58,425 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,438 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,440 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,440 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,503 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-11 11:48:58,503 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-11 11:48:58,504 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 82 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,504 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-11 11:48:58,505 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-11 11:48:58,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-11 11:48:58,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-11 11:48:58,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-11 11:48:58,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 1)
2014-07-11 11:48:58,550 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 127 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,550 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at CalEigenVector.scala:38) finished in 0.128 s
2014-07-11 11:48:58,550 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.134060897 s
2014-07-11 11:48:58,557 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,558 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,558 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 43(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,558 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,560 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,561 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 43 (MappedRDD[174] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,563 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 43 (MappedRDD[174] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,563 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 43.0 with 2 tasks
2014-07-11 11:48:58,564 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 43.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,564 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 43.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:58,564 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 43.0:1 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,565 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 43.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:58,565 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-11 11:48:58,565 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-11 11:48:58,566 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,567 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,568 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,568 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,568 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,568 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,634 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-11 11:48:58,634 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-11 11:48:58,634 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-11 11:48:58,635 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(43, 0)
2014-07-11 11:48:58,635 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,646 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-11 11:48:58,646 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-11 11:48:58,646 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-11 11:48:58,647 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(43, 1)
2014-07-11 11:48:58,647 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,647 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,647 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 43 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:48:58,650 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.093319263 s
2014-07-11 11:48:58,656 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,657 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,657 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,657 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,658 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,659 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[178] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,661 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 44 (MappedRDD[178] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,661 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 2 tasks
2014-07-11 11:48:58,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:58,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:1 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,663 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:58,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-11 11:48:58,663 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-11 11:48:58,665 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,666 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,666 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,672 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,727 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-11 11:48:58,727 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-11 11:48:58,728 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-11 11:48:58,729 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 1)
2014-07-11 11:48:58,729 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,740 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-11 11:48:58,740 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-11 11:48:58,740 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-11 11:48:58,741 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-11 11:48:58,741 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,741 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,741 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:48:58,741 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085222338 s
2014-07-11 11:48:58,747 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,748 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,748 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 45(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,748 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,749 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,750 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 45 (MappedRDD[182] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,755 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 45 (MappedRDD[182] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,755 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 2 tasks
2014-07-11 11:48:58,755 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 45.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,756 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 45.0:0 as 2293 bytes in 1 ms
2014-07-11 11:48:58,756 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 45.0:1 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,756 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 45.0:1 as 2293 bytes in 0 ms
2014-07-11 11:48:58,757 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-11 11:48:58,757 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-11 11:48:58,758 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,758 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,759 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,760 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,778 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,778 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,826 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-11 11:48:58,827 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-11 11:48:58,828 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,828 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(45, 1)
2014-07-11 11:48:58,828 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-11 11:48:58,867 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-11 11:48:58,867 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-11 11:48:58,867 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-11 11:48:58,868 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(45, 0)
2014-07-11 11:48:58,868 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 113 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,868 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,868 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 45 (reduce at CalEigenVector.scala:38) finished in 0.113 s
2014-07-11 11:48:58,868 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.121503129 s
2014-07-11 11:48:58,874 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,875 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,875 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,875 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,876 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,877 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[186] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 46 (MappedRDD[186] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2014-07-11 11:48:58,880 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,880 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:58,880 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:1 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,880 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:58,881 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-11 11:48:58,881 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-11 11:48:58,882 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,882 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,883 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,883 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,883 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,883 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,950 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-11 11:48:58,951 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-11 11:48:58,952 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:48:58,952 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 1)
2014-07-11 11:48:58,952 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-11 11:48:58,954 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-11 11:48:58,954 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-11 11:48:58,954 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-11 11:48:58,955 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-11 11:48:58,955 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:48:58,955 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-11 11:48:58,955 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:48:58,956 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081720737 s
2014-07-11 11:48:58,961 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:58,962 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:58,962 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 47(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:58,962 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:58,964 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:58,964 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 47 (MappedRDD[190] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:58,966 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 47 (MappedRDD[190] at map at CalEigenVector.scala:38)
2014-07-11 11:48:58,966 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 47.0 with 2 tasks
2014-07-11 11:48:58,967 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 47.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,967 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 47.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:58,969 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 47.0:1 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:58,969 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 47.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:58,971 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-11 11:48:58,972 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,974 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:58,974 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-11 11:48:58,975 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:58,977 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:58,977 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,041 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-11 11:48:59,041 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-11 11:48:59,042 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,042 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(47, 1)
2014-07-11 11:48:59,042 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-11 11:48:59,044 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-11 11:48:59,044 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-11 11:48:59,045 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-11 11:48:59,045 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(47, 0)
2014-07-11 11:48:59,045 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,045 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,045 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 47 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:48:59,046 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.084561996 s
2014-07-11 11:48:59,051 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,052 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,052 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,052 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,053 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,054 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[194] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,056 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 48 (MappedRDD[194] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,056 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2014-07-11 11:48:59,057 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,057 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,057 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:1 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,057 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,058 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-11 11:48:59,058 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-11 11:48:59,059 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,059 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,060 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,060 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,060 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,060 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,120 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-11 11:48:59,120 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-11 11:48:59,122 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,122 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 1)
2014-07-11 11:48:59,123 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-11 11:48:59,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-11 11:48:59,126 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-11 11:48:59,126 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-11 11:48:59,126 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-11 11:48:59,126 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,126 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,127 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:48:59,127 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075713292 s
2014-07-11 11:48:59,132 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,133 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,133 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 49(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,133 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,134 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,135 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 49 (MappedRDD[198] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,137 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 49 (MappedRDD[198] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,137 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 49.0 with 2 tasks
2014-07-11 11:48:59,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 49.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 49.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 49.0:1 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 49.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,139 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-11 11:48:59,140 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,140 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-11 11:48:59,141 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,141 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,141 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,143 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,144 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,194 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-11 11:48:59,194 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-11 11:48:59,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-11 11:48:59,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-11 11:48:59,195 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(49, 0)
2014-07-11 11:48:59,195 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,196 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-11 11:48:59,199 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 61 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,199 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,200 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(49, 1)
2014-07-11 11:48:59,200 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 49 (reduce at CalEigenVector.scala:38) finished in 0.063 s
2014-07-11 11:48:59,200 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.068135951 s
2014-07-11 11:48:59,194 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-11 11:48:59,205 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,206 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,206 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,206 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,208 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,208 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[202] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,210 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 50 (MappedRDD[202] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,210 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2014-07-11 11:48:59,212 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,212 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,212 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:1 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,213 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:1 as 2294 bytes in 1 ms
2014-07-11 11:48:59,213 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-11 11:48:59,214 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-11 11:48:59,215 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,217 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,218 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,218 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,219 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,219 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,338 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-11 11:48:59,338 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-11 11:48:59,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-11 11:48:59,338 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-11 11:48:59,339 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-11 11:48:59,339 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-11 11:48:59,340 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-11 11:48:59,340 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 128 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,343 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 1)
2014-07-11 11:48:59,343 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 131 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,343 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at CalEigenVector.scala:38) finished in 0.132 s
2014-07-11 11:48:59,343 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,344 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.138504329 s
2014-07-11 11:48:59,351 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,352 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,352 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 51(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,352 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,356 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,357 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 51 (MappedRDD[206] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,363 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 51 (MappedRDD[206] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,363 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 2 tasks
2014-07-11 11:48:59,364 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 51.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,364 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 51.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,365 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 51.0:1 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,365 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 51.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,366 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-11 11:48:59,367 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,368 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,368 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,369 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-11 11:48:59,370 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,375 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,375 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,459 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-11 11:48:59,459 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-11 11:48:59,460 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-11 11:48:59,460 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 95 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,460 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(51, 1)
2014-07-11 11:48:59,467 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-11 11:48:59,467 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-11 11:48:59,467 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-11 11:48:59,468 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(51, 0)
2014-07-11 11:48:59,468 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 104 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,468 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,468 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 51 (reduce at CalEigenVector.scala:38) finished in 0.104 s
2014-07-11 11:48:59,469 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.117059938 s
2014-07-11 11:48:59,474 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,475 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,475 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,475 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,477 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,477 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[210] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,480 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 52 (MappedRDD[210] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,480 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 2 tasks
2014-07-11 11:48:59,481 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,481 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,481 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:1 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,482 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,482 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-11 11:48:59,483 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,484 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,484 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,487 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-11 11:48:59,488 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,489 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,489 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-11 11:48:59,557 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-11 11:48:59,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-11 11:48:59,557 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-11 11:48:59,557 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-11 11:48:59,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-11 11:48:59,558 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 77 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,558 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-11 11:48:59,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 1)
2014-07-11 11:48:59,558 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,558 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:48:59,559 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.084307156 s
2014-07-11 11:48:59,564 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,565 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,565 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 53(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,565 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,567 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,567 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 53 (MappedRDD[214] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,569 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 53 (MappedRDD[214] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,569 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 53.0 with 2 tasks
2014-07-11 11:48:59,570 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 53.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,570 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 53.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,570 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 53.0:1 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,571 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 53.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,571 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-11 11:48:59,572 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-11 11:48:59,574 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,575 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,575 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,575 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,575 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,642 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-11 11:48:59,642 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-11 11:48:59,642 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-11 11:48:59,643 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,643 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(53, 0)
2014-07-11 11:48:59,648 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-11 11:48:59,648 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-11 11:48:59,648 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-11 11:48:59,649 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 79 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,650 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,650 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(53, 1)
2014-07-11 11:48:59,650 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 53 (reduce at CalEigenVector.scala:38) finished in 0.081 s
2014-07-11 11:48:59,650 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.085942456 s
2014-07-11 11:48:59,656 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,657 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,657 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,657 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,659 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,659 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[218] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,661 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 54 (MappedRDD[218] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,661 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2014-07-11 11:48:59,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:1 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,663 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-11 11:48:59,663 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-11 11:48:59,664 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,664 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,665 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,665 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,665 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,665 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,734 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-11 11:48:59,734 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-11 11:48:59,734 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-11 11:48:59,734 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-11 11:48:59,734 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-11 11:48:59,735 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-11 11:48:59,735 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,735 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-11 11:48:59,736 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,736 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,736 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 1)
2014-07-11 11:48:59,736 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:48:59,736 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079953305 s
2014-07-11 11:48:59,741 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,742 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,742 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 55(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,742 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,750 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,751 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 55 (MappedRDD[222] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,753 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 55 (MappedRDD[222] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,753 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 55.0 with 2 tasks
2014-07-11 11:48:59,754 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 55.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,754 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 55.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,755 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 55.0:1 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,755 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 55.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,755 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-11 11:48:59,757 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,758 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,758 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,760 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-11 11:48:59,761 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,765 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,765 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-11 11:48:59,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-11 11:48:59,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-11 11:48:59,823 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,824 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(55, 1)
2014-07-11 11:48:59,841 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-11 11:48:59,841 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-11 11:48:59,842 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-11 11:48:59,842 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(55, 0)
2014-07-11 11:48:59,842 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 88 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,842 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,842 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 55 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:48:59,843 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.101295111 s
2014-07-11 11:48:59,848 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,848 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,848 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,848 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,850 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,850 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[226] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,852 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 56 (MappedRDD[226] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,852 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 2 tasks
2014-07-11 11:48:59,853 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,853 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2293 bytes in 0 ms
2014-07-11 11:48:59,853 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:1 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,854 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:1 as 2293 bytes in 1 ms
2014-07-11 11:48:59,854 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-11 11:48:59,854 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-11 11:48:59,855 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,856 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,857 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,857 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,868 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,869 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,922 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-11 11:48:59,922 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-11 11:48:59,922 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-11 11:48:59,923 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 1)
2014-07-11 11:48:59,923 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:48:59,935 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-11 11:48:59,935 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-11 11:48:59,935 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-11 11:48:59,936 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-11 11:48:59,936 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:48:59,936 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-11 11:48:59,936 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:48:59,936 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088581195 s
2014-07-11 11:48:59,941 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:48:59,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:48:59,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 57(reduce at CalEigenVector.scala:38)
2014-07-11 11:48:59,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:48:59,943 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:48:59,944 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 57 (MappedRDD[230] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:48:59,946 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 57 (MappedRDD[230] at map at CalEigenVector.scala:38)
2014-07-11 11:48:59,946 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 2 tasks
2014-07-11 11:48:59,947 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 57.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,947 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 57.0:0 as 2294 bytes in 0 ms
2014-07-11 11:48:59,948 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 57.0:1 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:48:59,948 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 57.0:1 as 2294 bytes in 0 ms
2014-07-11 11:48:59,949 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-11 11:48:59,950 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,951 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,951 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:48:59,959 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-11 11:48:59,961 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:48:59,962 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:48:59,962 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-11 11:49:00,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-11 11:49:00,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-11 11:49:00,019 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,019 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(57, 1)
2014-07-11 11:49:00,031 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-11 11:49:00,031 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-11 11:49:00,031 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-11 11:49:00,032 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(57, 0)
2014-07-11 11:49:00,032 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 84 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,032 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,032 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 57 (reduce at CalEigenVector.scala:38) finished in 0.086 s
2014-07-11 11:49:00,032 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.090860946 s
2014-07-11 11:49:00,037 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,038 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,038 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,038 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,039 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,040 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[234] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,042 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 58 (MappedRDD[234] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,042 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 2 tasks
2014-07-11 11:49:00,042 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,042 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2293 bytes in 0 ms
2014-07-11 11:49:00,043 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:1 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,043 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:1 as 2293 bytes in 0 ms
2014-07-11 11:49:00,044 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-11 11:49:00,044 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-11 11:49:00,045 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,045 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,046 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,046 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,046 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,046 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,111 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-11 11:49:00,111 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-11 11:49:00,111 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-11 11:49:00,112 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-11 11:49:00,112 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-11 11:49:00,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-11 11:49:00,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-11 11:49:00,114 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 1)
2014-07-11 11:49:00,114 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,114 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,114 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:49:00,114 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.07680072 s
2014-07-11 11:49:00,119 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,120 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,120 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 59(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,120 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,121 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,122 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 59 (MappedRDD[238] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,124 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 59 (MappedRDD[238] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,124 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 59.0 with 2 tasks
2014-07-11 11:49:00,124 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 59.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,124 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 59.0:0 as 2294 bytes in 0 ms
2014-07-11 11:49:00,125 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 59.0:1 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,125 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 59.0:1 as 2294 bytes in 0 ms
2014-07-11 11:49:00,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-11 11:49:00,126 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-11 11:49:00,127 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,128 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,128 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,131 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,132 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,133 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-11 11:49:00,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-11 11:49:00,203 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,203 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(59, 1)
2014-07-11 11:49:00,204 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-11 11:49:00,205 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-11 11:49:00,205 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-11 11:49:00,205 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-11 11:49:00,205 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(59, 0)
2014-07-11 11:49:00,205 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,206 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,206 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 59 (reduce at CalEigenVector.scala:38) finished in 0.081 s
2014-07-11 11:49:00,206 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086600908 s
2014-07-11 11:49:00,211 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,212 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,212 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,212 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,214 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,214 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[242] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,216 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 60 (MappedRDD[242] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,216 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 2 tasks
2014-07-11 11:49:00,217 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,218 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2294 bytes in 0 ms
2014-07-11 11:49:00,218 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:1 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,218 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:1 as 2294 bytes in 0 ms
2014-07-11 11:49:00,219 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-11 11:49:00,220 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,221 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,221 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,223 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-11 11:49:00,229 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,231 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,231 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-11 11:49:00,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-11 11:49:00,277 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-11 11:49:00,277 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 59 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,277 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 1)
2014-07-11 11:49:00,311 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-11 11:49:00,311 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-11 11:49:00,311 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-11 11:49:00,312 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-11 11:49:00,312 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 95 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,312 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,312 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at CalEigenVector.scala:38) finished in 0.096 s
2014-07-11 11:49:00,313 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.101253735 s
2014-07-11 11:49:00,318 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,319 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,319 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 61(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,319 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,320 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,321 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 61 (MappedRDD[246] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,322 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 61 (MappedRDD[246] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,322 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 61.0 with 2 tasks
2014-07-11 11:49:00,323 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 61.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,324 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 61.0:0 as 2293 bytes in 0 ms
2014-07-11 11:49:00,324 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 61.0:1 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,324 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 61.0:1 as 2293 bytes in 0 ms
2014-07-11 11:49:00,324 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-11 11:49:00,324 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-11 11:49:00,325 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,325 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,326 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,326 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,326 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,327 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,374 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-11 11:49:00,374 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-11 11:49:00,374 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-11 11:49:00,374 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-11 11:49:00,374 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-11 11:49:00,375 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-11 11:49:00,375 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 52 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,375 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(61, 0)
2014-07-11 11:49:00,375 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(61, 1)
2014-07-11 11:49:00,376 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 61 (reduce at CalEigenVector.scala:38) finished in 0.052 s
2014-07-11 11:49:00,377 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.059148343 s
2014-07-11 11:49:00,375 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 51 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,379 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,382 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,383 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,383 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,383 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,385 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,385 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[250] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,387 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 62 (MappedRDD[250] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,387 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 2 tasks
2014-07-11 11:49:00,387 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 124 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,388 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2294 bytes in 1 ms
2014-07-11 11:49:00,388 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:1 as TID 125 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,388 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:1 as 2294 bytes in 0 ms
2014-07-11 11:49:00,388 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 124
2014-07-11 11:49:00,389 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 125
2014-07-11 11:49:00,389 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,390 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,390 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,390 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,390 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,390 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 125 is 678
2014-07-11 11:49:00,452 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 124 is 678
2014-07-11 11:49:00,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 125 directly to driver
2014-07-11 11:49:00,452 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 124 directly to driver
2014-07-11 11:49:00,452 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 124
2014-07-11 11:49:00,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 125
2014-07-11 11:49:00,453 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 125 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,453 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 1)
2014-07-11 11:49:00,454 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 124 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,454 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,454 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-11 11:49:00,454 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at CalEigenVector.scala:38) finished in 0.067 s
2014-07-11 11:49:00,455 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072257605 s
2014-07-11 11:49:00,459 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,460 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,460 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 63(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,460 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,462 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,463 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 63 (MappedRDD[254] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,464 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 63 (MappedRDD[254] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,464 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 2 tasks
2014-07-11 11:49:00,465 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 63.0:0 as TID 126 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,465 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 63.0:0 as 2294 bytes in 0 ms
2014-07-11 11:49:00,465 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 63.0:1 as TID 127 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,466 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 63.0:1 as 2294 bytes in 1 ms
2014-07-11 11:49:00,466 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 126
2014-07-11 11:49:00,467 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 127
2014-07-11 11:49:00,467 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,468 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,468 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,468 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,469 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,469 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 126 is 678
2014-07-11 11:49:00,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 126 directly to driver
2014-07-11 11:49:00,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 126
2014-07-11 11:49:00,539 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(63, 0)
2014-07-11 11:49:00,539 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 126 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,547 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 127 is 678
2014-07-11 11:49:00,547 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 127 directly to driver
2014-07-11 11:49:00,547 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 127
2014-07-11 11:49:00,548 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(63, 1)
2014-07-11 11:49:00,548 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 127 in 83 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,548 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,548 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 63 (reduce at CalEigenVector.scala:38) finished in 0.083 s
2014-07-11 11:49:00,548 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088730046 s
2014-07-11 11:49:00,553 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,554 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,554 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,554 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,556 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,556 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[258] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 64 (MappedRDD[258] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 2 tasks
2014-07-11 11:49:00,558 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 128 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,559 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2293 bytes in 0 ms
2014-07-11 11:49:00,559 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:1 as TID 129 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,559 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:1 as 2293 bytes in 0 ms
2014-07-11 11:49:00,559 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 128
2014-07-11 11:49:00,560 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,561 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,561 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,563 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 129
2014-07-11 11:49:00,564 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,565 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,566 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 128 is 678
2014-07-11 11:49:00,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 128 directly to driver
2014-07-11 11:49:00,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 128
2014-07-11 11:49:00,633 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 128 in 75 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-11 11:49:00,636 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 129 is 678
2014-07-11 11:49:00,636 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 129 directly to driver
2014-07-11 11:49:00,636 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 129
2014-07-11 11:49:00,636 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 1)
2014-07-11 11:49:00,637 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:49:00,636 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 129 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,637 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,637 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083562317 s
2014-07-11 11:49:00,642 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,642 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,642 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 65(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,643 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 65 (MappedRDD[262] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,646 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 65 (MappedRDD[262] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,646 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 65.0 with 2 tasks
2014-07-11 11:49:00,647 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 65.0:0 as TID 130 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,647 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 65.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:00,648 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 65.0:1 as TID 131 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,648 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 65.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:00,648 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 131
2014-07-11 11:49:00,650 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,651 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,651 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,653 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 130
2014-07-11 11:49:00,654 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,659 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,660 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,716 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 131 is 678
2014-07-11 11:49:00,716 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 131 directly to driver
2014-07-11 11:49:00,717 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 131 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,717 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(65, 1)
2014-07-11 11:49:00,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 131
2014-07-11 11:49:00,747 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 130 is 678
2014-07-11 11:49:00,747 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 130 directly to driver
2014-07-11 11:49:00,747 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 130
2014-07-11 11:49:00,748 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(65, 0)
2014-07-11 11:49:00,749 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 65 (reduce at CalEigenVector.scala:38) finished in 0.101 s
2014-07-11 11:49:00,748 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 130 in 101 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,749 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,749 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.107096886 s
2014-07-11 11:49:00,754 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,755 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,755 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,755 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,756 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,757 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[266] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,758 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 66 (MappedRDD[266] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,758 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 2 tasks
2014-07-11 11:49:00,759 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 132 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,759 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:00,759 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:1 as TID 133 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,760 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:1 as 2296 bytes in 1 ms
2014-07-11 11:49:00,760 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 132
2014-07-11 11:49:00,760 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 133
2014-07-11 11:49:00,761 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,761 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,762 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,762 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,762 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,762 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,827 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 133 is 678
2014-07-11 11:49:00,827 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 133 directly to driver
2014-07-11 11:49:00,828 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 133 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,828 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 1)
2014-07-11 11:49:00,829 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 133
2014-07-11 11:49:00,833 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 132 is 678
2014-07-11 11:49:00,833 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 132 directly to driver
2014-07-11 11:49:00,833 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 132
2014-07-11 11:49:00,834 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-11 11:49:00,834 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 132 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,834 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,834 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:49:00,834 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080073317 s
2014-07-11 11:49:00,839 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,840 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,840 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 67(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,840 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,841 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,842 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 67 (MappedRDD[270] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,844 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 67 (MappedRDD[270] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,844 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 67.0 with 2 tasks
2014-07-11 11:49:00,845 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 67.0:0 as TID 134 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,845 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 67.0:0 as 2294 bytes in 0 ms
2014-07-11 11:49:00,845 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 67.0:1 as TID 135 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,846 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 67.0:1 as 2294 bytes in 1 ms
2014-07-11 11:49:00,846 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 135
2014-07-11 11:49:00,846 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 134
2014-07-11 11:49:00,847 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,847 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,848 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,848 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,848 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,848 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,914 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 135 is 678
2014-07-11 11:49:00,914 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 135 directly to driver
2014-07-11 11:49:00,915 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 134 is 678
2014-07-11 11:49:00,915 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 135
2014-07-11 11:49:00,915 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 135 in 70 ms on localhost (progress: 1/2)
2014-07-11 11:49:00,915 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(67, 1)
2014-07-11 11:49:00,915 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 134 directly to driver
2014-07-11 11:49:00,916 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 134
2014-07-11 11:49:00,916 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(67, 0)
2014-07-11 11:49:00,917 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 134 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:49:00,917 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2014-07-11 11:49:00,917 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 67 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:49:00,917 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077811373 s
2014-07-11 11:49:00,922 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:00,923 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:00,923 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:00,923 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:00,924 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:00,925 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[274] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:00,926 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 68 (MappedRDD[274] at map at CalEigenVector.scala:38)
2014-07-11 11:49:00,926 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 2 tasks
2014-07-11 11:49:00,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 136 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:00,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:1 as TID 137 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:00,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:00,928 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 136
2014-07-11 11:49:00,928 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 137
2014-07-11 11:49:00,929 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,929 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:00,930 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,930 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:00,939 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:00,939 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,000 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 137 is 678
2014-07-11 11:49:01,000 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 137 directly to driver
2014-07-11 11:49:01,001 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 137 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,001 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 1)
2014-07-11 11:49:01,002 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 137
2014-07-11 11:49:01,013 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 136 is 678
2014-07-11 11:49:01,013 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 136 directly to driver
2014-07-11 11:49:01,013 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 136
2014-07-11 11:49:01,014 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 136 in 87 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,014 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,014 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-11 11:49:01,014 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at CalEigenVector.scala:38) finished in 0.088 s
2014-07-11 11:49:01,015 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.092736857 s
2014-07-11 11:49:01,020 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,020 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,020 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 69(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,020 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,022 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,022 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 69 (MappedRDD[278] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,024 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 69 (MappedRDD[278] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,024 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 69.0 with 2 tasks
2014-07-11 11:49:01,024 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 69.0:0 as TID 138 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,025 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 69.0:0 as 2297 bytes in 1 ms
2014-07-11 11:49:01,025 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 69.0:1 as TID 139 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,025 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 69.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:01,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 138
2014-07-11 11:49:01,026 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 139
2014-07-11 11:49:01,026 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,026 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,027 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,027 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,027 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,027 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,091 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 138 is 678
2014-07-11 11:49:01,091 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 138 directly to driver
2014-07-11 11:49:01,091 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 138
2014-07-11 11:49:01,092 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(69, 0)
2014-07-11 11:49:01,092 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 138 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,094 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 139 is 678
2014-07-11 11:49:01,094 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 139 directly to driver
2014-07-11 11:49:01,094 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 139
2014-07-11 11:49:01,095 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 139 in 70 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,095 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,095 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(69, 1)
2014-07-11 11:49:01,096 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 69 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:49:01,096 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076284221 s
2014-07-11 11:49:01,101 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,102 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,102 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,102 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,103 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,104 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[282] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,105 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 70 (MappedRDD[282] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,105 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 2 tasks
2014-07-11 11:49:01,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 140 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:01,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:1 as TID 141 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:01,107 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 140
2014-07-11 11:49:01,107 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 141
2014-07-11 11:49:01,108 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,108 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,109 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,109 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,109 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,109 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,171 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 141 is 678
2014-07-11 11:49:01,171 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 141 directly to driver
2014-07-11 11:49:01,171 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 141
2014-07-11 11:49:01,172 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 1)
2014-07-11 11:49:01,172 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 141 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,175 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 140 is 678
2014-07-11 11:49:01,175 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 140 directly to driver
2014-07-11 11:49:01,175 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 140
2014-07-11 11:49:01,176 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-11 11:49:01,176 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 140 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,176 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,176 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:49:01,176 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.07473485 s
2014-07-11 11:49:01,181 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,182 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,182 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 71(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,182 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,183 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,184 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 71 (MappedRDD[286] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,185 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 71 (MappedRDD[286] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,185 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 71.0 with 2 tasks
2014-07-11 11:49:01,186 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 71.0:0 as TID 142 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,186 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 71.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:01,187 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 71.0:1 as TID 143 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,187 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 71.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:01,187 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 142
2014-07-11 11:49:01,187 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 143
2014-07-11 11:49:01,188 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,188 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,189 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,189 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,196 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,197 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,250 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 143 is 678
2014-07-11 11:49:01,250 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 143 directly to driver
2014-07-11 11:49:01,251 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 143 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,251 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(71, 1)
2014-07-11 11:49:01,251 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 143
2014-07-11 11:49:01,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 142 is 678
2014-07-11 11:49:01,261 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 142 directly to driver
2014-07-11 11:49:01,261 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 142
2014-07-11 11:49:01,261 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(71, 0)
2014-07-11 11:49:01,261 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 71 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:49:01,262 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080651584 s
2014-07-11 11:49:01,261 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 142 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,262 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,267 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,268 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,268 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,268 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,269 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,270 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[290] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,271 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 72 (MappedRDD[290] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,271 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 2 tasks
2014-07-11 11:49:01,272 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 144 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,272 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:01,273 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:1 as TID 145 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,273 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:01,273 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 145
2014-07-11 11:49:01,275 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,276 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,276 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,280 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 144
2014-07-11 11:49:01,281 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,282 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,282 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 145 is 678
2014-07-11 11:49:01,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 145 directly to driver
2014-07-11 11:49:01,337 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 145 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,337 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 1)
2014-07-11 11:49:01,337 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 145
2014-07-11 11:49:01,366 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 144 is 678
2014-07-11 11:49:01,366 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 144 directly to driver
2014-07-11 11:49:01,366 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 144
2014-07-11 11:49:01,366 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 144 in 94 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,367 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,367 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-11 11:49:01,367 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at CalEigenVector.scala:38) finished in 0.096 s
2014-07-11 11:49:01,368 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.100568411 s
2014-07-11 11:49:01,374 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,375 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,375 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 73(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,375 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,376 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,377 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 73 (MappedRDD[294] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,379 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 73 (MappedRDD[294] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,379 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 73.0 with 2 tasks
2014-07-11 11:49:01,379 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 73.0:0 as TID 146 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,380 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 73.0:0 as 2296 bytes in 1 ms
2014-07-11 11:49:01,380 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 73.0:1 as TID 147 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,380 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 73.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:01,380 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 146
2014-07-11 11:49:01,380 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 147
2014-07-11 11:49:01,381 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,381 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,382 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,382 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,382 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,382 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,428 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 146 is 678
2014-07-11 11:49:01,428 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 146 directly to driver
2014-07-11 11:49:01,429 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 146 in 50 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,430 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(73, 0)
2014-07-11 11:49:01,430 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 146
2014-07-11 11:49:01,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 147 is 678
2014-07-11 11:49:01,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 147 directly to driver
2014-07-11 11:49:01,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 147
2014-07-11 11:49:01,453 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 147 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,453 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,453 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(73, 1)
2014-07-11 11:49:01,453 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 73 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:49:01,454 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079912627 s
2014-07-11 11:49:01,459 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,460 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,460 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,460 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,462 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,462 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[298] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,465 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 74 (MappedRDD[298] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,465 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 2 tasks
2014-07-11 11:49:01,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 148 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:01,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:1 as TID 149 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,466 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:01,467 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 149
2014-07-11 11:49:01,468 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,469 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,469 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,471 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 148
2014-07-11 11:49:01,472 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,473 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,473 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 149 is 678
2014-07-11 11:49:01,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 149 directly to driver
2014-07-11 11:49:01,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 149
2014-07-11 11:49:01,532 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 1)
2014-07-11 11:49:01,532 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 149 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 148 is 678
2014-07-11 11:49:01,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 148 directly to driver
2014-07-11 11:49:01,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 148
2014-07-11 11:49:01,539 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-11 11:49:01,539 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:49:01,539 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079474268 s
2014-07-11 11:49:01,539 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 148 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,541 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,546 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,546 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,547 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 75(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,547 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,552 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,553 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 75 (MappedRDD[302] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,554 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 75 (MappedRDD[302] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,555 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 75.0 with 2 tasks
2014-07-11 11:49:01,555 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 75.0:0 as TID 150 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,556 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 75.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:01,556 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 75.0:1 as TID 151 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,556 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 75.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:01,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 150
2014-07-11 11:49:01,556 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 151
2014-07-11 11:49:01,557 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,557 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,558 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,558 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,558 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,558 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,627 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 151 is 678
2014-07-11 11:49:01,627 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 151 directly to driver
2014-07-11 11:49:01,627 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 150 is 678
2014-07-11 11:49:01,627 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 150 directly to driver
2014-07-11 11:49:01,627 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 150
2014-07-11 11:49:01,628 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 151
2014-07-11 11:49:01,628 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(75, 1)
2014-07-11 11:49:01,628 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 151 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,629 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(75, 0)
2014-07-11 11:49:01,629 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 75 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:49:01,629 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 150 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,629 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,629 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.083179149 s
2014-07-11 11:49:01,634 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,635 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,635 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,635 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,636 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,637 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[306] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,638 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 76 (MappedRDD[306] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,638 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 2 tasks
2014-07-11 11:49:01,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 152 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:01,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:1 as TID 153 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:01,640 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 152
2014-07-11 11:49:01,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 153
2014-07-11 11:49:01,641 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,641 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,642 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,642 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,642 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,642 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,707 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 153 is 678
2014-07-11 11:49:01,707 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 153 directly to driver
2014-07-11 11:49:01,708 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 153 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,708 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 1)
2014-07-11 11:49:01,708 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 153
2014-07-11 11:49:01,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 152 is 678
2014-07-11 11:49:01,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 152 directly to driver
2014-07-11 11:49:01,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 152
2014-07-11 11:49:01,718 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-11 11:49:01,718 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 152 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,718 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,718 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at CalEigenVector.scala:38) finished in 0.080 s
2014-07-11 11:49:01,718 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08401991 s
2014-07-11 11:49:01,724 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,725 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,725 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 77(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,725 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,726 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,727 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 77 (MappedRDD[310] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,728 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 77 (MappedRDD[310] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,728 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 77.0 with 2 tasks
2014-07-11 11:49:01,729 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 77.0:0 as TID 154 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,729 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 77.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:01,729 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 77.0:1 as TID 155 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,730 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 77.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:01,730 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 154
2014-07-11 11:49:01,730 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 155
2014-07-11 11:49:01,731 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,731 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,732 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,732 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,732 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,732 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,797 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 155 is 678
2014-07-11 11:49:01,797 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 155 directly to driver
2014-07-11 11:49:01,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 155
2014-07-11 11:49:01,801 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 155 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,801 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(77, 1)
2014-07-11 11:49:01,805 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 154 is 678
2014-07-11 11:49:01,805 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 154 directly to driver
2014-07-11 11:49:01,805 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 154
2014-07-11 11:49:01,806 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(77, 0)
2014-07-11 11:49:01,806 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 154 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,806 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,806 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 77 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:49:01,807 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082591878 s
2014-07-11 11:49:01,813 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,814 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,814 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,814 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,825 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,825 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[314] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,829 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 78 (MappedRDD[314] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,829 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 2 tasks
2014-07-11 11:49:01,833 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 156 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,833 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:01,834 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:1 as TID 157 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,834 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:01,834 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 156
2014-07-11 11:49:01,835 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 157
2014-07-11 11:49:01,836 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,836 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,837 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,838 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,839 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,840 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,921 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 157 is 678
2014-07-11 11:49:01,921 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 157 directly to driver
2014-07-11 11:49:01,921 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 157
2014-07-11 11:49:01,921 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 1)
2014-07-11 11:49:01,921 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 157 in 87 ms on localhost (progress: 1/2)
2014-07-11 11:49:01,925 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 156 is 678
2014-07-11 11:49:01,925 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 156 directly to driver
2014-07-11 11:49:01,925 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 156
2014-07-11 11:49:01,926 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 156 in 93 ms on localhost (progress: 2/2)
2014-07-11 11:49:01,926 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-11 11:49:01,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-11 11:49:01,927 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:49:01,930 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.116507533 s
2014-07-11 11:49:01,936 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:01,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:01,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 79(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:01,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:01,938 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:01,939 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 79 (MappedRDD[318] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:01,940 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 79 (MappedRDD[318] at map at CalEigenVector.scala:38)
2014-07-11 11:49:01,940 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 79.0 with 2 tasks
2014-07-11 11:49:01,941 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 79.0:0 as TID 158 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,941 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 79.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:01,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 79.0:1 as TID 159 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:01,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 79.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:01,942 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 159
2014-07-11 11:49:01,943 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 158
2014-07-11 11:49:01,944 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,944 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:01,945 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,945 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:01,945 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:01,945 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 158 is 678
2014-07-11 11:49:02,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 158 directly to driver
2014-07-11 11:49:02,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 158
2014-07-11 11:49:02,009 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(79, 0)
2014-07-11 11:49:02,009 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 158 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,018 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 159 is 678
2014-07-11 11:49:02,018 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 159 directly to driver
2014-07-11 11:49:02,018 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 159
2014-07-11 11:49:02,019 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(79, 1)
2014-07-11 11:49:02,019 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 159 in 78 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,019 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,019 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 79 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:49:02,019 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082963354 s
2014-07-11 11:49:02,025 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,026 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,026 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,026 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,027 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,028 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[322] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,029 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 80 (MappedRDD[322] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,029 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 2 tasks
2014-07-11 11:49:02,030 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 160 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,030 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:02,030 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:1 as TID 161 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,030 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:02,031 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 160
2014-07-11 11:49:02,031 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 161
2014-07-11 11:49:02,032 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,033 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,034 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,034 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,036 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,036 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 160 is 678
2014-07-11 11:49:02,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 160 directly to driver
2014-07-11 11:49:02,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 160
2014-07-11 11:49:02,099 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 160 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,099 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-11 11:49:02,114 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 161 is 678
2014-07-11 11:49:02,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 161 directly to driver
2014-07-11 11:49:02,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 161
2014-07-11 11:49:02,115 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 1)
2014-07-11 11:49:02,115 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 161 in 85 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,116 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,116 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at CalEigenVector.scala:38) finished in 0.086 s
2014-07-11 11:49:02,116 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.09044315 s
2014-07-11 11:49:02,122 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,123 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,123 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 81(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,123 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,125 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,125 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 81 (MappedRDD[326] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 81 (MappedRDD[326] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 81.0 with 2 tasks
2014-07-11 11:49:02,128 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 81.0:0 as TID 162 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,128 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 81.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:02,129 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 81.0:1 as TID 163 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,129 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 81.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:02,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 162
2014-07-11 11:49:02,130 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 163
2014-07-11 11:49:02,131 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,131 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,132 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,132 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,132 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,132 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,203 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 163 is 678
2014-07-11 11:49:02,203 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 163 directly to driver
2014-07-11 11:49:02,203 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 163
2014-07-11 11:49:02,204 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(81, 1)
2014-07-11 11:49:02,204 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 163 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,208 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 162 is 678
2014-07-11 11:49:02,208 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 162 directly to driver
2014-07-11 11:49:02,208 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 162
2014-07-11 11:49:02,209 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(81, 0)
2014-07-11 11:49:02,209 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 81 (reduce at CalEigenVector.scala:38) finished in 0.081 s
2014-07-11 11:49:02,209 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 162 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,209 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,209 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.087504266 s
2014-07-11 11:49:02,214 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,215 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,215 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,215 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,217 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,218 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[330] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,219 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 82 (MappedRDD[330] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,219 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 2 tasks
2014-07-11 11:49:02,219 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 164 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,220 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2295 bytes in 1 ms
2014-07-11 11:49:02,220 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:1 as TID 165 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,220 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:02,221 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 165
2014-07-11 11:49:02,221 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 164
2014-07-11 11:49:02,222 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,222 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,223 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,223 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,226 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,226 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,293 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 165 is 678
2014-07-11 11:49:02,293 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 165 directly to driver
2014-07-11 11:49:02,293 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 165
2014-07-11 11:49:02,294 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 1)
2014-07-11 11:49:02,294 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 165 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,295 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 164 is 678
2014-07-11 11:49:02,295 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 164 directly to driver
2014-07-11 11:49:02,295 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 164
2014-07-11 11:49:02,295 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-11 11:49:02,295 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 164 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,295 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,295 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:49:02,296 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081046034 s
2014-07-11 11:49:02,310 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,311 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,311 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 83(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,311 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,316 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,316 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 83 (MappedRDD[334] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,318 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 83 (MappedRDD[334] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,318 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 83.0 with 2 tasks
2014-07-11 11:49:02,320 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 83.0:0 as TID 166 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,320 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 83.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:02,321 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 83.0:1 as TID 167 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,321 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 83.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:02,321 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 167
2014-07-11 11:49:02,322 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,323 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,324 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,324 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 166
2014-07-11 11:49:02,326 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,327 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,329 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 166 is 678
2014-07-11 11:49:02,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 166 directly to driver
2014-07-11 11:49:02,402 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 166 in 82 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,403 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(83, 0)
2014-07-11 11:49:02,403 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 166
2014-07-11 11:49:02,425 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 167 is 678
2014-07-11 11:49:02,425 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 167 directly to driver
2014-07-11 11:49:02,425 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 167
2014-07-11 11:49:02,426 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(83, 1)
2014-07-11 11:49:02,426 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 83 (reduce at CalEigenVector.scala:38) finished in 0.102 s
2014-07-11 11:49:02,426 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 167 in 105 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,426 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,426 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.11644863 s
2014-07-11 11:49:02,434 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,435 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,435 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,435 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,438 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,438 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[338] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,441 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 84 (MappedRDD[338] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,441 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 2 tasks
2014-07-11 11:49:02,442 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 168 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,442 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:02,442 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:1 as TID 169 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,442 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:02,443 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 168
2014-07-11 11:49:02,443 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 169
2014-07-11 11:49:02,444 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,445 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,445 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,446 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,447 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,448 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,529 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 168 is 678
2014-07-11 11:49:02,529 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 168 directly to driver
2014-07-11 11:49:02,530 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 168
2014-07-11 11:49:02,530 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-11 11:49:02,530 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 168 in 88 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,543 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 169 is 678
2014-07-11 11:49:02,543 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 169 directly to driver
2014-07-11 11:49:02,544 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 169 in 102 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,544 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,544 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 1)
2014-07-11 11:49:02,544 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at CalEigenVector.scala:38) finished in 0.100 s
2014-07-11 11:49:02,545 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.110617202 s
2014-07-11 11:49:02,555 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,555 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 169
2014-07-11 11:49:02,556 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,556 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 85(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,556 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 85 (MappedRDD[342] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,559 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 85 (MappedRDD[342] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,559 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 85.0 with 2 tasks
2014-07-11 11:49:02,561 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 85.0:0 as TID 170 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,561 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 85.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:02,561 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 85.0:1 as TID 171 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,562 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 85.0:1 as 2295 bytes in 1 ms
2014-07-11 11:49:02,562 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 171
2014-07-11 11:49:02,563 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,564 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,564 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,572 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 170
2014-07-11 11:49:02,573 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,580 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,580 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,617 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 171 is 678
2014-07-11 11:49:02,618 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 171 directly to driver
2014-07-11 11:49:02,618 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 171
2014-07-11 11:49:02,618 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(85, 1)
2014-07-11 11:49:02,618 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 171 in 57 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,636 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 170 is 678
2014-07-11 11:49:02,636 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 170 directly to driver
2014-07-11 11:49:02,636 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 170
2014-07-11 11:49:02,637 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(85, 0)
2014-07-11 11:49:02,637 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 170 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,637 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,637 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 85 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:49:02,637 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082336286 s
2014-07-11 11:49:02,642 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,643 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,643 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,643 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,644 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,644 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[346] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,646 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 86 (MappedRDD[346] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,646 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 2 tasks
2014-07-11 11:49:02,646 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 172 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,646 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:02,647 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:1 as TID 173 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,647 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:02,647 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 172
2014-07-11 11:49:02,647 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 173
2014-07-11 11:49:02,648 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,648 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,652 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,652 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,655 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,717 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 173 is 678
2014-07-11 11:49:02,717 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 173 directly to driver
2014-07-11 11:49:02,717 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 173
2014-07-11 11:49:02,718 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 1)
2014-07-11 11:49:02,718 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 173 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 172 is 678
2014-07-11 11:49:02,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 172 directly to driver
2014-07-11 11:49:02,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 172
2014-07-11 11:49:02,723 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-11 11:49:02,723 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 172 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,723 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,723 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:49:02,723 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081081913 s
2014-07-11 11:49:02,728 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,729 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,729 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 87(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,729 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,730 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,730 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 87 (MappedRDD[350] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,732 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 87 (MappedRDD[350] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,732 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 87.0 with 2 tasks
2014-07-11 11:49:02,732 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 87.0:0 as TID 174 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,732 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 87.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:02,733 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 87.0:1 as TID 175 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,733 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 87.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:02,733 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 174
2014-07-11 11:49:02,733 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 175
2014-07-11 11:49:02,734 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,734 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,735 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,735 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,735 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,735 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 174 is 678
2014-07-11 11:49:02,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 174 directly to driver
2014-07-11 11:49:02,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 174
2014-07-11 11:49:02,804 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(87, 0)
2014-07-11 11:49:02,804 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 174 in 72 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,807 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 175 is 678
2014-07-11 11:49:02,807 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 175 directly to driver
2014-07-11 11:49:02,808 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 175 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,809 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,809 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(87, 1)
2014-07-11 11:49:02,809 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 87 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:49:02,809 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081359231 s
2014-07-11 11:49:02,816 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,816 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,816 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,816 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,818 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,819 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[354] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,820 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 88 (MappedRDD[354] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,820 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 2 tasks
2014-07-11 11:49:02,821 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 175
2014-07-11 11:49:02,821 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 176 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,821 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:02,821 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:1 as TID 177 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,821 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:02,822 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 176
2014-07-11 11:49:02,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 177
2014-07-11 11:49:02,823 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,823 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,824 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,825 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,825 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,825 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 177 is 678
2014-07-11 11:49:02,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 177 directly to driver
2014-07-11 11:49:02,887 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 177 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,887 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 1)
2014-07-11 11:49:02,888 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 177
2014-07-11 11:49:02,891 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 176 is 678
2014-07-11 11:49:02,891 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 176 directly to driver
2014-07-11 11:49:02,891 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 176
2014-07-11 11:49:02,892 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-11 11:49:02,892 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:49:02,892 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 176 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,892 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,892 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076464361 s
2014-07-11 11:49:02,898 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,899 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,899 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 89(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,899 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,900 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,900 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 89 (MappedRDD[358] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,902 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 89 (MappedRDD[358] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,902 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 89.0 with 2 tasks
2014-07-11 11:49:02,902 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 89.0:0 as TID 178 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,902 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 89.0:0 as 2293 bytes in 0 ms
2014-07-11 11:49:02,903 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 89.0:1 as TID 179 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,903 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 89.0:1 as 2293 bytes in 0 ms
2014-07-11 11:49:02,903 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 178
2014-07-11 11:49:02,903 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 179
2014-07-11 11:49:02,904 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,904 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,905 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,905 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,905 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,905 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,970 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 178 is 678
2014-07-11 11:49:02,971 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 178 directly to driver
2014-07-11 11:49:02,971 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 178
2014-07-11 11:49:02,971 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 178 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:02,972 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(89, 0)
2014-07-11 11:49:02,975 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 179 is 678
2014-07-11 11:49:02,975 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 179 directly to driver
2014-07-11 11:49:02,975 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 179
2014-07-11 11:49:02,975 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(89, 1)
2014-07-11 11:49:02,976 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 179 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:49:02,976 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 89.0, whose tasks have all completed, from pool 
2014-07-11 11:49:02,976 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 89 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:49:02,976 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077684245 s
2014-07-11 11:49:02,981 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:02,981 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:02,981 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:02,981 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:02,983 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:02,983 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[362] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:02,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 90 (MappedRDD[362] at map at CalEigenVector.scala:38)
2014-07-11 11:49:02,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 2 tasks
2014-07-11 11:49:02,985 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 180 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,985 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:02,985 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:1 as TID 181 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:02,985 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:02,985 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 180
2014-07-11 11:49:02,986 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,987 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 181
2014-07-11 11:49:02,988 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:02,988 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,988 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:02,989 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:02,990 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 180 is 678
2014-07-11 11:49:03,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 180 directly to driver
2014-07-11 11:49:03,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 180
2014-07-11 11:49:03,056 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 180 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,056 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-11 11:49:03,060 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 181 is 678
2014-07-11 11:49:03,060 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 181 directly to driver
2014-07-11 11:49:03,060 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 181
2014-07-11 11:49:03,061 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 1)
2014-07-11 11:49:03,061 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 181 in 76 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,061 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:49:03,061 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,061 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.08069026 s
2014-07-11 11:49:03,066 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,067 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,067 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 91(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,067 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,069 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,069 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 91 (MappedRDD[366] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,070 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 91 (MappedRDD[366] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,070 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 91.0 with 2 tasks
2014-07-11 11:49:03,071 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 91.0:0 as TID 182 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,071 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 91.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:03,071 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 91.0:1 as TID 183 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,071 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 91.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:03,072 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 182
2014-07-11 11:49:03,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 183
2014-07-11 11:49:03,073 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,073 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,074 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,074 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,074 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,074 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,143 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 182 is 678
2014-07-11 11:49:03,143 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 183 is 678
2014-07-11 11:49:03,143 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 182 directly to driver
2014-07-11 11:49:03,143 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 183 directly to driver
2014-07-11 11:49:03,145 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(91, 0)
2014-07-11 11:49:03,145 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 182 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,143 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 182
2014-07-11 11:49:03,145 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 183
2014-07-11 11:49:03,146 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(91, 1)
2014-07-11 11:49:03,146 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 91 (reduce at CalEigenVector.scala:38) finished in 0.076 s
2014-07-11 11:49:03,146 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 183 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,147 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080659343 s
2014-07-11 11:49:03,159 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,159 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,160 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,160 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,160 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,162 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,162 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[370] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 92 (MappedRDD[370] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 2 tasks
2014-07-11 11:49:03,164 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 184 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:03,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:1 as TID 185 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:03,165 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 184
2014-07-11 11:49:03,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 185
2014-07-11 11:49:03,166 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,166 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,167 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,167 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,167 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,169 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,234 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 184 is 678
2014-07-11 11:49:03,234 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 184 directly to driver
2014-07-11 11:49:03,234 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 184
2014-07-11 11:49:03,235 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-11 11:49:03,235 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 184 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,238 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 185 is 678
2014-07-11 11:49:03,238 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 185 directly to driver
2014-07-11 11:49:03,238 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 185
2014-07-11 11:49:03,239 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 1)
2014-07-11 11:49:03,239 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:49:03,239 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 185 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,239 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,239 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080110941 s
2014-07-11 11:49:03,244 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,245 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,245 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 93(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,245 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,246 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,247 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 93 (MappedRDD[374] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,248 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 93 (MappedRDD[374] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,248 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 93.0 with 2 tasks
2014-07-11 11:49:03,248 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 93.0:0 as TID 186 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,249 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 93.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:03,249 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 93.0:1 as TID 187 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,249 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 93.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:03,249 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 187
2014-07-11 11:49:03,249 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 186
2014-07-11 11:49:03,250 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,250 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,251 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,251 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,251 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,251 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,318 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 187 is 678
2014-07-11 11:49:03,318 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 187 directly to driver
2014-07-11 11:49:03,318 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 187
2014-07-11 11:49:03,318 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(93, 1)
2014-07-11 11:49:03,318 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 187 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 186 is 678
2014-07-11 11:49:03,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 186 directly to driver
2014-07-11 11:49:03,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 186
2014-07-11 11:49:03,325 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(93, 0)
2014-07-11 11:49:03,326 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 93 (reduce at CalEigenVector.scala:38) finished in 0.077 s
2014-07-11 11:49:03,325 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 186 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,326 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,326 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.081371337 s
2014-07-11 11:49:03,330 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,331 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,331 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,331 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,334 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[378] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,335 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 94 (MappedRDD[378] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,335 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 2 tasks
2014-07-11 11:49:03,335 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 188 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,336 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2296 bytes in 1 ms
2014-07-11 11:49:03,336 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:1 as TID 189 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,336 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:03,337 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 188
2014-07-11 11:49:03,338 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,339 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 189
2014-07-11 11:49:03,339 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,340 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,341 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,341 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 189 is 678
2014-07-11 11:49:03,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 189 directly to driver
2014-07-11 11:49:03,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 188 is 678
2014-07-11 11:49:03,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 188 directly to driver
2014-07-11 11:49:03,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 188
2014-07-11 11:49:03,410 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 189 in 73 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,410 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 1)
2014-07-11 11:49:03,410 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 188 in 75 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,410 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-11 11:49:03,410 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,410 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:49:03,411 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 189
2014-07-11 11:49:03,411 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080007166 s
2014-07-11 11:49:03,415 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 95(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 95 (MappedRDD[382] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,420 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 95 (MappedRDD[382] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,420 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 95.0 with 2 tasks
2014-07-11 11:49:03,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 95.0:0 as TID 190 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 95.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:03,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 95.0:1 as TID 191 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 95.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:03,422 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 190
2014-07-11 11:49:03,422 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 191
2014-07-11 11:49:03,423 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,424 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,424 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,424 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,425 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,426 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,498 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 191 is 678
2014-07-11 11:49:03,498 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 191 directly to driver
2014-07-11 11:49:03,498 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 191
2014-07-11 11:49:03,499 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 191 in 78 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,499 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(95, 1)
2014-07-11 11:49:03,503 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 190 is 678
2014-07-11 11:49:03,503 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 190 directly to driver
2014-07-11 11:49:03,503 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 190
2014-07-11 11:49:03,504 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(95, 0)
2014-07-11 11:49:03,504 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 190 in 82 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,504 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 95.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,504 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 95 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:49:03,504 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.088492577 s
2014-07-11 11:49:03,509 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,509 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,509 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,509 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,511 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,511 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[386] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,513 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 96 (MappedRDD[386] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,513 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 2 tasks
2014-07-11 11:49:03,514 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 192 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,515 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:03,515 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:1 as TID 193 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,515 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:03,515 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 192
2014-07-11 11:49:03,516 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 193
2014-07-11 11:49:03,516 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,517 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,518 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,518 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,531 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,531 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,572 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 193 is 678
2014-07-11 11:49:03,572 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 193 directly to driver
2014-07-11 11:49:03,573 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 193
2014-07-11 11:49:03,573 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 1)
2014-07-11 11:49:03,573 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 193 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,586 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 192 is 678
2014-07-11 11:49:03,586 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 192 directly to driver
2014-07-11 11:49:03,586 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 192
2014-07-11 11:49:03,587 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-11 11:49:03,587 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 192 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,587 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,587 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:49:03,587 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078433084 s
2014-07-11 11:49:03,592 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,593 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,593 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 97(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,593 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,594 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,595 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 97 (MappedRDD[390] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,596 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 97 (MappedRDD[390] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,596 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 97.0 with 2 tasks
2014-07-11 11:49:03,596 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 97.0:0 as TID 194 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,597 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 97.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:03,597 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 97.0:1 as TID 195 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,597 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 97.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:03,597 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 194
2014-07-11 11:49:03,598 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 195
2014-07-11 11:49:03,599 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,599 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,600 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,600 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,608 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,609 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,644 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 195 is 678
2014-07-11 11:49:03,644 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 195 directly to driver
2014-07-11 11:49:03,644 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 195
2014-07-11 11:49:03,645 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(97, 1)
2014-07-11 11:49:03,645 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 195 in 48 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 194 is 678
2014-07-11 11:49:03,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 194 directly to driver
2014-07-11 11:49:03,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 194
2014-07-11 11:49:03,655 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(97, 0)
2014-07-11 11:49:03,656 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 97 (reduce at CalEigenVector.scala:38) finished in 0.059 s
2014-07-11 11:49:03,655 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 194 in 59 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,656 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 97.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,656 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.063404819 s
2014-07-11 11:49:03,660 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,661 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,661 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,661 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,663 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[394] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,664 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 98 (MappedRDD[394] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,664 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 2 tasks
2014-07-11 11:49:03,665 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 196 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,665 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:03,665 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:1 as TID 197 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,666 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:1 as 2297 bytes in 1 ms
2014-07-11 11:49:03,666 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 196
2014-07-11 11:49:03,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 197
2014-07-11 11:49:03,667 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,668 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,668 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,668 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,668 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,669 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,726 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 196 is 678
2014-07-11 11:49:03,726 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 196 directly to driver
2014-07-11 11:49:03,726 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 196
2014-07-11 11:49:03,727 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-11 11:49:03,727 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 196 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,730 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 197 is 678
2014-07-11 11:49:03,730 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 197 directly to driver
2014-07-11 11:49:03,730 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 197
2014-07-11 11:49:03,731 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 1)
2014-07-11 11:49:03,731 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:49:03,731 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 197 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,731 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,731 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.070900254 s
2014-07-11 11:49:03,736 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,737 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,737 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 99(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,737 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,738 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,739 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 99 (MappedRDD[398] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,740 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 99 (MappedRDD[398] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,740 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 99.0 with 2 tasks
2014-07-11 11:49:03,741 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 99.0:0 as TID 198 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,741 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 99.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:03,741 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 99.0:1 as TID 199 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,741 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 99.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:03,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 198
2014-07-11 11:49:03,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 199
2014-07-11 11:49:03,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,743 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,744 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,744 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,753 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,753 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 199 is 678
2014-07-11 11:49:03,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 199 directly to driver
2014-07-11 11:49:03,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 199
2014-07-11 11:49:03,804 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 199 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,805 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(99, 1)
2014-07-11 11:49:03,821 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 198 is 678
2014-07-11 11:49:03,821 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 198 directly to driver
2014-07-11 11:49:03,821 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 198
2014-07-11 11:49:03,822 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(99, 0)
2014-07-11 11:49:03,822 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 198 in 81 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,822 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,822 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 99 (reduce at CalEigenVector.scala:38) finished in 0.082 s
2014-07-11 11:49:03,823 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.086312282 s
2014-07-11 11:49:03,828 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,829 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,829 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,829 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,831 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,831 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[402] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,832 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 100 (MappedRDD[402] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,832 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 2 tasks
2014-07-11 11:49:03,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 200 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2295 bytes in 0 ms
2014-07-11 11:49:03,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:1 as TID 201 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:03,834 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 200
2014-07-11 11:49:03,834 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 201
2014-07-11 11:49:03,835 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,836 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,836 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,844 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,845 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,845 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,897 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 201 is 678
2014-07-11 11:49:03,897 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 201 directly to driver
2014-07-11 11:49:03,898 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 201 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:49:03,898 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 1)
2014-07-11 11:49:03,899 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 201
2014-07-11 11:49:03,935 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 200 is 678
2014-07-11 11:49:03,935 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 200 directly to driver
2014-07-11 11:49:03,935 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 200
2014-07-11 11:49:03,936 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-11 11:49:03,937 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at CalEigenVector.scala:38) finished in 0.105 s
2014-07-11 11:49:03,937 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.108237111 s
2014-07-11 11:49:03,936 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 200 in 103 ms on localhost (progress: 2/2)
2014-07-11 11:49:03,939 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-11 11:49:03,942 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:03,943 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:03,943 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 101(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:03,943 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:03,944 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:03,945 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 101 (MappedRDD[406] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:03,946 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 101 (MappedRDD[406] at map at CalEigenVector.scala:38)
2014-07-11 11:49:03,946 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 101.0 with 2 tasks
2014-07-11 11:49:03,947 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 101.0:0 as TID 202 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,947 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 101.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:03,947 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 101.0:1 as TID 203 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:03,947 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 101.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:03,948 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 202
2014-07-11 11:49:03,948 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 203
2014-07-11 11:49:03,949 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,949 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:03,949 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,949 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:03,949 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:03,950 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,012 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 202 is 678
2014-07-11 11:49:04,012 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 202 directly to driver
2014-07-11 11:49:04,012 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 202
2014-07-11 11:49:04,013 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(101, 0)
2014-07-11 11:49:04,013 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 202 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,039 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 203 is 678
2014-07-11 11:49:04,039 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 203 directly to driver
2014-07-11 11:49:04,039 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 203
2014-07-11 11:49:04,040 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 203 in 93 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,040 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 101.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,040 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(101, 1)
2014-07-11 11:49:04,040 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 101 (reduce at CalEigenVector.scala:38) finished in 0.094 s
2014-07-11 11:49:04,040 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.097789863 s
2014-07-11 11:49:04,045 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,046 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,046 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,046 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,047 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,047 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[410] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,049 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 102 (MappedRDD[410] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,049 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 2 tasks
2014-07-11 11:49:04,049 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 204 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,049 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,050 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:1 as TID 205 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,050 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,050 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 204
2014-07-11 11:49:04,050 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 205
2014-07-11 11:49:04,051 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,051 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,052 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,052 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,055 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,055 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,117 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 204 is 678
2014-07-11 11:49:04,117 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 204 directly to driver
2014-07-11 11:49:04,117 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 204
2014-07-11 11:49:04,118 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-11 11:49:04,118 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 204 in 69 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,120 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 205 is 678
2014-07-11 11:49:04,120 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 205 directly to driver
2014-07-11 11:49:04,120 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 205
2014-07-11 11:49:04,121 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 1)
2014-07-11 11:49:04,121 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:49:04,121 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076306522 s
2014-07-11 11:49:04,121 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 205 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,123 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,126 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,127 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,127 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 103(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,127 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,128 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,129 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 103 (MappedRDD[414] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,130 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 103 (MappedRDD[414] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,130 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 103.0 with 2 tasks
2014-07-11 11:49:04,130 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 103.0:0 as TID 206 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,131 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 103.0:0 as 2296 bytes in 1 ms
2014-07-11 11:49:04,131 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 103.0:1 as TID 207 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,131 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 103.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,131 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 206
2014-07-11 11:49:04,132 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 207
2014-07-11 11:49:04,133 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,133 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,133 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,135 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,136 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,136 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,197 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 207 is 678
2014-07-11 11:49:04,197 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 207 directly to driver
2014-07-11 11:49:04,198 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 207
2014-07-11 11:49:04,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(103, 1)
2014-07-11 11:49:04,198 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 207 in 67 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,202 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 206 is 678
2014-07-11 11:49:04,202 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 206 directly to driver
2014-07-11 11:49:04,202 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 206
2014-07-11 11:49:04,203 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 206 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,203 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,203 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(103, 0)
2014-07-11 11:49:04,204 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 103 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:49:04,207 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.080704208 s
2014-07-11 11:49:04,212 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,212 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,212 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,212 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,214 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,214 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[418] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,216 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 104 (MappedRDD[418] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,216 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 2 tasks
2014-07-11 11:49:04,216 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 208 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,216 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,217 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:1 as TID 209 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,217 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,217 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 208
2014-07-11 11:49:04,217 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 209
2014-07-11 11:49:04,218 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,218 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,219 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,219 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,219 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,219 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 208 is 678
2014-07-11 11:49:04,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 208 directly to driver
2014-07-11 11:49:04,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 208
2014-07-11 11:49:04,284 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-11 11:49:04,284 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 208 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,286 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 209 is 678
2014-07-11 11:49:04,286 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 209 directly to driver
2014-07-11 11:49:04,286 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 209
2014-07-11 11:49:04,286 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 1)
2014-07-11 11:49:04,287 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:49:04,286 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 209 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,287 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,287 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075083074 s
2014-07-11 11:49:04,295 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,295 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,295 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 105(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,295 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,297 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,297 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 105 (MappedRDD[422] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,298 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 105 (MappedRDD[422] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,298 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 105.0 with 2 tasks
2014-07-11 11:49:04,299 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 105.0:0 as TID 210 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,299 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 105.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,299 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 105.0:1 as TID 211 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,299 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 105.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,305 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 210
2014-07-11 11:49:04,306 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,307 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,307 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,307 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 211
2014-07-11 11:49:04,311 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,312 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,312 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,386 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 210 is 678
2014-07-11 11:49:04,386 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 210 directly to driver
2014-07-11 11:49:04,386 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 211 is 678
2014-07-11 11:49:04,386 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 211 directly to driver
2014-07-11 11:49:04,387 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(105, 0)
2014-07-11 11:49:04,387 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 210 in 89 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,386 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 210
2014-07-11 11:49:04,387 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 211
2014-07-11 11:49:04,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(105, 1)
2014-07-11 11:49:04,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 105 (reduce at CalEigenVector.scala:38) finished in 0.090 s
2014-07-11 11:49:04,388 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.093311936 s
2014-07-11 11:49:04,388 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 211 in 88 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,388 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,393 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,399 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,399 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,399 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,400 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,401 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[426] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,402 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 106 (MappedRDD[426] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,402 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 2 tasks
2014-07-11 11:49:04,402 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 212 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,403 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2296 bytes in 1 ms
2014-07-11 11:49:04,403 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:1 as TID 213 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,403 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,403 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 212
2014-07-11 11:49:04,403 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 213
2014-07-11 11:49:04,404 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,404 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,405 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,405 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,405 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,405 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,465 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 212 is 678
2014-07-11 11:49:04,466 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 212 directly to driver
2014-07-11 11:49:04,466 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 212
2014-07-11 11:49:04,466 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-11 11:49:04,466 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 212 in 64 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,468 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 213 is 678
2014-07-11 11:49:04,468 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 213 directly to driver
2014-07-11 11:49:04,468 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 213
2014-07-11 11:49:04,468 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 1)
2014-07-11 11:49:04,468 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:49:04,468 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 213 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,469 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,469 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.075427888 s
2014-07-11 11:49:04,474 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,475 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,475 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 107(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,475 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,476 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,476 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 107 (MappedRDD[430] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,477 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 107 (MappedRDD[430] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,478 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 107.0 with 2 tasks
2014-07-11 11:49:04,478 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 107.0:0 as TID 214 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,478 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 107.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,478 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 107.0:1 as TID 215 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,479 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 107.0:1 as 2296 bytes in 1 ms
2014-07-11 11:49:04,479 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 214
2014-07-11 11:49:04,479 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 215
2014-07-11 11:49:04,480 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,481 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,481 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,488 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,538 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 214 is 678
2014-07-11 11:49:04,538 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 214 directly to driver
2014-07-11 11:49:04,540 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 214 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,540 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(107, 0)
2014-07-11 11:49:04,540 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 214
2014-07-11 11:49:04,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 215 is 678
2014-07-11 11:49:04,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 215 directly to driver
2014-07-11 11:49:04,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 215
2014-07-11 11:49:04,550 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(107, 1)
2014-07-11 11:49:04,550 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 215 in 72 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,550 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 107.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,550 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 107 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:49:04,550 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076117832 s
2014-07-11 11:49:04,555 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,555 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,555 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,555 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,557 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,557 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[434] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,558 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 108 (MappedRDD[434] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,558 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 2 tasks
2014-07-11 11:49:04,558 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 216 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,559 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,559 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:1 as TID 217 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,559 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,559 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 216
2014-07-11 11:49:04,560 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,561 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 217
2014-07-11 11:49:04,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,563 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,563 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,621 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 217 is 678
2014-07-11 11:49:04,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 216 is 678
2014-07-11 11:49:04,621 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 217 directly to driver
2014-07-11 11:49:04,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 216 directly to driver
2014-07-11 11:49:04,621 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 216
2014-07-11 11:49:04,622 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 217 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,622 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 1)
2014-07-11 11:49:04,623 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 216 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,621 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 217
2014-07-11 11:49:04,623 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-11 11:49:04,623 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,623 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at CalEigenVector.scala:38) finished in 0.065 s
2014-07-11 11:49:04,623 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.068545208 s
2014-07-11 11:49:04,628 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,629 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,629 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 109(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,629 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,630 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,630 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 109 (MappedRDD[438] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,631 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 109 (MappedRDD[438] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,631 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 109.0 with 2 tasks
2014-07-11 11:49:04,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 109.0:0 as TID 218 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 109.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 109.0:1 as TID 219 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,633 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 109.0:1 as 2296 bytes in 1 ms
2014-07-11 11:49:04,633 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 218
2014-07-11 11:49:04,634 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,635 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,635 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,637 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 219
2014-07-11 11:49:04,638 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,639 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,639 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,691 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 218 is 678
2014-07-11 11:49:04,692 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 218 directly to driver
2014-07-11 11:49:04,692 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 218
2014-07-11 11:49:04,693 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 218 in 60 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,692 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(109, 0)
2014-07-11 11:49:04,693 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 219 is 678
2014-07-11 11:49:04,693 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 219 directly to driver
2014-07-11 11:49:04,693 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 219
2014-07-11 11:49:04,694 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(109, 1)
2014-07-11 11:49:04,694 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 219 in 62 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,694 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,694 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 109 (reduce at CalEigenVector.scala:38) finished in 0.062 s
2014-07-11 11:49:04,694 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.066020824 s
2014-07-11 11:49:04,699 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,699 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,699 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,699 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,701 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,701 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[442] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,702 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 110 (MappedRDD[442] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,702 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 2 tasks
2014-07-11 11:49:04,703 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 220 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,703 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,703 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:1 as TID 221 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,703 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,703 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 220
2014-07-11 11:49:04,704 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 221
2014-07-11 11:49:04,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,707 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,708 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,708 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,762 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 220 is 678
2014-07-11 11:49:04,762 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 220 directly to driver
2014-07-11 11:49:04,762 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 220
2014-07-11 11:49:04,763 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 220 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,763 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-11 11:49:04,767 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 221 is 678
2014-07-11 11:49:04,768 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 221 directly to driver
2014-07-11 11:49:04,768 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 221
2014-07-11 11:49:04,768 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 221 in 65 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,768 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 1)
2014-07-11 11:49:04,768 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,768 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at CalEigenVector.scala:38) finished in 0.066 s
2014-07-11 11:49:04,769 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.069767378 s
2014-07-11 11:49:04,773 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,774 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,774 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 111(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,774 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,775 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,776 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 111 (MappedRDD[446] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 111 (MappedRDD[446] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 111.0 with 2 tasks
2014-07-11 11:49:04,777 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 111.0:0 as TID 222 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,778 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 111.0:0 as 2295 bytes in 1 ms
2014-07-11 11:49:04,778 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 111.0:1 as TID 223 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,778 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 111.0:1 as 2295 bytes in 0 ms
2014-07-11 11:49:04,779 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 222
2014-07-11 11:49:04,779 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 223
2014-07-11 11:49:04,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,780 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,780 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,781 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,843 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 223 is 678
2014-07-11 11:49:04,843 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 223 directly to driver
2014-07-11 11:49:04,844 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 223
2014-07-11 11:49:04,844 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 223 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,844 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(111, 1)
2014-07-11 11:49:04,849 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 222 is 678
2014-07-11 11:49:04,849 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 222 directly to driver
2014-07-11 11:49:04,849 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 222
2014-07-11 11:49:04,850 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(111, 0)
2014-07-11 11:49:04,850 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 222 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,850 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 111 (reduce at CalEigenVector.scala:38) finished in 0.073 s
2014-07-11 11:49:04,850 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,850 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.077060102 s
2014-07-11 11:49:04,856 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,859 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,859 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,859 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,862 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,863 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[450] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,864 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 112 (MappedRDD[450] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,864 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 2 tasks
2014-07-11 11:49:04,865 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 224 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,865 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:04,865 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:1 as TID 225 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,865 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:04,866 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 224
2014-07-11 11:49:04,867 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,867 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,867 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,871 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 225
2014-07-11 11:49:04,873 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,875 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,875 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,927 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 224 is 678
2014-07-11 11:49:04,928 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 224 directly to driver
2014-07-11 11:49:04,928 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 224
2014-07-11 11:49:04,928 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-11 11:49:04,928 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 224 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:49:04,948 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 225 is 678
2014-07-11 11:49:04,948 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 225 directly to driver
2014-07-11 11:49:04,949 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 225
2014-07-11 11:49:04,949 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 1)
2014-07-11 11:49:04,949 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 225 in 84 ms on localhost (progress: 2/2)
2014-07-11 11:49:04,949 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-11 11:49:04,949 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at CalEigenVector.scala:38) finished in 0.084 s
2014-07-11 11:49:04,950 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.094004624 s
2014-07-11 11:49:04,954 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:04,955 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:04,955 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 113(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:04,955 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:04,957 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:04,957 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 113 (MappedRDD[454] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:04,958 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 113 (MappedRDD[454] at map at CalEigenVector.scala:38)
2014-07-11 11:49:04,958 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 113.0 with 2 tasks
2014-07-11 11:49:04,959 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 113.0:0 as TID 226 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,959 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 113.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:04,959 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 113.0:1 as TID 227 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:04,959 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 113.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:04,960 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 227
2014-07-11 11:49:04,961 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 226
2014-07-11 11:49:04,961 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,961 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:04,962 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,962 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:04,962 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:04,962 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,023 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 227 is 678
2014-07-11 11:49:05,023 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 227 directly to driver
2014-07-11 11:49:05,023 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 227
2014-07-11 11:49:05,024 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(113, 1)
2014-07-11 11:49:05,024 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 227 in 65 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 226 is 678
2014-07-11 11:49:05,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 226 directly to driver
2014-07-11 11:49:05,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 226
2014-07-11 11:49:05,026 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(113, 0)
2014-07-11 11:49:05,026 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 226 in 66 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,026 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 113.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,026 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 113 (reduce at CalEigenVector.scala:38) finished in 0.068 s
2014-07-11 11:49:05,026 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.071633537 s
2014-07-11 11:49:05,031 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,031 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,031 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,031 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,033 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,033 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[458] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,034 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 114 (MappedRDD[458] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,034 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 2 tasks
2014-07-11 11:49:05,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 228 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:05,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:1 as TID 229 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,035 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:05,036 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 228
2014-07-11 11:49:05,036 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 229
2014-07-11 11:49:05,036 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,037 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,037 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,037 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,037 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,037 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,108 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 229 is 678
2014-07-11 11:49:05,108 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 229 directly to driver
2014-07-11 11:49:05,109 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 229 in 74 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,110 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 1)
2014-07-11 11:49:05,110 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 229
2014-07-11 11:49:05,112 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 228 is 678
2014-07-11 11:49:05,112 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 228 directly to driver
2014-07-11 11:49:05,112 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 228
2014-07-11 11:49:05,112 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 228 in 77 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,112 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,113 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-11 11:49:05,113 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at CalEigenVector.scala:38) finished in 0.078 s
2014-07-11 11:49:05,113 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.082206996 s
2014-07-11 11:49:05,118 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,118 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,118 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 115(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,118 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,120 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,120 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 115 (MappedRDD[462] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,121 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 115 (MappedRDD[462] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,121 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 115.0 with 2 tasks
2014-07-11 11:49:05,121 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 115.0:0 as TID 230 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,122 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 115.0:0 as 2296 bytes in 1 ms
2014-07-11 11:49:05,122 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 115.0:1 as TID 231 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,122 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 115.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:05,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 230
2014-07-11 11:49:05,122 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 231
2014-07-11 11:49:05,123 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,123 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,124 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,124 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,124 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,124 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,183 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 230 is 678
2014-07-11 11:49:05,183 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 230 directly to driver
2014-07-11 11:49:05,184 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 230
2014-07-11 11:49:05,184 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(115, 0)
2014-07-11 11:49:05,184 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 230 in 63 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,187 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 231 is 678
2014-07-11 11:49:05,187 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 231 directly to driver
2014-07-11 11:49:05,187 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 231
2014-07-11 11:49:05,190 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(115, 1)
2014-07-11 11:49:05,190 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 115 (reduce at CalEigenVector.scala:38) finished in 0.069 s
2014-07-11 11:49:05,190 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.072321662 s
2014-07-11 11:49:05,190 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 231 in 67 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,191 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,195 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,197 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,197 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[466] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 116 (MappedRDD[466] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 2 tasks
2014-07-11 11:49:05,199 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 232 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,199 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:05,199 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:1 as TID 233 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,200 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:05,200 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 232
2014-07-11 11:49:05,200 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 233
2014-07-11 11:49:05,201 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,207 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,209 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,210 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,210 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,210 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,269 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 233 is 678
2014-07-11 11:49:05,269 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 233 directly to driver
2014-07-11 11:49:05,270 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 233
2014-07-11 11:49:05,270 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 233 in 71 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,270 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 1)
2014-07-11 11:49:05,272 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 232 is 678
2014-07-11 11:49:05,272 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 232 directly to driver
2014-07-11 11:49:05,272 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 232
2014-07-11 11:49:05,273 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 232 in 73 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,273 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,273 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-11 11:49:05,273 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at CalEigenVector.scala:38) finished in 0.074 s
2014-07-11 11:49:05,273 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.078516716 s
2014-07-11 11:49:05,279 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,279 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,279 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 117(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,279 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,281 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,281 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 117 (MappedRDD[470] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,282 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 117 (MappedRDD[470] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,282 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 117.0 with 2 tasks
2014-07-11 11:49:05,283 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 117.0:0 as TID 234 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,283 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 117.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:05,283 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 117.0:1 as TID 235 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,283 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 117.0:1 as 2296 bytes in 0 ms
2014-07-11 11:49:05,284 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 235
2014-07-11 11:49:05,284 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 234
2014-07-11 11:49:05,285 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,286 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,286 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,286 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,286 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,286 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,348 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 234 is 678
2014-07-11 11:49:05,348 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 234 directly to driver
2014-07-11 11:49:05,349 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 234
2014-07-11 11:49:05,349 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 234 in 66 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,349 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(117, 0)
2014-07-11 11:49:05,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 235 is 678
2014-07-11 11:49:05,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 235 directly to driver
2014-07-11 11:49:05,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 235
2014-07-11 11:49:05,354 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(117, 1)
2014-07-11 11:49:05,354 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 235 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,354 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 117 (reduce at CalEigenVector.scala:38) finished in 0.072 s
2014-07-11 11:49:05,355 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,355 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.076011434 s
2014-07-11 11:49:05,360 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,361 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,361 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,361 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,366 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,366 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[474] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,367 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 118 (MappedRDD[474] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,367 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 2 tasks
2014-07-11 11:49:05,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 236 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:05,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:1 as TID 237 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,369 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:1 as 2296 bytes in 1 ms
2014-07-11 11:49:05,369 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 236
2014-07-11 11:49:05,369 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 237
2014-07-11 11:49:05,370 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,371 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,371 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,372 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,372 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,372 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,435 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 237 is 678
2014-07-11 11:49:05,435 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 237 directly to driver
2014-07-11 11:49:05,435 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 237
2014-07-11 11:49:05,436 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 1)
2014-07-11 11:49:05,436 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 237 in 68 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,438 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 236 is 678
2014-07-11 11:49:05,438 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 236 directly to driver
2014-07-11 11:49:05,438 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 236
2014-07-11 11:49:05,439 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-11 11:49:05,439 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 236 in 71 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,439 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at CalEigenVector.scala:38) finished in 0.071 s
2014-07-11 11:49:05,439 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,439 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079069005 s
2014-07-11 11:49:05,446 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,447 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,447 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 119(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,447 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,448 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,448 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 119 (MappedRDD[478] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,449 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 119 (MappedRDD[478] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,449 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 119.0 with 2 tasks
2014-07-11 11:49:05,450 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 119.0:0 as TID 238 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,450 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 119.0:0 as 2297 bytes in 0 ms
2014-07-11 11:49:05,450 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 119.0:1 as TID 239 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,450 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 119.0:1 as 2297 bytes in 0 ms
2014-07-11 11:49:05,451 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 239
2014-07-11 11:49:05,451 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 238
2014-07-11 11:49:05,452 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,452 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,453 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,453 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,453 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,453 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,510 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 239 is 678
2014-07-11 11:49:05,510 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 239 directly to driver
2014-07-11 11:49:05,510 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 239
2014-07-11 11:49:05,511 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(119, 1)
2014-07-11 11:49:05,511 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 239 in 61 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,518 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 238 is 678
2014-07-11 11:49:05,518 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 238 directly to driver
2014-07-11 11:49:05,519 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 238 in 69 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,519 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 119.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,520 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(119, 0)
2014-07-11 11:49:05,520 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 119 (reduce at CalEigenVector.scala:38) finished in 0.070 s
2014-07-11 11:49:05,520 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.074134132 s
2014-07-11 11:49:05,528 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,528 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 238
2014-07-11 11:49:05,529 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,529 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,529 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,531 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,531 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[482] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,532 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 120 (MappedRDD[482] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,532 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 2 tasks
2014-07-11 11:49:05,533 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 240 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,533 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:05,533 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:1 as TID 241 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,534 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:1 as 2296 bytes in 1 ms
2014-07-11 11:49:05,534 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 241
2014-07-11 11:49:05,535 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,536 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,536 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,537 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 240
2014-07-11 11:49:05,538 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,538 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,538 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,590 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 240 is 678
2014-07-11 11:49:05,590 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 240 directly to driver
2014-07-11 11:49:05,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-11 11:49:05,592 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 240 in 58 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,599 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 240
2014-07-11 11:49:05,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 241 is 678
2014-07-11 11:49:05,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 241 directly to driver
2014-07-11 11:49:05,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 241
2014-07-11 11:49:05,633 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 1)
2014-07-11 11:49:05,633 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 241 in 100 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,633 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,633 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at CalEigenVector.scala:38) finished in 0.100 s
2014-07-11 11:49:05,633 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.105107309 s
2014-07-11 11:49:05,640 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at CalEigenVector.scala:38
2014-07-11 11:49:05,641 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at CalEigenVector.scala:38) with 2 output partitions (allowLocal=false)
2014-07-11 11:49:05,641 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 121(reduce at CalEigenVector.scala:38)
2014-07-11 11:49:05,641 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2014-07-11 11:49:05,643 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-11 11:49:05,643 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 121 (MappedRDD[486] at map at CalEigenVector.scala:38), which has no missing parents
2014-07-11 11:49:05,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 121 (MappedRDD[486] at map at CalEigenVector.scala:38)
2014-07-11 11:49:05,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 121.0 with 2 tasks
2014-07-11 11:49:05,645 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 121.0:0 as TID 242 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,645 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 121.0:0 as 2296 bytes in 0 ms
2014-07-11 11:49:05,645 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 121.0:1 as TID 243 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-11 11:49:05,646 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 121.0:1 as 2296 bytes in 1 ms
2014-07-11 11:49:05,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 243
2014-07-11 11:49:05,647 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 242
2014-07-11 11:49:05,647 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,647 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-11 11:49:05,647 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,648 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_1 locally
2014-07-11 11:49:05,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,649 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_2_0 locally
2014-07-11 11:49:05,692 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 243 is 678
2014-07-11 11:49:05,692 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 243 directly to driver
2014-07-11 11:49:05,693 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 243 in 48 ms on localhost (progress: 1/2)
2014-07-11 11:49:05,694 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(121, 1)
2014-07-11 11:49:05,694 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 243
2014-07-11 11:49:05,718 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 242 is 678
2014-07-11 11:49:05,718 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 242 directly to driver
2014-07-11 11:49:05,719 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 242 in 74 ms on localhost (progress: 2/2)
2014-07-11 11:49:05,719 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 121.0, whose tasks have all completed, from pool 
2014-07-11 11:49:05,720 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(121, 0)
2014-07-11 11:49:05,720 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 121 (reduce at CalEigenVector.scala:38) finished in 0.075 s
2014-07-11 11:49:05,720 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at CalEigenVector.scala:38, took 0.079544246 s
2014-07-11 11:49:05,729 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 242
2014-07-11 11:49:05,827 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/static,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2014-07-11 11:49:05,828 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage,null}
2014-07-11 11:49:05,829 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2014-07-11 11:49:05,829 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2014-07-11 11:49:05,829 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2014-07-11 11:49:05,829 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2014-07-11 11:49:05,829 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2014-07-11 11:49:05,829 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages,null}
2014-07-11 11:49:05,882 [main] INFO  [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://10.74.147.155:4040
2014-07-11 11:49:05,883 [main] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stopping DAGScheduler
2014-07-11 11:49:06,938 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.MapOutputTrackerMasterActor] - MapOutputTrackerActor stopped!
2014-07-11 11:49:06,993 [connection-manager-thread] INFO  [org.apache.spark.network.ConnectionManager] - Selector thread was interrupted!
2014-07-11 11:49:06,993 [main] INFO  [org.apache.spark.network.ConnectionManager] - ConnectionManager stopped
2014-07-11 11:49:06,995 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore cleared
2014-07-11 11:49:06,996 [main] INFO  [org.apache.spark.storage.BlockManager] - BlockManager stopped
2014-07-11 11:49:06,996 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.storage.BlockManagerMasterActor] - Stopping BlockManagerMaster
2014-07-11 11:49:06,997 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2014-07-11 11:49:06,998 [main] INFO  [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2014-07-11 11:49:07,009 [spark-akka.actor.default-dispatcher-3] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Shutting down remote daemon.
2014-07-11 11:49:07,016 [spark-akka.actor.default-dispatcher-5] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Remote daemon shut down; proceeding with flushing remote transports.
