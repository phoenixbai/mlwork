2014-07-23 17:20:04,147 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.225 instead (on interface eth0)
2014-07-23 17:20:04,170 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-23 17:20:04,340 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-23 17:20:04,341 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-23 17:20:05,065 [spark-akka.actor.default-dispatcher-4] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-23 17:20:05,198 [spark-akka.actor.default-dispatcher-3] INFO  [Remoting] - Starting remoting
2014-07-23 17:20:05,482 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.225:38806]
2014-07-23 17:20:05,484 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.225:38806]
2014-07-23 17:20:05,518 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-23 17:20:05,528 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-23 17:20:05,562 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140723172005-54bf
2014-07-23 17:20:05,566 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-23 17:20:05,654 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 46334 with id = ConnectionManagerId(10.74.147.225,46334)
2014-07-23 17:20:05,659 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-23 17:20:05,661 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.225:46334 with 1056.0 MB RAM
2014-07-23 17:20:05,667 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-23 17:20:05,716 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:20:05,886 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:20:05,904 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:43107
2014-07-23 17:20:05,905 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.225:43107
2014-07-23 17:20:05,914 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-2e11ab34-b5d1-49fc-afb2-551ef4c01fb6
2014-07-23 17:20:05,914 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:20:05,915 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:20:05,924 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:51785
2014-07-23 17:20:06,606 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:20:06,637 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-23 17:20:06,640 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.225:4040
2014-07-23 17:20:07,424 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-23 17:20:07,426 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-23 17:20:07,711 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at PCA.scala:50
2014-07-23 17:20:07,785 [spark-akka.actor.default-dispatcher-3] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-23 17:20:07,785 [spark-akka.actor.default-dispatcher-3] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-23 17:20:07,799 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-23 17:20:07,841 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (repartition at PCA.scala:46)
2014-07-23 17:20:07,844 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PCA.scala:50) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:07,845 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at PCA.scala:50)
2014-07-23 17:20:07,845 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 1)
2014-07-23 17:20:07,849 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(Stage 1)
2014-07-23 17:20:07,856 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46), which has no missing parents
2014-07-23 17:20:07,926 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46)
2014-07-23 17:20:07,927 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-23 17:20:07,954 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:07,957 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2030 bytes in 2 ms
2014-07-23 17:20:07,960 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:07,961 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2030 bytes in 0 ms
2014-07-23 17:20:07,968 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-23 17:20:07,969 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-23 17:20:07,994 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:07,994 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:08,013 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-23 17:20:08,013 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-23 17:20:09,682 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 783
2014-07-23 17:20:09,683 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-23 17:20:09,683 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-23 17:20:09,684 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 783
2014-07-23 17:20:09,684 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-23 17:20:09,684 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-23 17:20:09,690 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 1)
2014-07-23 17:20:09,700 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 1728 ms on localhost (progress: 1/2)
2014-07-23 17:20:09,705 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 0)
2014-07-23 17:20:09,705 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 1753 ms on localhost (progress: 2/2)
2014-07-23 17:20:09,706 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (repartition at PCA.scala:46) finished in 1.761 s
2014-07-23 17:20:09,706 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2014-07-23 17:20:09,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2014-07-23 17:20:09,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(Stage 0)
2014-07-23 17:20:09,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2014-07-23 17:20:09,709 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-23 17:20:09,722 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents for Stage 0: List()
2014-07-23 17:20:09,724 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[7] at repartition at PCA.scala:46), which is now runnable
2014-07-23 17:20:09,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 0 (MappedRDD[7] at repartition at PCA.scala:46)
2014-07-23 17:20:09,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2014-07-23 17:20:09,746 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:09,746 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 2265 bytes in 0 ms
2014-07-23 17:20:09,747 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-23 17:20:09,751 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:09,758 [Executor task launch worker-0] INFO  [org.apache.spark.CacheManager] - Partition rdd_7_0 not found, computing it
2014-07-23 17:20:09,765 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-23 17:20:09,768 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2014-07-23 17:20:09,769 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2014-07-23 17:20:12,039 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(170498505) called with curMem=32856, maxMem=1107296256
2014-07-23 17:20:12,039 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_7_0 stored as values to memory (estimated size 162.6 MB, free 893.4 MB)
2014-07-23 17:20:12,042 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_7_0 in memory on 10.74.147.225:46334 (size: 162.6 MB, free: 893.4 MB)
2014-07-23 17:20:12,043 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_7_0
2014-07-23 17:20:12,065 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 1390
2014-07-23 17:20:12,065 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-23 17:20:12,066 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-23 17:20:12,075 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-23 17:20:12,075 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at PCA.scala:50) finished in 2.321 s
2014-07-23 17:20:12,082 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 2330 ms on localhost (progress: 1/1)
2014-07-23 17:20:12,082 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-23 17:20:12,085 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at PCA.scala:50, took 4.373979006 s
2014-07-23 17:20:12,123 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:12,127 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 0 is 146 bytes
2014-07-23 17:20:12,129 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:12,129 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at PCA.scala:57)
2014-07-23 17:20:12,129 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 3)
2014-07-23 17:20:12,130 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:12,131 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[9] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:12,139 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 2 (MappedRDD[9] at map at PCA.scala:57)
2014-07-23 17:20:12,139 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 1 tasks
2014-07-23 17:20:12,140 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:12,141 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:12,142 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-23 17:20:12,145 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:12,147 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:12,650 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 678
2014-07-23 17:20:12,650 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-23 17:20:12,651 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-23 17:20:12,652 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 511 ms on localhost (progress: 1/1)
2014-07-23 17:20:12,652 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-23 17:20:12,651 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-23 17:20:12,652 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at PCA.scala:57) finished in 0.513 s
2014-07-23 17:20:12,653 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.529702214 s
2014-07-23 17:20:12,659 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:12,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:12,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(reduce at PCA.scala:57)
2014-07-23 17:20:12,664 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 5)
2014-07-23 17:20:12,665 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:12,666 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[11] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:12,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 4 (MappedRDD[11] at map at PCA.scala:57)
2014-07-23 17:20:12,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 1 tasks
2014-07-23 17:20:12,669 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:12,670 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2521 bytes in 1 ms
2014-07-23 17:20:12,670 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-23 17:20:12,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:12,675 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:12,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 678
2014-07-23 17:20:12,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-23 17:20:12,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-23 17:20:12,820 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-23 17:20:12,820 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 150 ms on localhost (progress: 1/1)
2014-07-23 17:20:12,820 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-23 17:20:12,820 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (reduce at PCA.scala:57) finished in 0.151 s
2014-07-23 17:20:12,821 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.161027692 s
2014-07-23 17:20:12,829 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:12,831 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:12,831 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(reduce at PCA.scala:57)
2014-07-23 17:20:12,831 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 7)
2014-07-23 17:20:12,832 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:12,833 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[13] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:12,835 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 6 (MappedRDD[13] at map at PCA.scala:57)
2014-07-23 17:20:12,836 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 1 tasks
2014-07-23 17:20:12,836 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:12,837 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2516 bytes in 1 ms
2014-07-23 17:20:12,837 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-23 17:20:12,840 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:12,844 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:12,976 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 678
2014-07-23 17:20:12,977 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-23 17:20:12,977 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-23 17:20:12,978 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-23 17:20:12,978 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 141 ms on localhost (progress: 1/1)
2014-07-23 17:20:12,978 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-23 17:20:12,978 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (reduce at PCA.scala:57) finished in 0.142 s
2014-07-23 17:20:12,978 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.149582524 s
2014-07-23 17:20:12,985 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:12,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:12,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at PCA.scala:57)
2014-07-23 17:20:12,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 9)
2014-07-23 17:20:12,989 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:12,989 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[15] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:12,992 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 8 (MappedRDD[15] at map at PCA.scala:57)
2014-07-23 17:20:12,992 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 1 tasks
2014-07-23 17:20:12,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:12,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:12,994 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-23 17:20:12,996 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:12,999 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:13,112 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-23 17:20:13,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-23 17:20:13,113 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-23 17:20:13,114 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-23 17:20:13,114 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 120 ms on localhost (progress: 1/1)
2014-07-23 17:20:13,114 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-23 17:20:13,114 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at PCA.scala:57) finished in 0.122 s
2014-07-23 17:20:13,115 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12931933 s
2014-07-23 17:20:13,121 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:13,123 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:13,123 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at PCA.scala:57)
2014-07-23 17:20:13,123 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 11)
2014-07-23 17:20:13,125 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:13,125 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[17] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:13,128 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 10 (MappedRDD[17] at map at PCA.scala:57)
2014-07-23 17:20:13,128 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 1 tasks
2014-07-23 17:20:13,129 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:13,129 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:13,130 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-23 17:20:13,132 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:13,135 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:13,257 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-23 17:20:13,257 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-23 17:20:13,257 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-23 17:20:13,258 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-23 17:20:13,258 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 129 ms on localhost (progress: 1/1)
2014-07-23 17:20:13,258 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-23 17:20:13,258 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at PCA.scala:57) finished in 0.130 s
2014-07-23 17:20:13,259 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.137783102 s
2014-07-23 17:20:13,265 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:13,267 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:13,267 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at PCA.scala:57)
2014-07-23 17:20:13,267 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 13)
2014-07-23 17:20:13,269 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:13,269 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[19] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:13,272 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 12 (MappedRDD[19] at map at PCA.scala:57)
2014-07-23 17:20:13,272 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 1 tasks
2014-07-23 17:20:13,273 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:13,273 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:13,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-23 17:20:13,277 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:13,280 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:13,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-23 17:20:13,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-23 17:20:13,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-23 17:20:13,401 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 127 ms on localhost (progress: 1/1)
2014-07-23 17:20:13,401 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-23 17:20:13,401 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-23 17:20:13,401 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at PCA.scala:57) finished in 0.129 s
2014-07-23 17:20:13,402 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.136558395 s
2014-07-23 17:20:13,408 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:13,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:13,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at PCA.scala:57)
2014-07-23 17:20:13,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 15)
2014-07-23 17:20:13,412 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:13,412 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[21] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:13,415 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 14 (MappedRDD[21] at map at PCA.scala:57)
2014-07-23 17:20:13,415 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 1 tasks
2014-07-23 17:20:13,416 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:13,416 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:13,417 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-23 17:20:13,419 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:13,422 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:13,550 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-23 17:20:13,550 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-23 17:20:13,550 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-23 17:20:13,552 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-23 17:20:13,552 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 136 ms on localhost (progress: 1/1)
2014-07-23 17:20:13,552 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-23 17:20:13,552 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at PCA.scala:57) finished in 0.137 s
2014-07-23 17:20:13,552 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.144390566 s
2014-07-23 17:20:13,558 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:13,561 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:13,561 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at PCA.scala:57)
2014-07-23 17:20:13,561 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 17)
2014-07-23 17:20:13,562 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:13,562 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[23] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:13,565 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 16 (MappedRDD[23] at map at PCA.scala:57)
2014-07-23 17:20:13,565 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 1 tasks
2014-07-23 17:20:13,566 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:13,566 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:13,567 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-23 17:20:13,569 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:13,571 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:13,700 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-23 17:20:13,700 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-23 17:20:13,700 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-23 17:20:13,701 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-23 17:20:13,701 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 134 ms on localhost (progress: 1/1)
2014-07-23 17:20:13,701 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-23 17:20:13,701 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at PCA.scala:57) finished in 0.136 s
2014-07-23 17:20:13,703 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.144116285 s
2014-07-23 17:20:13,709 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:13,711 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:13,711 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at PCA.scala:57)
2014-07-23 17:20:13,711 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 19)
2014-07-23 17:20:13,713 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:13,713 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[25] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:13,716 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 18 (MappedRDD[25] at map at PCA.scala:57)
2014-07-23 17:20:13,716 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 1 tasks
2014-07-23 17:20:13,717 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:13,718 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2521 bytes in 1 ms
2014-07-23 17:20:13,719 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-23 17:20:13,721 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:13,723 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,007 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-23 17:20:14,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-23 17:20:14,008 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-23 17:20:14,009 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-23 17:20:14,009 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 292 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,009 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,009 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at PCA.scala:57) finished in 0.292 s
2014-07-23 17:20:14,010 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.301010984 s
2014-07-23 17:20:14,017 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,025 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,025 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at PCA.scala:57)
2014-07-23 17:20:14,025 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 21)
2014-07-23 17:20:14,028 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,031 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[27] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,038 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 20 (MappedRDD[27] at map at PCA.scala:57)
2014-07-23 17:20:14,038 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 1 tasks
2014-07-23 17:20:14,039 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,040 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:14,040 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-23 17:20:14,043 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,046 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,182 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-23 17:20:14,182 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-23 17:20:14,182 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-23 17:20:14,184 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 144 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,184 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,184 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-23 17:20:14,184 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at PCA.scala:57) finished in 0.143 s
2014-07-23 17:20:14,185 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.168438443 s
2014-07-23 17:20:14,194 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,196 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,196 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at PCA.scala:57)
2014-07-23 17:20:14,196 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 23)
2014-07-23 17:20:14,198 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,199 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[29] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,202 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 22 (MappedRDD[29] at map at PCA.scala:57)
2014-07-23 17:20:14,202 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 1 tasks
2014-07-23 17:20:14,203 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,204 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:14,205 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-23 17:20:14,209 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,211 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,337 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-23 17:20:14,337 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-23 17:20:14,339 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 135 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,340 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,339 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-23 17:20:14,340 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at PCA.scala:57) finished in 0.129 s
2014-07-23 17:20:14,341 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.147099403 s
2014-07-23 17:20:14,349 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,350 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-23 17:20:14,352 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,352 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at PCA.scala:57)
2014-07-23 17:20:14,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 25)
2014-07-23 17:20:14,354 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,355 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[31] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,358 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 24 (MappedRDD[31] at map at PCA.scala:57)
2014-07-23 17:20:14,358 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 1 tasks
2014-07-23 17:20:14,360 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,360 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:14,361 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-23 17:20:14,363 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,367 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,486 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-23 17:20:14,486 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-23 17:20:14,489 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 130 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,489 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,490 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-23 17:20:14,491 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at PCA.scala:57) finished in 0.127 s
2014-07-23 17:20:14,491 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.142314079 s
2014-07-23 17:20:14,501 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,501 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-23 17:20:14,504 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,504 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at PCA.scala:57)
2014-07-23 17:20:14,504 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 27)
2014-07-23 17:20:14,505 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[33] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,510 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 26 (MappedRDD[33] at map at PCA.scala:57)
2014-07-23 17:20:14,510 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 1 tasks
2014-07-23 17:20:14,511 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,511 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2516 bytes in 0 ms
2014-07-23 17:20:14,512 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-23 17:20:14,515 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,518 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,611 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-23 17:20:14,611 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-23 17:20:14,611 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-23 17:20:14,613 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,613 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,613 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-23 17:20:14,614 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:20:14,615 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11405487 s
2014-07-23 17:20:14,629 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,632 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,632 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at PCA.scala:57)
2014-07-23 17:20:14,632 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 29)
2014-07-23 17:20:14,634 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,634 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[35] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 28 (MappedRDD[35] at map at PCA.scala:57)
2014-07-23 17:20:14,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 1 tasks
2014-07-23 17:20:14,640 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,640 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:14,641 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-23 17:20:14,643 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,646 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,793 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-23 17:20:14,793 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-23 17:20:14,794 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-23 17:20:14,795 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 154 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,795 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,795 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-23 17:20:14,795 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at PCA.scala:57) finished in 0.156 s
2014-07-23 17:20:14,796 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.167313382 s
2014-07-23 17:20:14,804 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,806 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,806 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at PCA.scala:57)
2014-07-23 17:20:14,806 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 31)
2014-07-23 17:20:14,808 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,808 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[37] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,815 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 30 (MappedRDD[37] at map at PCA.scala:57)
2014-07-23 17:20:14,815 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 1 tasks
2014-07-23 17:20:14,816 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,816 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:14,817 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-23 17:20:14,820 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,827 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:14,960 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-23 17:20:14,960 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-23 17:20:14,962 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 145 ms on localhost (progress: 1/1)
2014-07-23 17:20:14,962 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-23 17:20:14,962 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-23 17:20:14,962 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at PCA.scala:57) finished in 0.141 s
2014-07-23 17:20:14,963 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.159422926 s
2014-07-23 17:20:14,971 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-23 17:20:14,971 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:14,974 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:14,974 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at PCA.scala:57)
2014-07-23 17:20:14,974 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 33)
2014-07-23 17:20:14,976 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:14,977 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[39] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:14,980 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 32 (MappedRDD[39] at map at PCA.scala:57)
2014-07-23 17:20:14,980 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 1 tasks
2014-07-23 17:20:14,981 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:14,981 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:14,983 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-23 17:20:14,985 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:14,988 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:15,137 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-23 17:20:15,138 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-23 17:20:15,139 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 159 ms on localhost (progress: 1/1)
2014-07-23 17:20:15,139 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-23 17:20:15,140 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-23 17:20:15,140 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at PCA.scala:57) finished in 0.150 s
2014-07-23 17:20:15,141 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.169531859 s
2014-07-23 17:20:15,155 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-23 17:20:15,156 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:15,159 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:15,159 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at PCA.scala:57)
2014-07-23 17:20:15,159 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 35)
2014-07-23 17:20:15,161 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:15,161 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[41] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:15,165 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 34 (MappedRDD[41] at map at PCA.scala:57)
2014-07-23 17:20:15,165 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 1 tasks
2014-07-23 17:20:15,166 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:15,167 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2518 bytes in 1 ms
2014-07-23 17:20:15,168 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-23 17:20:15,170 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:15,172 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:15,327 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-23 17:20:15,327 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-23 17:20:15,327 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-23 17:20:15,328 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 162 ms on localhost (progress: 1/1)
2014-07-23 17:20:15,329 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-23 17:20:15,328 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-23 17:20:15,329 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at PCA.scala:57) finished in 0.156 s
2014-07-23 17:20:15,329 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.173098563 s
2014-07-23 17:20:15,337 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:15,339 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:15,339 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at PCA.scala:57)
2014-07-23 17:20:15,339 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 37)
2014-07-23 17:20:15,340 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:15,342 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[43] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:15,346 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 36 (MappedRDD[43] at map at PCA.scala:57)
2014-07-23 17:20:15,346 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 1 tasks
2014-07-23 17:20:15,347 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:15,348 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2519 bytes in 1 ms
2014-07-23 17:20:15,348 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-23 17:20:15,351 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:15,354 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:15,512 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-23 17:20:15,512 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-23 17:20:15,514 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 166 ms on localhost (progress: 1/1)
2014-07-23 17:20:15,514 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-23 17:20:15,514 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-23 17:20:15,515 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at PCA.scala:57) finished in 0.163 s
2014-07-23 17:20:15,515 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.177792995 s
2014-07-23 17:20:15,522 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:15,528 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:15,528 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at PCA.scala:57)
2014-07-23 17:20:15,528 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 39)
2014-07-23 17:20:15,530 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:15,531 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[45] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:15,534 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-23 17:20:15,535 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 38 (MappedRDD[45] at map at PCA.scala:57)
2014-07-23 17:20:15,535 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 1 tasks
2014-07-23 17:20:15,536 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:15,537 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:15,537 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-23 17:20:15,539 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:15,543 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:16,876 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-23 17:20:16,876 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-23 17:20:16,876 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-23 17:20:16,877 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-23 17:20:16,877 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 1341 ms on localhost (progress: 1/1)
2014-07-23 17:20:16,878 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-23 17:20:16,878 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at PCA.scala:57) finished in 1.338 s
2014-07-23 17:20:16,878 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 1.356290006 s
2014-07-23 17:20:16,886 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:16,888 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:16,888 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at PCA.scala:57)
2014-07-23 17:20:16,888 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 41)
2014-07-23 17:20:16,890 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:16,891 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[47] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:16,894 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 40 (MappedRDD[47] at map at PCA.scala:57)
2014-07-23 17:20:16,894 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 1 tasks
2014-07-23 17:20:16,895 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:16,895 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:16,896 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-23 17:20:16,901 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:16,903 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-23 17:20:17,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-23 17:20:17,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-23 17:20:17,013 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-23 17:20:17,013 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,013 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,014 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at PCA.scala:57) finished in 0.117 s
2014-07-23 17:20:17,014 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128072449 s
2014-07-23 17:20:17,019 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,021 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,021 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at PCA.scala:57)
2014-07-23 17:20:17,021 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 43)
2014-07-23 17:20:17,023 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,023 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[49] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,026 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 42 (MappedRDD[49] at map at PCA.scala:57)
2014-07-23 17:20:17,026 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 1 tasks
2014-07-23 17:20:17,026 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,027 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:17,027 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-23 17:20:17,029 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,031 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,138 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-23 17:20:17,139 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-23 17:20:17,139 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-23 17:20:17,140 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-23 17:20:17,140 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,140 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,140 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:20:17,140 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121146461 s
2014-07-23 17:20:17,146 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,148 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,148 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at PCA.scala:57)
2014-07-23 17:20:17,148 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 45)
2014-07-23 17:20:17,149 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,150 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[51] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,153 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 44 (MappedRDD[51] at map at PCA.scala:57)
2014-07-23 17:20:17,153 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 1 tasks
2014-07-23 17:20:17,154 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,154 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:17,155 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-23 17:20:17,157 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,159 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-23 17:20:17,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-23 17:20:17,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-23 17:20:17,261 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-23 17:20:17,261 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,261 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,261 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:17,261 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115243059 s
2014-07-23 17:20:17,266 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,268 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,268 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at PCA.scala:57)
2014-07-23 17:20:17,268 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 47)
2014-07-23 17:20:17,269 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,269 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[53] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,272 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 46 (MappedRDD[53] at map at PCA.scala:57)
2014-07-23 17:20:17,272 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 1 tasks
2014-07-23 17:20:17,273 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,273 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:17,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-23 17:20:17,276 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,378 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-23 17:20:17,378 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-23 17:20:17,378 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-23 17:20:17,379 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-23 17:20:17,380 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,380 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,380 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:17,380 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113979223 s
2014-07-23 17:20:17,385 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,387 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,387 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at PCA.scala:57)
2014-07-23 17:20:17,387 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 49)
2014-07-23 17:20:17,388 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,388 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[55] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,391 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 48 (MappedRDD[55] at map at PCA.scala:57)
2014-07-23 17:20:17,391 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 1 tasks
2014-07-23 17:20:17,392 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,392 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:17,393 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-23 17:20:17,395 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,397 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,492 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-23 17:20:17,492 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-23 17:20:17,492 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-23 17:20:17,493 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-23 17:20:17,493 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,493 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,493 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:20:17,494 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108701858 s
2014-07-23 17:20:17,499 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,501 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,501 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at PCA.scala:57)
2014-07-23 17:20:17,501 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 51)
2014-07-23 17:20:17,502 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,502 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[57] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,505 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 50 (MappedRDD[57] at map at PCA.scala:57)
2014-07-23 17:20:17,505 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 1 tasks
2014-07-23 17:20:17,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2516 bytes in 0 ms
2014-07-23 17:20:17,507 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-23 17:20:17,509 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,511 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,598 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-23 17:20:17,598 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-23 17:20:17,598 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-23 17:20:17,600 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-23 17:20:17,600 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 93 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,600 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,600 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at PCA.scala:57) finished in 0.094 s
2014-07-23 17:20:17,600 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101031535 s
2014-07-23 17:20:17,605 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,607 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,607 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at PCA.scala:57)
2014-07-23 17:20:17,607 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 53)
2014-07-23 17:20:17,608 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,609 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[59] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,611 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 52 (MappedRDD[59] at map at PCA.scala:57)
2014-07-23 17:20:17,611 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2014-07-23 17:20:17,612 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,613 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:17,613 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-23 17:20:17,615 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,617 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-23 17:20:17,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-23 17:20:17,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-23 17:20:17,723 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-23 17:20:17,723 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,723 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at PCA.scala:57) finished in 0.111 s
2014-07-23 17:20:17,724 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118663242 s
2014-07-23 17:20:17,729 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at PCA.scala:57)
2014-07-23 17:20:17,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 55)
2014-07-23 17:20:17,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[61] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,735 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 54 (MappedRDD[61] at map at PCA.scala:57)
2014-07-23 17:20:17,735 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 1 tasks
2014-07-23 17:20:17,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:17,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-23 17:20:17,738 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,741 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,858 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-23 17:20:17,858 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-23 17:20:17,858 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-23 17:20:17,859 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-23 17:20:17,859 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,859 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,859 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at PCA.scala:57) finished in 0.124 s
2014-07-23 17:20:17,861 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.132459688 s
2014-07-23 17:20:17,866 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:17,868 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:17,868 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at PCA.scala:57)
2014-07-23 17:20:17,868 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 57)
2014-07-23 17:20:17,869 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:17,869 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[63] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:17,872 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 56 (MappedRDD[63] at map at PCA.scala:57)
2014-07-23 17:20:17,872 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 1 tasks
2014-07-23 17:20:17,873 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:17,873 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:17,874 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-23 17:20:17,876 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:17,878 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:17,996 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-23 17:20:17,996 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-23 17:20:17,996 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-23 17:20:17,997 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-23 17:20:17,997 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:20:17,997 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-23 17:20:17,997 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at PCA.scala:57) finished in 0.125 s
2014-07-23 17:20:17,998 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.131785447 s
2014-07-23 17:20:18,003 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,004 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,005 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at PCA.scala:57)
2014-07-23 17:20:18,005 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 59)
2014-07-23 17:20:18,006 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,006 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[65] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 58 (MappedRDD[65] at map at PCA.scala:57)
2014-07-23 17:20:18,009 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 1 tasks
2014-07-23 17:20:18,009 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,010 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:18,010 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-23 17:20:18,012 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,014 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-23 17:20:18,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-23 17:20:18,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-23 17:20:18,130 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-23 17:20:18,130 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 121 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,130 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,131 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:20:18,131 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128097983 s
2014-07-23 17:20:18,135 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at PCA.scala:57)
2014-07-23 17:20:18,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 61)
2014-07-23 17:20:18,138 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,139 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[67] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,141 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 60 (MappedRDD[67] at map at PCA.scala:57)
2014-07-23 17:20:18,141 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 1 tasks
2014-07-23 17:20:18,142 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,143 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2517 bytes in 1 ms
2014-07-23 17:20:18,143 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-23 17:20:18,145 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,147 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-23 17:20:18,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-23 17:20:18,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-23 17:20:18,259 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-23 17:20:18,259 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,259 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,260 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at PCA.scala:57) finished in 0.117 s
2014-07-23 17:20:18,261 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.125127524 s
2014-07-23 17:20:18,265 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at PCA.scala:57)
2014-07-23 17:20:18,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 63)
2014-07-23 17:20:18,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,269 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[69] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,270 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 62 (MappedRDD[69] at map at PCA.scala:57)
2014-07-23 17:20:18,271 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 1 tasks
2014-07-23 17:20:18,271 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,272 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2521 bytes in 1 ms
2014-07-23 17:20:18,272 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-23 17:20:18,274 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,276 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,389 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-23 17:20:18,389 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-23 17:20:18,389 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-23 17:20:18,390 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-23 17:20:18,390 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,390 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,390 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at PCA.scala:57) finished in 0.119 s
2014-07-23 17:20:18,391 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12547508 s
2014-07-23 17:20:18,396 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,397 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,397 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at PCA.scala:57)
2014-07-23 17:20:18,398 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 65)
2014-07-23 17:20:18,398 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,399 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[71] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,401 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 64 (MappedRDD[71] at map at PCA.scala:57)
2014-07-23 17:20:18,401 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 1 tasks
2014-07-23 17:20:18,402 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,402 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:18,403 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-23 17:20:18,405 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,407 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,509 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-23 17:20:18,509 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-23 17:20:18,509 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-23 17:20:18,510 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-23 17:20:18,510 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,510 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,510 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:20:18,511 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115444312 s
2014-07-23 17:20:18,516 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,517 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,517 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at PCA.scala:57)
2014-07-23 17:20:18,517 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 67)
2014-07-23 17:20:18,518 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,519 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[73] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,521 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 66 (MappedRDD[73] at map at PCA.scala:57)
2014-07-23 17:20:18,521 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 1 tasks
2014-07-23 17:20:18,522 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,522 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:18,522 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-23 17:20:18,524 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,526 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,624 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-23 17:20:18,624 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-23 17:20:18,624 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-23 17:20:18,625 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-23 17:20:18,626 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,626 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,626 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:20:18,626 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110090514 s
2014-07-23 17:20:18,631 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at PCA.scala:57)
2014-07-23 17:20:18,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 69)
2014-07-23 17:20:18,634 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,635 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[75] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,637 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 68 (MappedRDD[75] at map at PCA.scala:57)
2014-07-23 17:20:18,637 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 1 tasks
2014-07-23 17:20:18,638 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,638 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:18,639 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-23 17:20:18,640 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,643 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,748 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-23 17:20:18,748 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-23 17:20:18,748 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-23 17:20:18,749 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,749 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,751 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-23 17:20:18,752 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at PCA.scala:57) finished in 0.115 s
2014-07-23 17:20:18,752 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121585178 s
2014-07-23 17:20:18,757 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,759 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,759 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at PCA.scala:57)
2014-07-23 17:20:18,759 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 71)
2014-07-23 17:20:18,760 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,768 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[77] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,783 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 70 (MappedRDD[77] at map at PCA.scala:57)
2014-07-23 17:20:18,783 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 1 tasks
2014-07-23 17:20:18,784 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,785 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2517 bytes in 1 ms
2014-07-23 17:20:18,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-23 17:20:18,788 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,792 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:18,902 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-23 17:20:18,902 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-23 17:20:18,902 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-23 17:20:18,903 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-23 17:20:18,903 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:20:18,903 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at PCA.scala:57) finished in 0.119 s
2014-07-23 17:20:18,904 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.146733543 s
2014-07-23 17:20:18,904 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-23 17:20:18,909 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:18,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:18,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at PCA.scala:57)
2014-07-23 17:20:18,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 73)
2014-07-23 17:20:18,912 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:18,912 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[79] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:18,914 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 72 (MappedRDD[79] at map at PCA.scala:57)
2014-07-23 17:20:18,914 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 1 tasks
2014-07-23 17:20:18,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:18,916 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:18,916 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-23 17:20:18,918 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:18,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,014 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-23 17:20:19,014 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-23 17:20:19,014 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-23 17:20:19,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-23 17:20:19,015 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,015 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at PCA.scala:57) finished in 0.100 s
2014-07-23 17:20:19,016 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106788098 s
2014-07-23 17:20:19,021 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at PCA.scala:57)
2014-07-23 17:20:19,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 75)
2014-07-23 17:20:19,023 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,024 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[81] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,026 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 74 (MappedRDD[81] at map at PCA.scala:57)
2014-07-23 17:20:19,026 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 1 tasks
2014-07-23 17:20:19,027 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,027 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:19,027 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-23 17:20:19,029 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,031 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,107 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-23 17:20:19,107 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-23 17:20:19,108 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-23 17:20:19,108 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-23 17:20:19,109 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 82 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,109 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,109 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at PCA.scala:57) finished in 0.083 s
2014-07-23 17:20:19,109 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.088361866 s
2014-07-23 17:20:19,114 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,119 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,119 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at PCA.scala:57)
2014-07-23 17:20:19,119 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 77)
2014-07-23 17:20:19,120 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,121 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[83] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,123 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 76 (MappedRDD[83] at map at PCA.scala:57)
2014-07-23 17:20:19,123 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 1 tasks
2014-07-23 17:20:19,124 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,124 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2523 bytes in 0 ms
2014-07-23 17:20:19,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-23 17:20:19,127 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,128 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,228 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-23 17:20:19,228 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-23 17:20:19,228 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-23 17:20:19,229 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-23 17:20:19,229 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,229 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,229 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:20:19,229 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115429014 s
2014-07-23 17:20:19,234 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,237 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,237 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at PCA.scala:57)
2014-07-23 17:20:19,237 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 79)
2014-07-23 17:20:19,238 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,239 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[85] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,241 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 78 (MappedRDD[85] at map at PCA.scala:57)
2014-07-23 17:20:19,241 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 1 tasks
2014-07-23 17:20:19,242 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,242 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:19,243 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-23 17:20:19,245 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,246 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,357 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-23 17:20:19,357 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-23 17:20:19,357 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-23 17:20:19,358 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,358 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,359 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-23 17:20:19,359 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:20:19,364 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.129231795 s
2014-07-23 17:20:19,369 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,371 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,371 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at PCA.scala:57)
2014-07-23 17:20:19,371 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 81)
2014-07-23 17:20:19,372 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,373 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[87] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,375 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 80 (MappedRDD[87] at map at PCA.scala:57)
2014-07-23 17:20:19,375 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 1 tasks
2014-07-23 17:20:19,376 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,376 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:19,377 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-23 17:20:19,379 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,381 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,505 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-23 17:20:19,505 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-23 17:20:19,505 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-23 17:20:19,507 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 131 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,507 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,507 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-23 17:20:19,507 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at PCA.scala:57) finished in 0.132 s
2014-07-23 17:20:19,508 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.138196789 s
2014-07-23 17:20:19,512 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,514 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,514 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at PCA.scala:57)
2014-07-23 17:20:19,514 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 83)
2014-07-23 17:20:19,515 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,516 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[89] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,517 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 82 (MappedRDD[89] at map at PCA.scala:57)
2014-07-23 17:20:19,517 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 1 tasks
2014-07-23 17:20:19,518 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,519 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:19,519 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-23 17:20:19,521 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,522 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-23 17:20:19,630 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-23 17:20:19,630 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-23 17:20:19,631 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-23 17:20:19,631 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 112 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,631 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,631 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:20:19,631 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119020244 s
2014-07-23 17:20:19,636 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,638 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,638 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at PCA.scala:57)
2014-07-23 17:20:19,638 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 85)
2014-07-23 17:20:19,639 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,641 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[91] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,644 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 84 (MappedRDD[91] at map at PCA.scala:57)
2014-07-23 17:20:19,644 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 1 tasks
2014-07-23 17:20:19,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,645 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2520 bytes in 1 ms
2014-07-23 17:20:19,645 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-23 17:20:19,647 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,648 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,760 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-23 17:20:19,760 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-23 17:20:19,760 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-23 17:20:19,762 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,762 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,762 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-23 17:20:19,762 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:20:19,763 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.126600846 s
2014-07-23 17:20:19,768 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,769 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,770 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at PCA.scala:57)
2014-07-23 17:20:19,770 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 87)
2014-07-23 17:20:19,770 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,771 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[93] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,773 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 86 (MappedRDD[93] at map at PCA.scala:57)
2014-07-23 17:20:19,773 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 1 tasks
2014-07-23 17:20:19,774 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,774 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:19,774 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-23 17:20:19,776 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,778 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:19,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-23 17:20:19,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-23 17:20:19,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-23 17:20:19,887 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-23 17:20:19,887 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:20:19,887 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-23 17:20:19,887 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:20:19,887 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11936043 s
2014-07-23 17:20:19,893 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:19,894 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:19,894 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at PCA.scala:57)
2014-07-23 17:20:19,894 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 89)
2014-07-23 17:20:19,896 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:19,896 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[95] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:19,898 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 88 (MappedRDD[95] at map at PCA.scala:57)
2014-07-23 17:20:19,898 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 1 tasks
2014-07-23 17:20:19,899 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:19,899 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:19,899 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-23 17:20:19,901 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:19,903 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-23 17:20:20,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-23 17:20:20,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-23 17:20:20,005 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,006 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,006 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-23 17:20:20,006 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:20,007 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114529453 s
2014-07-23 17:20:20,012 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at PCA.scala:57)
2014-07-23 17:20:20,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 91)
2014-07-23 17:20:20,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[97] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 90 (MappedRDD[97] at map at PCA.scala:57)
2014-07-23 17:20:20,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 1 tasks
2014-07-23 17:20:20,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:20,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-23 17:20:20,020 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,022 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,130 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-23 17:20:20,130 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-23 17:20:20,130 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-23 17:20:20,131 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-23 17:20:20,131 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,131 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,131 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:20:20,132 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119465473 s
2014-07-23 17:20:20,137 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,138 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,138 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at PCA.scala:57)
2014-07-23 17:20:20,138 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 93)
2014-07-23 17:20:20,139 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,140 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[99] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,142 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 92 (MappedRDD[99] at map at PCA.scala:57)
2014-07-23 17:20:20,142 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 1 tasks
2014-07-23 17:20:20,142 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,143 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2521 bytes in 1 ms
2014-07-23 17:20:20,143 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-23 17:20:20,145 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,146 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,250 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-23 17:20:20,250 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-23 17:20:20,250 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-23 17:20:20,251 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-23 17:20:20,251 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,251 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,251 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:20:20,251 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114429726 s
2014-07-23 17:20:20,255 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,257 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,257 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at PCA.scala:57)
2014-07-23 17:20:20,257 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 95)
2014-07-23 17:20:20,258 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,259 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[101] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 94 (MappedRDD[101] at map at PCA.scala:57)
2014-07-23 17:20:20,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 1 tasks
2014-07-23 17:20:20,263 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,263 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:20,264 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-23 17:20:20,265 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,267 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-23 17:20:20,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-23 17:20:20,365 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-23 17:20:20,366 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,366 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,367 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-23 17:20:20,367 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:20,367 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.111899503 s
2014-07-23 17:20:20,372 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at PCA.scala:57)
2014-07-23 17:20:20,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 97)
2014-07-23 17:20:20,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[103] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 96 (MappedRDD[103] at map at PCA.scala:57)
2014-07-23 17:20:20,381 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 1 tasks
2014-07-23 17:20:20,382 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,382 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:20,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-23 17:20:20,385 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,387 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,481 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-23 17:20:20,481 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-23 17:20:20,481 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-23 17:20:20,482 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-23 17:20:20,482 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,482 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,482 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:20:20,482 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109999693 s
2014-07-23 17:20:20,487 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,488 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,488 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at PCA.scala:57)
2014-07-23 17:20:20,488 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 99)
2014-07-23 17:20:20,489 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,490 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[105] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,492 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 98 (MappedRDD[105] at map at PCA.scala:57)
2014-07-23 17:20:20,492 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 1 tasks
2014-07-23 17:20:20,493 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,493 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:20,493 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-23 17:20:20,495 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,497 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-23 17:20:20,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-23 17:20:20,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-23 17:20:20,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-23 17:20:20,578 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 85 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,578 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at PCA.scala:57) finished in 0.086 s
2014-07-23 17:20:20,578 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.091492334 s
2014-07-23 17:20:20,583 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,584 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,584 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at PCA.scala:57)
2014-07-23 17:20:20,584 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 101)
2014-07-23 17:20:20,585 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,586 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[107] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 100 (MappedRDD[107] at map at PCA.scala:57)
2014-07-23 17:20:20,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 1 tasks
2014-07-23 17:20:20,588 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,589 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2518 bytes in 1 ms
2014-07-23 17:20:20,589 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-23 17:20:20,591 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,592 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,697 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-23 17:20:20,697 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-23 17:20:20,697 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-23 17:20:20,698 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-23 17:20:20,698 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,698 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,698 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:20:20,699 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115804803 s
2014-07-23 17:20:20,704 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,706 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,706 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at PCA.scala:57)
2014-07-23 17:20:20,706 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 103)
2014-07-23 17:20:20,707 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,707 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[109] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,709 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 102 (MappedRDD[109] at map at PCA.scala:57)
2014-07-23 17:20:20,709 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 1 tasks
2014-07-23 17:20:20,710 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,710 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:20,711 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-23 17:20:20,713 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,714 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,830 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-23 17:20:20,830 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-23 17:20:20,830 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-23 17:20:20,831 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 121 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,831 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,831 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-23 17:20:20,831 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:20:20,832 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.127723898 s
2014-07-23 17:20:20,836 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,838 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,838 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at PCA.scala:57)
2014-07-23 17:20:20,838 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 105)
2014-07-23 17:20:20,839 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,840 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[111] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,842 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 104 (MappedRDD[111] at map at PCA.scala:57)
2014-07-23 17:20:20,842 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 1 tasks
2014-07-23 17:20:20,842 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,843 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:20,843 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-23 17:20:20,846 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,847 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:20,965 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-23 17:20:20,965 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-23 17:20:20,965 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-23 17:20:20,966 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-23 17:20:20,966 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:20:20,966 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-23 17:20:20,966 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:20:20,966 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.130231065 s
2014-07-23 17:20:20,971 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:20,972 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:20,972 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at PCA.scala:57)
2014-07-23 17:20:20,972 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 107)
2014-07-23 17:20:20,973 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:20,974 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[113] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:20,976 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 106 (MappedRDD[113] at map at PCA.scala:57)
2014-07-23 17:20:20,976 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 1 tasks
2014-07-23 17:20:20,977 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:20,977 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:20,981 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-23 17:20:20,982 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:20,984 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,096 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-23 17:20:21,096 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-23 17:20:21,097 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 121 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,097 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,098 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-23 17:20:21,098 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at PCA.scala:57) finished in 0.122 s
2014-07-23 17:20:21,098 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.127459035 s
2014-07-23 17:20:21,109 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at PCA.scala:57)
2014-07-23 17:20:21,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 109)
2014-07-23 17:20:21,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[115] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,114 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 108 (MappedRDD[115] at map at PCA.scala:57)
2014-07-23 17:20:21,114 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 1 tasks
2014-07-23 17:20:21,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-23 17:20:21,116 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,116 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:21,117 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-23 17:20:21,119 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,120 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,225 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-23 17:20:21,225 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-23 17:20:21,225 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-23 17:20:21,226 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-23 17:20:21,226 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,226 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,226 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at PCA.scala:57) finished in 0.111 s
2014-07-23 17:20:21,226 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117497253 s
2014-07-23 17:20:21,231 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,232 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,232 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at PCA.scala:57)
2014-07-23 17:20:21,232 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 111)
2014-07-23 17:20:21,233 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,234 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[117] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,235 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 110 (MappedRDD[117] at map at PCA.scala:57)
2014-07-23 17:20:21,235 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 1 tasks
2014-07-23 17:20:21,236 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,236 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:21,237 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-23 17:20:21,239 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,240 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,341 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-23 17:20:21,341 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-23 17:20:21,342 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-23 17:20:21,343 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-23 17:20:21,343 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,343 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,343 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:20:21,344 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112617609 s
2014-07-23 17:20:21,348 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,349 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,349 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at PCA.scala:57)
2014-07-23 17:20:21,350 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 113)
2014-07-23 17:20:21,351 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,351 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[119] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 112 (MappedRDD[119] at map at PCA.scala:57)
2014-07-23 17:20:21,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 1 tasks
2014-07-23 17:20:21,354 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,354 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:21,355 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-23 17:20:21,357 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,358 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,466 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-23 17:20:21,466 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-23 17:20:21,466 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-23 17:20:21,467 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-23 17:20:21,467 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,467 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,467 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:20:21,468 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119637541 s
2014-07-23 17:20:21,472 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,474 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,474 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at PCA.scala:57)
2014-07-23 17:20:21,474 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 115)
2014-07-23 17:20:21,475 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,475 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[121] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,477 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 114 (MappedRDD[121] at map at PCA.scala:57)
2014-07-23 17:20:21,477 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 1 tasks
2014-07-23 17:20:21,477 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,478 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2517 bytes in 1 ms
2014-07-23 17:20:21,478 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-23 17:20:21,480 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,481 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,587 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-23 17:20:21,587 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-23 17:20:21,587 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-23 17:20:21,588 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,588 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,588 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-23 17:20:21,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:20:21,590 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118078336 s
2014-07-23 17:20:21,596 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,598 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,598 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at PCA.scala:57)
2014-07-23 17:20:21,598 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 117)
2014-07-23 17:20:21,600 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,600 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[123] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,602 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 116 (MappedRDD[123] at map at PCA.scala:57)
2014-07-23 17:20:21,602 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 1 tasks
2014-07-23 17:20:21,603 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,603 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:21,604 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-23 17:20:21,606 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,608 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-23 17:20:21,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-23 17:20:21,722 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-23 17:20:21,723 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,723 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-23 17:20:21,724 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at PCA.scala:57) finished in 0.120 s
2014-07-23 17:20:21,724 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12771565 s
2014-07-23 17:20:21,729 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at PCA.scala:57)
2014-07-23 17:20:21,731 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 119)
2014-07-23 17:20:21,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[125] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,733 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 118 (MappedRDD[125] at map at PCA.scala:57)
2014-07-23 17:20:21,734 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 1 tasks
2014-07-23 17:20:21,734 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,735 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:21,735 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-23 17:20:21,737 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,738 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-23 17:20:21,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-23 17:20:21,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-23 17:20:21,848 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-23 17:20:21,848 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,848 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,848 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:20:21,848 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118860803 s
2014-07-23 17:20:21,852 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,854 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,854 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at PCA.scala:57)
2014-07-23 17:20:21,854 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 121)
2014-07-23 17:20:21,855 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,856 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[127] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,857 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 120 (MappedRDD[127] at map at PCA.scala:57)
2014-07-23 17:20:21,857 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 1 tasks
2014-07-23 17:20:21,858 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,858 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:21,859 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-23 17:20:21,860 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,862 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:21,959 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-23 17:20:21,959 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-23 17:20:21,959 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-23 17:20:21,960 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-23 17:20:21,960 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:20:21,960 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-23 17:20:21,960 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:20:21,960 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107935233 s
2014-07-23 17:20:21,965 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:21,966 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:21,966 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 122(reduce at PCA.scala:57)
2014-07-23 17:20:21,966 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 123)
2014-07-23 17:20:21,967 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:21,968 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 122 (MappedRDD[129] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:21,969 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 122 (MappedRDD[129] at map at PCA.scala:57)
2014-07-23 17:20:21,969 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 122.0 with 1 tasks
2014-07-23 17:20:21,970 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 122.0:0 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:21,970 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 122.0:0 as 2515 bytes in 0 ms
2014-07-23 17:20:21,970 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-23 17:20:21,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:21,973 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,058 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-23 17:20:22,058 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-23 17:20:22,058 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-23 17:20:22,059 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 90 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,059 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(122, 0)
2014-07-23 17:20:22,059 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,060 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 122 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:20:22,060 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.094965217 s
2014-07-23 17:20:22,064 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,066 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,066 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 124(reduce at PCA.scala:57)
2014-07-23 17:20:22,066 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 125)
2014-07-23 17:20:22,067 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,067 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 124 (MappedRDD[131] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,068 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 124 (MappedRDD[131] at map at PCA.scala:57)
2014-07-23 17:20:22,068 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 124.0 with 1 tasks
2014-07-23 17:20:22,069 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 124.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,070 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 124.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:22,070 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-23 17:20:22,072 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,073 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,173 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-23 17:20:22,174 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-23 17:20:22,174 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-23 17:20:22,175 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(124, 0)
2014-07-23 17:20:22,175 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 124 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:20:22,175 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,176 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,176 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.111321273 s
2014-07-23 17:20:22,181 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,183 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,183 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 126(reduce at PCA.scala:57)
2014-07-23 17:20:22,183 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 127)
2014-07-23 17:20:22,188 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,189 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 126 (MappedRDD[133] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,190 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 126 (MappedRDD[133] at map at PCA.scala:57)
2014-07-23 17:20:22,190 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 126.0 with 1 tasks
2014-07-23 17:20:22,191 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 126.0:0 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,192 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 126.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:22,192 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-23 17:20:22,194 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,195 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,301 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-23 17:20:22,301 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-23 17:20:22,301 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-23 17:20:22,302 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(126, 0)
2014-07-23 17:20:22,302 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,302 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,302 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 126 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:20:22,302 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12134674 s
2014-07-23 17:20:22,307 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,308 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,308 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 128(reduce at PCA.scala:57)
2014-07-23 17:20:22,308 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 129)
2014-07-23 17:20:22,310 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,311 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 128 (MappedRDD[135] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,313 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 128 (MappedRDD[135] at map at PCA.scala:57)
2014-07-23 17:20:22,313 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 128.0 with 1 tasks
2014-07-23 17:20:22,314 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 128.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,314 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 128.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:22,315 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-23 17:20:22,318 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,321 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,446 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-23 17:20:22,446 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-23 17:20:22,446 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-23 17:20:22,447 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 134 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,447 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 128.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,448 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(128, 0)
2014-07-23 17:20:22,448 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 128 (reduce at PCA.scala:57) finished in 0.134 s
2014-07-23 17:20:22,449 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.141800263 s
2014-07-23 17:20:22,453 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,455 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,455 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 130(reduce at PCA.scala:57)
2014-07-23 17:20:22,455 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 131)
2014-07-23 17:20:22,456 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,456 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 130 (MappedRDD[137] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,457 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 130 (MappedRDD[137] at map at PCA.scala:57)
2014-07-23 17:20:22,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 130.0 with 1 tasks
2014-07-23 17:20:22,458 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 130.0:0 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,458 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 130.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:22,459 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-23 17:20:22,460 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,461 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,566 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-23 17:20:22,566 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-23 17:20:22,567 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-23 17:20:22,567 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(130, 0)
2014-07-23 17:20:22,567 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,567 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 130 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:20:22,568 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114497843 s
2014-07-23 17:20:22,572 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,574 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,574 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 132(reduce at PCA.scala:57)
2014-07-23 17:20:22,574 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 133)
2014-07-23 17:20:22,575 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,575 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 132 (MappedRDD[139] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,577 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 132 (MappedRDD[139] at map at PCA.scala:57)
2014-07-23 17:20:22,577 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 132.0 with 1 tasks
2014-07-23 17:20:22,577 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 132.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 132.0:0 as 2518 bytes in 1 ms
2014-07-23 17:20:22,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-23 17:20:22,579 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,581 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-23 17:20:22,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-23 17:20:22,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-23 17:20:22,680 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(132, 0)
2014-07-23 17:20:22,680 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,680 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,680 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 132 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:22,680 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10774842 s
2014-07-23 17:20:22,684 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,686 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,686 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 134(reduce at PCA.scala:57)
2014-07-23 17:20:22,686 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 135)
2014-07-23 17:20:22,687 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,687 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 134 (MappedRDD[141] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,688 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 134 (MappedRDD[141] at map at PCA.scala:57)
2014-07-23 17:20:22,688 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 134.0 with 1 tasks
2014-07-23 17:20:22,689 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 134.0:0 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,689 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 134.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:22,690 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-23 17:20:22,691 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,693 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-23 17:20:22,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-23 17:20:22,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-23 17:20:22,804 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(134, 0)
2014-07-23 17:20:22,804 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,804 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 134.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,804 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 134 (reduce at PCA.scala:57) finished in 0.115 s
2014-07-23 17:20:22,804 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119930088 s
2014-07-23 17:20:22,809 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 136(reduce at PCA.scala:57)
2014-07-23 17:20:22,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 137)
2014-07-23 17:20:22,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,812 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 136 (MappedRDD[143] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,813 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 136 (MappedRDD[143] at map at PCA.scala:57)
2014-07-23 17:20:22,813 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 136.0 with 1 tasks
2014-07-23 17:20:22,814 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 136.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,814 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 136.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:22,814 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-23 17:20:22,816 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,817 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:22,925 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-23 17:20:22,925 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-23 17:20:22,925 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-23 17:20:22,925 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(136, 0)
2014-07-23 17:20:22,926 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 112 ms on localhost (progress: 1/1)
2014-07-23 17:20:22,926 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 136.0, whose tasks have all completed, from pool 
2014-07-23 17:20:22,926 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 136 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:20:22,928 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119297596 s
2014-07-23 17:20:22,933 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:22,934 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:22,934 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 138(reduce at PCA.scala:57)
2014-07-23 17:20:22,934 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 139)
2014-07-23 17:20:22,935 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:22,935 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 138 (MappedRDD[145] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:22,937 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 138 (MappedRDD[145] at map at PCA.scala:57)
2014-07-23 17:20:22,937 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 138.0 with 1 tasks
2014-07-23 17:20:22,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 138.0:0 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:22,938 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 138.0:0 as 2520 bytes in 1 ms
2014-07-23 17:20:22,938 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-23 17:20:22,939 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:22,940 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-23 17:20:23,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-23 17:20:23,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-23 17:20:23,047 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,047 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,047 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(138, 0)
2014-07-23 17:20:23,047 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 138 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:20:23,047 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114741927 s
2014-07-23 17:20:23,052 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,053 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,053 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 140(reduce at PCA.scala:57)
2014-07-23 17:20:23,053 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 141)
2014-07-23 17:20:23,054 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,054 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 140 (MappedRDD[147] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,056 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 140 (MappedRDD[147] at map at PCA.scala:57)
2014-07-23 17:20:23,056 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 140.0 with 1 tasks
2014-07-23 17:20:23,056 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 140.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,057 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 140.0:0 as 2518 bytes in 1 ms
2014-07-23 17:20:23,057 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-23 17:20:23,058 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,060 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,161 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-23 17:20:23,161 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-23 17:20:23,161 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-23 17:20:23,162 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,162 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 140.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,164 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(140, 0)
2014-07-23 17:20:23,164 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 140 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:23,168 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115883544 s
2014-07-23 17:20:23,173 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,174 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,174 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 142(reduce at PCA.scala:57)
2014-07-23 17:20:23,174 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 143)
2014-07-23 17:20:23,175 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,176 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 142 (MappedRDD[149] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,177 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 142 (MappedRDD[149] at map at PCA.scala:57)
2014-07-23 17:20:23,177 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 142.0 with 1 tasks
2014-07-23 17:20:23,178 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 142.0:0 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,178 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 142.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:23,179 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-23 17:20:23,181 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,182 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,290 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-23 17:20:23,290 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-23 17:20:23,291 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-23 17:20:23,291 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(142, 0)
2014-07-23 17:20:23,291 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,291 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 142.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,291 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 142 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:20:23,291 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118429913 s
2014-07-23 17:20:23,296 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,297 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,297 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 144(reduce at PCA.scala:57)
2014-07-23 17:20:23,297 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 145)
2014-07-23 17:20:23,298 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,299 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 144 (MappedRDD[151] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,300 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 144 (MappedRDD[151] at map at PCA.scala:57)
2014-07-23 17:20:23,300 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 144.0 with 1 tasks
2014-07-23 17:20:23,301 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 144.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,301 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 144.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:23,302 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-23 17:20:23,303 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,305 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-23 17:20:23,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-23 17:20:23,399 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-23 17:20:23,400 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(144, 0)
2014-07-23 17:20:23,400 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 99 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,401 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,401 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 144 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:20:23,401 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105299641 s
2014-07-23 17:20:23,405 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 146(reduce at PCA.scala:57)
2014-07-23 17:20:23,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 147)
2014-07-23 17:20:23,408 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,408 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 146 (MappedRDD[153] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,409 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 146 (MappedRDD[153] at map at PCA.scala:57)
2014-07-23 17:20:23,409 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 146.0 with 1 tasks
2014-07-23 17:20:23,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 146.0:0 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 146.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:23,410 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-23 17:20:23,412 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,413 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-23 17:20:23,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-23 17:20:23,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-23 17:20:23,495 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(146, 0)
2014-07-23 17:20:23,495 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 85 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,495 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 146.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,495 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 146 (reduce at PCA.scala:57) finished in 0.086 s
2014-07-23 17:20:23,496 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.090354928 s
2014-07-23 17:20:23,500 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,502 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,502 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 148(reduce at PCA.scala:57)
2014-07-23 17:20:23,502 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 149)
2014-07-23 17:20:23,503 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,503 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 148 (MappedRDD[155] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,504 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 148 (MappedRDD[155] at map at PCA.scala:57)
2014-07-23 17:20:23,504 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 148.0 with 1 tasks
2014-07-23 17:20:23,505 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 148.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,505 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 148.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:23,506 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-23 17:20:23,507 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,508 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-23 17:20:23,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-23 17:20:23,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-23 17:20:23,607 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(148, 0)
2014-07-23 17:20:23,608 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,608 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,608 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 148 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:20:23,612 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11138636 s
2014-07-23 17:20:23,617 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,618 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,618 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 150(reduce at PCA.scala:57)
2014-07-23 17:20:23,618 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 151)
2014-07-23 17:20:23,619 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,620 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 150 (MappedRDD[157] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,621 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 150 (MappedRDD[157] at map at PCA.scala:57)
2014-07-23 17:20:23,621 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 150.0 with 1 tasks
2014-07-23 17:20:23,622 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 150.0:0 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,622 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 150.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:23,622 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-23 17:20:23,624 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,625 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,727 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-23 17:20:23,728 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-23 17:20:23,728 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-23 17:20:23,728 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,729 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,729 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(150, 0)
2014-07-23 17:20:23,729 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 150 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:23,730 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112736208 s
2014-07-23 17:20:23,734 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,737 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,737 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 152(reduce at PCA.scala:57)
2014-07-23 17:20:23,737 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 153)
2014-07-23 17:20:23,738 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,739 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 152 (MappedRDD[159] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,740 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 152 (MappedRDD[159] at map at PCA.scala:57)
2014-07-23 17:20:23,740 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 152.0 with 1 tasks
2014-07-23 17:20:23,741 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 152.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,742 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 152.0:0 as 2518 bytes in 1 ms
2014-07-23 17:20:23,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-23 17:20:23,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,744 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,848 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-23 17:20:23,848 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-23 17:20:23,848 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-23 17:20:23,849 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,849 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 152.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,849 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(152, 0)
2014-07-23 17:20:23,849 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 152 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:20:23,849 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115481849 s
2014-07-23 17:20:23,854 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,855 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,855 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 154(reduce at PCA.scala:57)
2014-07-23 17:20:23,855 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 155)
2014-07-23 17:20:23,856 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,857 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 154 (MappedRDD[161] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,858 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 154 (MappedRDD[161] at map at PCA.scala:57)
2014-07-23 17:20:23,858 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 154.0 with 1 tasks
2014-07-23 17:20:23,859 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 154.0:0 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,859 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 154.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:23,860 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-23 17:20:23,861 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,862 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:23,959 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-23 17:20:23,959 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-23 17:20:23,959 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-23 17:20:23,959 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:20:23,960 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 154.0, whose tasks have all completed, from pool 
2014-07-23 17:20:23,960 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(154, 0)
2014-07-23 17:20:23,960 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 154 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:20:23,960 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106377234 s
2014-07-23 17:20:23,964 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:23,966 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:23,966 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 156(reduce at PCA.scala:57)
2014-07-23 17:20:23,966 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 157)
2014-07-23 17:20:23,967 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:23,967 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 156 (MappedRDD[163] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:23,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 156 (MappedRDD[163] at map at PCA.scala:57)
2014-07-23 17:20:23,969 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 156.0 with 1 tasks
2014-07-23 17:20:23,969 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 156.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:23,969 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 156.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:23,970 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-23 17:20:23,971 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:23,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-23 17:20:24,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-23 17:20:24,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-23 17:20:24,074 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,074 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,075 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(156, 0)
2014-07-23 17:20:24,075 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 156 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:20:24,075 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110616424 s
2014-07-23 17:20:24,079 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,081 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,081 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 158(reduce at PCA.scala:57)
2014-07-23 17:20:24,081 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 159)
2014-07-23 17:20:24,082 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,082 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 158 (MappedRDD[165] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,083 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 158 (MappedRDD[165] at map at PCA.scala:57)
2014-07-23 17:20:24,083 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 158.0 with 1 tasks
2014-07-23 17:20:24,084 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 158.0:0 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,084 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 158.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:24,085 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-23 17:20:24,086 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,087 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,188 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-23 17:20:24,188 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-23 17:20:24,188 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-23 17:20:24,189 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(158, 0)
2014-07-23 17:20:24,189 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,189 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 158.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,189 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 158 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:20:24,190 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110125402 s
2014-07-23 17:20:24,194 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,196 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 160(reduce at PCA.scala:57)
2014-07-23 17:20:24,196 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 161)
2014-07-23 17:20:24,197 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,197 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 160 (MappedRDD[167] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 160 (MappedRDD[167] at map at PCA.scala:57)
2014-07-23 17:20:24,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 160.0 with 1 tasks
2014-07-23 17:20:24,199 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 160.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,199 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 160.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:24,200 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-23 17:20:24,201 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,202 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,303 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-23 17:20:24,303 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-23 17:20:24,304 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-23 17:20:24,304 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,304 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(160, 0)
2014-07-23 17:20:24,304 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 160.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,305 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 160 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:20:24,305 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110501103 s
2014-07-23 17:20:24,309 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,311 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,311 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 162(reduce at PCA.scala:57)
2014-07-23 17:20:24,311 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 163)
2014-07-23 17:20:24,312 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,312 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 162 (MappedRDD[169] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,313 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 162 (MappedRDD[169] at map at PCA.scala:57)
2014-07-23 17:20:24,314 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 162.0 with 1 tasks
2014-07-23 17:20:24,314 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 162.0:0 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,314 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 162.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:24,315 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-23 17:20:24,316 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,317 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,421 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-23 17:20:24,421 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-23 17:20:24,421 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-23 17:20:24,422 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(162, 0)
2014-07-23 17:20:24,422 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,422 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,422 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 162 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:24,423 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113632134 s
2014-07-23 17:20:24,427 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,428 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,429 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 164(reduce at PCA.scala:57)
2014-07-23 17:20:24,429 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 165)
2014-07-23 17:20:24,429 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,430 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 164 (MappedRDD[171] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,431 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 164 (MappedRDD[171] at map at PCA.scala:57)
2014-07-23 17:20:24,431 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 164.0 with 1 tasks
2014-07-23 17:20:24,432 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 164.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,432 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 164.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:24,432 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-23 17:20:24,433 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,434 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,537 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-23 17:20:24,537 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-23 17:20:24,538 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-23 17:20:24,539 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,539 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,539 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(164, 0)
2014-07-23 17:20:24,540 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 164 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:20:24,540 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112756452 s
2014-07-23 17:20:24,545 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 166(reduce at PCA.scala:57)
2014-07-23 17:20:24,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 167)
2014-07-23 17:20:24,547 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,547 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 166 (MappedRDD[173] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,549 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 166 (MappedRDD[173] at map at PCA.scala:57)
2014-07-23 17:20:24,549 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 166.0 with 1 tasks
2014-07-23 17:20:24,549 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 166.0:0 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,549 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 166.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:24,550 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-23 17:20:24,553 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,554 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-23 17:20:24,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-23 17:20:24,655 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-23 17:20:24,656 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(166, 0)
2014-07-23 17:20:24,656 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,656 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,656 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 166 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:20:24,656 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.111622013 s
2014-07-23 17:20:24,661 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,662 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,662 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 168(reduce at PCA.scala:57)
2014-07-23 17:20:24,662 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 169)
2014-07-23 17:20:24,663 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,664 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 168 (MappedRDD[175] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,665 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 168 (MappedRDD[175] at map at PCA.scala:57)
2014-07-23 17:20:24,665 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 168.0 with 1 tasks
2014-07-23 17:20:24,666 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 168.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,666 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 168.0:0 as 2523 bytes in 0 ms
2014-07-23 17:20:24,667 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-23 17:20:24,668 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,669 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,765 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-23 17:20:24,765 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-23 17:20:24,766 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-23 17:20:24,770 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,770 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,770 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(168, 0)
2014-07-23 17:20:24,771 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 168 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:20:24,771 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109703173 s
2014-07-23 17:20:24,775 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 170(reduce at PCA.scala:57)
2014-07-23 17:20:24,777 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 171)
2014-07-23 17:20:24,778 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,778 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 170 (MappedRDD[177] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,779 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 170 (MappedRDD[177] at map at PCA.scala:57)
2014-07-23 17:20:24,779 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 170.0 with 1 tasks
2014-07-23 17:20:24,780 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 170.0:0 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,780 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 170.0:0 as 2516 bytes in 0 ms
2014-07-23 17:20:24,781 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-23 17:20:24,782 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,783 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,864 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-23 17:20:24,864 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-23 17:20:24,864 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-23 17:20:24,865 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(170, 0)
2014-07-23 17:20:24,865 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 85 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,865 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,865 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 170 (reduce at PCA.scala:57) finished in 0.085 s
2014-07-23 17:20:24,866 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.090766803 s
2014-07-23 17:20:24,871 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,873 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,873 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 172(reduce at PCA.scala:57)
2014-07-23 17:20:24,873 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 173)
2014-07-23 17:20:24,874 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:24,874 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 172 (MappedRDD[179] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:24,875 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 172 (MappedRDD[179] at map at PCA.scala:57)
2014-07-23 17:20:24,875 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 172.0 with 1 tasks
2014-07-23 17:20:24,876 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 172.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:24,876 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 172.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:24,877 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-23 17:20:24,879 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:24,880 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:24,991 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-23 17:20:24,991 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-23 17:20:24,992 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-23 17:20:24,992 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(172, 0)
2014-07-23 17:20:24,993 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 172 (reduce at PCA.scala:57) finished in 0.116 s
2014-07-23 17:20:24,993 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121656329 s
2014-07-23 17:20:24,996 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 116 ms on localhost (progress: 1/1)
2014-07-23 17:20:24,996 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 172.0, whose tasks have all completed, from pool 
2014-07-23 17:20:24,998 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:24,999 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:24,999 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 174(reduce at PCA.scala:57)
2014-07-23 17:20:24,999 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 175)
2014-07-23 17:20:25,000 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,000 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 174 (MappedRDD[181] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 174 (MappedRDD[181] at map at PCA.scala:57)
2014-07-23 17:20:25,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 174.0 with 1 tasks
2014-07-23 17:20:25,002 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 174.0:0 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,003 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 174.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:25,003 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-23 17:20:25,004 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,005 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,104 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-23 17:20:25,105 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-23 17:20:25,105 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-23 17:20:25,105 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(174, 0)
2014-07-23 17:20:25,105 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,105 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,105 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 174 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:25,106 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108061602 s
2014-07-23 17:20:25,110 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,111 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,111 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 176(reduce at PCA.scala:57)
2014-07-23 17:20:25,111 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 177)
2014-07-23 17:20:25,112 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,113 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 176 (MappedRDD[183] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,114 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 176 (MappedRDD[183] at map at PCA.scala:57)
2014-07-23 17:20:25,114 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 176.0 with 1 tasks
2014-07-23 17:20:25,114 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 176.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,115 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 176.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:25,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-23 17:20:25,117 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,119 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,214 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-23 17:20:25,214 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-23 17:20:25,215 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-23 17:20:25,215 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(176, 0)
2014-07-23 17:20:25,215 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 176 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:20:25,215 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,216 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 176.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,216 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105586275 s
2014-07-23 17:20:25,220 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,221 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,221 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 178(reduce at PCA.scala:57)
2014-07-23 17:20:25,221 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 179)
2014-07-23 17:20:25,222 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,222 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 178 (MappedRDD[185] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,224 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 178 (MappedRDD[185] at map at PCA.scala:57)
2014-07-23 17:20:25,224 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 178.0 with 1 tasks
2014-07-23 17:20:25,224 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 178.0:0 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,224 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 178.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:25,225 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-23 17:20:25,226 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,227 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,331 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-23 17:20:25,331 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-23 17:20:25,331 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-23 17:20:25,332 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,332 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 178.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,332 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(178, 0)
2014-07-23 17:20:25,332 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 178 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:25,333 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112716087 s
2014-07-23 17:20:25,338 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,339 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,339 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 180(reduce at PCA.scala:57)
2014-07-23 17:20:25,339 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 181)
2014-07-23 17:20:25,340 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,340 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 180 (MappedRDD[187] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,342 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 180 (MappedRDD[187] at map at PCA.scala:57)
2014-07-23 17:20:25,342 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 180.0 with 1 tasks
2014-07-23 17:20:25,342 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 180.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,343 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 180.0:0 as 2521 bytes in 1 ms
2014-07-23 17:20:25,343 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-23 17:20:25,344 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,345 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,452 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-23 17:20:25,452 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-23 17:20:25,452 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-23 17:20:25,452 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(180, 0)
2014-07-23 17:20:25,452 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,453 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,453 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 180 (reduce at PCA.scala:57) finished in 0.111 s
2014-07-23 17:20:25,453 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115510409 s
2014-07-23 17:20:25,458 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,459 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,459 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 182(reduce at PCA.scala:57)
2014-07-23 17:20:25,459 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 183)
2014-07-23 17:20:25,460 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,460 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 182 (MappedRDD[189] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,462 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 182 (MappedRDD[189] at map at PCA.scala:57)
2014-07-23 17:20:25,462 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 182.0 with 1 tasks
2014-07-23 17:20:25,462 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 182.0:0 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,463 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 182.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:25,463 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-23 17:20:25,464 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,465 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,568 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-23 17:20:25,568 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-23 17:20:25,568 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-23 17:20:25,569 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(182, 0)
2014-07-23 17:20:25,569 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,569 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,569 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 182 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:20:25,569 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11145909 s
2014-07-23 17:20:25,575 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,576 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,576 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 184(reduce at PCA.scala:57)
2014-07-23 17:20:25,576 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 185)
2014-07-23 17:20:25,577 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,578 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 184 (MappedRDD[191] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,579 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 184 (MappedRDD[191] at map at PCA.scala:57)
2014-07-23 17:20:25,579 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 184.0 with 1 tasks
2014-07-23 17:20:25,580 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 184.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,580 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 184.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:25,580 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-23 17:20:25,581 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,583 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-23 17:20:25,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-23 17:20:25,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-23 17:20:25,687 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(184, 0)
2014-07-23 17:20:25,687 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,687 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,687 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 184 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:25,688 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112474439 s
2014-07-23 17:20:25,692 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,693 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,693 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 186(reduce at PCA.scala:57)
2014-07-23 17:20:25,693 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 187)
2014-07-23 17:20:25,695 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,695 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 186 (MappedRDD[193] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,696 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 186 (MappedRDD[193] at map at PCA.scala:57)
2014-07-23 17:20:25,696 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 186.0 with 1 tasks
2014-07-23 17:20:25,697 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 186.0:0 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,697 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 186.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:25,698 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-23 17:20:25,699 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,700 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,813 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-23 17:20:25,813 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-23 17:20:25,813 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-23 17:20:25,814 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(186, 0)
2014-07-23 17:20:25,814 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,814 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,814 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 186 (reduce at PCA.scala:57) finished in 0.117 s
2014-07-23 17:20:25,814 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.122142659 s
2014-07-23 17:20:25,818 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,820 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,820 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 188(reduce at PCA.scala:57)
2014-07-23 17:20:25,820 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 189)
2014-07-23 17:20:25,821 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,821 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 188 (MappedRDD[195] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 188 (MappedRDD[195] at map at PCA.scala:57)
2014-07-23 17:20:25,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 188.0 with 1 tasks
2014-07-23 17:20:25,823 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 188.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,823 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 188.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:25,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-23 17:20:25,824 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,826 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:25,930 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-23 17:20:25,930 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-23 17:20:25,930 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-23 17:20:25,931 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(188, 0)
2014-07-23 17:20:25,931 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:20:25,931 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 188.0, whose tasks have all completed, from pool 
2014-07-23 17:20:25,931 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 188 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:20:25,932 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113069254 s
2014-07-23 17:20:25,936 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:25,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:25,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 190(reduce at PCA.scala:57)
2014-07-23 17:20:25,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 191)
2014-07-23 17:20:25,938 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:25,939 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 190 (MappedRDD[197] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:25,940 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 190 (MappedRDD[197] at map at PCA.scala:57)
2014-07-23 17:20:25,940 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 190.0 with 1 tasks
2014-07-23 17:20:25,941 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 190.0:0 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:25,941 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 190.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:25,941 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-23 17:20:25,944 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:25,945 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-23 17:20:26,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-23 17:20:26,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-23 17:20:26,047 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(190, 0)
2014-07-23 17:20:26,047 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,047 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 190.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,047 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 190 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:20:26,049 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112195651 s
2014-07-23 17:20:26,053 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,054 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,054 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 192(reduce at PCA.scala:57)
2014-07-23 17:20:26,054 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 193)
2014-07-23 17:20:26,055 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,055 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 192 (MappedRDD[199] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,056 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 192 (MappedRDD[199] at map at PCA.scala:57)
2014-07-23 17:20:26,056 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 192.0 with 1 tasks
2014-07-23 17:20:26,057 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 192.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,057 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 192.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:26,058 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-23 17:20:26,059 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,060 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-23 17:20:26,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-23 17:20:26,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-23 17:20:26,154 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,154 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,154 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(192, 0)
2014-07-23 17:20:26,154 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 192 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:20:26,154 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10162879 s
2014-07-23 17:20:26,159 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 194(reduce at PCA.scala:57)
2014-07-23 17:20:26,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 195)
2014-07-23 17:20:26,161 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,161 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 194 (MappedRDD[201] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,162 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 194 (MappedRDD[201] at map at PCA.scala:57)
2014-07-23 17:20:26,163 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 194.0 with 1 tasks
2014-07-23 17:20:26,163 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 194.0:0 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,163 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 194.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:26,164 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-23 17:20:26,165 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,166 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,246 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-23 17:20:26,246 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-23 17:20:26,246 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-23 17:20:26,247 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(194, 0)
2014-07-23 17:20:26,247 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 83 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,247 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,247 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 194 (reduce at PCA.scala:57) finished in 0.084 s
2014-07-23 17:20:26,247 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.087923904 s
2014-07-23 17:20:26,251 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,252 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,252 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 196(reduce at PCA.scala:57)
2014-07-23 17:20:26,252 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 197)
2014-07-23 17:20:26,253 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,254 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 196 (MappedRDD[203] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,255 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 196 (MappedRDD[203] at map at PCA.scala:57)
2014-07-23 17:20:26,255 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 196.0 with 1 tasks
2014-07-23 17:20:26,255 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 196.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,256 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 196.0:0 as 2520 bytes in 1 ms
2014-07-23 17:20:26,256 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-23 17:20:26,257 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,258 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-23 17:20:26,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-23 17:20:26,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-23 17:20:26,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(196, 0)
2014-07-23 17:20:26,354 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 99 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,354 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 196.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 196 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:20:26,354 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.103178962 s
2014-07-23 17:20:26,359 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,360 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,360 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 198(reduce at PCA.scala:57)
2014-07-23 17:20:26,360 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 199)
2014-07-23 17:20:26,361 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,361 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 198 (MappedRDD[205] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,363 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 198 (MappedRDD[205] at map at PCA.scala:57)
2014-07-23 17:20:26,363 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 198.0 with 1 tasks
2014-07-23 17:20:26,363 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 198.0:0 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,363 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 198.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:26,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-23 17:20:26,365 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,366 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,460 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-23 17:20:26,460 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-23 17:20:26,461 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-23 17:20:26,461 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,461 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,461 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(198, 0)
2014-07-23 17:20:26,462 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 198 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:20:26,462 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.103068292 s
2014-07-23 17:20:26,466 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,468 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,468 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 200(reduce at PCA.scala:57)
2014-07-23 17:20:26,468 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 201)
2014-07-23 17:20:26,469 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,469 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 200 (MappedRDD[207] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,470 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 200 (MappedRDD[207] at map at PCA.scala:57)
2014-07-23 17:20:26,470 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 200.0 with 1 tasks
2014-07-23 17:20:26,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 200.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 200.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:26,471 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-23 17:20:26,472 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,474 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-23 17:20:26,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-23 17:20:26,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-23 17:20:26,573 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(200, 0)
2014-07-23 17:20:26,574 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 200 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:20:26,573 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,574 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,574 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107502133 s
2014-07-23 17:20:26,578 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,580 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,580 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 202(reduce at PCA.scala:57)
2014-07-23 17:20:26,580 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 203)
2014-07-23 17:20:26,582 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,582 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 202 (MappedRDD[209] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,583 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 202 (MappedRDD[209] at map at PCA.scala:57)
2014-07-23 17:20:26,584 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 202.0 with 1 tasks
2014-07-23 17:20:26,584 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 202.0:0 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,584 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 202.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:26,585 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-23 17:20:26,586 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,588 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,687 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-23 17:20:26,687 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-23 17:20:26,687 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-23 17:20:26,688 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(202, 0)
2014-07-23 17:20:26,688 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 202 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:26,688 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,688 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 202.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,689 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110002559 s
2014-07-23 17:20:26,693 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,694 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,694 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 204(reduce at PCA.scala:57)
2014-07-23 17:20:26,694 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 205)
2014-07-23 17:20:26,695 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,696 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 204 (MappedRDD[211] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,697 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 204 (MappedRDD[211] at map at PCA.scala:57)
2014-07-23 17:20:26,697 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 1 tasks
2014-07-23 17:20:26,698 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 204.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,698 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 204.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:26,698 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-23 17:20:26,700 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,701 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,800 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-23 17:20:26,800 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-23 17:20:26,801 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-23 17:20:26,801 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,801 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,801 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(204, 0)
2014-07-23 17:20:26,802 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 204 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:20:26,802 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108657617 s
2014-07-23 17:20:26,806 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,808 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,808 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 206(reduce at PCA.scala:57)
2014-07-23 17:20:26,808 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 207)
2014-07-23 17:20:26,809 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,810 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 206 (MappedRDD[213] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,811 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 206 (MappedRDD[213] at map at PCA.scala:57)
2014-07-23 17:20:26,811 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 206.0 with 1 tasks
2014-07-23 17:20:26,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 206.0:0 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,812 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 206.0:0 as 2521 bytes in 1 ms
2014-07-23 17:20:26,812 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-23 17:20:26,813 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,815 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:26,918 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-23 17:20:26,918 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-23 17:20:26,918 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-23 17:20:26,919 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:20:26,919 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(206, 0)
2014-07-23 17:20:26,919 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2014-07-23 17:20:26,919 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 206 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:20:26,920 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113910975 s
2014-07-23 17:20:26,924 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:26,925 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:26,926 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 208(reduce at PCA.scala:57)
2014-07-23 17:20:26,926 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 209)
2014-07-23 17:20:26,926 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:26,927 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 208 (MappedRDD[215] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:26,928 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 208 (MappedRDD[215] at map at PCA.scala:57)
2014-07-23 17:20:26,928 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 208.0 with 1 tasks
2014-07-23 17:20:26,928 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 208.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:26,929 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 208.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:26,929 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-23 17:20:26,930 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:26,931 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,037 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-23 17:20:27,037 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-23 17:20:27,037 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-23 17:20:27,038 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(208, 0)
2014-07-23 17:20:27,038 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,038 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 208.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,038 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 208 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:20:27,038 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113701849 s
2014-07-23 17:20:27,042 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,044 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,045 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 210(reduce at PCA.scala:57)
2014-07-23 17:20:27,045 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 211)
2014-07-23 17:20:27,046 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,046 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 210 (MappedRDD[217] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,048 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 210 (MappedRDD[217] at map at PCA.scala:57)
2014-07-23 17:20:27,048 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 210.0 with 1 tasks
2014-07-23 17:20:27,048 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 210.0:0 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,048 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 210.0:0 as 2519 bytes in 0 ms
2014-07-23 17:20:27,049 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-23 17:20:27,050 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,051 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,164 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-23 17:20:27,164 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-23 17:20:27,165 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,166 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 210.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,166 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(210, 0)
2014-07-23 17:20:27,166 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 210 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:20:27,166 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.123893257 s
2014-07-23 17:20:27,166 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-23 17:20:27,171 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,172 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,173 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 212(reduce at PCA.scala:57)
2014-07-23 17:20:27,173 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 213)
2014-07-23 17:20:27,174 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,175 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 212 (MappedRDD[219] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,176 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 212 (MappedRDD[219] at map at PCA.scala:57)
2014-07-23 17:20:27,176 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 212.0 with 1 tasks
2014-07-23 17:20:27,177 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 212.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,177 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 212.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:27,178 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-23 17:20:27,179 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,181 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,291 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-23 17:20:27,291 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-23 17:20:27,292 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-23 17:20:27,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(212, 0)
2014-07-23 17:20:27,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 212 (reduce at PCA.scala:57) finished in 0.115 s
2014-07-23 17:20:27,292 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121394891 s
2014-07-23 17:20:27,292 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 115 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,293 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 212.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,297 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 214(reduce at PCA.scala:57)
2014-07-23 17:20:27,298 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 215)
2014-07-23 17:20:27,299 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,300 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 214 (MappedRDD[221] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,301 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 214 (MappedRDD[221] at map at PCA.scala:57)
2014-07-23 17:20:27,301 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 214.0 with 1 tasks
2014-07-23 17:20:27,301 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 214.0:0 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,302 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 214.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:27,302 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-23 17:20:27,303 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,304 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-23 17:20:27,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-23 17:20:27,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-23 17:20:27,409 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,409 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 214.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,410 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(214, 0)
2014-07-23 17:20:27,410 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 214 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:20:27,410 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113175748 s
2014-07-23 17:20:27,415 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 216(reduce at PCA.scala:57)
2014-07-23 17:20:27,416 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 217)
2014-07-23 17:20:27,417 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,418 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 216 (MappedRDD[223] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 216 (MappedRDD[223] at map at PCA.scala:57)
2014-07-23 17:20:27,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 216.0 with 1 tasks
2014-07-23 17:20:27,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 216.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,419 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 216.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:27,420 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-23 17:20:27,421 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,422 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-23 17:20:27,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-23 17:20:27,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-23 17:20:27,514 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(216, 0)
2014-07-23 17:20:27,514 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,514 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 216.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,514 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 216 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:20:27,514 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099319617 s
2014-07-23 17:20:27,519 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,520 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,520 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 218(reduce at PCA.scala:57)
2014-07-23 17:20:27,520 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 219)
2014-07-23 17:20:27,521 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,522 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 218 (MappedRDD[225] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,523 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 218 (MappedRDD[225] at map at PCA.scala:57)
2014-07-23 17:20:27,523 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 218.0 with 1 tasks
2014-07-23 17:20:27,524 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 218.0:0 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,524 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 218.0:0 as 2515 bytes in 0 ms
2014-07-23 17:20:27,524 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-23 17:20:27,525 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,526 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-23 17:20:27,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-23 17:20:27,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-23 17:20:27,606 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(218, 0)
2014-07-23 17:20:27,606 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 218 (reduce at PCA.scala:57) finished in 0.083 s
2014-07-23 17:20:27,606 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 82 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,606 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 218.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,606 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.086801526 s
2014-07-23 17:20:27,610 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,611 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,611 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 220(reduce at PCA.scala:57)
2014-07-23 17:20:27,612 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 221)
2014-07-23 17:20:27,614 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,615 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 220 (MappedRDD[227] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,616 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 220 (MappedRDD[227] at map at PCA.scala:57)
2014-07-23 17:20:27,616 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 220.0 with 1 tasks
2014-07-23 17:20:27,617 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 220.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,617 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 220.0:0 as 2517 bytes in 0 ms
2014-07-23 17:20:27,617 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-23 17:20:27,618 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,619 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,710 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-23 17:20:27,710 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-23 17:20:27,710 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-23 17:20:27,711 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(220, 0)
2014-07-23 17:20:27,711 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,711 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 220.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,711 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 220 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:20:27,711 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.100718765 s
2014-07-23 17:20:27,715 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,717 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,718 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 222(reduce at PCA.scala:57)
2014-07-23 17:20:27,718 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 223)
2014-07-23 17:20:27,718 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,719 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 222 (MappedRDD[229] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,720 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 222 (MappedRDD[229] at map at PCA.scala:57)
2014-07-23 17:20:27,720 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 222.0 with 1 tasks
2014-07-23 17:20:27,720 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 222.0:0 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,721 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 222.0:0 as 2522 bytes in 1 ms
2014-07-23 17:20:27,721 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-23 17:20:27,722 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,723 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-23 17:20:27,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-23 17:20:27,822 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-23 17:20:27,823 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(222, 0)
2014-07-23 17:20:27,823 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,823 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 222.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,823 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 222 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:27,823 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107933756 s
2014-07-23 17:20:27,827 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,829 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,829 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 224(reduce at PCA.scala:57)
2014-07-23 17:20:27,829 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 225)
2014-07-23 17:20:27,830 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,831 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 224 (MappedRDD[231] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,832 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 224 (MappedRDD[231] at map at PCA.scala:57)
2014-07-23 17:20:27,832 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 224.0 with 1 tasks
2014-07-23 17:20:27,833 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 224.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,833 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 224.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:27,834 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-23 17:20:27,835 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,836 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:27,935 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-23 17:20:27,935 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-23 17:20:27,935 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-23 17:20:27,936 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(224, 0)
2014-07-23 17:20:27,936 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:20:27,936 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 224.0, whose tasks have all completed, from pool 
2014-07-23 17:20:27,936 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 224 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:27,936 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108405615 s
2014-07-23 17:20:27,941 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:27,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:27,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 226(reduce at PCA.scala:57)
2014-07-23 17:20:27,942 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 227)
2014-07-23 17:20:27,943 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:27,944 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 226 (MappedRDD[233] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:27,945 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 226 (MappedRDD[233] at map at PCA.scala:57)
2014-07-23 17:20:27,945 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 226.0 with 1 tasks
2014-07-23 17:20:27,945 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 226.0:0 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:27,946 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 226.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:27,946 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-23 17:20:27,947 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:27,948 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,041 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-23 17:20:28,041 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-23 17:20:28,041 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-23 17:20:28,042 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,042 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 226.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,042 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(226, 0)
2014-07-23 17:20:28,042 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 226 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:20:28,042 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10171046 s
2014-07-23 17:20:28,047 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,048 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,048 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 228(reduce at PCA.scala:57)
2014-07-23 17:20:28,048 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 229)
2014-07-23 17:20:28,049 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,049 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 228 (MappedRDD[235] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,050 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 228 (MappedRDD[235] at map at PCA.scala:57)
2014-07-23 17:20:28,050 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 228.0 with 1 tasks
2014-07-23 17:20:28,051 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 228.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,051 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 228.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:28,051 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-23 17:20:28,052 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,053 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,147 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-23 17:20:28,147 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-23 17:20:28,147 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-23 17:20:28,148 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(228, 0)
2014-07-23 17:20:28,148 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,148 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 228.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,148 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 228 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:20:28,149 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10191951 s
2014-07-23 17:20:28,154 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 230(reduce at PCA.scala:57)
2014-07-23 17:20:28,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 231)
2014-07-23 17:20:28,156 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,156 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 230 (MappedRDD[237] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,157 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 230 (MappedRDD[237] at map at PCA.scala:57)
2014-07-23 17:20:28,157 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 230.0 with 1 tasks
2014-07-23 17:20:28,158 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 230.0:0 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,158 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 230.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:28,159 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-23 17:20:28,160 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,161 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-23 17:20:28,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-23 17:20:28,260 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-23 17:20:28,261 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,261 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 230.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(230, 0)
2014-07-23 17:20:28,261 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 230 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:20:28,262 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107885026 s
2014-07-23 17:20:28,266 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,267 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 232(reduce at PCA.scala:57)
2014-07-23 17:20:28,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 233)
2014-07-23 17:20:28,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,269 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 232 (MappedRDD[239] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,270 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 232 (MappedRDD[239] at map at PCA.scala:57)
2014-07-23 17:20:28,270 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 232.0 with 1 tasks
2014-07-23 17:20:28,270 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 232.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,271 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 232.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:28,271 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-23 17:20:28,272 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,273 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,366 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-23 17:20:28,366 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-23 17:20:28,366 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-23 17:20:28,367 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(232, 0)
2014-07-23 17:20:28,367 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,367 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 232.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,367 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 232 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:20:28,367 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101553414 s
2014-07-23 17:20:28,372 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,373 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,373 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 234(reduce at PCA.scala:57)
2014-07-23 17:20:28,373 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 235)
2014-07-23 17:20:28,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,374 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 234 (MappedRDD[241] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 234 (MappedRDD[241] at map at PCA.scala:57)
2014-07-23 17:20:28,375 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 234.0 with 1 tasks
2014-07-23 17:20:28,376 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 234.0:0 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,376 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 234.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:28,376 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-23 17:20:28,377 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,378 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,471 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-23 17:20:28,471 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-23 17:20:28,471 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-23 17:20:28,472 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,472 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 234.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,472 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(234, 0)
2014-07-23 17:20:28,473 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 234 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:20:28,473 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101457526 s
2014-07-23 17:20:28,478 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,479 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,479 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 236(reduce at PCA.scala:57)
2014-07-23 17:20:28,479 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 237)
2014-07-23 17:20:28,480 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,480 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 236 (MappedRDD[243] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,481 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 236 (MappedRDD[243] at map at PCA.scala:57)
2014-07-23 17:20:28,481 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 236.0 with 1 tasks
2014-07-23 17:20:28,482 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 236.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,482 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 236.0:0 as 2518 bytes in 0 ms
2014-07-23 17:20:28,482 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-23 17:20:28,484 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,484 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,581 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-23 17:20:28,581 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-23 17:20:28,581 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-23 17:20:28,582 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(236, 0)
2014-07-23 17:20:28,582 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,582 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 236 (reduce at PCA.scala:57) finished in 0.100 s
2014-07-23 17:20:28,582 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 236.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,582 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104457602 s
2014-07-23 17:20:28,586 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,587 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,587 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 238(reduce at PCA.scala:57)
2014-07-23 17:20:28,588 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 239)
2014-07-23 17:20:28,588 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,589 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 238 (MappedRDD[245] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,590 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 238 (MappedRDD[245] at map at PCA.scala:57)
2014-07-23 17:20:28,590 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 238.0 with 1 tasks
2014-07-23 17:20:28,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 238.0:0 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 238.0:0 as 2522 bytes in 0 ms
2014-07-23 17:20:28,591 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-23 17:20:28,592 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,593 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-23 17:20:28,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-23 17:20:28,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-23 17:20:28,680 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(238, 0)
2014-07-23 17:20:28,680 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 90 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,680 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 238.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,680 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 238 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:20:28,680 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.093982166 s
2014-07-23 17:20:28,685 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,686 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,686 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 240(reduce at PCA.scala:57)
2014-07-23 17:20:28,686 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 241)
2014-07-23 17:20:28,687 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,687 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 240 (MappedRDD[247] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,688 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 240 (MappedRDD[247] at map at PCA.scala:57)
2014-07-23 17:20:28,688 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 240.0 with 1 tasks
2014-07-23 17:20:28,689 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 240.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,689 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 240.0:0 as 2521 bytes in 0 ms
2014-07-23 17:20:28,689 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-23 17:20:28,690 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,691 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,775 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-23 17:20:28,775 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-23 17:20:28,775 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-23 17:20:28,776 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(240, 0)
2014-07-23 17:20:28,776 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 87 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,776 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 240.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,776 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 240 (reduce at PCA.scala:57) finished in 0.087 s
2014-07-23 17:20:28,776 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.091849171 s
2014-07-23 17:20:28,781 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:20:28,782 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:20:28,782 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 242(reduce at PCA.scala:57)
2014-07-23 17:20:28,782 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 243)
2014-07-23 17:20:28,783 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:20:28,783 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 242 (MappedRDD[249] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:20:28,785 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 242 (MappedRDD[249] at map at PCA.scala:57)
2014-07-23 17:20:28,785 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 242.0 with 1 tasks
2014-07-23 17:20:28,785 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 242.0:0 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:20:28,786 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 242.0:0 as 2520 bytes in 0 ms
2014-07-23 17:20:28,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-23 17:20:28,787 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:20:28,788 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:20:28,856 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-23 17:20:28,856 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-23 17:20:28,856 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-23 17:20:28,857 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 72 ms on localhost (progress: 1/1)
2014-07-23 17:20:28,857 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 242.0, whose tasks have all completed, from pool 
2014-07-23 17:20:28,857 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(242, 0)
2014-07-23 17:20:28,857 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 242 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:20:28,858 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.076671219 s
2014-07-23 17:22:37,585 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.225 instead (on interface eth0)
2014-07-23 17:22:37,586 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-23 17:22:37,650 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-23 17:22:37,650 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-23 17:22:38,127 [spark-akka.actor.default-dispatcher-2] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-23 17:22:38,186 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Starting remoting
2014-07-23 17:22:38,360 [spark-akka.actor.default-dispatcher-6] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.225:43374]
2014-07-23 17:22:38,363 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.225:43374]
2014-07-23 17:22:38,389 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-23 17:22:38,393 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-23 17:22:38,406 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140723172238-cd6c
2014-07-23 17:22:38,410 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-23 17:22:38,441 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 38109 with id = ConnectionManagerId(10.74.147.225,38109)
2014-07-23 17:22:38,446 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-23 17:22:38,448 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.225:38109 with 1056.0 MB RAM
2014-07-23 17:22:38,449 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-23 17:22:38,466 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:22:38,601 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:22:38,619 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:57343
2014-07-23 17:22:38,619 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.225:57343
2014-07-23 17:22:38,627 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-021ae7b5-5bf9-4ebd-81fc-b69183db6322
2014-07-23 17:22:38,627 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:22:38,628 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:22:38,629 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:38829
2014-07-23 17:22:38,956 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:22:38,968 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-23 17:22:38,973 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.225:4040
2014-07-23 17:22:39,494 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-23 17:22:39,496 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-23 17:22:39,588 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at PCA.scala:50
2014-07-23 17:22:39,620 [spark-akka.actor.default-dispatcher-4] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-23 17:22:39,620 [spark-akka.actor.default-dispatcher-4] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-23 17:22:39,628 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-23 17:22:39,641 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (repartition at PCA.scala:46)
2014-07-23 17:22:39,643 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PCA.scala:50) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:39,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at PCA.scala:50)
2014-07-23 17:22:39,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 1)
2014-07-23 17:22:39,647 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(Stage 1)
2014-07-23 17:22:39,655 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46), which has no missing parents
2014-07-23 17:22:39,719 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46)
2014-07-23 17:22:39,721 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-23 17:22:39,741 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:39,745 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2031 bytes in 2 ms
2014-07-23 17:22:39,747 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:39,748 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2031 bytes in 1 ms
2014-07-23 17:22:39,756 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-23 17:22:39,756 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-23 17:22:39,789 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:39,790 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:39,801 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-23 17:22:39,802 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-23 17:22:41,877 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 783
2014-07-23 17:22:41,877 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 783
2014-07-23 17:22:41,878 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-23 17:22:41,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-23 17:22:41,883 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-23 17:22:41,883 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-23 17:22:41,889 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 2139 ms on localhost (progress: 1/2)
2014-07-23 17:22:41,890 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 1)
2014-07-23 17:22:41,898 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 0)
2014-07-23 17:22:41,899 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (repartition at PCA.scala:46) finished in 2.167 s
2014-07-23 17:22:41,900 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2014-07-23 17:22:41,900 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 2158 ms on localhost (progress: 2/2)
2014-07-23 17:22:41,901 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-23 17:22:41,901 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2014-07-23 17:22:41,902 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(Stage 0)
2014-07-23 17:22:41,902 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2014-07-23 17:22:41,911 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents for Stage 0: List()
2014-07-23 17:22:41,918 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[7] at repartition at PCA.scala:46), which is now runnable
2014-07-23 17:22:41,939 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 0 (MappedRDD[7] at repartition at PCA.scala:46)
2014-07-23 17:22:41,940 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2014-07-23 17:22:41,941 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:41,942 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 2265 bytes in 1 ms
2014-07-23 17:22:41,943 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-23 17:22:41,947 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:41,958 [Executor task launch worker-1] INFO  [org.apache.spark.CacheManager] - Partition rdd_7_0 not found, computing it
2014-07-23 17:22:41,965 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-23 17:22:41,968 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2014-07-23 17:22:41,969 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2014-07-23 17:22:44,028 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(170498505) called with curMem=32856, maxMem=1107296256
2014-07-23 17:22:44,029 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_7_0 stored as values to memory (estimated size 162.6 MB, free 893.4 MB)
2014-07-23 17:22:44,032 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_7_0 in memory on 10.74.147.225:38109 (size: 162.6 MB, free: 893.4 MB)
2014-07-23 17:22:44,033 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_7_0
2014-07-23 17:22:44,054 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 1390
2014-07-23 17:22:44,054 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-23 17:22:44,054 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-23 17:22:44,057 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-23 17:22:44,058 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at PCA.scala:50) finished in 2.117 s
2014-07-23 17:22:44,065 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 2116 ms on localhost (progress: 1/1)
2014-07-23 17:22:44,065 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at PCA.scala:50, took 4.476693029 s
2014-07-23 17:22:44,065 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-23 17:22:44,089 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:44,094 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 0 is 146 bytes
2014-07-23 17:22:44,097 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:44,097 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at PCA.scala:57)
2014-07-23 17:22:44,097 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 3)
2014-07-23 17:22:44,098 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:44,099 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[9] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:44,107 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 2 (MappedRDD[9] at map at PCA.scala:57)
2014-07-23 17:22:44,107 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 1 tasks
2014-07-23 17:22:44,108 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:44,109 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2520 bytes in 1 ms
2014-07-23 17:22:44,109 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-23 17:22:44,113 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:44,117 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:44,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 678
2014-07-23 17:22:44,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-23 17:22:44,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-23 17:22:44,559 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-23 17:22:44,559 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at PCA.scala:57) finished in 0.451 s
2014-07-23 17:22:44,560 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 451 ms on localhost (progress: 1/1)
2014-07-23 17:22:44,560 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.469819474 s
2014-07-23 17:22:44,560 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-23 17:22:44,567 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:44,569 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:44,569 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(reduce at PCA.scala:57)
2014-07-23 17:22:44,569 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 5)
2014-07-23 17:22:44,571 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:44,571 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[11] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:44,574 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 4 (MappedRDD[11] at map at PCA.scala:57)
2014-07-23 17:22:44,574 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 1 tasks
2014-07-23 17:22:44,575 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:44,576 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:44,576 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-23 17:22:44,579 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:44,582 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:44,684 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 678
2014-07-23 17:22:44,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-23 17:22:44,687 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:22:44,687 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-23 17:22:44,687 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-23 17:22:44,687 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:22:44,688 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121010009 s
2014-07-23 17:22:44,695 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-23 17:22:44,698 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:44,700 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:44,700 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(reduce at PCA.scala:57)
2014-07-23 17:22:44,701 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 7)
2014-07-23 17:22:44,702 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:44,703 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[13] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:44,706 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 6 (MappedRDD[13] at map at PCA.scala:57)
2014-07-23 17:22:44,706 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 1 tasks
2014-07-23 17:22:44,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:44,707 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:44,708 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-23 17:22:44,711 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:44,714 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:44,818 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 678
2014-07-23 17:22:44,818 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-23 17:22:44,818 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-23 17:22:44,819 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 112 ms on localhost (progress: 1/1)
2014-07-23 17:22:44,819 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-23 17:22:44,819 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-23 17:22:44,820 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:22:44,820 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121894632 s
2014-07-23 17:22:44,826 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:44,828 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:44,828 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at PCA.scala:57)
2014-07-23 17:22:44,828 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 9)
2014-07-23 17:22:44,829 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:44,830 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[15] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:44,832 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 8 (MappedRDD[15] at map at PCA.scala:57)
2014-07-23 17:22:44,833 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 1 tasks
2014-07-23 17:22:44,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:44,834 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2522 bytes in 1 ms
2014-07-23 17:22:44,834 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-23 17:22:44,837 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:44,839 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:44,955 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-23 17:22:44,955 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-23 17:22:44,956 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-23 17:22:44,957 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:22:44,958 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-23 17:22:44,958 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-23 17:22:44,958 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at PCA.scala:57) finished in 0.125 s
2014-07-23 17:22:44,959 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.13288671 s
2014-07-23 17:22:44,966 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:44,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:44,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at PCA.scala:57)
2014-07-23 17:22:44,968 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 11)
2014-07-23 17:22:44,970 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:44,971 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[17] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:44,973 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 10 (MappedRDD[17] at map at PCA.scala:57)
2014-07-23 17:22:44,974 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 1 tasks
2014-07-23 17:22:44,975 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:44,975 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2521 bytes in 0 ms
2014-07-23 17:22:44,976 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-23 17:22:44,979 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:44,982 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:45,084 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-23 17:22:45,085 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-23 17:22:45,085 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-23 17:22:45,086 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-23 17:22:45,086 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:22:45,086 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-23 17:22:45,086 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:45,086 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.120457434 s
2014-07-23 17:22:45,092 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:45,095 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:45,095 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at PCA.scala:57)
2014-07-23 17:22:45,095 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 13)
2014-07-23 17:22:45,097 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:45,097 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[19] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:45,100 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 12 (MappedRDD[19] at map at PCA.scala:57)
2014-07-23 17:22:45,100 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 1 tasks
2014-07-23 17:22:45,101 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:45,101 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:45,102 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-23 17:22:45,105 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:45,108 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:45,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-23 17:22:45,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-23 17:22:45,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-23 17:22:45,210 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-23 17:22:45,210 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:22:45,211 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-23 17:22:45,211 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:22:45,211 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118720243 s
2014-07-23 17:22:45,217 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:45,220 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:45,220 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at PCA.scala:57)
2014-07-23 17:22:45,220 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 15)
2014-07-23 17:22:45,221 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:45,222 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[21] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:45,224 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 14 (MappedRDD[21] at map at PCA.scala:57)
2014-07-23 17:22:45,224 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 1 tasks
2014-07-23 17:22:45,225 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:45,226 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:45,227 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-23 17:22:45,230 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:45,232 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:45,335 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-23 17:22:45,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-23 17:22:45,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-23 17:22:45,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-23 17:22:45,337 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:22:45,337 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-23 17:22:45,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at PCA.scala:57) finished in 0.112 s
2014-07-23 17:22:45,338 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.120267215 s
2014-07-23 17:22:45,344 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:45,346 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:45,346 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at PCA.scala:57)
2014-07-23 17:22:45,346 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 17)
2014-07-23 17:22:45,347 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:45,348 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[23] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:45,350 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 16 (MappedRDD[23] at map at PCA.scala:57)
2014-07-23 17:22:45,351 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 1 tasks
2014-07-23 17:22:45,351 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:45,352 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:45,352 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-23 17:22:45,356 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:45,358 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:45,469 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-23 17:22:45,470 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-23 17:22:45,470 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-23 17:22:45,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-23 17:22:45,471 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 120 ms on localhost (progress: 1/1)
2014-07-23 17:22:45,471 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-23 17:22:45,471 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at PCA.scala:57) finished in 0.120 s
2014-07-23 17:22:45,471 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.127731165 s
2014-07-23 17:22:45,481 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:45,483 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:45,483 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at PCA.scala:57)
2014-07-23 17:22:45,483 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 19)
2014-07-23 17:22:45,485 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:45,485 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[25] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:45,488 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 18 (MappedRDD[25] at map at PCA.scala:57)
2014-07-23 17:22:45,488 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 1 tasks
2014-07-23 17:22:45,489 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:45,489 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:45,490 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-23 17:22:45,493 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:45,495 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:45,788 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-23 17:22:45,788 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-23 17:22:45,788 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-23 17:22:45,789 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-23 17:22:45,789 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 300 ms on localhost (progress: 1/1)
2014-07-23 17:22:45,789 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-23 17:22:45,789 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at PCA.scala:57) finished in 0.301 s
2014-07-23 17:22:45,790 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.308373814 s
2014-07-23 17:22:45,801 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:45,804 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:45,804 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at PCA.scala:57)
2014-07-23 17:22:45,804 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 21)
2014-07-23 17:22:45,805 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:45,806 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[27] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:45,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 20 (MappedRDD[27] at map at PCA.scala:57)
2014-07-23 17:22:45,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 1 tasks
2014-07-23 17:22:45,812 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:45,812 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:45,813 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-23 17:22:45,815 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:45,818 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:45,933 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-23 17:22:45,933 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-23 17:22:45,933 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-23 17:22:45,936 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:22:45,936 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-23 17:22:45,936 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-23 17:22:45,937 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:22:45,937 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.136558387 s
2014-07-23 17:22:45,955 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:45,957 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:45,957 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at PCA.scala:57)
2014-07-23 17:22:45,957 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 23)
2014-07-23 17:22:45,959 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:45,959 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[29] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:45,962 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 22 (MappedRDD[29] at map at PCA.scala:57)
2014-07-23 17:22:45,962 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 1 tasks
2014-07-23 17:22:45,963 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:45,964 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2522 bytes in 1 ms
2014-07-23 17:22:45,964 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-23 17:22:45,969 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:45,972 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,079 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-23 17:22:46,080 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-23 17:22:46,082 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,082 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,082 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-23 17:22:46,083 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at PCA.scala:57) finished in 0.119 s
2014-07-23 17:22:46,084 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128961391 s
2014-07-23 17:22:46,090 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,092 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,092 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at PCA.scala:57)
2014-07-23 17:22:46,092 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 25)
2014-07-23 17:22:46,092 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-23 17:22:46,093 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,093 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[31] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,096 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 24 (MappedRDD[31] at map at PCA.scala:57)
2014-07-23 17:22:46,096 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 1 tasks
2014-07-23 17:22:46,097 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,098 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:46,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-23 17:22:46,102 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,104 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-23 17:22:46,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-23 17:22:46,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-23 17:22:46,207 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,207 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,207 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-23 17:22:46,207 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:22:46,207 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117691483 s
2014-07-23 17:22:46,214 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,216 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,216 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at PCA.scala:57)
2014-07-23 17:22:46,216 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 27)
2014-07-23 17:22:46,218 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,218 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[33] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,230 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 26 (MappedRDD[33] at map at PCA.scala:57)
2014-07-23 17:22:46,230 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 1 tasks
2014-07-23 17:22:46,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:46,233 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-23 17:22:46,236 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,239 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,320 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-23 17:22:46,320 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-23 17:22:46,321 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-23 17:22:46,322 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-23 17:22:46,322 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 90 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,322 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at PCA.scala:57) finished in 0.079 s
2014-07-23 17:22:46,322 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,322 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107927289 s
2014-07-23 17:22:46,331 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at PCA.scala:57)
2014-07-23 17:22:46,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 29)
2014-07-23 17:22:46,335 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,336 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[35] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,339 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 28 (MappedRDD[35] at map at PCA.scala:57)
2014-07-23 17:22:46,340 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 1 tasks
2014-07-23 17:22:46,341 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,341 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:46,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-23 17:22:46,344 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,350 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,457 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-23 17:22:46,458 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-23 17:22:46,458 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-23 17:22:46,459 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-23 17:22:46,459 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 118 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,459 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,459 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at PCA.scala:57) finished in 0.117 s
2014-07-23 17:22:46,459 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128003103 s
2014-07-23 17:22:46,466 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,468 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,468 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at PCA.scala:57)
2014-07-23 17:22:46,468 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 31)
2014-07-23 17:22:46,470 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[37] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,478 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 30 (MappedRDD[37] at map at PCA.scala:57)
2014-07-23 17:22:46,478 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 1 tasks
2014-07-23 17:22:46,481 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,481 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:46,482 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-23 17:22:46,485 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,631 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-23 17:22:46,631 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-23 17:22:46,633 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 152 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,633 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,633 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-23 17:22:46,633 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at PCA.scala:57) finished in 0.137 s
2014-07-23 17:22:46,634 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.167957541 s
2014-07-23 17:22:46,641 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,641 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-23 17:22:46,643 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at PCA.scala:57)
2014-07-23 17:22:46,644 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 33)
2014-07-23 17:22:46,645 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,646 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[39] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,649 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 32 (MappedRDD[39] at map at PCA.scala:57)
2014-07-23 17:22:46,649 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 1 tasks
2014-07-23 17:22:46,650 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,650 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:46,651 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-23 17:22:46,654 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,657 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,824 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-23 17:22:46,824 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-23 17:22:46,826 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 176 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,827 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,827 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-23 17:22:46,827 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at PCA.scala:57) finished in 0.173 s
2014-07-23 17:22:46,828 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.186447089 s
2014-07-23 17:22:46,835 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-23 17:22:46,836 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,838 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,838 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at PCA.scala:57)
2014-07-23 17:22:46,838 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 35)
2014-07-23 17:22:46,840 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,841 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[41] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,844 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 34 (MappedRDD[41] at map at PCA.scala:57)
2014-07-23 17:22:46,844 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 1 tasks
2014-07-23 17:22:46,845 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,845 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:46,847 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-23 17:22:46,849 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,851 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:46,971 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-23 17:22:46,971 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-23 17:22:46,973 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-23 17:22:46,973 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at PCA.scala:57) finished in 0.124 s
2014-07-23 17:22:46,974 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 128 ms on localhost (progress: 1/1)
2014-07-23 17:22:46,975 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-23 17:22:46,976 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.139559452 s
2014-07-23 17:22:46,983 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-23 17:22:46,983 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:46,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:46,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at PCA.scala:57)
2014-07-23 17:22:46,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 37)
2014-07-23 17:22:46,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:46,988 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[43] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:46,991 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 36 (MappedRDD[43] at map at PCA.scala:57)
2014-07-23 17:22:46,991 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 1 tasks
2014-07-23 17:22:46,992 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:46,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:46,993 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-23 17:22:46,996 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:46,998 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:47,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-23 17:22:47,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-23 17:22:47,154 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-23 17:22:47,154 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-23 17:22:47,155 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 162 ms on localhost (progress: 1/1)
2014-07-23 17:22:47,155 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-23 17:22:47,155 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at PCA.scala:57) finished in 0.156 s
2014-07-23 17:22:47,156 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.172436897 s
2014-07-23 17:22:47,163 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:47,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:47,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at PCA.scala:57)
2014-07-23 17:22:47,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 39)
2014-07-23 17:22:47,166 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:47,167 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[45] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:47,170 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 38 (MappedRDD[45] at map at PCA.scala:57)
2014-07-23 17:22:47,170 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 1 tasks
2014-07-23 17:22:47,171 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:47,171 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:47,172 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-23 17:22:47,174 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:47,176 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:48,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-23 17:22:48,579 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-23 17:22:48,579 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-23 17:22:48,580 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-23 17:22:48,580 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 1408 ms on localhost (progress: 1/1)
2014-07-23 17:22:48,580 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-23 17:22:48,580 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at PCA.scala:57) finished in 1.405 s
2014-07-23 17:22:48,580 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 1.417619007 s
2014-07-23 17:22:48,589 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:48,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:48,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at PCA.scala:57)
2014-07-23 17:22:48,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 41)
2014-07-23 17:22:48,592 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:48,593 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[47] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:48,595 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 40 (MappedRDD[47] at map at PCA.scala:57)
2014-07-23 17:22:48,596 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 1 tasks
2014-07-23 17:22:48,596 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:48,597 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:48,598 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-23 17:22:48,600 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:48,602 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:48,702 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-23 17:22:48,702 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-23 17:22:48,702 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-23 17:22:48,703 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:22:48,703 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-23 17:22:48,704 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-23 17:22:48,704 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:48,704 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115461308 s
2014-07-23 17:22:48,710 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:48,713 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:48,713 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at PCA.scala:57)
2014-07-23 17:22:48,713 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 43)
2014-07-23 17:22:48,714 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:48,714 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[49] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:48,717 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 42 (MappedRDD[49] at map at PCA.scala:57)
2014-07-23 17:22:48,717 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 1 tasks
2014-07-23 17:22:48,718 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:48,718 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:48,719 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-23 17:22:48,722 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:48,723 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:48,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-23 17:22:48,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-23 17:22:48,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-23 17:22:48,824 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-23 17:22:48,824 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:22:48,824 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-23 17:22:48,824 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:22:48,824 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114385309 s
2014-07-23 17:22:48,830 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:48,831 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:48,832 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at PCA.scala:57)
2014-07-23 17:22:48,832 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 45)
2014-07-23 17:22:48,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:48,833 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[51] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:48,835 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 44 (MappedRDD[51] at map at PCA.scala:57)
2014-07-23 17:22:48,835 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 1 tasks
2014-07-23 17:22:48,836 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:48,837 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2522 bytes in 1 ms
2014-07-23 17:22:48,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-23 17:22:48,841 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:48,843 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:48,938 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-23 17:22:48,938 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-23 17:22:48,938 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-23 17:22:48,939 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-23 17:22:48,939 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:22:48,939 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:48,939 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-23 17:22:48,940 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11002466 s
2014-07-23 17:22:48,944 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:48,946 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:48,946 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at PCA.scala:57)
2014-07-23 17:22:48,946 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 47)
2014-07-23 17:22:48,947 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:48,948 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[53] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:48,951 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 46 (MappedRDD[53] at map at PCA.scala:57)
2014-07-23 17:22:48,951 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 1 tasks
2014-07-23 17:22:48,952 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:48,952 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:48,953 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-23 17:22:48,955 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:48,956 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,047 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-23 17:22:49,048 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-23 17:22:49,048 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-23 17:22:49,049 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,049 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,049 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-23 17:22:49,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:22:49,050 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105647512 s
2014-07-23 17:22:49,055 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,056 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,056 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at PCA.scala:57)
2014-07-23 17:22:49,057 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 49)
2014-07-23 17:22:49,058 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,058 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[55] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,061 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 48 (MappedRDD[55] at map at PCA.scala:57)
2014-07-23 17:22:49,061 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 1 tasks
2014-07-23 17:22:49,062 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,062 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:49,063 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-23 17:22:49,065 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,067 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,158 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-23 17:22:49,158 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-23 17:22:49,160 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,160 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,160 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-23 17:22:49,161 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:49,161 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106111695 s
2014-07-23 17:22:49,161 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-23 17:22:49,171 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,173 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,173 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at PCA.scala:57)
2014-07-23 17:22:49,173 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 51)
2014-07-23 17:22:49,174 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,175 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[57] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,178 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 50 (MappedRDD[57] at map at PCA.scala:57)
2014-07-23 17:22:49,178 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 1 tasks
2014-07-23 17:22:49,179 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,179 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:49,180 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-23 17:22:49,182 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,184 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,271 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-23 17:22:49,271 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-23 17:22:49,271 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-23 17:22:49,272 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-23 17:22:49,272 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 93 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,272 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,272 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at PCA.scala:57) finished in 0.092 s
2014-07-23 17:22:49,273 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.102103703 s
2014-07-23 17:22:49,278 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,280 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,280 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at PCA.scala:57)
2014-07-23 17:22:49,280 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 53)
2014-07-23 17:22:49,281 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,281 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[59] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,283 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 52 (MappedRDD[59] at map at PCA.scala:57)
2014-07-23 17:22:49,283 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2014-07-23 17:22:49,284 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,285 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:49,285 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-23 17:22:49,287 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,289 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,381 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-23 17:22:49,381 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-23 17:22:49,381 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-23 17:22:49,382 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,382 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,382 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-23 17:22:49,382 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:22:49,383 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104626103 s
2014-07-23 17:22:49,387 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,389 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,389 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at PCA.scala:57)
2014-07-23 17:22:49,389 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 55)
2014-07-23 17:22:49,390 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,391 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[61] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,392 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 54 (MappedRDD[61] at map at PCA.scala:57)
2014-07-23 17:22:49,392 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 1 tasks
2014-07-23 17:22:49,393 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,393 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:49,394 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-23 17:22:49,396 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,398 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,507 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-23 17:22:49,507 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-23 17:22:49,507 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-23 17:22:49,508 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-23 17:22:49,508 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,508 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,508 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at PCA.scala:57) finished in 0.115 s
2014-07-23 17:22:49,510 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.122733197 s
2014-07-23 17:22:49,515 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,517 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,517 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at PCA.scala:57)
2014-07-23 17:22:49,517 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 57)
2014-07-23 17:22:49,518 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,519 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[63] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,520 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 56 (MappedRDD[63] at map at PCA.scala:57)
2014-07-23 17:22:49,521 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 1 tasks
2014-07-23 17:22:49,521 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,522 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:49,522 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-23 17:22:49,524 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,526 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,630 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-23 17:22:49,630 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-23 17:22:49,630 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-23 17:22:49,631 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-23 17:22:49,631 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,631 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,632 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:22:49,633 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117558152 s
2014-07-23 17:22:49,637 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,639 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,639 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at PCA.scala:57)
2014-07-23 17:22:49,639 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 59)
2014-07-23 17:22:49,640 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,641 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[65] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,643 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 58 (MappedRDD[65] at map at PCA.scala:57)
2014-07-23 17:22:49,643 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 1 tasks
2014-07-23 17:22:49,643 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:49,644 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-23 17:22:49,646 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,648 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,752 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-23 17:22:49,752 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-23 17:22:49,752 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-23 17:22:49,753 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-23 17:22:49,753 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,753 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,753 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:22:49,754 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115912803 s
2014-07-23 17:22:49,758 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,760 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,760 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at PCA.scala:57)
2014-07-23 17:22:49,760 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 61)
2014-07-23 17:22:49,763 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,763 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[67] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,766 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 60 (MappedRDD[67] at map at PCA.scala:57)
2014-07-23 17:22:49,766 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 1 tasks
2014-07-23 17:22:49,768 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,768 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:49,769 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-23 17:22:49,771 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,776 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:49,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-23 17:22:49,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-23 17:22:49,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-23 17:22:49,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-23 17:22:49,886 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 118 ms on localhost (progress: 1/1)
2014-07-23 17:22:49,886 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-23 17:22:49,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at PCA.scala:57) finished in 0.119 s
2014-07-23 17:22:49,887 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128518839 s
2014-07-23 17:22:49,892 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:49,893 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:49,893 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at PCA.scala:57)
2014-07-23 17:22:49,893 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 63)
2014-07-23 17:22:49,894 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:49,895 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[69] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:49,897 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 62 (MappedRDD[69] at map at PCA.scala:57)
2014-07-23 17:22:49,897 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 1 tasks
2014-07-23 17:22:49,898 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:49,898 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:49,898 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-23 17:22:49,901 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:49,903 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-23 17:22:50,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-23 17:22:50,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-23 17:22:50,007 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-23 17:22:50,007 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,007 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,007 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:22:50,008 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.116032661 s
2014-07-23 17:22:50,012 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at PCA.scala:57)
2014-07-23 17:22:50,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 65)
2014-07-23 17:22:50,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,016 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[71] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 64 (MappedRDD[71] at map at PCA.scala:57)
2014-07-23 17:22:50,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 1 tasks
2014-07-23 17:22:50,018 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,019 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:50,019 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-23 17:22:50,021 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,023 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-23 17:22:50,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-23 17:22:50,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-23 17:22:50,123 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-23 17:22:50,123 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,124 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,124 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:50,124 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.111686325 s
2014-07-23 17:22:50,129 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,130 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,130 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at PCA.scala:57)
2014-07-23 17:22:50,130 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 67)
2014-07-23 17:22:50,131 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,132 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[73] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,134 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 66 (MappedRDD[73] at map at PCA.scala:57)
2014-07-23 17:22:50,134 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 1 tasks
2014-07-23 17:22:50,135 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,135 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:50,136 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-23 17:22:50,137 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,139 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,232 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-23 17:22:50,232 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-23 17:22:50,232 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-23 17:22:50,233 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 99 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,233 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,233 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-23 17:22:50,233 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:50,234 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104796777 s
2014-07-23 17:22:50,238 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,240 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,240 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at PCA.scala:57)
2014-07-23 17:22:50,240 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 69)
2014-07-23 17:22:50,241 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,242 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[75] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,244 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 68 (MappedRDD[75] at map at PCA.scala:57)
2014-07-23 17:22:50,244 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 1 tasks
2014-07-23 17:22:50,244 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,245 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:50,245 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-23 17:22:50,247 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,248 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,343 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-23 17:22:50,343 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-23 17:22:50,343 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-23 17:22:50,345 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-23 17:22:50,345 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,345 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,345 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:50,345 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106860884 s
2014-07-23 17:22:50,350 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,351 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,351 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at PCA.scala:57)
2014-07-23 17:22:50,351 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 71)
2014-07-23 17:22:50,353 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,353 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[77] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,355 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 70 (MappedRDD[77] at map at PCA.scala:57)
2014-07-23 17:22:50,355 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 1 tasks
2014-07-23 17:22:50,356 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,356 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:50,357 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-23 17:22:50,358 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,360 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-23 17:22:50,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-23 17:22:50,452 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-23 17:22:50,453 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-23 17:22:50,453 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,453 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,453 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:22:50,453 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.103303756 s
2014-07-23 17:22:50,458 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,459 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,459 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at PCA.scala:57)
2014-07-23 17:22:50,460 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 73)
2014-07-23 17:22:50,461 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,461 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[79] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,463 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 72 (MappedRDD[79] at map at PCA.scala:57)
2014-07-23 17:22:50,463 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 1 tasks
2014-07-23 17:22:50,464 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,464 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:50,465 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-23 17:22:50,467 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,469 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-23 17:22:50,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-23 17:22:50,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-23 17:22:50,558 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-23 17:22:50,558 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 94 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,559 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,559 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at PCA.scala:57) finished in 0.094 s
2014-07-23 17:22:50,559 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101031245 s
2014-07-23 17:22:50,563 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at PCA.scala:57)
2014-07-23 17:22:50,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 75)
2014-07-23 17:22:50,566 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,566 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[81] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,568 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 74 (MappedRDD[81] at map at PCA.scala:57)
2014-07-23 17:22:50,568 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 1 tasks
2014-07-23 17:22:50,569 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,569 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:50,570 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-23 17:22:50,571 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,573 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-23 17:22:50,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-23 17:22:50,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-23 17:22:50,647 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-23 17:22:50,647 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 77 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,647 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,647 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at PCA.scala:57) finished in 0.078 s
2014-07-23 17:22:50,647 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.083875255 s
2014-07-23 17:22:50,652 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,653 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,654 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at PCA.scala:57)
2014-07-23 17:22:50,654 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 77)
2014-07-23 17:22:50,655 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,655 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[83] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,657 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 76 (MappedRDD[83] at map at PCA.scala:57)
2014-07-23 17:22:50,657 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 1 tasks
2014-07-23 17:22:50,658 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,659 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:50,659 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-23 17:22:50,661 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,662 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,750 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-23 17:22:50,750 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-23 17:22:50,750 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-23 17:22:50,751 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-23 17:22:50,751 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 92 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,751 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,751 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at PCA.scala:57) finished in 0.093 s
2014-07-23 17:22:50,752 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099852136 s
2014-07-23 17:22:50,757 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,767 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,767 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at PCA.scala:57)
2014-07-23 17:22:50,767 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 79)
2014-07-23 17:22:50,768 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,769 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[85] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,773 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 78 (MappedRDD[85] at map at PCA.scala:57)
2014-07-23 17:22:50,773 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 1 tasks
2014-07-23 17:22:50,774 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,774 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:50,775 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-23 17:22:50,777 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,778 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:50,877 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-23 17:22:50,877 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-23 17:22:50,877 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-23 17:22:50,878 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-23 17:22:50,878 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:50,878 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-23 17:22:50,879 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:22:50,879 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121928985 s
2014-07-23 17:22:50,885 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:50,889 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:50,889 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at PCA.scala:57)
2014-07-23 17:22:50,889 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 81)
2014-07-23 17:22:50,890 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:50,890 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[87] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:50,893 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 80 (MappedRDD[87] at map at PCA.scala:57)
2014-07-23 17:22:50,893 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 1 tasks
2014-07-23 17:22:50,894 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:50,895 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:50,895 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-23 17:22:50,897 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:50,898 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,004 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-23 17:22:51,004 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-23 17:22:51,004 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-23 17:22:51,005 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,005 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,006 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-23 17:22:51,006 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at PCA.scala:57) finished in 0.112 s
2014-07-23 17:22:51,006 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.120223681 s
2014-07-23 17:22:51,012 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,014 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,014 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at PCA.scala:57)
2014-07-23 17:22:51,014 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 83)
2014-07-23 17:22:51,016 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,017 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[89] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,019 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 82 (MappedRDD[89] at map at PCA.scala:57)
2014-07-23 17:22:51,019 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 1 tasks
2014-07-23 17:22:51,019 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,020 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2524 bytes in 1 ms
2014-07-23 17:22:51,020 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-23 17:22:51,022 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,024 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,128 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-23 17:22:51,128 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-23 17:22:51,128 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-23 17:22:51,129 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-23 17:22:51,129 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,129 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,129 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:22:51,130 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117420072 s
2014-07-23 17:22:51,134 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,136 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,136 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at PCA.scala:57)
2014-07-23 17:22:51,136 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 85)
2014-07-23 17:22:51,137 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,138 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[91] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,140 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 84 (MappedRDD[91] at map at PCA.scala:57)
2014-07-23 17:22:51,140 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 1 tasks
2014-07-23 17:22:51,141 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,142 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:51,142 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-23 17:22:51,144 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,146 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,248 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-23 17:22:51,248 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-23 17:22:51,248 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-23 17:22:51,249 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-23 17:22:51,249 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,249 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,249 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:22:51,249 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11483089 s
2014-07-23 17:22:51,255 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,256 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,256 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at PCA.scala:57)
2014-07-23 17:22:51,256 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 87)
2014-07-23 17:22:51,257 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,258 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[93] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,259 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 86 (MappedRDD[93] at map at PCA.scala:57)
2014-07-23 17:22:51,260 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 1 tasks
2014-07-23 17:22:51,260 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,261 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:51,261 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-23 17:22:51,263 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,265 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-23 17:22:51,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-23 17:22:51,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-23 17:22:51,365 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-23 17:22:51,365 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,365 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,365 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:51,365 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110545949 s
2014-07-23 17:22:51,370 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,371 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,371 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at PCA.scala:57)
2014-07-23 17:22:51,371 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 89)
2014-07-23 17:22:51,372 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,373 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[95] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,374 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 88 (MappedRDD[95] at map at PCA.scala:57)
2014-07-23 17:22:51,374 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 1 tasks
2014-07-23 17:22:51,375 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,376 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:51,376 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-23 17:22:51,378 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,379 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,472 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-23 17:22:51,472 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-23 17:22:51,473 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-23 17:22:51,473 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-23 17:22:51,473 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,474 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,474 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:22:51,474 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104145626 s
2014-07-23 17:22:51,479 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,481 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,481 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at PCA.scala:57)
2014-07-23 17:22:51,481 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 91)
2014-07-23 17:22:51,482 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,482 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[97] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,484 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 90 (MappedRDD[97] at map at PCA.scala:57)
2014-07-23 17:22:51,484 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 1 tasks
2014-07-23 17:22:51,485 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,485 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2521 bytes in 0 ms
2014-07-23 17:22:51,486 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-23 17:22:51,487 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,586 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-23 17:22:51,586 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-23 17:22:51,586 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-23 17:22:51,587 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,587 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,587 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-23 17:22:51,587 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:22:51,588 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108180047 s
2014-07-23 17:22:51,592 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,594 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,594 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at PCA.scala:57)
2014-07-23 17:22:51,594 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 93)
2014-07-23 17:22:51,595 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,595 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[99] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,597 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 92 (MappedRDD[99] at map at PCA.scala:57)
2014-07-23 17:22:51,597 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 1 tasks
2014-07-23 17:22:51,598 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,598 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:51,599 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-23 17:22:51,600 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,601 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,697 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-23 17:22:51,697 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-23 17:22:51,697 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-23 17:22:51,698 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-23 17:22:51,698 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,698 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,698 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:51,699 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106176737 s
2014-07-23 17:22:51,703 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,705 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,705 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at PCA.scala:57)
2014-07-23 17:22:51,705 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 95)
2014-07-23 17:22:51,706 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,707 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[101] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,709 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 94 (MappedRDD[101] at map at PCA.scala:57)
2014-07-23 17:22:51,709 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 1 tasks
2014-07-23 17:22:51,710 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,710 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:51,711 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-23 17:22:51,712 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,714 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,805 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-23 17:22:51,805 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-23 17:22:51,805 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-23 17:22:51,806 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-23 17:22:51,806 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,806 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,806 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:22:51,806 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.103040593 s
2014-07-23 17:22:51,811 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,812 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,812 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at PCA.scala:57)
2014-07-23 17:22:51,812 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 97)
2014-07-23 17:22:51,813 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,814 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[103] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,815 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 96 (MappedRDD[103] at map at PCA.scala:57)
2014-07-23 17:22:51,815 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 1 tasks
2014-07-23 17:22:51,816 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,816 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:51,817 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-23 17:22:51,818 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,820 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,903 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-23 17:22:51,903 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-23 17:22:51,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-23 17:22:51,904 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-23 17:22:51,904 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 88 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,905 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,905 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at PCA.scala:57) finished in 0.088 s
2014-07-23 17:22:51,905 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.094076993 s
2014-07-23 17:22:51,910 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:51,911 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:51,911 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at PCA.scala:57)
2014-07-23 17:22:51,911 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 99)
2014-07-23 17:22:51,912 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:51,913 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[105] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:51,915 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 98 (MappedRDD[105] at map at PCA.scala:57)
2014-07-23 17:22:51,915 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 1 tasks
2014-07-23 17:22:51,915 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:51,916 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2520 bytes in 1 ms
2014-07-23 17:22:51,916 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-23 17:22:51,918 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:51,919 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:51,994 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-23 17:22:51,994 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-23 17:22:51,994 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-23 17:22:51,995 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-23 17:22:51,995 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 80 ms on localhost (progress: 1/1)
2014-07-23 17:22:51,995 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-23 17:22:51,995 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at PCA.scala:57) finished in 0.080 s
2014-07-23 17:22:51,996 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.085706962 s
2014-07-23 17:22:52,001 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,003 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,003 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at PCA.scala:57)
2014-07-23 17:22:52,003 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 101)
2014-07-23 17:22:52,004 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,005 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[107] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 100 (MappedRDD[107] at map at PCA.scala:57)
2014-07-23 17:22:52,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 1 tasks
2014-07-23 17:22:52,008 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,008 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2526 bytes in 0 ms
2014-07-23 17:22:52,008 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-23 17:22:52,010 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,012 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,104 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-23 17:22:52,104 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-23 17:22:52,104 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-23 17:22:52,105 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-23 17:22:52,105 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,106 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:52,106 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104766096 s
2014-07-23 17:22:52,110 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,112 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,112 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at PCA.scala:57)
2014-07-23 17:22:52,112 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 103)
2014-07-23 17:22:52,113 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,113 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[109] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,115 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 102 (MappedRDD[109] at map at PCA.scala:57)
2014-07-23 17:22:52,115 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 1 tasks
2014-07-23 17:22:52,116 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,116 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:52,117 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-23 17:22:52,118 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,120 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,216 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-23 17:22:52,216 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-23 17:22:52,216 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-23 17:22:52,217 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,217 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,217 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-23 17:22:52,218 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:22:52,218 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107417639 s
2014-07-23 17:22:52,222 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,224 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,224 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at PCA.scala:57)
2014-07-23 17:22:52,224 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 105)
2014-07-23 17:22:52,225 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,226 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[111] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,227 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 104 (MappedRDD[111] at map at PCA.scala:57)
2014-07-23 17:22:52,230 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 1 tasks
2014-07-23 17:22:52,231 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,231 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:52,232 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-23 17:22:52,234 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,235 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-23 17:22:52,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-23 17:22:52,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-23 17:22:52,331 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-23 17:22:52,331 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,331 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,331 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:52,332 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109460961 s
2014-07-23 17:22:52,336 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at PCA.scala:57)
2014-07-23 17:22:52,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 107)
2014-07-23 17:22:52,339 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,339 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[113] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,341 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 106 (MappedRDD[113] at map at PCA.scala:57)
2014-07-23 17:22:52,341 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 1 tasks
2014-07-23 17:22:52,342 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,342 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:52,348 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-23 17:22:52,349 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,351 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-23 17:22:52,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-23 17:22:52,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-23 17:22:52,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-23 17:22:52,454 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,454 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:22:52,454 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118075374 s
2014-07-23 17:22:52,459 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at PCA.scala:57)
2014-07-23 17:22:52,461 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 109)
2014-07-23 17:22:52,468 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,468 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[115] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,470 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 108 (MappedRDD[115] at map at PCA.scala:57)
2014-07-23 17:22:52,470 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 1 tasks
2014-07-23 17:22:52,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:52,476 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-23 17:22:52,478 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,480 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,576 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-23 17:22:52,576 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-23 17:22:52,576 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-23 17:22:52,577 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-23 17:22:52,577 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,577 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,577 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:22:52,578 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11831183 s
2014-07-23 17:22:52,583 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,584 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,584 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at PCA.scala:57)
2014-07-23 17:22:52,584 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 111)
2014-07-23 17:22:52,585 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,586 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[117] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,587 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 110 (MappedRDD[117] at map at PCA.scala:57)
2014-07-23 17:22:52,587 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 1 tasks
2014-07-23 17:22:52,588 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,588 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:52,589 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-23 17:22:52,591 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,592 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-23 17:22:52,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-23 17:22:52,685 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-23 17:22:52,686 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-23 17:22:52,687 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,687 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,687 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:52,687 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104622422 s
2014-07-23 17:22:52,692 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,694 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,694 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at PCA.scala:57)
2014-07-23 17:22:52,694 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 113)
2014-07-23 17:22:52,695 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,696 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[119] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,698 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 112 (MappedRDD[119] at map at PCA.scala:57)
2014-07-23 17:22:52,698 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 1 tasks
2014-07-23 17:22:52,699 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,699 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:52,699 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-23 17:22:52,701 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,702 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,802 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-23 17:22:52,802 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-23 17:22:52,802 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-23 17:22:52,803 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,803 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,803 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-23 17:22:52,803 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:52,804 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.111861378 s
2014-07-23 17:22:52,809 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at PCA.scala:57)
2014-07-23 17:22:52,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 115)
2014-07-23 17:22:52,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,811 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[121] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,813 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 114 (MappedRDD[121] at map at PCA.scala:57)
2014-07-23 17:22:52,813 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 1 tasks
2014-07-23 17:22:52,814 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,815 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:52,815 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-23 17:22:52,817 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,818 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:52,923 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-23 17:22:52,923 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-23 17:22:52,923 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-23 17:22:52,924 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:22:52,924 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-23 17:22:52,924 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-23 17:22:52,925 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:22:52,925 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.116114782 s
2014-07-23 17:22:52,930 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:52,931 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:52,931 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at PCA.scala:57)
2014-07-23 17:22:52,931 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 117)
2014-07-23 17:22:52,933 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:52,933 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[123] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:52,935 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 116 (MappedRDD[123] at map at PCA.scala:57)
2014-07-23 17:22:52,935 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 1 tasks
2014-07-23 17:22:52,936 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:52,937 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:52,937 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-23 17:22:52,939 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:52,940 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,046 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-23 17:22:53,046 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-23 17:22:53,046 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-23 17:22:53,048 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-23 17:22:53,048 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,048 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,048 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:22:53,048 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.118428049 s
2014-07-23 17:22:53,053 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,054 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,054 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at PCA.scala:57)
2014-07-23 17:22:53,054 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 119)
2014-07-23 17:22:53,056 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,056 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[125] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,057 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 118 (MappedRDD[125] at map at PCA.scala:57)
2014-07-23 17:22:53,058 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 1 tasks
2014-07-23 17:22:53,058 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,058 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:53,059 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-23 17:22:53,061 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,062 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-23 17:22:53,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-23 17:22:53,153 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-23 17:22:53,154 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-23 17:22:53,154 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,154 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,154 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at PCA.scala:57) finished in 0.096 s
2014-07-23 17:22:53,154 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101653396 s
2014-07-23 17:22:53,159 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,160 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,160 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at PCA.scala:57)
2014-07-23 17:22:53,160 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 121)
2014-07-23 17:22:53,161 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,162 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[127] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 120 (MappedRDD[127] at map at PCA.scala:57)
2014-07-23 17:22:53,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 1 tasks
2014-07-23 17:22:53,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:53,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-23 17:22:53,166 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,167 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-23 17:22:53,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-23 17:22:53,254 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-23 17:22:53,255 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-23 17:22:53,255 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 91 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,255 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,256 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at PCA.scala:57) finished in 0.091 s
2014-07-23 17:22:53,256 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.097048306 s
2014-07-23 17:22:53,260 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,261 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,262 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 122(reduce at PCA.scala:57)
2014-07-23 17:22:53,262 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 123)
2014-07-23 17:22:53,263 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,263 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 122 (MappedRDD[129] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,265 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 122 (MappedRDD[129] at map at PCA.scala:57)
2014-07-23 17:22:53,265 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 122.0 with 1 tasks
2014-07-23 17:22:53,265 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 122.0:0 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,266 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 122.0:0 as 2520 bytes in 1 ms
2014-07-23 17:22:53,266 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-23 17:22:53,268 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,269 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-23 17:22:53,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-23 17:22:53,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-23 17:22:53,343 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 78 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,343 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,344 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(122, 0)
2014-07-23 17:22:53,344 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 122 (reduce at PCA.scala:57) finished in 0.079 s
2014-07-23 17:22:53,344 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.08397538 s
2014-07-23 17:22:53,348 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,350 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,350 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 124(reduce at PCA.scala:57)
2014-07-23 17:22:53,350 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 125)
2014-07-23 17:22:53,351 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,351 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 124 (MappedRDD[131] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 124 (MappedRDD[131] at map at PCA.scala:57)
2014-07-23 17:22:53,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 124.0 with 1 tasks
2014-07-23 17:22:53,353 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 124.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,353 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 124.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:53,354 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-23 17:22:53,355 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,358 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-23 17:22:53,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-23 17:22:53,453 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-23 17:22:53,454 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,454 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,458 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(124, 0)
2014-07-23 17:22:53,459 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 124 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:53,459 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110381099 s
2014-07-23 17:22:53,464 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,466 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,466 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 126(reduce at PCA.scala:57)
2014-07-23 17:22:53,466 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 127)
2014-07-23 17:22:53,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 126 (MappedRDD[133] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,471 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 126 (MappedRDD[133] at map at PCA.scala:57)
2014-07-23 17:22:53,473 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 126.0 with 1 tasks
2014-07-23 17:22:53,474 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 126.0:0 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,474 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 126.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:53,475 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-23 17:22:53,477 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,479 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,575 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-23 17:22:53,575 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-23 17:22:53,576 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-23 17:22:53,576 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(126, 0)
2014-07-23 17:22:53,576 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,577 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,577 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 126 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:22:53,577 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112604387 s
2014-07-23 17:22:53,581 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,583 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,583 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 128(reduce at PCA.scala:57)
2014-07-23 17:22:53,583 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 129)
2014-07-23 17:22:53,584 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,584 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 128 (MappedRDD[135] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,586 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 128 (MappedRDD[135] at map at PCA.scala:57)
2014-07-23 17:22:53,586 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 128.0 with 1 tasks
2014-07-23 17:22:53,586 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 128.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,587 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 128.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:53,587 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-23 17:22:53,589 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,590 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,690 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-23 17:22:53,690 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-23 17:22:53,691 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-23 17:22:53,691 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,692 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 128.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,692 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(128, 0)
2014-07-23 17:22:53,692 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 128 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:22:53,692 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110712615 s
2014-07-23 17:22:53,697 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 130(reduce at PCA.scala:57)
2014-07-23 17:22:53,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 131)
2014-07-23 17:22:53,699 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,699 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 130 (MappedRDD[137] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 130 (MappedRDD[137] at map at PCA.scala:57)
2014-07-23 17:22:53,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 130.0 with 1 tasks
2014-07-23 17:22:53,702 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 130.0:0 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,702 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 130.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:53,702 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-23 17:22:53,704 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,705 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,800 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-23 17:22:53,800 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-23 17:22:53,800 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-23 17:22:53,801 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 99 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,801 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,804 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(130, 0)
2014-07-23 17:22:53,804 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 130 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:22:53,804 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10780015 s
2014-07-23 17:22:53,809 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 132(reduce at PCA.scala:57)
2014-07-23 17:22:53,811 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 133)
2014-07-23 17:22:53,812 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,813 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 132 (MappedRDD[139] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,814 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 132 (MappedRDD[139] at map at PCA.scala:57)
2014-07-23 17:22:53,814 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 132.0 with 1 tasks
2014-07-23 17:22:53,815 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 132.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,815 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 132.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:53,816 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-23 17:22:53,817 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,818 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:53,908 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-23 17:22:53,908 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-23 17:22:53,909 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-23 17:22:53,909 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(132, 0)
2014-07-23 17:22:53,909 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 94 ms on localhost (progress: 1/1)
2014-07-23 17:22:53,909 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2014-07-23 17:22:53,909 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 132 (reduce at PCA.scala:57) finished in 0.094 s
2014-07-23 17:22:53,910 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099980821 s
2014-07-23 17:22:53,914 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:53,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:53,916 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 134(reduce at PCA.scala:57)
2014-07-23 17:22:53,916 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 135)
2014-07-23 17:22:53,916 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:53,917 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 134 (MappedRDD[141] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:53,918 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 134 (MappedRDD[141] at map at PCA.scala:57)
2014-07-23 17:22:53,918 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 134.0 with 1 tasks
2014-07-23 17:22:53,919 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 134.0:0 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:53,919 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 134.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:53,919 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-23 17:22:53,921 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:53,922 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,022 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-23 17:22:54,023 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-23 17:22:54,023 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-23 17:22:54,024 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(134, 0)
2014-07-23 17:22:54,024 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,024 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 134.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,024 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 134 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:22:54,024 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109960498 s
2014-07-23 17:22:54,028 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,030 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,030 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 136(reduce at PCA.scala:57)
2014-07-23 17:22:54,030 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 137)
2014-07-23 17:22:54,031 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,031 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 136 (MappedRDD[143] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,033 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 136 (MappedRDD[143] at map at PCA.scala:57)
2014-07-23 17:22:54,033 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 136.0 with 1 tasks
2014-07-23 17:22:54,033 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 136.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,034 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 136.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:54,034 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-23 17:22:54,035 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,036 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,134 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-23 17:22:54,134 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-23 17:22:54,134 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-23 17:22:54,135 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,135 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 136.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,137 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(136, 0)
2014-07-23 17:22:54,138 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 136 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:22:54,138 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109639256 s
2014-07-23 17:22:54,142 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,144 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,144 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 138(reduce at PCA.scala:57)
2014-07-23 17:22:54,144 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 139)
2014-07-23 17:22:54,145 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,145 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 138 (MappedRDD[145] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,146 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 138 (MappedRDD[145] at map at PCA.scala:57)
2014-07-23 17:22:54,146 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 138.0 with 1 tasks
2014-07-23 17:22:54,147 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 138.0:0 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,147 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 138.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:54,148 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-23 17:22:54,149 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,150 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-23 17:22:54,247 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-23 17:22:54,248 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-23 17:22:54,248 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(138, 0)
2014-07-23 17:22:54,248 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,249 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,249 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 138 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:22:54,249 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106629781 s
2014-07-23 17:22:54,254 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,255 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,255 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 140(reduce at PCA.scala:57)
2014-07-23 17:22:54,255 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 141)
2014-07-23 17:22:54,256 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,256 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 140 (MappedRDD[147] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,258 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 140 (MappedRDD[147] at map at PCA.scala:57)
2014-07-23 17:22:54,258 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 140.0 with 1 tasks
2014-07-23 17:22:54,258 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 140.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,259 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 140.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:54,259 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-23 17:22:54,260 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,261 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,357 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-23 17:22:54,357 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-23 17:22:54,357 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-23 17:22:54,358 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(140, 0)
2014-07-23 17:22:54,358 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 99 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,358 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 140.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,358 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 140 (reduce at PCA.scala:57) finished in 0.100 s
2014-07-23 17:22:54,358 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104224927 s
2014-07-23 17:22:54,362 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,364 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,364 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 142(reduce at PCA.scala:57)
2014-07-23 17:22:54,364 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 143)
2014-07-23 17:22:54,365 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,365 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 142 (MappedRDD[149] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,366 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 142 (MappedRDD[149] at map at PCA.scala:57)
2014-07-23 17:22:54,367 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 142.0 with 1 tasks
2014-07-23 17:22:54,367 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 142.0:0 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,368 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 142.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:54,368 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-23 17:22:54,370 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,371 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,469 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-23 17:22:54,469 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-23 17:22:54,469 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-23 17:22:54,471 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,472 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 142.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,472 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(142, 0)
2014-07-23 17:22:54,472 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 142 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:54,472 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109840573 s
2014-07-23 17:22:54,476 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,478 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,478 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 144(reduce at PCA.scala:57)
2014-07-23 17:22:54,478 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 145)
2014-07-23 17:22:54,479 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,480 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 144 (MappedRDD[151] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,481 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 144 (MappedRDD[151] at map at PCA.scala:57)
2014-07-23 17:22:54,482 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 144.0 with 1 tasks
2014-07-23 17:22:54,482 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 144.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,482 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 144.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:54,483 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-23 17:22:54,484 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,485 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-23 17:22:54,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-23 17:22:54,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-23 17:22:54,583 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(144, 0)
2014-07-23 17:22:54,583 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,583 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,583 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 144 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:54,583 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106970197 s
2014-07-23 17:22:54,588 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,589 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,589 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 146(reduce at PCA.scala:57)
2014-07-23 17:22:54,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 147)
2014-07-23 17:22:54,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,591 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 146 (MappedRDD[153] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,592 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 146 (MappedRDD[153] at map at PCA.scala:57)
2014-07-23 17:22:54,592 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 146.0 with 1 tasks
2014-07-23 17:22:54,593 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 146.0:0 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,593 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 146.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:54,593 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-23 17:22:54,594 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,596 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,671 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-23 17:22:54,671 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-23 17:22:54,671 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-23 17:22:54,672 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(146, 0)
2014-07-23 17:22:54,672 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 80 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,672 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 146.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,672 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 146 (reduce at PCA.scala:57) finished in 0.080 s
2014-07-23 17:22:54,672 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.084102625 s
2014-07-23 17:22:54,677 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,678 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,678 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 148(reduce at PCA.scala:57)
2014-07-23 17:22:54,678 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 149)
2014-07-23 17:22:54,679 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,680 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 148 (MappedRDD[155] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,681 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 148 (MappedRDD[155] at map at PCA.scala:57)
2014-07-23 17:22:54,681 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 148.0 with 1 tasks
2014-07-23 17:22:54,682 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 148.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,682 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 148.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:54,682 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-23 17:22:54,684 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,685 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-23 17:22:54,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-23 17:22:54,774 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-23 17:22:54,775 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(148, 0)
2014-07-23 17:22:54,775 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 94 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,775 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 148 (reduce at PCA.scala:57) finished in 0.094 s
2014-07-23 17:22:54,776 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.098780494 s
2014-07-23 17:22:54,776 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,781 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,784 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,784 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 150(reduce at PCA.scala:57)
2014-07-23 17:22:54,784 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 151)
2014-07-23 17:22:54,786 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,786 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 150 (MappedRDD[157] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,788 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 150 (MappedRDD[157] at map at PCA.scala:57)
2014-07-23 17:22:54,788 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 150.0 with 1 tasks
2014-07-23 17:22:54,789 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 150.0:0 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,789 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 150.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:54,789 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-23 17:22:54,790 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,791 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-23 17:22:54,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-23 17:22:54,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-23 17:22:54,885 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,886 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,886 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(150, 0)
2014-07-23 17:22:54,886 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 150 (reduce at PCA.scala:57) finished in 0.093 s
2014-07-23 17:22:54,886 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105062741 s
2014-07-23 17:22:54,891 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:54,893 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:54,893 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 152(reduce at PCA.scala:57)
2014-07-23 17:22:54,893 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 153)
2014-07-23 17:22:54,897 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:54,897 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 152 (MappedRDD[159] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:54,898 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 152 (MappedRDD[159] at map at PCA.scala:57)
2014-07-23 17:22:54,898 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 152.0 with 1 tasks
2014-07-23 17:22:54,899 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 152.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:54,899 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 152.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:54,900 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-23 17:22:54,901 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:54,902 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:54,998 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-23 17:22:54,998 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-23 17:22:54,998 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-23 17:22:54,999 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(152, 0)
2014-07-23 17:22:54,999 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:22:54,999 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 152.0, whose tasks have all completed, from pool 
2014-07-23 17:22:54,999 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 152 (reduce at PCA.scala:57) finished in 0.100 s
2014-07-23 17:22:54,999 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108660313 s
2014-07-23 17:22:55,004 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,005 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,005 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 154(reduce at PCA.scala:57)
2014-07-23 17:22:55,005 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 155)
2014-07-23 17:22:55,006 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,006 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 154 (MappedRDD[161] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 154 (MappedRDD[161] at map at PCA.scala:57)
2014-07-23 17:22:55,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 154.0 with 1 tasks
2014-07-23 17:22:55,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 154.0:0 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,009 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 154.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:55,009 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-23 17:22:55,010 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,011 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,104 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-23 17:22:55,104 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-23 17:22:55,104 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-23 17:22:55,104 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(154, 0)
2014-07-23 17:22:55,104 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,105 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 154.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,105 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 154 (reduce at PCA.scala:57) finished in 0.096 s
2014-07-23 17:22:55,105 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101048159 s
2014-07-23 17:22:55,110 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 156(reduce at PCA.scala:57)
2014-07-23 17:22:55,111 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 157)
2014-07-23 17:22:55,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,112 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 156 (MappedRDD[163] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,113 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 156 (MappedRDD[163] at map at PCA.scala:57)
2014-07-23 17:22:55,113 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 156.0 with 1 tasks
2014-07-23 17:22:55,114 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 156.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,114 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 156.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:55,115 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-23 17:22:55,116 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,117 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,217 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-23 17:22:55,217 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-23 17:22:55,217 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-23 17:22:55,218 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(156, 0)
2014-07-23 17:22:55,218 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,218 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,218 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 156 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:22:55,218 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108629978 s
2014-07-23 17:22:55,223 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,224 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,224 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 158(reduce at PCA.scala:57)
2014-07-23 17:22:55,224 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 159)
2014-07-23 17:22:55,225 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,226 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 158 (MappedRDD[165] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,227 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 158 (MappedRDD[165] at map at PCA.scala:57)
2014-07-23 17:22:55,227 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 158.0 with 1 tasks
2014-07-23 17:22:55,228 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 158.0:0 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,228 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 158.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:55,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-23 17:22:55,230 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,231 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,331 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-23 17:22:55,331 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-23 17:22:55,332 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-23 17:22:55,332 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(158, 0)
2014-07-23 17:22:55,332 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,332 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 158.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,332 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 158 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:55,333 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109970269 s
2014-07-23 17:22:55,337 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,339 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,339 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 160(reduce at PCA.scala:57)
2014-07-23 17:22:55,339 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 161)
2014-07-23 17:22:55,340 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,340 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 160 (MappedRDD[167] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,341 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 160 (MappedRDD[167] at map at PCA.scala:57)
2014-07-23 17:22:55,341 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 160.0 with 1 tasks
2014-07-23 17:22:55,342 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 160.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,342 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 160.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:55,343 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-23 17:22:55,344 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,345 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,445 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-23 17:22:55,445 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-23 17:22:55,445 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-23 17:22:55,446 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,446 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 160.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,446 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(160, 0)
2014-07-23 17:22:55,446 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 160 (reduce at PCA.scala:57) finished in 0.104 s
2014-07-23 17:22:55,447 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109297332 s
2014-07-23 17:22:55,451 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,452 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,453 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 162(reduce at PCA.scala:57)
2014-07-23 17:22:55,453 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 163)
2014-07-23 17:22:55,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,454 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 162 (MappedRDD[169] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,455 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 162 (MappedRDD[169] at map at PCA.scala:57)
2014-07-23 17:22:55,455 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 162.0 with 1 tasks
2014-07-23 17:22:55,456 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 162.0:0 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,456 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 162.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:55,457 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-23 17:22:55,458 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,459 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,560 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-23 17:22:55,560 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-23 17:22:55,560 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-23 17:22:55,561 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(162, 0)
2014-07-23 17:22:55,561 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,561 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,561 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 162 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:22:55,561 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109717951 s
2014-07-23 17:22:55,566 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,567 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,567 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 164(reduce at PCA.scala:57)
2014-07-23 17:22:55,567 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 165)
2014-07-23 17:22:55,568 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,568 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 164 (MappedRDD[171] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,570 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 164 (MappedRDD[171] at map at PCA.scala:57)
2014-07-23 17:22:55,570 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 164.0 with 1 tasks
2014-07-23 17:22:55,570 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 164.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,571 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 164.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:55,571 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-23 17:22:55,572 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,573 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-23 17:22:55,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-23 17:22:55,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-23 17:22:55,668 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,668 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(164, 0)
2014-07-23 17:22:55,669 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 164 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:55,669 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.103131898 s
2014-07-23 17:22:55,673 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,674 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,675 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 166(reduce at PCA.scala:57)
2014-07-23 17:22:55,675 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 167)
2014-07-23 17:22:55,675 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,676 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 166 (MappedRDD[173] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,677 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 166 (MappedRDD[173] at map at PCA.scala:57)
2014-07-23 17:22:55,677 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 166.0 with 1 tasks
2014-07-23 17:22:55,678 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 166.0:0 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,678 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 166.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:55,678 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-23 17:22:55,680 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,681 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,778 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-23 17:22:55,778 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-23 17:22:55,779 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-23 17:22:55,779 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,779 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,783 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(166, 0)
2014-07-23 17:22:55,783 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 166 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:22:55,783 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110167406 s
2014-07-23 17:22:55,788 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,790 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,790 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 168(reduce at PCA.scala:57)
2014-07-23 17:22:55,790 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 169)
2014-07-23 17:22:55,791 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,791 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 168 (MappedRDD[175] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,793 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 168 (MappedRDD[175] at map at PCA.scala:57)
2014-07-23 17:22:55,793 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 168.0 with 1 tasks
2014-07-23 17:22:55,793 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 168.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,794 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 168.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:55,794 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-23 17:22:55,795 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,796 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,884 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-23 17:22:55,884 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-23 17:22:55,884 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-23 17:22:55,885 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(168, 0)
2014-07-23 17:22:55,885 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 92 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,885 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,886 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 168 (reduce at PCA.scala:57) finished in 0.092 s
2014-07-23 17:22:55,886 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.097667911 s
2014-07-23 17:22:55,890 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,892 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,892 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 170(reduce at PCA.scala:57)
2014-07-23 17:22:55,892 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 171)
2014-07-23 17:22:55,893 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,894 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 170 (MappedRDD[177] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,895 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 170 (MappedRDD[177] at map at PCA.scala:57)
2014-07-23 17:22:55,895 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 170.0 with 1 tasks
2014-07-23 17:22:55,896 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 170.0:0 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,896 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 170.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:55,896 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-23 17:22:55,898 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,899 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:55,976 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-23 17:22:55,976 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-23 17:22:55,976 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-23 17:22:55,977 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(170, 0)
2014-07-23 17:22:55,977 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 81 ms on localhost (progress: 1/1)
2014-07-23 17:22:55,977 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2014-07-23 17:22:55,977 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 170 (reduce at PCA.scala:57) finished in 0.082 s
2014-07-23 17:22:55,977 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.086663769 s
2014-07-23 17:22:55,982 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:55,983 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:55,983 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 172(reduce at PCA.scala:57)
2014-07-23 17:22:55,983 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 173)
2014-07-23 17:22:55,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:55,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 172 (MappedRDD[179] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:55,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 172 (MappedRDD[179] at map at PCA.scala:57)
2014-07-23 17:22:55,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 172.0 with 1 tasks
2014-07-23 17:22:55,986 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 172.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:55,986 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 172.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:55,987 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-23 17:22:55,988 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:55,989 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-23 17:22:56,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-23 17:22:56,087 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-23 17:22:56,088 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(172, 0)
2014-07-23 17:22:56,088 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,088 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 172.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,088 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 172 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:22:56,089 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107015047 s
2014-07-23 17:22:56,093 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,094 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,094 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 174(reduce at PCA.scala:57)
2014-07-23 17:22:56,094 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 175)
2014-07-23 17:22:56,095 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,096 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 174 (MappedRDD[181] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,097 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 174 (MappedRDD[181] at map at PCA.scala:57)
2014-07-23 17:22:56,097 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 174.0 with 1 tasks
2014-07-23 17:22:56,097 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 174.0:0 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,098 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 174.0:0 as 2524 bytes in 1 ms
2014-07-23 17:22:56,098 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-23 17:22:56,099 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,100 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-23 17:22:56,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-23 17:22:56,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-23 17:22:56,191 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 94 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,192 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(174, 0)
2014-07-23 17:22:56,192 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,192 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 174 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:22:56,192 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.098924863 s
2014-07-23 17:22:56,196 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 176(reduce at PCA.scala:57)
2014-07-23 17:22:56,198 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 177)
2014-07-23 17:22:56,199 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,199 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 176 (MappedRDD[183] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,200 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 176 (MappedRDD[183] at map at PCA.scala:57)
2014-07-23 17:22:56,200 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 176.0 with 1 tasks
2014-07-23 17:22:56,201 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 176.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,201 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 176.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:56,201 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-23 17:22:56,203 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,204 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,297 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-23 17:22:56,297 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-23 17:22:56,297 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-23 17:22:56,298 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(176, 0)
2014-07-23 17:22:56,298 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 176 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:22:56,298 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,298 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 176.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,298 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.102367197 s
2014-07-23 17:22:56,303 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,304 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,304 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 178(reduce at PCA.scala:57)
2014-07-23 17:22:56,304 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 179)
2014-07-23 17:22:56,305 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,305 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 178 (MappedRDD[185] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,306 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 178 (MappedRDD[185] at map at PCA.scala:57)
2014-07-23 17:22:56,306 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 178.0 with 1 tasks
2014-07-23 17:22:56,307 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 178.0:0 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,307 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 178.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:56,308 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-23 17:22:56,309 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,310 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-23 17:22:56,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-23 17:22:56,409 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-23 17:22:56,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(178, 0)
2014-07-23 17:22:56,410 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,410 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 178.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 178 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:22:56,410 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10742367 s
2014-07-23 17:22:56,414 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,416 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,416 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 180(reduce at PCA.scala:57)
2014-07-23 17:22:56,416 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 181)
2014-07-23 17:22:56,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 180 (MappedRDD[187] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,418 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 180 (MappedRDD[187] at map at PCA.scala:57)
2014-07-23 17:22:56,418 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 180.0 with 1 tasks
2014-07-23 17:22:56,419 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 180.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,419 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 180.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:56,419 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-23 17:22:56,420 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,421 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,519 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-23 17:22:56,519 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-23 17:22:56,520 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-23 17:22:56,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(180, 0)
2014-07-23 17:22:56,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 180 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:22:56,521 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,521 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,521 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.106447772 s
2014-07-23 17:22:56,527 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,529 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,529 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 182(reduce at PCA.scala:57)
2014-07-23 17:22:56,529 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 183)
2014-07-23 17:22:56,530 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,531 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 182 (MappedRDD[189] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,532 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 182 (MappedRDD[189] at map at PCA.scala:57)
2014-07-23 17:22:56,532 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 182.0 with 1 tasks
2014-07-23 17:22:56,533 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 182.0:0 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,533 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 182.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:56,534 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-23 17:22:56,536 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,537 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,651 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-23 17:22:56,651 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-23 17:22:56,652 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-23 17:22:56,652 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 118 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,652 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,652 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(182, 0)
2014-07-23 17:22:56,652 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 182 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:22:56,653 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.125594915 s
2014-07-23 17:22:56,658 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,659 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,659 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 184(reduce at PCA.scala:57)
2014-07-23 17:22:56,659 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 185)
2014-07-23 17:22:56,660 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,661 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 184 (MappedRDD[191] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 184 (MappedRDD[191] at map at PCA.scala:57)
2014-07-23 17:22:56,662 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 184.0 with 1 tasks
2014-07-23 17:22:56,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 184.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 184.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:56,663 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-23 17:22:56,664 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,665 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,765 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-23 17:22:56,765 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-23 17:22:56,767 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,767 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,768 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(184, 0)
2014-07-23 17:22:56,768 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 184 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:22:56,769 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110776334 s
2014-07-23 17:22:56,774 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,775 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-23 17:22:56,776 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,776 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 186(reduce at PCA.scala:57)
2014-07-23 17:22:56,776 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 187)
2014-07-23 17:22:56,777 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,777 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 186 (MappedRDD[193] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,778 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 186 (MappedRDD[193] at map at PCA.scala:57)
2014-07-23 17:22:56,778 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 186.0 with 1 tasks
2014-07-23 17:22:56,779 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 186.0:0 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,779 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 186.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:56,779 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-23 17:22:56,780 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,781 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-23 17:22:56,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-23 17:22:56,878 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-23 17:22:56,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(186, 0)
2014-07-23 17:22:56,879 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 101 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,879 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 186 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:56,880 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105114828 s
2014-07-23 17:22:56,884 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,886 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,886 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 188(reduce at PCA.scala:57)
2014-07-23 17:22:56,886 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 189)
2014-07-23 17:22:56,887 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:56,887 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 188 (MappedRDD[195] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:56,888 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 188 (MappedRDD[195] at map at PCA.scala:57)
2014-07-23 17:22:56,888 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 188.0 with 1 tasks
2014-07-23 17:22:56,889 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 188.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:56,889 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 188.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:56,889 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-23 17:22:56,890 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:56,891 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:56,993 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-23 17:22:56,993 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-23 17:22:56,993 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-23 17:22:56,994 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:22:56,994 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 188.0, whose tasks have all completed, from pool 
2014-07-23 17:22:56,994 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(188, 0)
2014-07-23 17:22:56,994 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 188 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:22:56,994 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109713335 s
2014-07-23 17:22:56,998 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:56,999 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:56,999 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 190(reduce at PCA.scala:57)
2014-07-23 17:22:57,000 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 191)
2014-07-23 17:22:57,000 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,001 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 190 (MappedRDD[197] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,002 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 190 (MappedRDD[197] at map at PCA.scala:57)
2014-07-23 17:22:57,002 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 190.0 with 1 tasks
2014-07-23 17:22:57,003 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 190.0:0 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,003 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 190.0:0 as 2525 bytes in 0 ms
2014-07-23 17:22:57,004 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-23 17:22:57,005 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,006 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,096 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-23 17:22:57,096 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-23 17:22:57,096 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-23 17:22:57,097 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(190, 0)
2014-07-23 17:22:57,097 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,097 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 190.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,097 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 190 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:22:57,097 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.098918728 s
2014-07-23 17:22:57,102 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,103 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,103 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 192(reduce at PCA.scala:57)
2014-07-23 17:22:57,103 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 193)
2014-07-23 17:22:57,104 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,105 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 192 (MappedRDD[199] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 192 (MappedRDD[199] at map at PCA.scala:57)
2014-07-23 17:22:57,106 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 192.0 with 1 tasks
2014-07-23 17:22:57,106 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 192.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,107 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 192.0:0 as 2524 bytes in 1 ms
2014-07-23 17:22:57,107 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-23 17:22:57,108 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,109 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-23 17:22:57,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-23 17:22:57,194 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-23 17:22:57,195 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 89 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,195 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(192, 0)
2014-07-23 17:22:57,195 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 192 (reduce at PCA.scala:57) finished in 0.088 s
2014-07-23 17:22:57,196 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.093961572 s
2014-07-23 17:22:57,200 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,202 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,202 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 194(reduce at PCA.scala:57)
2014-07-23 17:22:57,202 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 195)
2014-07-23 17:22:57,203 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,203 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 194 (MappedRDD[201] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,204 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 194 (MappedRDD[201] at map at PCA.scala:57)
2014-07-23 17:22:57,204 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 194.0 with 1 tasks
2014-07-23 17:22:57,205 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 194.0:0 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,205 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 194.0:0 as 2521 bytes in 0 ms
2014-07-23 17:22:57,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-23 17:22:57,206 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,207 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,279 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-23 17:22:57,280 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-23 17:22:57,280 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-23 17:22:57,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(194, 0)
2014-07-23 17:22:57,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 194 (reduce at PCA.scala:57) finished in 0.076 s
2014-07-23 17:22:57,280 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 76 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,281 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,281 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.080241055 s
2014-07-23 17:22:57,285 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,286 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,286 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 196(reduce at PCA.scala:57)
2014-07-23 17:22:57,286 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 197)
2014-07-23 17:22:57,287 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,288 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 196 (MappedRDD[203] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,289 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 196 (MappedRDD[203] at map at PCA.scala:57)
2014-07-23 17:22:57,289 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 196.0 with 1 tasks
2014-07-23 17:22:57,289 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 196.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,290 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 196.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:57,290 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-23 17:22:57,291 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,292 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,378 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-23 17:22:57,378 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-23 17:22:57,378 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-23 17:22:57,379 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(196, 0)
2014-07-23 17:22:57,379 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 89 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,379 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 196.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,379 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 196 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:22:57,379 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.094287126 s
2014-07-23 17:22:57,383 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,385 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,385 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 198(reduce at PCA.scala:57)
2014-07-23 17:22:57,385 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 199)
2014-07-23 17:22:57,385 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,386 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 198 (MappedRDD[205] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,387 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 198 (MappedRDD[205] at map at PCA.scala:57)
2014-07-23 17:22:57,387 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 198.0 with 1 tasks
2014-07-23 17:22:57,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 198.0:0 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 198.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:57,388 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-23 17:22:57,390 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,390 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,476 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-23 17:22:57,476 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-23 17:22:57,476 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-23 17:22:57,477 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(198, 0)
2014-07-23 17:22:57,477 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 89 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,477 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,477 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 198 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:22:57,477 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.09407632 s
2014-07-23 17:22:57,483 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,484 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,484 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 200(reduce at PCA.scala:57)
2014-07-23 17:22:57,484 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 201)
2014-07-23 17:22:57,485 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,485 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 200 (MappedRDD[207] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,486 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 200 (MappedRDD[207] at map at PCA.scala:57)
2014-07-23 17:22:57,486 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 200.0 with 1 tasks
2014-07-23 17:22:57,487 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 200.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,487 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 200.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:57,488 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-23 17:22:57,489 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,490 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,584 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-23 17:22:57,584 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-23 17:22:57,584 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-23 17:22:57,585 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(200, 0)
2014-07-23 17:22:57,585 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,585 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,585 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 200 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:22:57,585 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10269547 s
2014-07-23 17:22:57,590 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,592 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,592 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 202(reduce at PCA.scala:57)
2014-07-23 17:22:57,592 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 203)
2014-07-23 17:22:57,593 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,593 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 202 (MappedRDD[209] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,594 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 202 (MappedRDD[209] at map at PCA.scala:57)
2014-07-23 17:22:57,594 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 202.0 with 1 tasks
2014-07-23 17:22:57,595 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 202.0:0 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,595 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 202.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:57,595 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-23 17:22:57,596 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,597 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,691 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-23 17:22:57,691 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-23 17:22:57,691 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-23 17:22:57,692 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(202, 0)
2014-07-23 17:22:57,692 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,692 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 202.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,692 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 202 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:22:57,692 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101841555 s
2014-07-23 17:22:57,697 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 204(reduce at PCA.scala:57)
2014-07-23 17:22:57,698 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 205)
2014-07-23 17:22:57,699 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,700 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 204 (MappedRDD[211] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 204 (MappedRDD[211] at map at PCA.scala:57)
2014-07-23 17:22:57,701 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 1 tasks
2014-07-23 17:22:57,701 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 204.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,702 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 204.0:0 as 2522 bytes in 1 ms
2014-07-23 17:22:57,702 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-23 17:22:57,704 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,704 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-23 17:22:57,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-23 17:22:57,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-23 17:22:57,799 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 98 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,799 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,800 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(204, 0)
2014-07-23 17:22:57,800 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 204 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:57,800 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.102956032 s
2014-07-23 17:22:57,804 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,805 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,805 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 206(reduce at PCA.scala:57)
2014-07-23 17:22:57,805 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 207)
2014-07-23 17:22:57,806 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,807 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 206 (MappedRDD[213] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,808 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 206 (MappedRDD[213] at map at PCA.scala:57)
2014-07-23 17:22:57,808 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 206.0 with 1 tasks
2014-07-23 17:22:57,808 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 206.0:0 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,808 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 206.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:57,809 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-23 17:22:57,810 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,811 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:57,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-23 17:22:57,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-23 17:22:57,904 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-23 17:22:57,905 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(206, 0)
2014-07-23 17:22:57,905 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 206 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:22:57,905 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:22:57,905 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2014-07-23 17:22:57,905 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.100944181 s
2014-07-23 17:22:57,909 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:57,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:57,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 208(reduce at PCA.scala:57)
2014-07-23 17:22:57,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 209)
2014-07-23 17:22:57,912 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:57,912 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 208 (MappedRDD[215] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:57,913 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 208 (MappedRDD[215] at map at PCA.scala:57)
2014-07-23 17:22:57,913 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 208.0 with 1 tasks
2014-07-23 17:22:57,914 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 208.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:57,914 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 208.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:57,914 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-23 17:22:57,915 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:57,916 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,010 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-23 17:22:58,011 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-23 17:22:58,011 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-23 17:22:58,012 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,012 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 208.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,012 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(208, 0)
2014-07-23 17:22:58,012 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 208 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:22:58,012 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.10272362 s
2014-07-23 17:22:58,017 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,018 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,018 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 210(reduce at PCA.scala:57)
2014-07-23 17:22:58,018 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 211)
2014-07-23 17:22:58,019 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,020 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 210 (MappedRDD[217] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,021 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 210 (MappedRDD[217] at map at PCA.scala:57)
2014-07-23 17:22:58,021 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 210.0 with 1 tasks
2014-07-23 17:22:58,021 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 210.0:0 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,022 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 210.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:58,022 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-23 17:22:58,023 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,024 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,126 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-23 17:22:58,126 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-23 17:22:58,127 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-23 17:22:58,127 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,127 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 210.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,128 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(210, 0)
2014-07-23 17:22:58,128 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 210 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:22:58,128 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110851466 s
2014-07-23 17:22:58,132 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,134 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,134 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 212(reduce at PCA.scala:57)
2014-07-23 17:22:58,134 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 213)
2014-07-23 17:22:58,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,135 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 212 (MappedRDD[219] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,136 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 212 (MappedRDD[219] at map at PCA.scala:57)
2014-07-23 17:22:58,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 212.0 with 1 tasks
2014-07-23 17:22:58,137 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 212.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,137 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 212.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:58,138 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-23 17:22:58,139 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,140 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,231 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-23 17:22:58,231 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-23 17:22:58,231 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-23 17:22:58,232 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(212, 0)
2014-07-23 17:22:58,232 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,232 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 212.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,232 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 212 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:22:58,232 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099960723 s
2014-07-23 17:22:58,237 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 214(reduce at PCA.scala:57)
2014-07-23 17:22:58,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 215)
2014-07-23 17:22:58,239 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,239 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 214 (MappedRDD[221] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,241 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 214 (MappedRDD[221] at map at PCA.scala:57)
2014-07-23 17:22:58,241 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 214.0 with 1 tasks
2014-07-23 17:22:58,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 214.0:0 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 214.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:58,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-23 17:22:58,243 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,244 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-23 17:22:58,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-23 17:22:58,330 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-23 17:22:58,331 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(214, 0)
2014-07-23 17:22:58,331 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 90 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,331 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 214.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,331 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 214 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:22:58,331 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.094529052 s
2014-07-23 17:22:58,335 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 216(reduce at PCA.scala:57)
2014-07-23 17:22:58,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 217)
2014-07-23 17:22:58,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 216 (MappedRDD[223] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,339 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 216 (MappedRDD[223] at map at PCA.scala:57)
2014-07-23 17:22:58,339 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 216.0 with 1 tasks
2014-07-23 17:22:58,340 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 216.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,340 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 216.0:0 as 2524 bytes in 0 ms
2014-07-23 17:22:58,342 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-23 17:22:58,343 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,344 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,424 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-23 17:22:58,424 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-23 17:22:58,424 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-23 17:22:58,428 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 88 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,428 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(216, 0)
2014-07-23 17:22:58,429 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 216.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,429 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 216 (reduce at PCA.scala:57) finished in 0.089 s
2014-07-23 17:22:58,429 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.093539155 s
2014-07-23 17:22:58,433 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,435 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,435 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 218(reduce at PCA.scala:57)
2014-07-23 17:22:58,435 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 219)
2014-07-23 17:22:58,436 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,436 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 218 (MappedRDD[225] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,437 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 218 (MappedRDD[225] at map at PCA.scala:57)
2014-07-23 17:22:58,437 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 218.0 with 1 tasks
2014-07-23 17:22:58,438 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 218.0:0 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,438 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 218.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:58,438 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-23 17:22:58,439 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,440 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,509 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-23 17:22:58,509 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-23 17:22:58,510 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-23 17:22:58,510 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(218, 0)
2014-07-23 17:22:58,510 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 72 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,510 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 218.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,510 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 218 (reduce at PCA.scala:57) finished in 0.073 s
2014-07-23 17:22:58,510 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.076922755 s
2014-07-23 17:22:58,515 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,516 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,516 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 220(reduce at PCA.scala:57)
2014-07-23 17:22:58,516 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 221)
2014-07-23 17:22:58,517 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,517 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 220 (MappedRDD[227] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,518 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 220 (MappedRDD[227] at map at PCA.scala:57)
2014-07-23 17:22:58,518 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 220.0 with 1 tasks
2014-07-23 17:22:58,519 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 220.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,519 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 220.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:58,519 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-23 17:22:58,520 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,521 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,601 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-23 17:22:58,601 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-23 17:22:58,601 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-23 17:22:58,602 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 82 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,602 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 220.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,602 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(220, 0)
2014-07-23 17:22:58,602 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 220 (reduce at PCA.scala:57) finished in 0.084 s
2014-07-23 17:22:58,602 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.087699388 s
2014-07-23 17:22:58,606 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,608 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,608 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 222(reduce at PCA.scala:57)
2014-07-23 17:22:58,608 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 223)
2014-07-23 17:22:58,609 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,609 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 222 (MappedRDD[229] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,610 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 222 (MappedRDD[229] at map at PCA.scala:57)
2014-07-23 17:22:58,611 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 222.0 with 1 tasks
2014-07-23 17:22:58,611 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 222.0:0 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,611 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 222.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:58,612 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-23 17:22:58,613 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,614 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,705 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-23 17:22:58,705 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-23 17:22:58,705 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-23 17:22:58,705 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(222, 0)
2014-07-23 17:22:58,705 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 94 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,706 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 222.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,706 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 222 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:22:58,706 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099272936 s
2014-07-23 17:22:58,710 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,711 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,711 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 224(reduce at PCA.scala:57)
2014-07-23 17:22:58,711 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 225)
2014-07-23 17:22:58,712 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,712 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 224 (MappedRDD[231] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,714 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 224 (MappedRDD[231] at map at PCA.scala:57)
2014-07-23 17:22:58,714 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 224.0 with 1 tasks
2014-07-23 17:22:58,714 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 224.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,715 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 224.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:58,715 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-23 17:22:58,716 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,717 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,810 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-23 17:22:58,810 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-23 17:22:58,810 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-23 17:22:58,810 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(224, 0)
2014-07-23 17:22:58,811 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 224 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:22:58,811 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.100937018 s
2014-07-23 17:22:58,810 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,811 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 224.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,815 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,817 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,817 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 226(reduce at PCA.scala:57)
2014-07-23 17:22:58,817 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 227)
2014-07-23 17:22:58,817 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,818 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 226 (MappedRDD[233] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,819 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 226 (MappedRDD[233] at map at PCA.scala:57)
2014-07-23 17:22:58,819 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 226.0 with 1 tasks
2014-07-23 17:22:58,819 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 226.0:0 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,820 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 226.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:58,820 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-23 17:22:58,821 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,822 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:58,913 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-23 17:22:58,913 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-23 17:22:58,913 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-23 17:22:58,913 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 94 ms on localhost (progress: 1/1)
2014-07-23 17:22:58,913 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 226.0, whose tasks have all completed, from pool 
2014-07-23 17:22:58,913 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(226, 0)
2014-07-23 17:22:58,914 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 226 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:22:58,914 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.098625271 s
2014-07-23 17:22:58,918 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:58,919 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:58,919 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 228(reduce at PCA.scala:57)
2014-07-23 17:22:58,920 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 229)
2014-07-23 17:22:58,921 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:58,921 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 228 (MappedRDD[235] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:58,922 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 228 (MappedRDD[235] at map at PCA.scala:57)
2014-07-23 17:22:58,922 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 228.0 with 1 tasks
2014-07-23 17:22:58,922 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 228.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:58,923 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 228.0:0 as 2523 bytes in 1 ms
2014-07-23 17:22:58,923 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-23 17:22:58,924 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:58,925 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,016 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-23 17:22:59,016 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-23 17:22:59,016 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-23 17:22:59,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(228, 0)
2014-07-23 17:22:59,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 228 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:22:59,017 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,017 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 228.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,018 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099148015 s
2014-07-23 17:22:59,022 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,023 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,023 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 230(reduce at PCA.scala:57)
2014-07-23 17:22:59,023 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 231)
2014-07-23 17:22:59,024 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,024 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 230 (MappedRDD[237] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,025 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 230 (MappedRDD[237] at map at PCA.scala:57)
2014-07-23 17:22:59,025 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 230.0 with 1 tasks
2014-07-23 17:22:59,026 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 230.0:0 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,026 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 230.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:59,026 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-23 17:22:59,027 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,028 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,116 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-23 17:22:59,116 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-23 17:22:59,116 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-23 17:22:59,117 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(230, 0)
2014-07-23 17:22:59,117 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 91 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,117 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 230.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,117 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 230 (reduce at PCA.scala:57) finished in 0.092 s
2014-07-23 17:22:59,118 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.095865347 s
2014-07-23 17:22:59,122 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,123 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,123 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 232(reduce at PCA.scala:57)
2014-07-23 17:22:59,123 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 233)
2014-07-23 17:22:59,124 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,124 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 232 (MappedRDD[239] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,126 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 232 (MappedRDD[239] at map at PCA.scala:57)
2014-07-23 17:22:59,126 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 232.0 with 1 tasks
2014-07-23 17:22:59,126 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 232.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,126 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 232.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:59,127 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-23 17:22:59,128 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,129 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,225 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-23 17:22:59,225 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-23 17:22:59,226 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,226 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 232.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,227 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(232, 0)
2014-07-23 17:22:59,227 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 232 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:22:59,227 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104941676 s
2014-07-23 17:22:59,227 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-23 17:22:59,232 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,233 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,233 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 234(reduce at PCA.scala:57)
2014-07-23 17:22:59,233 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 235)
2014-07-23 17:22:59,234 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,234 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 234 (MappedRDD[241] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,235 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 234 (MappedRDD[241] at map at PCA.scala:57)
2014-07-23 17:22:59,235 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 234.0 with 1 tasks
2014-07-23 17:22:59,235 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 234.0:0 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,236 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 234.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:59,236 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-23 17:22:59,237 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,238 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-23 17:22:59,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-23 17:22:59,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-23 17:22:59,326 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 91 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,326 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 234.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,326 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(234, 0)
2014-07-23 17:22:59,326 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 234 (reduce at PCA.scala:57) finished in 0.091 s
2014-07-23 17:22:59,327 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.09503009 s
2014-07-23 17:22:59,331 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 236(reduce at PCA.scala:57)
2014-07-23 17:22:59,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 237)
2014-07-23 17:22:59,333 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,334 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 236 (MappedRDD[243] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,335 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 236 (MappedRDD[243] at map at PCA.scala:57)
2014-07-23 17:22:59,335 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 236.0 with 1 tasks
2014-07-23 17:22:59,335 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 236.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,336 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 236.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:59,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-23 17:22:59,337 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,338 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-23 17:22:59,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-23 17:22:59,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-23 17:22:59,426 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 91 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,426 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 236.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,427 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(236, 0)
2014-07-23 17:22:59,427 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 236 (reduce at PCA.scala:57) finished in 0.092 s
2014-07-23 17:22:59,427 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.096136431 s
2014-07-23 17:22:59,431 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,432 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,432 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 238(reduce at PCA.scala:57)
2014-07-23 17:22:59,432 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 239)
2014-07-23 17:22:59,433 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,433 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 238 (MappedRDD[245] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,435 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 238 (MappedRDD[245] at map at PCA.scala:57)
2014-07-23 17:22:59,435 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 238.0 with 1 tasks
2014-07-23 17:22:59,435 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 238.0:0 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,435 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 238.0:0 as 2523 bytes in 0 ms
2014-07-23 17:22:59,436 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-23 17:22:59,437 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,438 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,518 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-23 17:22:59,518 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-23 17:22:59,518 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-23 17:22:59,519 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(238, 0)
2014-07-23 17:22:59,519 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 83 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,519 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 238.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,519 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 238 (reduce at PCA.scala:57) finished in 0.084 s
2014-07-23 17:22:59,519 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.087649054 s
2014-07-23 17:22:59,523 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,524 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,524 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 240(reduce at PCA.scala:57)
2014-07-23 17:22:59,524 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 241)
2014-07-23 17:22:59,525 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,525 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 240 (MappedRDD[247] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,527 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 240 (MappedRDD[247] at map at PCA.scala:57)
2014-07-23 17:22:59,527 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 240.0 with 1 tasks
2014-07-23 17:22:59,528 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 240.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,528 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 240.0:0 as 2522 bytes in 0 ms
2014-07-23 17:22:59,529 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-23 17:22:59,530 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,531 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,604 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-23 17:22:59,604 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-23 17:22:59,604 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-23 17:22:59,605 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 77 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,605 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 240.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,605 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(240, 0)
2014-07-23 17:22:59,605 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 240 (reduce at PCA.scala:57) finished in 0.078 s
2014-07-23 17:22:59,605 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.082444677 s
2014-07-23 17:22:59,610 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:22:59,611 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:22:59,611 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 242(reduce at PCA.scala:57)
2014-07-23 17:22:59,611 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 243)
2014-07-23 17:22:59,612 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:22:59,612 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 242 (MappedRDD[249] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:22:59,613 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 242 (MappedRDD[249] at map at PCA.scala:57)
2014-07-23 17:22:59,613 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 242.0 with 1 tasks
2014-07-23 17:22:59,614 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 242.0:0 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:22:59,614 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 242.0:0 as 2520 bytes in 0 ms
2014-07-23 17:22:59,614 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-23 17:22:59,616 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:22:59,616 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:22:59,681 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-23 17:22:59,682 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-23 17:22:59,682 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-23 17:22:59,682 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 68 ms on localhost (progress: 1/1)
2014-07-23 17:22:59,682 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(242, 0)
2014-07-23 17:22:59,682 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 242.0, whose tasks have all completed, from pool 
2014-07-23 17:22:59,682 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 242 (reduce at PCA.scala:57) finished in 0.068 s
2014-07-23 17:22:59,683 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.072993974 s
2014-07-23 17:22:59,788 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/static,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2014-07-23 17:22:59,789 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2014-07-23 17:22:59,790 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2014-07-23 17:22:59,791 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages,null}
2014-07-23 17:22:59,843 [main] INFO  [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://10.74.147.225:4040
2014-07-23 17:22:59,843 [main] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stopping DAGScheduler
2014-07-23 17:23:00,898 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.MapOutputTrackerMasterActor] - MapOutputTrackerActor stopped!
2014-07-23 17:23:00,951 [connection-manager-thread] INFO  [org.apache.spark.network.ConnectionManager] - Selector thread was interrupted!
2014-07-23 17:23:00,952 [main] INFO  [org.apache.spark.network.ConnectionManager] - ConnectionManager stopped
2014-07-23 17:23:00,958 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore cleared
2014-07-23 17:23:00,959 [main] INFO  [org.apache.spark.storage.BlockManager] - BlockManager stopped
2014-07-23 17:23:00,959 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.storage.BlockManagerMasterActor] - Stopping BlockManagerMaster
2014-07-23 17:23:00,960 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2014-07-23 17:23:00,962 [main] INFO  [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2014-07-23 17:23:00,971 [spark-akka.actor.default-dispatcher-2] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Shutting down remote daemon.
2014-07-23 17:23:00,971 [spark-akka.actor.default-dispatcher-2] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Remote daemon shut down; proceeding with flushing remote transports.
2014-07-23 17:30:39,109 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.225 instead (on interface eth0)
2014-07-23 17:30:39,110 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-23 17:30:39,177 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-23 17:30:39,178 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-23 17:30:39,748 [spark-akka.actor.default-dispatcher-4] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-23 17:30:39,848 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Starting remoting
2014-07-23 17:30:40,069 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.225:57795]
2014-07-23 17:30:40,071 [spark-akka.actor.default-dispatcher-4] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.225:57795]
2014-07-23 17:30:40,108 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-23 17:30:40,112 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-23 17:30:40,132 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140723173040-7784
2014-07-23 17:30:40,137 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-23 17:30:40,188 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 34199 with id = ConnectionManagerId(10.74.147.225,34199)
2014-07-23 17:30:40,194 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-23 17:30:40,197 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.225:34199 with 1056.0 MB RAM
2014-07-23 17:30:40,198 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-23 17:30:40,216 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:30:40,369 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:30:40,389 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:58856
2014-07-23 17:30:40,390 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.225:58856
2014-07-23 17:30:40,398 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-16fc113b-55c3-4ed0-abf8-d548ae305ee1
2014-07-23 17:30:40,399 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:30:40,400 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:30:40,409 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:51436
2014-07-23 17:30:40,796 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:30:40,817 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-23 17:30:40,820 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.225:4040
2014-07-23 17:30:41,556 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-23 17:30:41,558 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-23 17:30:41,697 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at PCA.scala:50
2014-07-23 17:30:41,739 [spark-akka.actor.default-dispatcher-5] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-23 17:30:41,739 [spark-akka.actor.default-dispatcher-5] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-23 17:30:41,750 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-23 17:30:41,778 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (repartition at PCA.scala:46)
2014-07-23 17:30:41,781 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PCA.scala:50) with 1 output partitions (allowLocal=false)
2014-07-23 17:30:41,782 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at PCA.scala:50)
2014-07-23 17:30:41,782 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 1)
2014-07-23 17:30:41,785 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(Stage 1)
2014-07-23 17:30:41,796 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46), which has no missing parents
2014-07-23 17:30:41,881 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46)
2014-07-23 17:30:41,882 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-23 17:30:41,903 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:30:41,907 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2030 bytes in 3 ms
2014-07-23 17:30:41,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:30:41,911 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2030 bytes in 0 ms
2014-07-23 17:30:41,924 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-23 17:30:41,932 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-23 17:30:41,954 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:30:41,955 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:30:41,969 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-23 17:30:41,969 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-23 17:30:43,991 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 783
2014-07-23 17:30:43,992 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-23 17:30:43,993 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-23 17:30:44,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 1)
2014-07-23 17:30:44,016 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 2092 ms on localhost (progress: 1/2)
2014-07-23 17:30:44,127 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 783
2014-07-23 17:30:44,127 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-23 17:30:44,127 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-23 17:30:44,129 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 0)
2014-07-23 17:30:44,129 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 2228 ms on localhost (progress: 2/2)
2014-07-23 17:30:44,130 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (repartition at PCA.scala:46) finished in 2.239 s
2014-07-23 17:30:44,130 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-23 17:30:44,131 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2014-07-23 17:30:44,132 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2014-07-23 17:30:44,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(Stage 0)
2014-07-23 17:30:44,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2014-07-23 17:30:44,137 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents for Stage 0: List()
2014-07-23 17:30:44,140 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[7] at repartition at PCA.scala:46), which is now runnable
2014-07-23 17:30:44,164 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 0 (MappedRDD[7] at repartition at PCA.scala:46)
2014-07-23 17:30:44,164 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2014-07-23 17:30:44,166 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:30:44,167 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 2265 bytes in 0 ms
2014-07-23 17:30:44,169 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-23 17:30:44,174 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:30:44,181 [Executor task launch worker-0] INFO  [org.apache.spark.CacheManager] - Partition rdd_7_0 not found, computing it
2014-07-23 17:30:44,189 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-23 17:30:44,192 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2014-07-23 17:30:44,194 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Started 0 remote fetches in 6 ms
2014-07-23 17:30:47,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(170498505) called with curMem=32856, maxMem=1107296256
2014-07-23 17:30:47,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_7_0 stored as values to memory (estimated size 162.6 MB, free 893.4 MB)
2014-07-23 17:30:47,282 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_7_0 in memory on 10.74.147.225:34199 (size: 162.6 MB, free: 893.4 MB)
2014-07-23 17:30:47,283 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_7_0
2014-07-23 17:30:47,307 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 1390
2014-07-23 17:30:47,307 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-23 17:30:47,307 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-23 17:30:47,311 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-23 17:30:47,312 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at PCA.scala:50) finished in 3.134 s
2014-07-23 17:30:47,319 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at PCA.scala:50, took 5.621833155 s
2014-07-23 17:30:47,322 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 3146 ms on localhost (progress: 1/1)
2014-07-23 17:30:47,322 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-23 17:30:47,363 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:30:47,367 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 0 is 146 bytes
2014-07-23 17:30:47,370 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:30:47,370 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at PCA.scala:57)
2014-07-23 17:30:47,370 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 3)
2014-07-23 17:30:47,372 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:30:47,372 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[9] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:30:47,381 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 2 (MappedRDD[9] at map at PCA.scala:57)
2014-07-23 17:30:47,381 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 1 tasks
2014-07-23 17:30:47,382 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:30:47,383 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2521 bytes in 0 ms
2014-07-23 17:30:47,384 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-23 17:30:47,388 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:30:47,392 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:30:47,588 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 678
2014-07-23 17:30:47,588 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-23 17:30:47,588 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-23 17:30:47,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-23 17:30:47,590 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 207 ms on localhost (progress: 1/1)
2014-07-23 17:30:47,590 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-23 17:30:47,590 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at PCA.scala:57) finished in 0.208 s
2014-07-23 17:30:47,590 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.227585135 s
2014-07-23 17:31:19,992 [main] INFO  [org.apache.spark.SparkContext] - Starting job: collect at PCA.scala:58
2014-07-23 17:31:19,995 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (collect at PCA.scala:58) with 1 output partitions (allowLocal=false)
2014-07-23 17:31:19,995 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(collect at PCA.scala:58)
2014-07-23 17:31:19,995 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 5)
2014-07-23 17:31:19,996 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:31:19,997 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[8] at map at PCA.scala:56), which has no missing parents
2014-07-23 17:31:20,001 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 4 (MappedRDD[8] at map at PCA.scala:56)
2014-07-23 17:31:20,001 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 1 tasks
2014-07-23 17:31:20,002 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:31:20,002 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2408 bytes in 0 ms
2014-07-23 17:31:20,003 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-23 17:31:20,005 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:31:20,008 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:31:20,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 4937053
2014-07-23 17:31:20,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-23 17:31:20,726 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-23 17:31:21,297 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-23 17:31:21,297 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (collect at PCA.scala:58) finished in 1.296 s
2014-07-23 17:31:21,298 [main] INFO  [org.apache.spark.SparkContext] - Job finished: collect at PCA.scala:58, took 1.305236643 s
2014-07-23 17:31:21,306 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 755 ms on localhost (progress: 1/1)
2014-07-23 17:31:21,307 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-23 17:31:31,488 [main] INFO  [org.apache.spark.SparkContext] - Starting job: collect at PCA.scala:58
2014-07-23 17:31:31,490 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (collect at PCA.scala:58) with 1 output partitions (allowLocal=false)
2014-07-23 17:31:31,490 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(collect at PCA.scala:58)
2014-07-23 17:31:31,490 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 7)
2014-07-23 17:31:31,492 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:31:31,494 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[8] at map at PCA.scala:56), which has no missing parents
2014-07-23 17:31:31,497 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 6 (MappedRDD[8] at map at PCA.scala:56)
2014-07-23 17:31:31,497 [spark-akka.actor.default-dispatcher-14] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 1 tasks
2014-07-23 17:31:31,501 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:31:31,502 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2408 bytes in 1 ms
2014-07-23 17:31:31,502 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-23 17:31:31,505 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:31:31,507 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:31:31,897 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 4937053
2014-07-23 17:31:31,897 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-23 17:31:31,909 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-23 17:31:32,354 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-23 17:31:32,355 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (collect at PCA.scala:58) finished in 0.853 s
2014-07-23 17:31:32,355 [main] INFO  [org.apache.spark.SparkContext] - Job finished: collect at PCA.scala:58, took 0.867066914 s
2014-07-23 17:31:32,356 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 406 ms on localhost (progress: 1/1)
2014-07-23 17:31:32,356 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-23 17:32:13,668 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:13,670 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:13,670 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at PCA.scala:57)
2014-07-23 17:32:13,670 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 9)
2014-07-23 17:32:13,671 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:13,672 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[11] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:13,674 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 8 (MappedRDD[11] at map at PCA.scala:57)
2014-07-23 17:32:13,674 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 1 tasks
2014-07-23 17:32:13,675 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:13,676 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2522 bytes in 1 ms
2014-07-23 17:32:13,676 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-23 17:32:13,681 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:13,686 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:13,821 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-23 17:32:13,821 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-23 17:32:13,821 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-23 17:32:13,822 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-23 17:32:13,822 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 147 ms on localhost (progress: 1/1)
2014-07-23 17:32:13,822 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-23 17:32:13,822 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at PCA.scala:57) finished in 0.134 s
2014-07-23 17:32:13,823 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.154920916 s
2014-07-23 17:32:13,830 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:13,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:13,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at PCA.scala:57)
2014-07-23 17:32:13,833 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 11)
2014-07-23 17:32:13,834 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:13,835 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[13] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:13,837 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 10 (MappedRDD[13] at map at PCA.scala:57)
2014-07-23 17:32:13,837 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 1 tasks
2014-07-23 17:32:13,838 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:13,838 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2521 bytes in 0 ms
2014-07-23 17:32:13,839 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-23 17:32:13,841 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:13,843 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:13,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-23 17:32:13,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-23 17:32:13,963 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-23 17:32:13,964 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 126 ms on localhost (progress: 1/1)
2014-07-23 17:32:13,964 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-23 17:32:13,965 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-23 17:32:13,965 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at PCA.scala:57) finished in 0.128 s
2014-07-23 17:32:13,965 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.134745872 s
2014-07-23 17:32:13,972 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:13,975 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:13,975 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at PCA.scala:57)
2014-07-23 17:32:13,975 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 13)
2014-07-23 17:32:13,976 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:13,977 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[15] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:13,979 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 12 (MappedRDD[15] at map at PCA.scala:57)
2014-07-23 17:32:13,979 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 1 tasks
2014-07-23 17:32:13,980 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:13,980 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:13,981 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-23 17:32:13,984 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:13,986 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:14,114 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-23 17:32:14,114 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-23 17:32:14,114 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-23 17:32:14,115 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-23 17:32:14,115 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 135 ms on localhost (progress: 1/1)
2014-07-23 17:32:14,115 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-23 17:32:14,115 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at PCA.scala:57) finished in 0.136 s
2014-07-23 17:32:14,116 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.143315901 s
2014-07-23 17:32:14,127 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:14,129 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:14,129 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at PCA.scala:57)
2014-07-23 17:32:14,129 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 15)
2014-07-23 17:32:14,131 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:14,131 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[17] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:14,134 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 14 (MappedRDD[17] at map at PCA.scala:57)
2014-07-23 17:32:14,141 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 1 tasks
2014-07-23 17:32:14,143 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:14,144 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2522 bytes in 1 ms
2014-07-23 17:32:14,145 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-23 17:32:14,147 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:14,149 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:14,283 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-23 17:32:14,283 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-23 17:32:14,283 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-23 17:32:14,284 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-23 17:32:14,284 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 142 ms on localhost (progress: 1/1)
2014-07-23 17:32:14,284 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-23 17:32:14,284 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at PCA.scala:57) finished in 0.142 s
2014-07-23 17:32:14,288 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.160976639 s
2014-07-23 17:32:14,294 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:14,296 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:14,297 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at PCA.scala:57)
2014-07-23 17:32:14,297 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 17)
2014-07-23 17:32:14,298 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:14,298 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[19] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:14,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 16 (MappedRDD[19] at map at PCA.scala:57)
2014-07-23 17:32:14,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 1 tasks
2014-07-23 17:32:14,302 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:14,302 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:14,303 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-23 17:32:14,305 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:14,308 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:14,438 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-23 17:32:14,438 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-23 17:32:14,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-23 17:32:14,439 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-23 17:32:14,440 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at PCA.scala:57) finished in 0.139 s
2014-07-23 17:32:14,440 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.145778886 s
2014-07-23 17:32:14,439 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 138 ms on localhost (progress: 1/1)
2014-07-23 17:32:14,443 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-23 17:32:14,447 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:14,449 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:14,449 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at PCA.scala:57)
2014-07-23 17:32:14,449 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 19)
2014-07-23 17:32:14,451 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:14,451 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[21] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:14,453 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 18 (MappedRDD[21] at map at PCA.scala:57)
2014-07-23 17:32:14,453 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 1 tasks
2014-07-23 17:32:14,455 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:14,455 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:14,456 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-23 17:32:14,458 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:14,460 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:14,586 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-23 17:32:14,586 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-23 17:32:14,586 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-23 17:32:14,587 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-23 17:32:14,587 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 133 ms on localhost (progress: 1/1)
2014-07-23 17:32:14,588 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-23 17:32:14,588 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at PCA.scala:57) finished in 0.133 s
2014-07-23 17:32:14,588 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.140807783 s
2014-07-23 17:32:14,596 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:14,598 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:14,598 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at PCA.scala:57)
2014-07-23 17:32:14,599 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 21)
2014-07-23 17:32:14,600 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:14,601 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[23] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:14,603 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 20 (MappedRDD[23] at map at PCA.scala:57)
2014-07-23 17:32:14,603 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 1 tasks
2014-07-23 17:32:14,604 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:14,604 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:14,605 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-23 17:32:14,607 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:14,609 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:14,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-23 17:32:14,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-23 17:32:14,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-23 17:32:14,787 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-23 17:32:14,787 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 183 ms on localhost (progress: 1/1)
2014-07-23 17:32:14,787 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-23 17:32:14,787 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at PCA.scala:57) finished in 0.184 s
2014-07-23 17:32:14,788 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.191552276 s
2014-07-23 17:32:14,801 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:14,803 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:14,803 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at PCA.scala:57)
2014-07-23 17:32:14,803 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 23)
2014-07-23 17:32:14,805 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:14,805 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[25] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:14,808 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 22 (MappedRDD[25] at map at PCA.scala:57)
2014-07-23 17:32:14,808 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 1 tasks
2014-07-23 17:32:14,809 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:14,809 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:14,810 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-23 17:32:14,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:14,814 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:14,946 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-23 17:32:14,946 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-23 17:32:14,947 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-23 17:32:14,947 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-23 17:32:14,947 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 138 ms on localhost (progress: 1/1)
2014-07-23 17:32:14,947 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-23 17:32:14,947 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at PCA.scala:57) finished in 0.128 s
2014-07-23 17:32:14,949 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.147895024 s
2014-07-23 17:32:14,956 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:14,958 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:14,958 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at PCA.scala:57)
2014-07-23 17:32:14,959 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 25)
2014-07-23 17:32:14,960 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:14,961 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[27] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:14,963 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 24 (MappedRDD[27] at map at PCA.scala:57)
2014-07-23 17:32:14,963 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 1 tasks
2014-07-23 17:32:14,965 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:14,965 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:14,966 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-23 17:32:14,968 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:14,969 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:15,121 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-23 17:32:15,121 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-23 17:32:15,123 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 158 ms on localhost (progress: 1/1)
2014-07-23 17:32:15,123 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-23 17:32:15,124 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-23 17:32:15,124 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at PCA.scala:57) finished in 0.153 s
2014-07-23 17:32:15,125 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.168792125 s
2014-07-23 17:32:15,135 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-23 17:32:15,136 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:15,138 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:15,138 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at PCA.scala:57)
2014-07-23 17:32:15,138 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 27)
2014-07-23 17:32:15,140 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:15,141 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[29] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:15,144 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 26 (MappedRDD[29] at map at PCA.scala:57)
2014-07-23 17:32:15,144 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 1 tasks
2014-07-23 17:32:15,145 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:15,146 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:15,146 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-23 17:32:15,151 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:15,154 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:15,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-23 17:32:15,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-23 17:32:15,313 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-23 17:32:15,314 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-23 17:32:15,314 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 168 ms on localhost (progress: 1/1)
2014-07-23 17:32:15,314 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at PCA.scala:57) finished in 0.166 s
2014-07-23 17:32:15,314 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-23 17:32:15,315 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.178593515 s
2014-07-23 17:32:15,328 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:15,330 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:15,330 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at PCA.scala:57)
2014-07-23 17:32:15,330 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 29)
2014-07-23 17:32:15,331 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:15,332 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[31] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:15,338 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 28 (MappedRDD[31] at map at PCA.scala:57)
2014-07-23 17:32:15,338 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 1 tasks
2014-07-23 17:32:15,339 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:15,339 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:15,340 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-23 17:32:15,342 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:15,344 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:15,456 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-23 17:32:15,456 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-23 17:32:15,458 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 118 ms on localhost (progress: 1/1)
2014-07-23 17:32:15,458 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-23 17:32:15,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-23 17:32:15,458 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:32:15,459 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.131263718 s
2014-07-23 17:32:15,467 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:15,468 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-23 17:32:15,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:15,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at PCA.scala:57)
2014-07-23 17:32:15,471 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 31)
2014-07-23 17:32:15,473 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:15,473 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[33] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:15,475 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 30 (MappedRDD[33] at map at PCA.scala:57)
2014-07-23 17:32:15,475 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 1 tasks
2014-07-23 17:32:15,476 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:15,477 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2521 bytes in 1 ms
2014-07-23 17:32:15,477 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-23 17:32:15,481 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:15,483 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:15,602 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-23 17:32:15,602 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-23 17:32:15,603 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-23 17:32:15,603 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-23 17:32:15,604 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at PCA.scala:57) finished in 0.119 s
2014-07-23 17:32:15,604 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 127 ms on localhost (progress: 1/1)
2014-07-23 17:32:15,604 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-23 17:32:15,604 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.136991191 s
2014-07-23 17:32:15,613 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:15,616 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:15,616 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at PCA.scala:57)
2014-07-23 17:32:15,616 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 33)
2014-07-23 17:32:15,617 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:15,618 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[35] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:15,620 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 32 (MappedRDD[35] at map at PCA.scala:57)
2014-07-23 17:32:15,620 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 1 tasks
2014-07-23 17:32:15,622 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:15,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:15,624 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-23 17:32:15,626 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:15,628 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:15,765 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-23 17:32:15,765 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-23 17:32:15,768 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 146 ms on localhost (progress: 1/1)
2014-07-23 17:32:15,768 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-23 17:32:15,770 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-23 17:32:15,771 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at PCA.scala:57) finished in 0.143 s
2014-07-23 17:32:15,771 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.158737211 s
2014-07-23 17:32:15,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-23 17:32:15,787 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:15,790 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:15,790 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at PCA.scala:57)
2014-07-23 17:32:15,790 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 35)
2014-07-23 17:32:15,792 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:15,794 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[37] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:15,796 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 34 (MappedRDD[37] at map at PCA.scala:57)
2014-07-23 17:32:15,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 1 tasks
2014-07-23 17:32:15,798 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:15,799 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2522 bytes in 1 ms
2014-07-23 17:32:15,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-23 17:32:15,809 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:15,811 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:15,972 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-23 17:32:15,972 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-23 17:32:15,973 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-23 17:32:15,974 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-23 17:32:15,974 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 175 ms on localhost (progress: 1/1)
2014-07-23 17:32:15,974 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-23 17:32:15,974 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at PCA.scala:57) finished in 0.164 s
2014-07-23 17:32:15,975 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.18718741 s
2014-07-23 17:32:15,982 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:15,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:15,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at PCA.scala:57)
2014-07-23 17:32:15,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 37)
2014-07-23 17:32:15,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:15,988 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[39] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:15,990 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 36 (MappedRDD[39] at map at PCA.scala:57)
2014-07-23 17:32:15,991 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 1 tasks
2014-07-23 17:32:15,991 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:15,992 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:15,992 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-23 17:32:15,994 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:15,997 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:16,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-23 17:32:16,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-23 17:32:16,207 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 215 ms on localhost (progress: 1/1)
2014-07-23 17:32:16,207 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-23 17:32:16,208 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-23 17:32:16,208 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at PCA.scala:57) finished in 0.212 s
2014-07-23 17:32:16,209 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.226300432 s
2014-07-23 17:32:16,226 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-23 17:32:16,236 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:16,238 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:16,238 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at PCA.scala:57)
2014-07-23 17:32:16,238 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 39)
2014-07-23 17:32:16,241 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:16,241 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[41] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:16,244 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 38 (MappedRDD[41] at map at PCA.scala:57)
2014-07-23 17:32:16,244 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 1 tasks
2014-07-23 17:32:16,245 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:16,245 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:16,246 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-23 17:32:16,248 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:16,250 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:16,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-23 17:32:16,426 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-23 17:32:16,428 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 182 ms on localhost (progress: 1/1)
2014-07-23 17:32:16,428 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-23 17:32:16,428 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-23 17:32:16,428 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at PCA.scala:57) finished in 0.175 s
2014-07-23 17:32:16,429 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.193507003 s
2014-07-23 17:32:16,437 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-23 17:32:16,441 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:16,444 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:16,444 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at PCA.scala:57)
2014-07-23 17:32:16,444 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 41)
2014-07-23 17:32:16,445 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:16,446 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[43] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:16,449 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 40 (MappedRDD[43] at map at PCA.scala:57)
2014-07-23 17:32:16,449 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 1 tasks
2014-07-23 17:32:16,451 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:16,452 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:16,453 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-23 17:32:16,455 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:16,461 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:16,636 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-23 17:32:16,636 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-23 17:32:16,639 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 186 ms on localhost (progress: 1/1)
2014-07-23 17:32:16,639 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-23 17:32:16,640 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-23 17:32:16,640 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at PCA.scala:57) finished in 0.176 s
2014-07-23 17:32:16,641 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.199174472 s
2014-07-23 17:32:16,650 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:16,653 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-23 17:32:16,653 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:16,653 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at PCA.scala:57)
2014-07-23 17:32:16,654 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 43)
2014-07-23 17:32:16,656 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:16,657 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[45] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:16,662 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 42 (MappedRDD[45] at map at PCA.scala:57)
2014-07-23 17:32:16,663 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 1 tasks
2014-07-23 17:32:16,668 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:16,669 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:16,671 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-23 17:32:16,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:16,675 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:16,877 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-23 17:32:16,877 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-23 17:32:16,878 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-23 17:32:16,878 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-23 17:32:16,878 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 210 ms on localhost (progress: 1/1)
2014-07-23 17:32:16,879 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-23 17:32:16,879 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at PCA.scala:57) finished in 0.203 s
2014-07-23 17:32:16,879 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.228424791 s
2014-07-23 17:32:16,885 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at PCA.scala:57)
2014-07-23 17:32:16,887 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 45)
2014-07-23 17:32:16,888 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:16,889 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[47] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:16,891 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 44 (MappedRDD[47] at map at PCA.scala:57)
2014-07-23 17:32:16,892 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 1 tasks
2014-07-23 17:32:16,892 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:16,893 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2523 bytes in 1 ms
2014-07-23 17:32:16,894 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-23 17:32:16,896 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:16,898 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,066 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-23 17:32:17,066 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-23 17:32:17,069 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 177 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,071 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,070 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-23 17:32:17,072 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at PCA.scala:57) finished in 0.176 s
2014-07-23 17:32:17,073 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.188565163 s
2014-07-23 17:32:17,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-23 17:32:17,084 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,086 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,086 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at PCA.scala:57)
2014-07-23 17:32:17,086 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 47)
2014-07-23 17:32:17,087 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:17,088 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[49] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:17,090 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 46 (MappedRDD[49] at map at PCA.scala:57)
2014-07-23 17:32:17,091 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 1 tasks
2014-07-23 17:32:17,091 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:17,092 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:17,093 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-23 17:32:17,095 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:17,096 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,231 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-23 17:32:17,231 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-23 17:32:17,232 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 141 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,232 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,233 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-23 17:32:17,233 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at PCA.scala:57) finished in 0.142 s
2014-07-23 17:32:17,233 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-23 17:32:17,234 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.150017406 s
2014-07-23 17:32:17,240 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,242 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,242 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at PCA.scala:57)
2014-07-23 17:32:17,242 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 49)
2014-07-23 17:32:17,244 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:17,244 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[51] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:17,247 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 48 (MappedRDD[51] at map at PCA.scala:57)
2014-07-23 17:32:17,247 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 1 tasks
2014-07-23 17:32:17,248 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:17,248 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:17,249 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-23 17:32:17,251 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:17,253 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,392 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-23 17:32:17,392 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-23 17:32:17,393 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 145 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,393 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,394 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-23 17:32:17,394 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at PCA.scala:57) finished in 0.140 s
2014-07-23 17:32:17,394 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.153653299 s
2014-07-23 17:32:17,395 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-23 17:32:17,401 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,402 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,403 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at PCA.scala:57)
2014-07-23 17:32:17,403 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 51)
2014-07-23 17:32:17,404 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:17,405 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[53] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:17,417 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 50 (MappedRDD[53] at map at PCA.scala:57)
2014-07-23 17:32:17,417 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 1 tasks
2014-07-23 17:32:17,420 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:17,420 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:17,421 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-23 17:32:17,423 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:17,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,563 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-23 17:32:17,563 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-23 17:32:17,564 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-23 17:32:17,564 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-23 17:32:17,564 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 145 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,564 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,564 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at PCA.scala:57) finished in 0.140 s
2014-07-23 17:32:17,565 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.163896842 s
2014-07-23 17:32:17,573 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,575 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,575 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at PCA.scala:57)
2014-07-23 17:32:17,575 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 53)
2014-07-23 17:32:17,578 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:17,578 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[55] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:17,581 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 52 (MappedRDD[55] at map at PCA.scala:57)
2014-07-23 17:32:17,581 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 1 tasks
2014-07-23 17:32:17,582 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:17,583 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:17,584 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-23 17:32:17,586 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:17,588 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,703 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-23 17:32:17,703 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-23 17:32:17,704 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 122 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,704 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-23 17:32:17,705 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:32:17,704 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,705 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.132333608 s
2014-07-23 17:32:17,719 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-23 17:32:17,721 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,725 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,725 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at PCA.scala:57)
2014-07-23 17:32:17,725 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 55)
2014-07-23 17:32:17,726 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:17,727 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[57] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:17,729 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 54 (MappedRDD[57] at map at PCA.scala:57)
2014-07-23 17:32:17,729 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 1 tasks
2014-07-23 17:32:17,730 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:17,730 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2521 bytes in 0 ms
2014-07-23 17:32:17,731 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-23 17:32:17,733 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:17,738 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,853 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-23 17:32:17,853 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-23 17:32:17,853 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-23 17:32:17,854 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-23 17:32:17,854 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,854 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,854 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:32:17,855 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.133104779 s
2014-07-23 17:32:17,867 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,868 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,869 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at PCA.scala:57)
2014-07-23 17:32:17,869 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 57)
2014-07-23 17:32:17,870 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:17,870 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[59] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:17,872 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 56 (MappedRDD[59] at map at PCA.scala:57)
2014-07-23 17:32:17,872 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 1 tasks
2014-07-23 17:32:17,873 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:17,873 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:17,873 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-23 17:32:17,875 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:17,877 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:17,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-23 17:32:17,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-23 17:32:17,989 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-23 17:32:17,990 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-23 17:32:17,990 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:32:17,990 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-23 17:32:17,990 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:32:17,991 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12391828 s
2014-07-23 17:32:17,996 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:17,998 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:17,998 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at PCA.scala:57)
2014-07-23 17:32:17,998 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 59)
2014-07-23 17:32:17,999 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,000 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[61] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,002 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 58 (MappedRDD[61] at map at PCA.scala:57)
2014-07-23 17:32:18,002 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 1 tasks
2014-07-23 17:32:18,003 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,003 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:18,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-23 17:32:18,005 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,007 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-23 17:32:18,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-23 17:32:18,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-23 17:32:18,126 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-23 17:32:18,126 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 122 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,126 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,126 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at PCA.scala:57) finished in 0.124 s
2014-07-23 17:32:18,126 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.129951165 s
2014-07-23 17:32:18,131 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,133 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,133 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at PCA.scala:57)
2014-07-23 17:32:18,133 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 61)
2014-07-23 17:32:18,134 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,135 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[63] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,136 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 60 (MappedRDD[63] at map at PCA.scala:57)
2014-07-23 17:32:18,136 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 1 tasks
2014-07-23 17:32:18,137 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,137 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:18,138 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-23 17:32:18,140 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,141 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-23 17:32:18,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-23 17:32:18,258 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-23 17:32:18,260 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-23 17:32:18,260 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,260 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,260 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:32:18,261 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.129186546 s
2014-07-23 17:32:18,266 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,267 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,267 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at PCA.scala:57)
2014-07-23 17:32:18,267 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 63)
2014-07-23 17:32:18,268 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,269 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[65] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,271 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 62 (MappedRDD[65] at map at PCA.scala:57)
2014-07-23 17:32:18,271 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 1 tasks
2014-07-23 17:32:18,271 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,272 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2523 bytes in 1 ms
2014-07-23 17:32:18,272 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-23 17:32:18,274 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,276 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,396 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-23 17:32:18,396 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-23 17:32:18,396 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-23 17:32:18,397 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-23 17:32:18,397 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 125 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,397 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,397 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at PCA.scala:57) finished in 0.126 s
2014-07-23 17:32:18,398 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.132027505 s
2014-07-23 17:32:18,403 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,405 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,405 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at PCA.scala:57)
2014-07-23 17:32:18,405 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 65)
2014-07-23 17:32:18,406 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,406 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[67] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,408 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 64 (MappedRDD[67] at map at PCA.scala:57)
2014-07-23 17:32:18,408 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 1 tasks
2014-07-23 17:32:18,411 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,411 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:18,412 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-23 17:32:18,414 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,415 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,534 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-23 17:32:18,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-23 17:32:18,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-23 17:32:18,535 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-23 17:32:18,536 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 126 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,536 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,536 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at PCA.scala:57) finished in 0.128 s
2014-07-23 17:32:18,536 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.133082779 s
2014-07-23 17:32:18,542 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,544 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,544 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at PCA.scala:57)
2014-07-23 17:32:18,544 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 67)
2014-07-23 17:32:18,545 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,545 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[69] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,547 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 66 (MappedRDD[69] at map at PCA.scala:57)
2014-07-23 17:32:18,547 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 1 tasks
2014-07-23 17:32:18,548 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,548 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:18,549 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-23 17:32:18,550 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,552 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-23 17:32:18,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-23 17:32:18,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-23 17:32:18,671 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-23 17:32:18,671 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 122 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,671 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,671 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at PCA.scala:57) finished in 0.124 s
2014-07-23 17:32:18,671 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.129024899 s
2014-07-23 17:32:18,676 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,678 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,678 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at PCA.scala:57)
2014-07-23 17:32:18,678 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 69)
2014-07-23 17:32:18,680 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,680 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[71] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,682 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 68 (MappedRDD[71] at map at PCA.scala:57)
2014-07-23 17:32:18,683 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 1 tasks
2014-07-23 17:32:18,684 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,684 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:18,685 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-23 17:32:18,687 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,688 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-23 17:32:18,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-23 17:32:18,804 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-23 17:32:18,805 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 122 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,805 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,806 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-23 17:32:18,806 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:32:18,807 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.130325204 s
2014-07-23 17:32:18,812 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,814 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,814 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at PCA.scala:57)
2014-07-23 17:32:18,814 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 71)
2014-07-23 17:32:18,815 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,816 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[73] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,817 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 70 (MappedRDD[73] at map at PCA.scala:57)
2014-07-23 17:32:18,817 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 1 tasks
2014-07-23 17:32:18,818 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,819 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2521 bytes in 0 ms
2014-07-23 17:32:18,819 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-23 17:32:18,821 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,822 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:18,926 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-23 17:32:18,926 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-23 17:32:18,926 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-23 17:32:18,927 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-23 17:32:18,927 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 109 ms on localhost (progress: 1/1)
2014-07-23 17:32:18,927 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-23 17:32:18,927 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:32:18,927 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115012948 s
2014-07-23 17:32:18,934 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:18,935 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:18,936 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at PCA.scala:57)
2014-07-23 17:32:18,936 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 73)
2014-07-23 17:32:18,937 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:18,937 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[75] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:18,939 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 72 (MappedRDD[75] at map at PCA.scala:57)
2014-07-23 17:32:18,939 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 1 tasks
2014-07-23 17:32:18,940 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:18,940 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:18,940 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-23 17:32:18,942 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:18,943 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:19,078 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-23 17:32:19,078 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-23 17:32:19,078 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-23 17:32:19,079 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 140 ms on localhost (progress: 1/1)
2014-07-23 17:32:19,079 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-23 17:32:19,079 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-23 17:32:19,079 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at PCA.scala:57) finished in 0.140 s
2014-07-23 17:32:19,080 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.145846684 s
2014-07-23 17:32:19,090 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:19,092 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:19,092 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at PCA.scala:57)
2014-07-23 17:32:19,092 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 75)
2014-07-23 17:32:19,093 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:19,093 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[77] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:19,095 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 74 (MappedRDD[77] at map at PCA.scala:57)
2014-07-23 17:32:19,095 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 1 tasks
2014-07-23 17:32:19,096 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:19,096 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:19,097 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-23 17:32:19,098 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:19,100 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:19,202 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-23 17:32:19,202 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-23 17:32:19,202 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-23 17:32:19,203 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:32:19,203 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-23 17:32:19,203 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-23 17:32:19,203 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:32:19,203 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113445242 s
2014-07-23 17:32:19,208 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:19,210 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:19,210 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at PCA.scala:57)
2014-07-23 17:32:19,210 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 77)
2014-07-23 17:32:19,211 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:19,211 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[79] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:19,213 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 76 (MappedRDD[79] at map at PCA.scala:57)
2014-07-23 17:32:19,213 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 1 tasks
2014-07-23 17:32:19,214 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:19,214 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:19,215 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-23 17:32:19,216 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:19,218 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:19,313 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-23 17:32:19,314 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-23 17:32:19,314 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-23 17:32:19,315 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:32:19,315 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-23 17:32:19,315 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-23 17:32:19,315 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at PCA.scala:57) finished in 0.102 s
2014-07-23 17:32:19,316 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107144924 s
2014-07-23 17:32:19,321 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:19,323 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:19,323 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at PCA.scala:57)
2014-07-23 17:32:19,323 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 79)
2014-07-23 17:32:19,325 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:19,325 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[81] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:19,327 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 78 (MappedRDD[81] at map at PCA.scala:57)
2014-07-23 17:32:19,327 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 1 tasks
2014-07-23 17:32:19,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:19,329 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2520 bytes in 1 ms
2014-07-23 17:32:19,329 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-23 17:32:19,332 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:19,333 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:19,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-23 17:32:19,439 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-23 17:32:19,441 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:32:19,442 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-23 17:32:19,442 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-23 17:32:19,442 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:32:19,443 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121872631 s
2014-07-23 17:32:19,458 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-23 17:32:19,461 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:19,473 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:19,473 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at PCA.scala:57)
2014-07-23 17:32:19,473 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 81)
2014-07-23 17:32:19,480 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:19,481 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[83] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:19,486 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 80 (MappedRDD[83] at map at PCA.scala:57)
2014-07-23 17:32:19,487 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 1 tasks
2014-07-23 17:32:19,490 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:19,490 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:19,491 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-23 17:32:19,494 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:19,495 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:19,628 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-23 17:32:19,629 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-23 17:32:19,630 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-23 17:32:19,631 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 141 ms on localhost (progress: 1/1)
2014-07-23 17:32:19,631 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-23 17:32:19,631 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-23 17:32:19,631 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at PCA.scala:57) finished in 0.136 s
2014-07-23 17:32:19,632 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.17038515 s
2014-07-23 17:32:19,637 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:19,639 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:19,639 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at PCA.scala:57)
2014-07-23 17:32:19,639 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 83)
2014-07-23 17:32:19,640 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:19,640 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[85] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:19,642 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 82 (MappedRDD[85] at map at PCA.scala:57)
2014-07-23 17:32:19,642 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 1 tasks
2014-07-23 17:32:19,643 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:19,643 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:19,644 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-23 17:32:19,646 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:19,647 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:19,833 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-23 17:32:19,833 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-23 17:32:19,834 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 191 ms on localhost (progress: 1/1)
2014-07-23 17:32:19,835 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-23 17:32:19,836 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-23 17:32:19,836 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at PCA.scala:57) finished in 0.192 s
2014-07-23 17:32:19,837 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.200117492 s
2014-07-23 17:32:19,845 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:19,845 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-23 17:32:19,847 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:19,847 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at PCA.scala:57)
2014-07-23 17:32:19,847 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 85)
2014-07-23 17:32:19,849 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:19,850 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[87] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:19,853 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 84 (MappedRDD[87] at map at PCA.scala:57)
2014-07-23 17:32:19,853 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 1 tasks
2014-07-23 17:32:19,854 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:19,855 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:19,855 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-23 17:32:19,857 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:19,860 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,000 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-23 17:32:20,000 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-23 17:32:20,000 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-23 17:32:20,003 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-23 17:32:20,003 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 149 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,003 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,003 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at PCA.scala:57) finished in 0.144 s
2014-07-23 17:32:20,004 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.159345741 s
2014-07-23 17:32:20,012 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,013 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,013 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at PCA.scala:57)
2014-07-23 17:32:20,014 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 87)
2014-07-23 17:32:20,015 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,016 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[89] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,017 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 86 (MappedRDD[89] at map at PCA.scala:57)
2014-07-23 17:32:20,017 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 1 tasks
2014-07-23 17:32:20,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:20,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-23 17:32:20,021 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,022 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,141 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-23 17:32:20,141 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-23 17:32:20,141 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-23 17:32:20,142 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-23 17:32:20,143 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at PCA.scala:57) finished in 0.125 s
2014-07-23 17:32:20,143 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,143 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,143 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.13115086 s
2014-07-23 17:32:20,148 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,150 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,150 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at PCA.scala:57)
2014-07-23 17:32:20,150 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 89)
2014-07-23 17:32:20,151 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,152 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[91] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,153 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 88 (MappedRDD[91] at map at PCA.scala:57)
2014-07-23 17:32:20,154 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 1 tasks
2014-07-23 17:32:20,154 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,155 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2523 bytes in 1 ms
2014-07-23 17:32:20,155 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-23 17:32:20,157 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,159 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-23 17:32:20,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-23 17:32:20,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-23 17:32:20,275 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-23 17:32:20,275 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 120 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,275 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,275 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:32:20,275 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.126940581 s
2014-07-23 17:32:20,280 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,281 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,281 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at PCA.scala:57)
2014-07-23 17:32:20,281 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 91)
2014-07-23 17:32:20,282 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,283 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[93] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,285 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 90 (MappedRDD[93] at map at PCA.scala:57)
2014-07-23 17:32:20,285 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 1 tasks
2014-07-23 17:32:20,286 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,286 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:20,287 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-23 17:32:20,289 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,290 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-23 17:32:20,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-23 17:32:20,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-23 17:32:20,410 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-23 17:32:20,410 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,410 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,410 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at PCA.scala:57) finished in 0.125 s
2014-07-23 17:32:20,410 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.130345382 s
2014-07-23 17:32:20,415 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,417 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,417 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at PCA.scala:57)
2014-07-23 17:32:20,417 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 93)
2014-07-23 17:32:20,418 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,419 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[95] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,420 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 92 (MappedRDD[95] at map at PCA.scala:57)
2014-07-23 17:32:20,421 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 1 tasks
2014-07-23 17:32:20,421 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,422 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:20,422 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-23 17:32:20,424 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,425 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,543 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-23 17:32:20,543 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-23 17:32:20,543 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-23 17:32:20,547 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 125 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,547 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,547 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-23 17:32:20,548 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at PCA.scala:57) finished in 0.126 s
2014-07-23 17:32:20,548 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.132883394 s
2014-07-23 17:32:20,562 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,564 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,564 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at PCA.scala:57)
2014-07-23 17:32:20,564 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 95)
2014-07-23 17:32:20,565 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,566 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[97] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,567 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 94 (MappedRDD[97] at map at PCA.scala:57)
2014-07-23 17:32:20,567 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 1 tasks
2014-07-23 17:32:20,568 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,568 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:20,569 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-23 17:32:20,571 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,572 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,687 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-23 17:32:20,687 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-23 17:32:20,687 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-23 17:32:20,688 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-23 17:32:20,688 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 120 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,688 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,688 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:32:20,689 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.126558429 s
2014-07-23 17:32:20,694 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,695 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,696 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at PCA.scala:57)
2014-07-23 17:32:20,696 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 97)
2014-07-23 17:32:20,699 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,700 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[99] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,702 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 96 (MappedRDD[99] at map at PCA.scala:57)
2014-07-23 17:32:20,702 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 1 tasks
2014-07-23 17:32:20,703 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,703 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:20,703 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-23 17:32:20,705 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,706 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,818 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-23 17:32:20,818 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-23 17:32:20,818 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-23 17:32:20,819 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-23 17:32:20,819 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,819 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,819 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at PCA.scala:57) finished in 0.117 s
2014-07-23 17:32:20,820 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.125869491 s
2014-07-23 17:32:20,825 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,826 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,826 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at PCA.scala:57)
2014-07-23 17:32:20,826 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 99)
2014-07-23 17:32:20,827 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,828 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[101] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,829 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 98 (MappedRDD[101] at map at PCA.scala:57)
2014-07-23 17:32:20,829 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 1 tasks
2014-07-23 17:32:20,830 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,831 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:20,831 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-23 17:32:20,833 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,834 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:20,957 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-23 17:32:20,957 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-23 17:32:20,960 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 130 ms on localhost (progress: 1/1)
2014-07-23 17:32:20,960 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-23 17:32:20,960 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-23 17:32:20,961 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at PCA.scala:57) finished in 0.130 s
2014-07-23 17:32:20,961 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.136386066 s
2014-07-23 17:32:20,964 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-23 17:32:20,967 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:20,968 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:20,968 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at PCA.scala:57)
2014-07-23 17:32:20,968 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 101)
2014-07-23 17:32:20,969 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:20,970 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[103] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:20,971 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 100 (MappedRDD[103] at map at PCA.scala:57)
2014-07-23 17:32:20,971 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 1 tasks
2014-07-23 17:32:20,972 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:20,972 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:20,973 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-23 17:32:20,974 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:20,976 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-23 17:32:21,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-23 17:32:21,077 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-23 17:32:21,078 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-23 17:32:21,078 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,078 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,078 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:32:21,078 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11154691 s
2014-07-23 17:32:21,083 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,085 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,085 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at PCA.scala:57)
2014-07-23 17:32:21,085 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 103)
2014-07-23 17:32:21,086 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,086 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[105] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,088 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 102 (MappedRDD[105] at map at PCA.scala:57)
2014-07-23 17:32:21,088 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 1 tasks
2014-07-23 17:32:21,089 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,089 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2520 bytes in 0 ms
2014-07-23 17:32:21,090 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-23 17:32:21,091 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,093 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,174 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-23 17:32:21,174 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-23 17:32:21,174 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-23 17:32:21,176 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-23 17:32:21,176 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at PCA.scala:57) finished in 0.088 s
2014-07-23 17:32:21,176 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 86 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,176 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,176 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.093069498 s
2014-07-23 17:32:21,181 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,183 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,183 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at PCA.scala:57)
2014-07-23 17:32:21,183 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 105)
2014-07-23 17:32:21,184 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,184 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[107] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,186 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 104 (MappedRDD[107] at map at PCA.scala:57)
2014-07-23 17:32:21,186 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 1 tasks
2014-07-23 17:32:21,187 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,187 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:21,188 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-23 17:32:21,190 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,191 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-23 17:32:21,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-23 17:32:21,300 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-23 17:32:21,300 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-23 17:32:21,300 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,301 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:32:21,301 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119878735 s
2014-07-23 17:32:21,306 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at PCA.scala:57)
2014-07-23 17:32:21,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 107)
2014-07-23 17:32:21,308 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,309 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[109] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,311 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 106 (MappedRDD[109] at map at PCA.scala:57)
2014-07-23 17:32:21,311 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 1 tasks
2014-07-23 17:32:21,311 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,312 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2522 bytes in 1 ms
2014-07-23 17:32:21,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-23 17:32:21,314 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,315 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,433 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-23 17:32:21,433 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-23 17:32:21,433 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-23 17:32:21,434 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-23 17:32:21,434 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,434 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,435 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:32:21,436 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.129713911 s
2014-07-23 17:32:21,441 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,442 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,442 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at PCA.scala:57)
2014-07-23 17:32:21,442 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 109)
2014-07-23 17:32:21,443 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,444 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[111] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,445 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 108 (MappedRDD[111] at map at PCA.scala:57)
2014-07-23 17:32:21,446 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 1 tasks
2014-07-23 17:32:21,446 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,446 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:21,447 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-23 17:32:21,448 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,450 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,566 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-23 17:32:21,566 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-23 17:32:21,566 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-23 17:32:21,567 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-23 17:32:21,567 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 121 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,567 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,567 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:32:21,567 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.126675884 s
2014-07-23 17:32:21,572 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,574 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,574 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at PCA.scala:57)
2014-07-23 17:32:21,574 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 111)
2014-07-23 17:32:21,575 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,575 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[113] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,577 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 110 (MappedRDD[113] at map at PCA.scala:57)
2014-07-23 17:32:21,577 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 1 tasks
2014-07-23 17:32:21,578 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,578 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:21,579 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-23 17:32:21,581 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,582 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,700 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-23 17:32:21,700 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-23 17:32:21,700 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-23 17:32:21,701 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-23 17:32:21,701 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 124 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,701 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,701 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at PCA.scala:57) finished in 0.124 s
2014-07-23 17:32:21,701 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128977609 s
2014-07-23 17:32:21,706 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,708 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,708 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at PCA.scala:57)
2014-07-23 17:32:21,708 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 113)
2014-07-23 17:32:21,709 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,710 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[115] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,711 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 112 (MappedRDD[115] at map at PCA.scala:57)
2014-07-23 17:32:21,711 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 1 tasks
2014-07-23 17:32:21,712 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,713 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:21,713 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-23 17:32:21,715 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,716 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,846 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-23 17:32:21,846 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-23 17:32:21,847 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-23 17:32:21,847 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-23 17:32:21,847 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 135 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,847 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,848 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at PCA.scala:57) finished in 0.135 s
2014-07-23 17:32:21,848 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.141431216 s
2014-07-23 17:32:21,858 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,860 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,860 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at PCA.scala:57)
2014-07-23 17:32:21,860 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 115)
2014-07-23 17:32:21,861 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,861 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[117] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:21,863 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 114 (MappedRDD[117] at map at PCA.scala:57)
2014-07-23 17:32:21,863 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 1 tasks
2014-07-23 17:32:21,864 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:21,864 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:21,864 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-23 17:32:21,866 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:21,867 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:21,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-23 17:32:21,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-23 17:32:21,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-23 17:32:21,989 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 125 ms on localhost (progress: 1/1)
2014-07-23 17:32:21,989 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-23 17:32:21,989 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-23 17:32:21,989 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at PCA.scala:57) finished in 0.126 s
2014-07-23 17:32:21,989 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.131233887 s
2014-07-23 17:32:21,994 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:21,996 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:21,996 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at PCA.scala:57)
2014-07-23 17:32:21,996 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 117)
2014-07-23 17:32:21,997 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:21,997 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[119] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 116 (MappedRDD[119] at map at PCA.scala:57)
2014-07-23 17:32:22,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 1 tasks
2014-07-23 17:32:22,003 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,003 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:22,009 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-23 17:32:22,011 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,013 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,121 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-23 17:32:22,122 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-23 17:32:22,122 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-23 17:32:22,123 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-23 17:32:22,123 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,123 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,123 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:32:22,123 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12896256 s
2014-07-23 17:32:22,128 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,130 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,130 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at PCA.scala:57)
2014-07-23 17:32:22,130 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 119)
2014-07-23 17:32:22,131 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,131 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[121] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,132 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 118 (MappedRDD[121] at map at PCA.scala:57)
2014-07-23 17:32:22,133 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 1 tasks
2014-07-23 17:32:22,133 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,134 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2522 bytes in 1 ms
2014-07-23 17:32:22,134 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-23 17:32:22,137 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,138 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,261 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-23 17:32:22,261 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-23 17:32:22,261 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-23 17:32:22,261 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-23 17:32:22,262 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 128 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,262 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,262 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at PCA.scala:57) finished in 0.128 s
2014-07-23 17:32:22,262 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.134152203 s
2014-07-23 17:32:22,267 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,269 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,269 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at PCA.scala:57)
2014-07-23 17:32:22,269 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 121)
2014-07-23 17:32:22,270 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,270 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[123] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,272 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 120 (MappedRDD[123] at map at PCA.scala:57)
2014-07-23 17:32:22,272 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 1 tasks
2014-07-23 17:32:22,272 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,273 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:22,273 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-23 17:32:22,274 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,276 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-23 17:32:22,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-23 17:32:22,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-23 17:32:22,384 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 112 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,384 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,384 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-23 17:32:22,384 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at PCA.scala:57) finished in 0.112 s
2014-07-23 17:32:22,385 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117163559 s
2014-07-23 17:32:22,389 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,391 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,391 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 122(reduce at PCA.scala:57)
2014-07-23 17:32:22,391 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 123)
2014-07-23 17:32:22,392 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,392 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 122 (MappedRDD[125] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,394 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 122 (MappedRDD[125] at map at PCA.scala:57)
2014-07-23 17:32:22,394 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 122.0 with 1 tasks
2014-07-23 17:32:22,394 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 122.0:0 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,395 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 122.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:22,395 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-23 17:32:22,396 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,398 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-23 17:32:22,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-23 17:32:22,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-23 17:32:22,509 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(122, 0)
2014-07-23 17:32:22,510 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 122 (reduce at PCA.scala:57) finished in 0.115 s
2014-07-23 17:32:22,510 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.120384256 s
2014-07-23 17:32:22,509 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 115 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,510 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,515 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,516 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,516 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 124(reduce at PCA.scala:57)
2014-07-23 17:32:22,516 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 125)
2014-07-23 17:32:22,517 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,517 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 124 (MappedRDD[127] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,519 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 124 (MappedRDD[127] at map at PCA.scala:57)
2014-07-23 17:32:22,519 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 124.0 with 1 tasks
2014-07-23 17:32:22,520 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 124.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,520 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 124.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:22,524 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-23 17:32:22,525 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,526 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,626 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-23 17:32:22,626 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-23 17:32:22,626 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-23 17:32:22,627 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(124, 0)
2014-07-23 17:32:22,628 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 124 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:32:22,627 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,628 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,628 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113222071 s
2014-07-23 17:32:22,633 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,635 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,635 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 126(reduce at PCA.scala:57)
2014-07-23 17:32:22,635 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 127)
2014-07-23 17:32:22,636 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,638 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 126 (MappedRDD[129] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,640 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 126 (MappedRDD[129] at map at PCA.scala:57)
2014-07-23 17:32:22,641 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 126.0 with 1 tasks
2014-07-23 17:32:22,642 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 126.0:0 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,642 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 126.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:22,643 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-23 17:32:22,645 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,648 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-23 17:32:22,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-23 17:32:22,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-23 17:32:22,738 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 97 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,738 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,738 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(126, 0)
2014-07-23 17:32:22,738 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 126 (reduce at PCA.scala:57) finished in 0.097 s
2014-07-23 17:32:22,739 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105488529 s
2014-07-23 17:32:22,745 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,748 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,748 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 128(reduce at PCA.scala:57)
2014-07-23 17:32:22,748 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 129)
2014-07-23 17:32:22,754 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,754 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 128 (MappedRDD[131] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,756 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 128 (MappedRDD[131] at map at PCA.scala:57)
2014-07-23 17:32:22,756 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 128.0 with 1 tasks
2014-07-23 17:32:22,757 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 128.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,758 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 128.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:22,758 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-23 17:32:22,760 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:22,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-23 17:32:22,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-23 17:32:22,885 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-23 17:32:22,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(128, 0)
2014-07-23 17:32:22,886 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 129 ms on localhost (progress: 1/1)
2014-07-23 17:32:22,886 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 128.0, whose tasks have all completed, from pool 
2014-07-23 17:32:22,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 128 (reduce at PCA.scala:57) finished in 0.128 s
2014-07-23 17:32:22,887 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.141320673 s
2014-07-23 17:32:22,892 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:22,893 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:22,893 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 130(reduce at PCA.scala:57)
2014-07-23 17:32:22,894 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 131)
2014-07-23 17:32:22,895 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:22,895 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 130 (MappedRDD[133] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:22,897 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 130 (MappedRDD[133] at map at PCA.scala:57)
2014-07-23 17:32:22,897 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 130.0 with 1 tasks
2014-07-23 17:32:22,897 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 130.0:0 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:22,898 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 130.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:22,898 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-23 17:32:22,900 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:22,901 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-23 17:32:23,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-23 17:32:23,021 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(130, 0)
2014-07-23 17:32:23,021 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 130 (reduce at PCA.scala:57) finished in 0.124 s
2014-07-23 17:32:23,021 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-23 17:32:23,021 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.129346837 s
2014-07-23 17:32:23,021 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,021 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,026 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,028 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,028 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 132(reduce at PCA.scala:57)
2014-07-23 17:32:23,028 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 133)
2014-07-23 17:32:23,029 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,029 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 132 (MappedRDD[135] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,031 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 132 (MappedRDD[135] at map at PCA.scala:57)
2014-07-23 17:32:23,031 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 132.0 with 1 tasks
2014-07-23 17:32:23,032 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 132.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,032 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 132.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:23,032 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-23 17:32:23,034 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,035 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-23 17:32:23,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-23 17:32:23,168 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-23 17:32:23,168 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(132, 0)
2014-07-23 17:32:23,168 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 137 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,168 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,168 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 132 (reduce at PCA.scala:57) finished in 0.137 s
2014-07-23 17:32:23,169 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.142656036 s
2014-07-23 17:32:23,179 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,181 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,181 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 134(reduce at PCA.scala:57)
2014-07-23 17:32:23,181 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 135)
2014-07-23 17:32:23,182 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,183 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 134 (MappedRDD[137] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,184 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 134 (MappedRDD[137] at map at PCA.scala:57)
2014-07-23 17:32:23,184 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 134.0 with 1 tasks
2014-07-23 17:32:23,185 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 134.0:0 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,185 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 134.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:23,185 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-23 17:32:23,187 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,188 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-23 17:32:23,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-23 17:32:23,299 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-23 17:32:23,300 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,300 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 134.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,300 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(134, 0)
2014-07-23 17:32:23,300 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 134 (reduce at PCA.scala:57) finished in 0.116 s
2014-07-23 17:32:23,300 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.120880365 s
2014-07-23 17:32:23,305 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 136(reduce at PCA.scala:57)
2014-07-23 17:32:23,307 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 137)
2014-07-23 17:32:23,308 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,308 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 136 (MappedRDD[139] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,310 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 136 (MappedRDD[139] at map at PCA.scala:57)
2014-07-23 17:32:23,310 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 136.0 with 1 tasks
2014-07-23 17:32:23,311 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 136.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,311 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 136.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:23,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-23 17:32:23,313 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,314 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-23 17:32:23,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-23 17:32:23,418 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-23 17:32:23,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(136, 0)
2014-07-23 17:32:23,419 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,419 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 136.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,419 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 136 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:32:23,420 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114283575 s
2014-07-23 17:32:23,425 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,427 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,427 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 138(reduce at PCA.scala:57)
2014-07-23 17:32:23,427 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 139)
2014-07-23 17:32:23,428 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,428 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 138 (MappedRDD[141] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,429 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 138 (MappedRDD[141] at map at PCA.scala:57)
2014-07-23 17:32:23,429 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 138.0 with 1 tasks
2014-07-23 17:32:23,430 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 138.0:0 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,430 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 138.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:23,431 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-23 17:32:23,432 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,433 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,546 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-23 17:32:23,546 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-23 17:32:23,546 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-23 17:32:23,548 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 118 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,548 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,549 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(138, 0)
2014-07-23 17:32:23,549 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 138 (reduce at PCA.scala:57) finished in 0.119 s
2014-07-23 17:32:23,552 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.126867186 s
2014-07-23 17:32:23,558 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,560 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,560 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 140(reduce at PCA.scala:57)
2014-07-23 17:32:23,560 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 141)
2014-07-23 17:32:23,562 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,563 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 140 (MappedRDD[143] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,564 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 140 (MappedRDD[143] at map at PCA.scala:57)
2014-07-23 17:32:23,564 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 140.0 with 1 tasks
2014-07-23 17:32:23,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 140.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 140.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:23,565 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-23 17:32:23,567 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,568 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,677 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-23 17:32:23,677 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-23 17:32:23,678 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-23 17:32:23,678 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(140, 0)
2014-07-23 17:32:23,678 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 113 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,679 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 140.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,679 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 140 (reduce at PCA.scala:57) finished in 0.115 s
2014-07-23 17:32:23,679 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.120739553 s
2014-07-23 17:32:23,684 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,685 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,685 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 142(reduce at PCA.scala:57)
2014-07-23 17:32:23,685 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 143)
2014-07-23 17:32:23,686 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,687 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 142 (MappedRDD[145] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,688 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 142 (MappedRDD[145] at map at PCA.scala:57)
2014-07-23 17:32:23,688 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 142.0 with 1 tasks
2014-07-23 17:32:23,689 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 142.0:0 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,689 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 142.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:23,690 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-23 17:32:23,692 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,693 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-23 17:32:23,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-23 17:32:23,810 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-23 17:32:23,810 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(142, 0)
2014-07-23 17:32:23,810 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 121 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,810 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 142.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,810 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 142 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:32:23,810 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.126438183 s
2014-07-23 17:32:23,815 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,816 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,817 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 144(reduce at PCA.scala:57)
2014-07-23 17:32:23,817 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 145)
2014-07-23 17:32:23,817 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,818 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 144 (MappedRDD[147] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,819 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 144 (MappedRDD[147] at map at PCA.scala:57)
2014-07-23 17:32:23,819 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 144.0 with 1 tasks
2014-07-23 17:32:23,820 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 144.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,820 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 144.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:23,821 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-23 17:32:23,822 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,823 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:23,933 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-23 17:32:23,933 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-23 17:32:23,934 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:32:23,934 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2014-07-23 17:32:23,934 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(144, 0)
2014-07-23 17:32:23,934 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 144 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:32:23,935 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119917329 s
2014-07-23 17:32:23,939 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-23 17:32:23,940 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:23,942 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:23,942 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 146(reduce at PCA.scala:57)
2014-07-23 17:32:23,942 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 147)
2014-07-23 17:32:23,944 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:23,944 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 146 (MappedRDD[149] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:23,946 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 146 (MappedRDD[149] at map at PCA.scala:57)
2014-07-23 17:32:23,946 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 146.0 with 1 tasks
2014-07-23 17:32:23,947 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 146.0:0 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:23,947 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 146.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:23,948 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-23 17:32:23,949 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:23,951 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,054 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-23 17:32:24,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-23 17:32:24,055 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-23 17:32:24,055 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,056 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 146.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,056 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(146, 0)
2014-07-23 17:32:24,056 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 146 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:32:24,056 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.115598786 s
2014-07-23 17:32:24,062 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,064 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,064 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 148(reduce at PCA.scala:57)
2014-07-23 17:32:24,064 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 149)
2014-07-23 17:32:24,065 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,065 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 148 (MappedRDD[151] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,067 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 148 (MappedRDD[151] at map at PCA.scala:57)
2014-07-23 17:32:24,067 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 148.0 with 1 tasks
2014-07-23 17:32:24,067 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 148.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,068 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 148.0:0 as 2527 bytes in 0 ms
2014-07-23 17:32:24,068 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-23 17:32:24,070 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,071 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,169 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-23 17:32:24,170 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-23 17:32:24,172 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 104 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,172 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,172 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(148, 0)
2014-07-23 17:32:24,173 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 148 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:32:24,173 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.110934474 s
2014-07-23 17:32:24,177 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-23 17:32:24,180 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,181 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,181 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 150(reduce at PCA.scala:57)
2014-07-23 17:32:24,181 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 151)
2014-07-23 17:32:24,182 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,182 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 150 (MappedRDD[153] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,184 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 150 (MappedRDD[153] at map at PCA.scala:57)
2014-07-23 17:32:24,184 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 150.0 with 1 tasks
2014-07-23 17:32:24,185 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 150.0:0 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,185 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 150.0:0 as 2521 bytes in 0 ms
2014-07-23 17:32:24,186 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-23 17:32:24,187 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,188 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,268 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-23 17:32:24,268 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-23 17:32:24,269 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-23 17:32:24,270 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 86 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,271 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,271 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(150, 0)
2014-07-23 17:32:24,271 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 150 (reduce at PCA.scala:57) finished in 0.086 s
2014-07-23 17:32:24,271 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.091575895 s
2014-07-23 17:32:24,276 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,278 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,278 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 152(reduce at PCA.scala:57)
2014-07-23 17:32:24,278 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 153)
2014-07-23 17:32:24,279 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,280 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 152 (MappedRDD[155] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,281 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 152 (MappedRDD[155] at map at PCA.scala:57)
2014-07-23 17:32:24,281 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 152.0 with 1 tasks
2014-07-23 17:32:24,282 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 152.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,282 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 152.0:0 as 2526 bytes in 0 ms
2014-07-23 17:32:24,283 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-23 17:32:24,284 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,285 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,404 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-23 17:32:24,404 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-23 17:32:24,405 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-23 17:32:24,406 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,406 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 152.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,406 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(152, 0)
2014-07-23 17:32:24,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 152 (reduce at PCA.scala:57) finished in 0.125 s
2014-07-23 17:32:24,408 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.131639179 s
2014-07-23 17:32:24,419 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,421 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,421 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 154(reduce at PCA.scala:57)
2014-07-23 17:32:24,421 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 155)
2014-07-23 17:32:24,422 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,423 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 154 (MappedRDD[157] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,424 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 154 (MappedRDD[157] at map at PCA.scala:57)
2014-07-23 17:32:24,424 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 154.0 with 1 tasks
2014-07-23 17:32:24,425 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 154.0:0 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,425 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 154.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:24,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-23 17:32:24,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,428 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-23 17:32:24,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-23 17:32:24,535 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-23 17:32:24,536 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(154, 0)
2014-07-23 17:32:24,537 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 111 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,537 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 154.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,537 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 154 (reduce at PCA.scala:57) finished in 0.113 s
2014-07-23 17:32:24,537 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117805263 s
2014-07-23 17:32:24,543 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,545 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,545 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 156(reduce at PCA.scala:57)
2014-07-23 17:32:24,545 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 157)
2014-07-23 17:32:24,546 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,546 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 156 (MappedRDD[159] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,548 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 156 (MappedRDD[159] at map at PCA.scala:57)
2014-07-23 17:32:24,548 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 156.0 with 1 tasks
2014-07-23 17:32:24,548 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 156.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,549 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 156.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:24,549 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-23 17:32:24,550 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,552 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-23 17:32:24,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-23 17:32:24,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-23 17:32:24,664 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(156, 0)
2014-07-23 17:32:24,664 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 116 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,664 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,664 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 156 (reduce at PCA.scala:57) finished in 0.116 s
2014-07-23 17:32:24,665 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.12146511 s
2014-07-23 17:32:24,671 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,672 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,672 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 158(reduce at PCA.scala:57)
2014-07-23 17:32:24,672 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 159)
2014-07-23 17:32:24,673 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,674 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 158 (MappedRDD[161] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,675 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 158 (MappedRDD[161] at map at PCA.scala:57)
2014-07-23 17:32:24,675 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 158.0 with 1 tasks
2014-07-23 17:32:24,676 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 158.0:0 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,676 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 158.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:24,676 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-23 17:32:24,678 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,679 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,781 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-23 17:32:24,781 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-23 17:32:24,781 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-23 17:32:24,783 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(158, 0)
2014-07-23 17:32:24,783 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 158 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:32:24,783 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,783 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 158.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,783 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112259588 s
2014-07-23 17:32:24,788 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,789 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,789 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 160(reduce at PCA.scala:57)
2014-07-23 17:32:24,789 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 161)
2014-07-23 17:32:24,791 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,791 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 160 (MappedRDD[163] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,792 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 160 (MappedRDD[163] at map at PCA.scala:57)
2014-07-23 17:32:24,793 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 160.0 with 1 tasks
2014-07-23 17:32:24,793 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 160.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,793 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 160.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:24,794 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-23 17:32:24,795 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,796 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:24,906 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-23 17:32:24,907 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-23 17:32:24,907 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-23 17:32:24,907 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(160, 0)
2014-07-23 17:32:24,907 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 114 ms on localhost (progress: 1/1)
2014-07-23 17:32:24,908 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 160 (reduce at PCA.scala:57) finished in 0.114 s
2014-07-23 17:32:24,908 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.119900239 s
2014-07-23 17:32:24,908 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 160.0, whose tasks have all completed, from pool 
2014-07-23 17:32:24,913 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:24,914 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:24,914 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 162(reduce at PCA.scala:57)
2014-07-23 17:32:24,914 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 163)
2014-07-23 17:32:24,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:24,916 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 162 (MappedRDD[165] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:24,917 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 162 (MappedRDD[165] at map at PCA.scala:57)
2014-07-23 17:32:24,917 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 162.0 with 1 tasks
2014-07-23 17:32:24,918 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 162.0:0 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:24,918 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 162.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:24,918 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-23 17:32:24,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:24,921 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-23 17:32:25,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-23 17:32:25,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-23 17:32:25,035 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(162, 0)
2014-07-23 17:32:25,035 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 162 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:32:25,035 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 117 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,036 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,036 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.122978646 s
2014-07-23 17:32:25,040 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,042 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,042 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 164(reduce at PCA.scala:57)
2014-07-23 17:32:25,042 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 165)
2014-07-23 17:32:25,043 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,043 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 164 (MappedRDD[167] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,045 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 164 (MappedRDD[167] at map at PCA.scala:57)
2014-07-23 17:32:25,045 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 164.0 with 1 tasks
2014-07-23 17:32:25,045 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 164.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,045 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 164.0:0 as 2526 bytes in 0 ms
2014-07-23 17:32:25,046 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-23 17:32:25,047 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,048 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-23 17:32:25,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-23 17:32:25,167 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-23 17:32:25,168 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(164, 0)
2014-07-23 17:32:25,168 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 123 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,168 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,168 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 164 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:32:25,169 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128089727 s
2014-07-23 17:32:25,175 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,177 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,177 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 166(reduce at PCA.scala:57)
2014-07-23 17:32:25,177 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 167)
2014-07-23 17:32:25,178 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,179 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 166 (MappedRDD[169] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,180 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 166 (MappedRDD[169] at map at PCA.scala:57)
2014-07-23 17:32:25,181 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 166.0 with 1 tasks
2014-07-23 17:32:25,181 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 166.0:0 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,182 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 166.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:25,182 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-23 17:32:25,183 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,185 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,319 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-23 17:32:25,319 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-23 17:32:25,320 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-23 17:32:25,320 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(166, 0)
2014-07-23 17:32:25,320 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 139 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,320 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,320 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 166 (reduce at PCA.scala:57) finished in 0.129 s
2014-07-23 17:32:25,321 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.145434182 s
2014-07-23 17:32:25,327 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 168(reduce at PCA.scala:57)
2014-07-23 17:32:25,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 169)
2014-07-23 17:32:25,330 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,330 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 168 (MappedRDD[171] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 168 (MappedRDD[171] at map at PCA.scala:57)
2014-07-23 17:32:25,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 168.0 with 1 tasks
2014-07-23 17:32:25,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 168.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 168.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:25,334 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-23 17:32:25,335 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,337 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,466 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-23 17:32:25,466 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-23 17:32:25,466 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-23 17:32:25,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(168, 0)
2014-07-23 17:32:25,469 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 136 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,469 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,469 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 168 (reduce at PCA.scala:57) finished in 0.128 s
2014-07-23 17:32:25,471 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.143795129 s
2014-07-23 17:32:25,478 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,481 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,481 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 170(reduce at PCA.scala:57)
2014-07-23 17:32:25,481 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 171)
2014-07-23 17:32:25,483 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,483 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 170 (MappedRDD[173] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,486 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 170 (MappedRDD[173] at map at PCA.scala:57)
2014-07-23 17:32:25,486 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 170.0 with 1 tasks
2014-07-23 17:32:25,487 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 170.0:0 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,487 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 170.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:25,488 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-23 17:32:25,490 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,491 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,631 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-23 17:32:25,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-23 17:32:25,632 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-23 17:32:25,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(170, 0)
2014-07-23 17:32:25,633 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 146 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,633 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 170 (reduce at PCA.scala:57) finished in 0.138 s
2014-07-23 17:32:25,633 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.154936532 s
2014-07-23 17:32:25,638 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 172(reduce at PCA.scala:57)
2014-07-23 17:32:25,639 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 173)
2014-07-23 17:32:25,640 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,641 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 172 (MappedRDD[175] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,643 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 172 (MappedRDD[175] at map at PCA.scala:57)
2014-07-23 17:32:25,643 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 172.0 with 1 tasks
2014-07-23 17:32:25,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 172.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,644 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 172.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:25,644 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-23 17:32:25,646 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,647 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,754 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-23 17:32:25,754 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-23 17:32:25,754 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-23 17:32:25,755 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(172, 0)
2014-07-23 17:32:25,755 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,755 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 172 (reduce at PCA.scala:57) finished in 0.112 s
2014-07-23 17:32:25,755 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 172.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,755 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117374681 s
2014-07-23 17:32:25,773 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,774 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,774 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 174(reduce at PCA.scala:57)
2014-07-23 17:32:25,774 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 175)
2014-07-23 17:32:25,775 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,775 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 174 (MappedRDD[177] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,777 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 174 (MappedRDD[177] at map at PCA.scala:57)
2014-07-23 17:32:25,777 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 174.0 with 1 tasks
2014-07-23 17:32:25,778 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 174.0:0 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,778 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 174.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:25,779 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-23 17:32:25,780 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,782 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:25,882 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-23 17:32:25,882 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-23 17:32:25,883 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-23 17:32:25,884 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 106 ms on localhost (progress: 1/1)
2014-07-23 17:32:25,884 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(174, 0)
2014-07-23 17:32:25,884 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2014-07-23 17:32:25,884 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 174 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:32:25,884 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.1116049 s
2014-07-23 17:32:25,895 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:25,896 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:25,896 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 176(reduce at PCA.scala:57)
2014-07-23 17:32:25,896 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 177)
2014-07-23 17:32:25,897 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:25,897 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 176 (MappedRDD[179] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:25,899 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 176 (MappedRDD[179] at map at PCA.scala:57)
2014-07-23 17:32:25,899 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 176.0 with 1 tasks
2014-07-23 17:32:25,900 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 176.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:25,900 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 176.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:25,900 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-23 17:32:25,902 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:25,903 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:26,006 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-23 17:32:26,006 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-23 17:32:26,007 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(176, 0)
2014-07-23 17:32:26,007 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 176 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:32:26,007 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:32:26,007 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 176.0, whose tasks have all completed, from pool 
2014-07-23 17:32:26,008 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112642658 s
2014-07-23 17:32:26,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-23 17:32:26,013 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:26,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:26,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 178(reduce at PCA.scala:57)
2014-07-23 17:32:26,015 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 179)
2014-07-23 17:32:26,016 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:26,016 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 178 (MappedRDD[181] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:26,018 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 178 (MappedRDD[181] at map at PCA.scala:57)
2014-07-23 17:32:26,018 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 178.0 with 1 tasks
2014-07-23 17:32:26,018 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 178.0:0 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:26,019 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 178.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:26,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-23 17:32:26,020 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:26,021 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:26,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-23 17:32:26,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-23 17:32:26,129 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-23 17:32:26,130 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(178, 0)
2014-07-23 17:32:26,130 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 112 ms on localhost (progress: 1/1)
2014-07-23 17:32:26,130 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 178.0, whose tasks have all completed, from pool 
2014-07-23 17:32:26,130 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 178 (reduce at PCA.scala:57) finished in 0.112 s
2014-07-23 17:32:26,130 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.117749447 s
2014-07-23 17:32:26,136 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:26,137 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:26,137 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 180(reduce at PCA.scala:57)
2014-07-23 17:32:26,137 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 181)
2014-07-23 17:32:26,138 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:26,138 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 180 (MappedRDD[183] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:26,140 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 180 (MappedRDD[183] at map at PCA.scala:57)
2014-07-23 17:32:26,140 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 180.0 with 1 tasks
2014-07-23 17:32:26,141 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 180.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:26,141 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 180.0:0 as 2526 bytes in 0 ms
2014-07-23 17:32:26,141 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-23 17:32:26,143 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:26,144 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:26,380 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-23 17:32:26,382 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-23 17:32:26,387 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 247 ms on localhost (progress: 1/1)
2014-07-23 17:32:26,387 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2014-07-23 17:32:26,387 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(180, 0)
2014-07-23 17:32:26,388 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 180 (reduce at PCA.scala:57) finished in 0.247 s
2014-07-23 17:32:26,388 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.252315581 s
2014-07-23 17:32:26,395 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:26,401 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:26,401 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 182(reduce at PCA.scala:57)
2014-07-23 17:32:26,401 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 183)
2014-07-23 17:32:26,402 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:26,403 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 182 (MappedRDD[185] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:26,404 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 182 (MappedRDD[185] at map at PCA.scala:57)
2014-07-23 17:32:26,404 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 182.0 with 1 tasks
2014-07-23 17:32:26,405 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 182.0:0 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:26,406 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 182.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:26,407 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-23 17:32:26,409 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-23 17:32:26,415 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:26,416 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:26,719 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-23 17:32:26,719 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-23 17:32:26,719 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-23 17:32:26,720 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(182, 0)
2014-07-23 17:32:26,720 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 314 ms on localhost (progress: 1/1)
2014-07-23 17:32:26,720 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 182 (reduce at PCA.scala:57) finished in 0.314 s
2014-07-23 17:32:26,720 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2014-07-23 17:32:26,720 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.325760125 s
2014-07-23 17:32:26,727 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:26,728 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:26,729 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 184(reduce at PCA.scala:57)
2014-07-23 17:32:26,729 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 185)
2014-07-23 17:32:26,730 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:26,730 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 184 (MappedRDD[187] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:26,732 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 184 (MappedRDD[187] at map at PCA.scala:57)
2014-07-23 17:32:26,732 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 184.0 with 1 tasks
2014-07-23 17:32:26,733 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 184.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:26,733 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 184.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:26,733 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-23 17:32:26,735 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:26,737 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:26,992 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-23 17:32:26,993 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-23 17:32:26,993 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-23 17:32:26,994 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 261 ms on localhost (progress: 1/1)
2014-07-23 17:32:26,994 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2014-07-23 17:32:26,994 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(184, 0)
2014-07-23 17:32:26,994 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 184 (reduce at PCA.scala:57) finished in 0.254 s
2014-07-23 17:32:26,995 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.267768143 s
2014-07-23 17:32:27,001 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:27,004 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:27,004 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 186(reduce at PCA.scala:57)
2014-07-23 17:32:27,005 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 187)
2014-07-23 17:32:27,006 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:27,007 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 186 (MappedRDD[189] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:27,008 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 186 (MappedRDD[189] at map at PCA.scala:57)
2014-07-23 17:32:27,009 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 186.0 with 1 tasks
2014-07-23 17:32:27,010 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 186.0:0 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:27,010 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 186.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:27,013 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-23 17:32:27,014 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:27,015 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:27,160 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-23 17:32:27,161 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-23 17:32:27,162 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 152 ms on localhost (progress: 1/1)
2014-07-23 17:32:27,162 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2014-07-23 17:32:27,162 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(186, 0)
2014-07-23 17:32:27,162 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 186 (reduce at PCA.scala:57) finished in 0.152 s
2014-07-23 17:32:27,163 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.161737275 s
2014-07-23 17:32:27,170 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-23 17:32:27,171 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:27,172 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:27,172 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 188(reduce at PCA.scala:57)
2014-07-23 17:32:27,172 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 189)
2014-07-23 17:32:27,174 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:27,174 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 188 (MappedRDD[191] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:27,176 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 188 (MappedRDD[191] at map at PCA.scala:57)
2014-07-23 17:32:27,176 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 188.0 with 1 tasks
2014-07-23 17:32:27,176 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 188.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:27,177 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 188.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:27,177 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-23 17:32:27,179 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:27,180 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:27,306 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-23 17:32:27,306 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-23 17:32:27,307 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 131 ms on localhost (progress: 1/1)
2014-07-23 17:32:27,307 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 188.0, whose tasks have all completed, from pool 
2014-07-23 17:32:27,307 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(188, 0)
2014-07-23 17:32:27,308 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 188 (reduce at PCA.scala:57) finished in 0.131 s
2014-07-23 17:32:27,308 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.137741225 s
2014-07-23 17:32:27,324 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:27,325 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-23 17:32:27,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:27,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 190(reduce at PCA.scala:57)
2014-07-23 17:32:27,328 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 191)
2014-07-23 17:32:27,330 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:27,330 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 190 (MappedRDD[193] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:27,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 190 (MappedRDD[193] at map at PCA.scala:57)
2014-07-23 17:32:27,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 190.0 with 1 tasks
2014-07-23 17:32:27,333 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 190.0:0 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:27,334 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 190.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:27,335 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-23 17:32:27,338 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:27,345 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:27,469 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-23 17:32:27,469 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-23 17:32:27,471 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 138 ms on localhost (progress: 1/1)
2014-07-23 17:32:27,472 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 190.0, whose tasks have all completed, from pool 
2014-07-23 17:32:27,472 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(190, 0)
2014-07-23 17:32:27,474 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 190 (reduce at PCA.scala:57) finished in 0.138 s
2014-07-23 17:32:27,474 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.149749217 s
2014-07-23 17:32:27,487 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-23 17:32:27,488 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:27,491 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:27,491 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 192(reduce at PCA.scala:57)
2014-07-23 17:32:27,491 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 193)
2014-07-23 17:32:27,492 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:27,493 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 192 (MappedRDD[195] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:27,496 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 192 (MappedRDD[195] at map at PCA.scala:57)
2014-07-23 17:32:27,496 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 192.0 with 1 tasks
2014-07-23 17:32:27,497 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 192.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:27,497 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 192.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:27,498 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-23 17:32:27,499 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:27,503 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:27,649 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-23 17:32:27,649 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-23 17:32:27,650 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 153 ms on localhost (progress: 1/1)
2014-07-23 17:32:27,650 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2014-07-23 17:32:27,650 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(192, 0)
2014-07-23 17:32:27,651 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 192 (reduce at PCA.scala:57) finished in 0.151 s
2014-07-23 17:32:27,651 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.162813872 s
2014-07-23 17:32:27,663 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-23 17:32:27,664 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:27,666 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:27,666 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 194(reduce at PCA.scala:57)
2014-07-23 17:32:27,666 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 195)
2014-07-23 17:32:27,668 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:27,668 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 194 (MappedRDD[197] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:27,672 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 194 (MappedRDD[197] at map at PCA.scala:57)
2014-07-23 17:32:27,672 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 194.0 with 1 tasks
2014-07-23 17:32:27,673 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 194.0:0 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:27,673 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 194.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:27,674 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-23 17:32:27,676 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:27,679 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:27,854 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-23 17:32:27,854 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-23 17:32:27,855 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 182 ms on localhost (progress: 1/1)
2014-07-23 17:32:27,855 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2014-07-23 17:32:27,855 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(194, 0)
2014-07-23 17:32:27,856 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 194 (reduce at PCA.scala:57) finished in 0.181 s
2014-07-23 17:32:27,856 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.191804574 s
2014-07-23 17:32:27,864 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-23 17:32:27,882 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:27,884 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:27,884 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 196(reduce at PCA.scala:57)
2014-07-23 17:32:27,884 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 197)
2014-07-23 17:32:27,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:27,887 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 196 (MappedRDD[199] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:27,889 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 196 (MappedRDD[199] at map at PCA.scala:57)
2014-07-23 17:32:27,889 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 196.0 with 1 tasks
2014-07-23 17:32:27,890 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 196.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:27,890 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 196.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:27,890 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-23 17:32:27,892 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:27,893 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:28,096 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-23 17:32:28,103 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-23 17:32:28,104 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 214 ms on localhost (progress: 1/1)
2014-07-23 17:32:28,105 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 196.0, whose tasks have all completed, from pool 
2014-07-23 17:32:28,105 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(196, 0)
2014-07-23 17:32:28,105 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 196 (reduce at PCA.scala:57) finished in 0.215 s
2014-07-23 17:32:28,106 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.223410041 s
2014-07-23 17:32:28,114 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:28,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-23 17:32:28,117 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:28,117 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 198(reduce at PCA.scala:57)
2014-07-23 17:32:28,117 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 199)
2014-07-23 17:32:28,122 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:28,122 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 198 (MappedRDD[201] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:28,124 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 198 (MappedRDD[201] at map at PCA.scala:57)
2014-07-23 17:32:28,124 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 198.0 with 1 tasks
2014-07-23 17:32:28,125 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 198.0:0 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:28,125 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 198.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:28,127 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-23 17:32:28,132 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:28,137 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:28,355 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-23 17:32:28,355 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-23 17:32:28,356 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 231 ms on localhost (progress: 1/1)
2014-07-23 17:32:28,356 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2014-07-23 17:32:28,356 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(198, 0)
2014-07-23 17:32:28,356 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 198 (reduce at PCA.scala:57) finished in 0.229 s
2014-07-23 17:32:28,357 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.242393668 s
2014-07-23 17:32:28,364 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:28,365 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:28,365 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 200(reduce at PCA.scala:57)
2014-07-23 17:32:28,365 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 201)
2014-07-23 17:32:28,367 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:28,367 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 200 (MappedRDD[203] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:28,370 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 200 (MappedRDD[203] at map at PCA.scala:57)
2014-07-23 17:32:28,370 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 200.0 with 1 tasks
2014-07-23 17:32:28,370 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 200.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:28,371 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 200.0:0 as 2524 bytes in 1 ms
2014-07-23 17:32:28,371 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-23 17:32:28,372 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:28,373 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:28,381 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-23 17:32:28,497 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-23 17:32:28,497 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-23 17:32:28,497 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-23 17:32:28,498 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(200, 0)
2014-07-23 17:32:28,498 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 128 ms on localhost (progress: 1/1)
2014-07-23 17:32:28,498 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2014-07-23 17:32:28,498 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 200 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:32:28,499 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.134661962 s
2014-07-23 17:32:28,505 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:28,506 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:28,506 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 202(reduce at PCA.scala:57)
2014-07-23 17:32:28,507 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 203)
2014-07-23 17:32:28,507 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:28,508 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 202 (MappedRDD[205] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:28,510 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 202 (MappedRDD[205] at map at PCA.scala:57)
2014-07-23 17:32:28,510 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 202.0 with 1 tasks
2014-07-23 17:32:28,510 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 202.0:0 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:28,511 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 202.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:28,511 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-23 17:32:28,513 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:28,514 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:28,612 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-23 17:32:28,612 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-23 17:32:28,613 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-23 17:32:28,613 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(202, 0)
2014-07-23 17:32:28,613 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:32:28,613 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 202.0, whose tasks have all completed, from pool 
2014-07-23 17:32:28,613 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 202 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:32:28,614 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109082646 s
2014-07-23 17:32:28,621 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:28,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:28,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 204(reduce at PCA.scala:57)
2014-07-23 17:32:28,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 205)
2014-07-23 17:32:28,624 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:28,624 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 204 (MappedRDD[207] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:28,626 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 204 (MappedRDD[207] at map at PCA.scala:57)
2014-07-23 17:32:28,626 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 1 tasks
2014-07-23 17:32:28,627 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 204.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:28,627 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 204.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:28,627 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-23 17:32:28,629 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:28,630 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:28,745 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-23 17:32:28,746 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-23 17:32:28,746 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-23 17:32:28,746 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:32:28,747 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2014-07-23 17:32:28,747 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(204, 0)
2014-07-23 17:32:28,747 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 204 (reduce at PCA.scala:57) finished in 0.121 s
2014-07-23 17:32:28,747 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.125750333 s
2014-07-23 17:32:28,756 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:28,758 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:28,758 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 206(reduce at PCA.scala:57)
2014-07-23 17:32:28,758 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 207)
2014-07-23 17:32:28,759 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:28,760 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 206 (MappedRDD[209] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:28,761 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 206 (MappedRDD[209] at map at PCA.scala:57)
2014-07-23 17:32:28,761 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 206.0 with 1 tasks
2014-07-23 17:32:28,762 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 206.0:0 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:28,762 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 206.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:28,762 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-23 17:32:28,764 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:28,765 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:28,871 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-23 17:32:28,872 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-23 17:32:28,872 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-23 17:32:28,872 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(206, 0)
2014-07-23 17:32:28,872 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 110 ms on localhost (progress: 1/1)
2014-07-23 17:32:28,872 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2014-07-23 17:32:28,873 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 206 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:32:28,873 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.116792437 s
2014-07-23 17:32:28,878 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:28,879 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:28,879 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 208(reduce at PCA.scala:57)
2014-07-23 17:32:28,879 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 209)
2014-07-23 17:32:28,880 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:28,881 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 208 (MappedRDD[211] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:28,882 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 208 (MappedRDD[211] at map at PCA.scala:57)
2014-07-23 17:32:28,882 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 208.0 with 1 tasks
2014-07-23 17:32:28,882 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 208.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:28,883 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 208.0:0 as 2523 bytes in 1 ms
2014-07-23 17:32:28,883 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-23 17:32:28,884 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:28,885 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:29,000 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-23 17:32:29,001 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-23 17:32:29,001 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-23 17:32:29,001 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 119 ms on localhost (progress: 1/1)
2014-07-23 17:32:29,002 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 208.0, whose tasks have all completed, from pool 
2014-07-23 17:32:29,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(208, 0)
2014-07-23 17:32:29,002 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 208 (reduce at PCA.scala:57) finished in 0.120 s
2014-07-23 17:32:29,002 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.124061434 s
2014-07-23 17:32:29,008 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:29,010 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:29,010 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 210(reduce at PCA.scala:57)
2014-07-23 17:32:29,010 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 211)
2014-07-23 17:32:29,011 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:29,011 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 210 (MappedRDD[213] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:29,013 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 210 (MappedRDD[213] at map at PCA.scala:57)
2014-07-23 17:32:29,013 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 210.0 with 1 tasks
2014-07-23 17:32:29,014 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 210.0:0 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:29,015 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 210.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:29,016 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-23 17:32:29,017 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:29,019 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:29,153 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-23 17:32:29,153 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-23 17:32:29,155 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 140 ms on localhost (progress: 1/1)
2014-07-23 17:32:29,155 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 210.0, whose tasks have all completed, from pool 
2014-07-23 17:32:29,155 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(210, 0)
2014-07-23 17:32:29,155 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 210 (reduce at PCA.scala:57) finished in 0.139 s
2014-07-23 17:32:29,156 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.147380912 s
2014-07-23 17:32:29,163 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:29,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:29,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 212(reduce at PCA.scala:57)
2014-07-23 17:32:29,165 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 213)
2014-07-23 17:32:29,165 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-23 17:32:29,167 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:29,168 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 212 (MappedRDD[215] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:29,169 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 212 (MappedRDD[215] at map at PCA.scala:57)
2014-07-23 17:32:29,169 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 212.0 with 1 tasks
2014-07-23 17:32:29,170 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 212.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:29,170 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 212.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:29,170 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-23 17:32:29,172 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:29,173 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:29,290 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-23 17:32:29,290 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-23 17:32:29,291 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-23 17:32:29,291 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(212, 0)
2014-07-23 17:32:29,291 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 212 (reduce at PCA.scala:57) finished in 0.122 s
2014-07-23 17:32:29,292 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128801074 s
2014-07-23 17:32:29,291 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 121 ms on localhost (progress: 1/1)
2014-07-23 17:32:29,292 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 212.0, whose tasks have all completed, from pool 
2014-07-23 17:32:29,297 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:29,298 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:29,298 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 214(reduce at PCA.scala:57)
2014-07-23 17:32:29,299 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 215)
2014-07-23 17:32:29,300 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:29,300 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 214 (MappedRDD[217] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:29,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 214 (MappedRDD[217] at map at PCA.scala:57)
2014-07-23 17:32:29,301 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 214.0 with 1 tasks
2014-07-23 17:32:29,302 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 214.0:0 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:29,302 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 214.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:29,303 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-23 17:32:29,304 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:29,305 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:29,435 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-23 17:32:29,435 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-23 17:32:29,436 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 134 ms on localhost (progress: 1/1)
2014-07-23 17:32:29,436 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 214.0, whose tasks have all completed, from pool 
2014-07-23 17:32:29,436 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(214, 0)
2014-07-23 17:32:29,436 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 214 (reduce at PCA.scala:57) finished in 0.134 s
2014-07-23 17:32:29,438 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.140390296 s
2014-07-23 17:32:29,446 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-23 17:32:29,451 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:29,453 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:29,453 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 216(reduce at PCA.scala:57)
2014-07-23 17:32:29,453 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 217)
2014-07-23 17:32:29,454 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:29,455 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 216 (MappedRDD[219] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:29,457 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 216 (MappedRDD[219] at map at PCA.scala:57)
2014-07-23 17:32:29,457 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 216.0 with 1 tasks
2014-07-23 17:32:29,458 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 216.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:29,458 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 216.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:29,458 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-23 17:32:29,460 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:29,461 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:29,577 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-23 17:32:29,577 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-23 17:32:29,578 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 120 ms on localhost (progress: 1/1)
2014-07-23 17:32:29,578 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 216.0, whose tasks have all completed, from pool 
2014-07-23 17:32:29,579 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(216, 0)
2014-07-23 17:32:29,579 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 216 (reduce at PCA.scala:57) finished in 0.112 s
2014-07-23 17:32:29,579 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.128116528 s
2014-07-23 17:32:29,587 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:29,587 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-23 17:32:29,589 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:29,589 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 218(reduce at PCA.scala:57)
2014-07-23 17:32:29,589 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 219)
2014-07-23 17:32:29,592 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:29,592 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 218 (MappedRDD[221] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:29,594 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 218 (MappedRDD[221] at map at PCA.scala:57)
2014-07-23 17:32:29,594 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 218.0 with 1 tasks
2014-07-23 17:32:29,595 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 218.0:0 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:29,595 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 218.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:29,596 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-23 17:32:29,597 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:29,598 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:29,775 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-23 17:32:29,775 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-23 17:32:29,775 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-23 17:32:29,776 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 181 ms on localhost (progress: 1/1)
2014-07-23 17:32:29,776 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 218.0, whose tasks have all completed, from pool 
2014-07-23 17:32:29,776 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(218, 0)
2014-07-23 17:32:29,776 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 218 (reduce at PCA.scala:57) finished in 0.181 s
2014-07-23 17:32:29,777 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.190184669 s
2014-07-23 17:32:29,785 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:29,789 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:29,789 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 220(reduce at PCA.scala:57)
2014-07-23 17:32:29,789 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 221)
2014-07-23 17:32:29,791 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:29,792 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 220 (MappedRDD[223] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:29,794 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 220 (MappedRDD[223] at map at PCA.scala:57)
2014-07-23 17:32:29,794 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 220.0 with 1 tasks
2014-07-23 17:32:29,795 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 220.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:29,795 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 220.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:29,796 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-23 17:32:29,798 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:29,800 [Executor task launch worker-2] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,055 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-23 17:32:30,055 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-23 17:32:30,056 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 261 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,056 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 220.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,056 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(220, 0)
2014-07-23 17:32:30,056 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 220 (reduce at PCA.scala:57) finished in 0.253 s
2014-07-23 17:32:30,057 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.272026741 s
2014-07-23 17:32:30,063 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,064 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,064 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 222(reduce at PCA.scala:57)
2014-07-23 17:32:30,064 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 223)
2014-07-23 17:32:30,065 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,066 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 222 (MappedRDD[225] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,067 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 222 (MappedRDD[225] at map at PCA.scala:57)
2014-07-23 17:32:30,067 [spark-akka.actor.default-dispatcher-15] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 222.0 with 1 tasks
2014-07-23 17:32:30,068 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 222.0:0 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,068 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 222.0:0 as 2520 bytes in 0 ms
2014-07-23 17:32:30,068 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-23 17:32:30,069 [Executor task launch worker-2] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-23 17:32:30,070 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,071 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,154 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-23 17:32:30,154 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-23 17:32:30,155 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-23 17:32:30,155 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(222, 0)
2014-07-23 17:32:30,155 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 87 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,156 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 222.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,156 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 222 (reduce at PCA.scala:57) finished in 0.087 s
2014-07-23 17:32:30,156 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.092871527 s
2014-07-23 17:32:30,162 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,164 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,164 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 224(reduce at PCA.scala:57)
2014-07-23 17:32:30,164 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 225)
2014-07-23 17:32:30,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,165 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 224 (MappedRDD[227] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,166 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 224 (MappedRDD[227] at map at PCA.scala:57)
2014-07-23 17:32:30,166 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 224.0 with 1 tasks
2014-07-23 17:32:30,167 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 224.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,167 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 224.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:30,168 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-23 17:32:30,169 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,170 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,262 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-23 17:32:30,262 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-23 17:32:30,262 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-23 17:32:30,263 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(224, 0)
2014-07-23 17:32:30,263 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 96 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,263 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 224.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,263 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 224 (reduce at PCA.scala:57) finished in 0.096 s
2014-07-23 17:32:30,264 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101609933 s
2014-07-23 17:32:30,268 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,270 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,270 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 226(reduce at PCA.scala:57)
2014-07-23 17:32:30,270 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 227)
2014-07-23 17:32:30,271 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,271 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 226 (MappedRDD[229] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,272 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 226 (MappedRDD[229] at map at PCA.scala:57)
2014-07-23 17:32:30,272 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 226.0 with 1 tasks
2014-07-23 17:32:30,273 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 226.0:0 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,273 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 226.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:30,274 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-23 17:32:30,275 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,276 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,377 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-23 17:32:30,377 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-23 17:32:30,377 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-23 17:32:30,379 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,379 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 226.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,379 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(226, 0)
2014-07-23 17:32:30,379 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 226 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:32:30,379 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.11105267 s
2014-07-23 17:32:30,384 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,385 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,386 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 228(reduce at PCA.scala:57)
2014-07-23 17:32:30,386 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 229)
2014-07-23 17:32:30,387 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,387 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 228 (MappedRDD[231] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,388 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 228 (MappedRDD[231] at map at PCA.scala:57)
2014-07-23 17:32:30,388 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 228.0 with 1 tasks
2014-07-23 17:32:30,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 228.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 228.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:30,391 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-23 17:32:30,393 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,394 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,495 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-23 17:32:30,495 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-23 17:32:30,496 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-23 17:32:30,496 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 107 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,496 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 228.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,496 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(228, 0)
2014-07-23 17:32:30,497 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 228 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:32:30,497 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.112500131 s
2014-07-23 17:32:30,502 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,503 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,503 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 230(reduce at PCA.scala:57)
2014-07-23 17:32:30,503 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 231)
2014-07-23 17:32:30,504 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,505 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 230 (MappedRDD[233] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 230 (MappedRDD[233] at map at PCA.scala:57)
2014-07-23 17:32:30,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 230.0 with 1 tasks
2014-07-23 17:32:30,507 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 230.0:0 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,507 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 230.0:0 as 2526 bytes in 0 ms
2014-07-23 17:32:30,507 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-23 17:32:30,508 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,510 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,611 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-23 17:32:30,611 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-23 17:32:30,611 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-23 17:32:30,612 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(230, 0)
2014-07-23 17:32:30,612 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 105 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,612 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 230.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,612 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 230 (reduce at PCA.scala:57) finished in 0.106 s
2014-07-23 17:32:30,613 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.111070933 s
2014-07-23 17:32:30,618 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,619 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,619 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 232(reduce at PCA.scala:57)
2014-07-23 17:32:30,619 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 233)
2014-07-23 17:32:30,620 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,621 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 232 (MappedRDD[235] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,622 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 232 (MappedRDD[235] at map at PCA.scala:57)
2014-07-23 17:32:30,622 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 232.0 with 1 tasks
2014-07-23 17:32:30,623 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 232.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,623 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 232.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:30,623 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-23 17:32:30,625 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,626 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-23 17:32:30,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-23 17:32:30,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-23 17:32:30,726 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 103 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,726 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 232.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,726 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(232, 0)
2014-07-23 17:32:30,727 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 232 (reduce at PCA.scala:57) finished in 0.105 s
2014-07-23 17:32:30,727 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.109280662 s
2014-07-23 17:32:30,732 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,733 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,733 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 234(reduce at PCA.scala:57)
2014-07-23 17:32:30,733 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 235)
2014-07-23 17:32:30,734 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,735 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 234 (MappedRDD[237] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,736 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 234 (MappedRDD[237] at map at PCA.scala:57)
2014-07-23 17:32:30,736 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 234.0 with 1 tasks
2014-07-23 17:32:30,737 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 234.0:0 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,737 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 234.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:30,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-23 17:32:30,738 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,739 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,844 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-23 17:32:30,844 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-23 17:32:30,844 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-23 17:32:30,844 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(234, 0)
2014-07-23 17:32:30,845 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 234 (reduce at PCA.scala:57) finished in 0.109 s
2014-07-23 17:32:30,845 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 108 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,845 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 234.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,845 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.113129161 s
2014-07-23 17:32:30,850 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,851 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,851 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 236(reduce at PCA.scala:57)
2014-07-23 17:32:30,851 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 237)
2014-07-23 17:32:30,853 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,853 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 236 (MappedRDD[239] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,855 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 236 (MappedRDD[239] at map at PCA.scala:57)
2014-07-23 17:32:30,855 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 236.0 with 1 tasks
2014-07-23 17:32:30,856 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 236.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,856 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 236.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:30,856 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-23 17:32:30,858 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,859 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:30,970 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-23 17:32:30,970 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-23 17:32:30,970 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-23 17:32:30,971 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 115 ms on localhost (progress: 1/1)
2014-07-23 17:32:30,971 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 236.0, whose tasks have all completed, from pool 
2014-07-23 17:32:30,971 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(236, 0)
2014-07-23 17:32:30,971 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 236 (reduce at PCA.scala:57) finished in 0.116 s
2014-07-23 17:32:30,972 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.121536039 s
2014-07-23 17:32:30,982 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:30,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:30,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 238(reduce at PCA.scala:57)
2014-07-23 17:32:30,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 239)
2014-07-23 17:32:30,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:30,985 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 238 (MappedRDD[241] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:30,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 238 (MappedRDD[241] at map at PCA.scala:57)
2014-07-23 17:32:30,986 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 238.0 with 1 tasks
2014-07-23 17:32:30,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 238.0:0 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:30,987 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 238.0:0 as 2525 bytes in 0 ms
2014-07-23 17:32:30,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-23 17:32:30,989 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:30,990 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:31,088 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-23 17:32:31,088 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-23 17:32:31,089 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-23 17:32:31,089 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 102 ms on localhost (progress: 1/1)
2014-07-23 17:32:31,089 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 238.0, whose tasks have all completed, from pool 
2014-07-23 17:32:31,090 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(238, 0)
2014-07-23 17:32:31,090 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 238 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:32:31,090 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.107812123 s
2014-07-23 17:32:31,095 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:31,096 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:31,096 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 240(reduce at PCA.scala:57)
2014-07-23 17:32:31,096 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 241)
2014-07-23 17:32:31,097 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:31,098 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 240 (MappedRDD[243] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:31,099 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 240 (MappedRDD[243] at map at PCA.scala:57)
2014-07-23 17:32:31,099 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 240.0 with 1 tasks
2014-07-23 17:32:31,100 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 240.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:31,100 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 240.0:0 as 2522 bytes in 0 ms
2014-07-23 17:32:31,100 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-23 17:32:31,101 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:31,103 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:31,199 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-23 17:32:31,199 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-23 17:32:31,199 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-23 17:32:31,200 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 100 ms on localhost (progress: 1/1)
2014-07-23 17:32:31,200 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(240, 0)
2014-07-23 17:32:31,200 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 240.0, whose tasks have all completed, from pool 
2014-07-23 17:32:31,200 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 240 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:32:31,200 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104982594 s
2014-07-23 17:32:31,205 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:31,206 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:31,206 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 242(reduce at PCA.scala:57)
2014-07-23 17:32:31,206 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 243)
2014-07-23 17:32:31,207 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:31,208 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 242 (MappedRDD[245] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:31,209 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 242 (MappedRDD[245] at map at PCA.scala:57)
2014-07-23 17:32:31,209 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 242.0 with 1 tasks
2014-07-23 17:32:31,210 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 242.0:0 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:31,210 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 242.0:0 as 2524 bytes in 0 ms
2014-07-23 17:32:31,211 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-23 17:32:31,212 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:31,213 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:31,304 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-23 17:32:31,304 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-23 17:32:31,304 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-23 17:32:31,305 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(242, 0)
2014-07-23 17:32:31,305 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 95 ms on localhost (progress: 1/1)
2014-07-23 17:32:31,305 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 242.0, whose tasks have all completed, from pool 
2014-07-23 17:32:31,305 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 242 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:32:31,306 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.101023094 s
2014-07-23 17:32:31,311 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:31,312 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 122 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:31,312 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 244(reduce at PCA.scala:57)
2014-07-23 17:32:31,312 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 245)
2014-07-23 17:32:31,314 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:31,314 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 244 (MappedRDD[247] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:31,315 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 244 (MappedRDD[247] at map at PCA.scala:57)
2014-07-23 17:32:31,315 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 244.0 with 1 tasks
2014-07-23 17:32:31,316 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 244.0:0 as TID 124 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:31,317 [spark-akka.actor.default-dispatcher-6] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 244.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:31,317 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 124
2014-07-23 17:32:31,319 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:31,320 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:31,405 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 124 is 678
2014-07-23 17:32:31,405 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 124 directly to driver
2014-07-23 17:32:31,405 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 124
2014-07-23 17:32:31,406 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(244, 0)
2014-07-23 17:32:31,406 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 124 in 90 ms on localhost (progress: 1/1)
2014-07-23 17:32:31,406 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 244.0, whose tasks have all completed, from pool 
2014-07-23 17:32:31,406 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 244 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:32:31,407 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.095671534 s
2014-07-23 17:32:31,412 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:32:31,413 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 123 (reduce at PCA.scala:57) with 1 output partitions (allowLocal=false)
2014-07-23 17:32:31,413 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 246(reduce at PCA.scala:57)
2014-07-23 17:32:31,413 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 247)
2014-07-23 17:32:31,414 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:32:31,415 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 246 (MappedRDD[249] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:32:31,416 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from Stage 246 (MappedRDD[249] at map at PCA.scala:57)
2014-07-23 17:32:31,416 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 246.0 with 1 tasks
2014-07-23 17:32:31,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 246.0:0 as TID 125 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:32:31,417 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 246.0:0 as 2523 bytes in 0 ms
2014-07-23 17:32:31,417 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 125
2014-07-23 17:32:31,419 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:32:31,420 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:32:31,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 125 is 678
2014-07-23 17:32:31,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 125 directly to driver
2014-07-23 17:32:31,494 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 125
2014-07-23 17:32:31,494 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(246, 0)
2014-07-23 17:32:31,494 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 125 in 77 ms on localhost (progress: 1/1)
2014-07-23 17:32:31,495 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 246.0, whose tasks have all completed, from pool 
2014-07-23 17:32:31,495 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 246 (reduce at PCA.scala:57) finished in 0.077 s
2014-07-23 17:32:31,495 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.083297939 s
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/,null}
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/static,null}
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors,null}
2014-07-23 17:32:31,609 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2014-07-23 17:32:31,610 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2014-07-23 17:32:31,611 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2014-07-23 17:32:31,611 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages,null}
2014-07-23 17:32:31,665 [main] INFO  [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://10.74.147.225:4040
2014-07-23 17:32:31,666 [main] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stopping DAGScheduler
2014-07-23 17:32:32,721 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.MapOutputTrackerMasterActor] - MapOutputTrackerActor stopped!
2014-07-23 17:32:32,776 [connection-manager-thread] INFO  [org.apache.spark.network.ConnectionManager] - Selector thread was interrupted!
2014-07-23 17:32:32,777 [main] INFO  [org.apache.spark.network.ConnectionManager] - ConnectionManager stopped
2014-07-23 17:32:32,783 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore cleared
2014-07-23 17:32:32,783 [main] INFO  [org.apache.spark.storage.BlockManager] - BlockManager stopped
2014-07-23 17:32:32,784 [spark-akka.actor.default-dispatcher-16] INFO  [org.apache.spark.storage.BlockManagerMasterActor] - Stopping BlockManagerMaster
2014-07-23 17:32:32,785 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2014-07-23 17:32:32,796 [spark-akka.actor.default-dispatcher-3] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Shutting down remote daemon.
2014-07-23 17:32:32,802 [main] INFO  [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2014-07-23 17:32:32,803 [spark-akka.actor.default-dispatcher-16] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Remote daemon shut down; proceeding with flushing remote transports.
2014-07-23 17:33:19,106 [main] WARN  [org.apache.spark.util.Utils] - Your hostname, PhoenixBai resolves to a loopback address: 127.0.1.1; using 10.74.147.225 instead (on interface eth0)
2014-07-23 17:33:19,107 [main] WARN  [org.apache.spark.util.Utils] - Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-23 17:33:19,179 [main] INFO  [org.apache.spark.SecurityManager] - Changing view acls to: phoenix
2014-07-23 17:33:19,179 [main] INFO  [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phoenix)
2014-07-23 17:33:19,646 [spark-akka.actor.default-dispatcher-2] INFO  [akka.event.slf4j.Slf4jLogger] - Slf4jLogger started
2014-07-23 17:33:19,703 [spark-akka.actor.default-dispatcher-2] INFO  [Remoting] - Starting remoting
2014-07-23 17:33:19,881 [spark-akka.actor.default-dispatcher-3] INFO  [Remoting] - Remoting started; listening on addresses :[akka.tcp://spark@10.74.147.225:40375]
2014-07-23 17:33:19,884 [spark-akka.actor.default-dispatcher-5] INFO  [Remoting] - Remoting now listens on addresses: [akka.tcp://spark@10.74.147.225:40375]
2014-07-23 17:33:19,911 [main] INFO  [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2014-07-23 17:33:19,915 [main] INFO  [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2014-07-23 17:33:19,928 [main] INFO  [org.apache.spark.storage.DiskBlockManager] - Created local directory at /tmp/spark-local-20140723173319-d949
2014-07-23 17:33:19,932 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore started with capacity 1056.0 MB.
2014-07-23 17:33:19,961 [main] INFO  [org.apache.spark.network.ConnectionManager] - Bound socket to port 40008 with id = ConnectionManagerId(10.74.147.225,40008)
2014-07-23 17:33:19,965 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Trying to register BlockManager
2014-07-23 17:33:19,968 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.storage.BlockManagerInfo] - Registering block manager 10.74.147.225:40008 with 1056.0 MB RAM
2014-07-23 17:33:19,969 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager
2014-07-23 17:33:19,984 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:33:20,121 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:33:20,137 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:43656
2014-07-23 17:33:20,138 [main] INFO  [org.apache.spark.broadcast.HttpBroadcast] - Broadcast server started at http://10.74.147.225:43656
2014-07-23 17:33:20,146 [main] INFO  [org.apache.spark.HttpFileServer] - HTTP File server directory is /tmp/spark-33a9ef38-dc5a-44df-8697-8b82d6aaa5bc
2014-07-23 17:33:20,146 [main] INFO  [org.apache.spark.HttpServer] - Starting HTTP Server
2014-07-23 17:33:20,147 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:33:20,149 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SocketConnector@0.0.0.0:60532
2014-07-23 17:33:20,484 [main] INFO  [org.eclipse.jetty.server.Server] - jetty-8.1.14.v20131031
2014-07-23 17:33:20,496 [main] INFO  [org.eclipse.jetty.server.AbstractConnector] - Started SelectChannelConnector@0.0.0.0:4040
2014-07-23 17:33:20,499 [main] INFO  [org.apache.spark.ui.SparkUI] - Started SparkUI at http://10.74.147.225:4040
2014-07-23 17:33:21,014 [main] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(32856) called with curMem=0, maxMem=1107296256
2014-07-23 17:33:21,016 [main] INFO  [org.apache.spark.storage.MemoryStore] - Block broadcast_0 stored as values to memory (estimated size 32.1 KB, free 1056.0 MB)
2014-07-23 17:33:21,117 [main] INFO  [org.apache.spark.SparkContext] - Starting job: count at PCA.scala:50
2014-07-23 17:33:21,149 [spark-akka.actor.default-dispatcher-5] WARN  [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-23 17:33:21,149 [spark-akka.actor.default-dispatcher-5] WARN  [org.apache.hadoop.io.compress.snappy.LoadSnappy] - Snappy native library not loaded
2014-07-23 17:33:21,158 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.hadoop.mapred.FileInputFormat] - Total input paths to process : 1
2014-07-23 17:33:21,170 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 4 (repartition at PCA.scala:46)
2014-07-23 17:33:21,173 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (count at PCA.scala:50) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:21,173 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 0(count at PCA.scala:50)
2014-07-23 17:33:21,173 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 1)
2014-07-23 17:33:21,177 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(Stage 1)
2014-07-23 17:33:21,184 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46), which has no missing parents
2014-07-23 17:33:21,249 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 1 (MapPartitionsRDD[4] at repartition at PCA.scala:46)
2014-07-23 17:33:21,250 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2014-07-23 17:33:21,268 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:21,271 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:0 as 2030 bytes in 2 ms
2014-07-23 17:33:21,276 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:21,276 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 1.0:1 as 2030 bytes in 0 ms
2014-07-23 17:33:21,282 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 0
2014-07-23 17:33:21,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 1
2014-07-23 17:33:21,300 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:21,300 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:21,311 [Executor task launch worker-0] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:0+10884786
2014-07-23 17:33:21,311 [Executor task launch worker-1] INFO  [org.apache.spark.rdd.HadoopRDD] - Input split: file:/home/phoenix/workspace/gitproject/mlwork/dataset/eigen.txt:10884786+10884786
2014-07-23 17:33:23,159 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 1 is 784
2014-07-23 17:33:23,160 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 1 directly to driver
2014-07-23 17:33:23,165 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 1
2014-07-23 17:33:23,182 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 1)
2014-07-23 17:33:23,191 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 1 in 1894 ms on localhost (progress: 1/2)
2014-07-23 17:33:23,348 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 0 is 784
2014-07-23 17:33:23,348 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 0 directly to driver
2014-07-23 17:33:23,348 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 0
2014-07-23 17:33:23,353 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 0 in 2087 ms on localhost (progress: 2/2)
2014-07-23 17:33:23,353 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ShuffleMapTask(1, 0)
2014-07-23 17:33:23,354 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2014-07-23 17:33:23,354 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 1 (repartition at PCA.scala:46) finished in 2.096 s
2014-07-23 17:33:23,354 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2014-07-23 17:33:23,355 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - running: Set()
2014-07-23 17:33:23,355 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(Stage 0)
2014-07-23 17:33:23,356 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2014-07-23 17:33:23,362 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents for Stage 0: List()
2014-07-23 17:33:23,365 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 0 (MappedRDD[7] at repartition at PCA.scala:46), which is now runnable
2014-07-23 17:33:23,387 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 0 (MappedRDD[7] at repartition at PCA.scala:46)
2014-07-23 17:33:23,387 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 2 tasks
2014-07-23 17:33:23,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:0 as TID 2 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:23,389 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:0 as 2265 bytes in 0 ms
2014-07-23 17:33:23,390 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0:1 as TID 3 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:23,390 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 0.0:1 as 2265 bytes in 0 ms
2014-07-23 17:33:23,391 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 2
2014-07-23 17:33:23,395 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:23,399 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 3
2014-07-23 17:33:23,403 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:23,416 [Executor task launch worker-1] INFO  [org.apache.spark.CacheManager] - Partition rdd_7_1 not found, computing it
2014-07-23 17:33:23,416 [Executor task launch worker-0] INFO  [org.apache.spark.CacheManager] - Partition rdd_7_0 not found, computing it
2014-07-23 17:33:23,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-23 17:33:23,428 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-23 17:33:23,430 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2014-07-23 17:33:23,431 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Started 0 remote fetches in 3 ms
2014-07-23 17:33:23,432 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Getting 2 non-empty blocks out of 2 blocks
2014-07-23 17:33:23,432 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2014-07-23 17:33:25,288 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85249276) called with curMem=32856, maxMem=1107296256
2014-07-23 17:33:25,290 [Executor task launch worker-0] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_7_0 stored as values to memory (estimated size 81.3 MB, free 974.7 MB)
2014-07-23 17:33:25,294 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_7_0 in memory on 10.74.147.225:40008 (size: 81.3 MB, free: 974.7 MB)
2014-07-23 17:33:25,296 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_7_0
2014-07-23 17:33:25,316 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - ensureFreeSpace(85228305) called with curMem=85282132, maxMem=1107296256
2014-07-23 17:33:25,316 [Executor task launch worker-1] INFO  [org.apache.spark.storage.MemoryStore] - Block rdd_7_1 stored as values to memory (estimated size 81.3 MB, free 893.4 MB)
2014-07-23 17:33:25,320 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 2 is 1390
2014-07-23 17:33:25,320 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 2 directly to driver
2014-07-23 17:33:25,321 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 2
2014-07-23 17:33:25,321 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.storage.BlockManagerInfo] - Added rdd_7_1 in memory on 10.74.147.225:40008 (size: 81.3 MB, free: 893.4 MB)
2014-07-23 17:33:25,321 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManagerMaster] - Updated info of block rdd_7_1
2014-07-23 17:33:25,324 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 0)
2014-07-23 17:33:25,332 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 2 in 1935 ms on localhost (progress: 1/2)
2014-07-23 17:33:25,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 3 is 1390
2014-07-23 17:33:25,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 3 directly to driver
2014-07-23 17:33:25,336 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 3
2014-07-23 17:33:25,347 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(0, 1)
2014-07-23 17:33:25,348 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 0 (count at PCA.scala:50) finished in 1.937 s
2014-07-23 17:33:25,353 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 3 in 1954 ms on localhost (progress: 2/2)
2014-07-23 17:33:25,353 [main] INFO  [org.apache.spark.SparkContext] - Job finished: count at PCA.scala:50, took 4.236471022 s
2014-07-23 17:33:25,353 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-23 17:33:25,370 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:25,374 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 0 is 147 bytes
2014-07-23 17:33:25,376 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:25,376 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 2(reduce at PCA.scala:57)
2014-07-23 17:33:25,377 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 3)
2014-07-23 17:33:25,378 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:25,379 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 2 (MappedRDD[9] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:25,386 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 2 (MappedRDD[9] at map at PCA.scala:57)
2014-07-23 17:33:25,386 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 2.0 with 2 tasks
2014-07-23 17:33:25,387 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:0 as TID 4 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:25,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:0 as 2517 bytes in 0 ms
2014-07-23 17:33:25,388 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 2.0:1 as TID 5 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:25,389 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 2.0:1 as 2517 bytes in 1 ms
2014-07-23 17:33:25,390 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 4
2014-07-23 17:33:25,390 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 5
2014-07-23 17:33:25,393 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:25,396 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:25,399 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:25,404 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:26,715 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 5 is 678
2014-07-23 17:33:26,715 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 5 directly to driver
2014-07-23 17:33:26,715 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 5
2014-07-23 17:33:26,716 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 1)
2014-07-23 17:33:26,716 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 5 in 1328 ms on localhost (progress: 1/2)
2014-07-23 17:33:26,719 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 4 is 678
2014-07-23 17:33:26,719 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 4 directly to driver
2014-07-23 17:33:26,719 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 4
2014-07-23 17:33:26,721 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(2, 0)
2014-07-23 17:33:26,721 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 4 in 1333 ms on localhost (progress: 2/2)
2014-07-23 17:33:26,721 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2014-07-23 17:33:26,721 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 2 (reduce at PCA.scala:57) finished in 1.334 s
2014-07-23 17:33:26,721 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 1.35113318 s
2014-07-23 17:33:26,728 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:26,730 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:26,730 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 4(reduce at PCA.scala:57)
2014-07-23 17:33:26,730 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 5)
2014-07-23 17:33:26,732 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:26,732 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 4 (MappedRDD[11] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:26,735 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 4 (MappedRDD[11] at map at PCA.scala:57)
2014-07-23 17:33:26,735 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 4.0 with 2 tasks
2014-07-23 17:33:26,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:0 as TID 6 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:26,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:26,737 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 4.0:1 as TID 7 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:26,737 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 4.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:26,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 7
2014-07-23 17:33:26,740 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:26,741 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 6
2014-07-23 17:33:26,744 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:26,749 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:26,751 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:26,858 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 7 is 678
2014-07-23 17:33:26,858 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 7 directly to driver
2014-07-23 17:33:26,858 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 7
2014-07-23 17:33:26,860 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 6 is 678
2014-07-23 17:33:26,860 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 6 directly to driver
2014-07-23 17:33:26,860 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 7 in 123 ms on localhost (progress: 1/2)
2014-07-23 17:33:26,860 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 1)
2014-07-23 17:33:26,861 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 6 in 126 ms on localhost (progress: 2/2)
2014-07-23 17:33:26,861 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(4, 0)
2014-07-23 17:33:26,861 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2014-07-23 17:33:26,861 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 4 (reduce at PCA.scala:57) finished in 0.126 s
2014-07-23 17:33:26,862 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.133822475 s
2014-07-23 17:33:26,862 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 6
2014-07-23 17:33:26,871 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:26,874 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:26,874 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 6(reduce at PCA.scala:57)
2014-07-23 17:33:26,874 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 7)
2014-07-23 17:33:26,875 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:26,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 6 (MappedRDD[13] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:26,878 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 6 (MappedRDD[13] at map at PCA.scala:57)
2014-07-23 17:33:26,878 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 2 tasks
2014-07-23 17:33:26,879 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:26,880 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:0 as 2518 bytes in 1 ms
2014-07-23 17:33:26,880 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 6.0:1 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:26,881 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 6.0:1 as 2518 bytes in 0 ms
2014-07-23 17:33:26,883 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 8
2014-07-23 17:33:26,883 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 9
2014-07-23 17:33:26,886 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:26,888 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:26,888 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:26,890 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:26,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 9 is 678
2014-07-23 17:33:26,956 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 9 directly to driver
2014-07-23 17:33:26,957 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 9
2014-07-23 17:33:26,957 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 1)
2014-07-23 17:33:26,957 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 9 in 77 ms on localhost (progress: 1/2)
2014-07-23 17:33:26,978 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 8 is 678
2014-07-23 17:33:26,979 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 8 directly to driver
2014-07-23 17:33:26,979 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 8
2014-07-23 17:33:26,980 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(6, 0)
2014-07-23 17:33:26,980 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 8 in 100 ms on localhost (progress: 2/2)
2014-07-23 17:33:26,980 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 6 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:33:26,980 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108912063 s
2014-07-23 17:33:26,980 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2014-07-23 17:33:26,987 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:26,989 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:26,989 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 8(reduce at PCA.scala:57)
2014-07-23 17:33:26,989 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 9)
2014-07-23 17:33:26,990 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:26,991 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 8 (MappedRDD[15] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:26,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 8 (MappedRDD[15] at map at PCA.scala:57)
2014-07-23 17:33:26,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2014-07-23 17:33:26,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:0 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:26,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:26,995 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 8.0:1 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:26,995 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 8.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:26,996 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 10
2014-07-23 17:33:26,996 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 11
2014-07-23 17:33:26,999 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,000 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,011 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,065 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 10 is 678
2014-07-23 17:33:27,065 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 10 directly to driver
2014-07-23 17:33:27,065 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 10
2014-07-23 17:33:27,071 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 10 in 77 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,073 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 0)
2014-07-23 17:33:27,093 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 11 is 678
2014-07-23 17:33:27,093 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 11 directly to driver
2014-07-23 17:33:27,093 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 11
2014-07-23 17:33:27,094 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(8, 1)
2014-07-23 17:33:27,094 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 11 in 99 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,094 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,094 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 8 (reduce at PCA.scala:57) finished in 0.101 s
2014-07-23 17:33:27,095 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108183502 s
2014-07-23 17:33:27,101 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,103 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,103 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 10(reduce at PCA.scala:57)
2014-07-23 17:33:27,104 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 11)
2014-07-23 17:33:27,105 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,105 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 10 (MappedRDD[17] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,108 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 10 (MappedRDD[17] at map at PCA.scala:57)
2014-07-23 17:33:27,108 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 10.0 with 2 tasks
2014-07-23 17:33:27,109 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:0 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,110 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:27,110 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 10.0:1 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,110 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 10.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:27,111 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 13
2014-07-23 17:33:27,113 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,115 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 12
2014-07-23 17:33:27,116 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,118 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,120 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,182 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 13 is 678
2014-07-23 17:33:27,182 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 13 directly to driver
2014-07-23 17:33:27,182 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 13
2014-07-23 17:33:27,186 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 1)
2014-07-23 17:33:27,186 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 13 in 75 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 12 is 678
2014-07-23 17:33:27,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 12 directly to driver
2014-07-23 17:33:27,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 12
2014-07-23 17:33:27,191 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(10, 0)
2014-07-23 17:33:27,191 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 12 in 82 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,191 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,191 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 10 (reduce at PCA.scala:57) finished in 0.083 s
2014-07-23 17:33:27,192 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.090258318 s
2014-07-23 17:33:27,197 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,200 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,200 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 12(reduce at PCA.scala:57)
2014-07-23 17:33:27,200 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 13)
2014-07-23 17:33:27,202 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,203 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 12 (MappedRDD[19] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,206 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 12 (MappedRDD[19] at map at PCA.scala:57)
2014-07-23 17:33:27,206 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 2 tasks
2014-07-23 17:33:27,207 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:0 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,207 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:27,207 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 12.0:1 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,208 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 12.0:1 as 2520 bytes in 1 ms
2014-07-23 17:33:27,208 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 15
2014-07-23 17:33:27,209 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 14
2014-07-23 17:33:27,214 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,217 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,228 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,236 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,324 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 14 is 678
2014-07-23 17:33:27,325 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 14 directly to driver
2014-07-23 17:33:27,326 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 14
2014-07-23 17:33:27,327 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 0)
2014-07-23 17:33:27,327 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 14 in 120 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,328 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 15 is 678
2014-07-23 17:33:27,328 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 15 directly to driver
2014-07-23 17:33:27,328 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 15
2014-07-23 17:33:27,329 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(12, 1)
2014-07-23 17:33:27,329 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 15 in 121 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,329 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,329 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 12 (reduce at PCA.scala:57) finished in 0.123 s
2014-07-23 17:33:27,330 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.13206996 s
2014-07-23 17:33:27,336 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,338 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,338 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 14(reduce at PCA.scala:57)
2014-07-23 17:33:27,338 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 15)
2014-07-23 17:33:27,340 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,340 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 14 (MappedRDD[21] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,342 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 14 (MappedRDD[21] at map at PCA.scala:57)
2014-07-23 17:33:27,343 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 14.0 with 2 tasks
2014-07-23 17:33:27,344 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:0 as TID 16 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,344 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:27,345 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 14.0:1 as TID 17 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,345 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 14.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:27,345 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 17
2014-07-23 17:33:27,347 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 16
2014-07-23 17:33:27,348 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,350 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,350 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,352 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,423 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 16 is 678
2014-07-23 17:33:27,424 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 16 directly to driver
2014-07-23 17:33:27,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 17 is 678
2014-07-23 17:33:27,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 17 directly to driver
2014-07-23 17:33:27,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 17
2014-07-23 17:33:27,425 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 16 in 81 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,425 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 0)
2014-07-23 17:33:27,426 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 16
2014-07-23 17:33:27,427 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(14, 1)
2014-07-23 17:33:27,427 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 17 in 82 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,427 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,427 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 14 (reduce at PCA.scala:57) finished in 0.084 s
2014-07-23 17:33:27,428 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.092737819 s
2014-07-23 17:33:27,435 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,437 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,438 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 16(reduce at PCA.scala:57)
2014-07-23 17:33:27,438 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 17)
2014-07-23 17:33:27,439 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,440 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 16 (MappedRDD[23] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,442 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 16 (MappedRDD[23] at map at PCA.scala:57)
2014-07-23 17:33:27,442 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 16.0 with 2 tasks
2014-07-23 17:33:27,443 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:0 as TID 18 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,443 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:27,444 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 16.0:1 as TID 19 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,444 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 16.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:27,445 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 19
2014-07-23 17:33:27,447 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,447 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 18
2014-07-23 17:33:27,449 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,450 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,452 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,527 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 19 is 678
2014-07-23 17:33:27,527 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 19 directly to driver
2014-07-23 17:33:27,527 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 19
2014-07-23 17:33:27,529 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 19 in 84 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,529 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 1)
2014-07-23 17:33:27,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 18 is 678
2014-07-23 17:33:27,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 18 directly to driver
2014-07-23 17:33:27,538 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 18
2014-07-23 17:33:27,540 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(16, 0)
2014-07-23 17:33:27,540 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 18 in 96 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,540 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,540 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 16 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:33:27,540 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104731051 s
2014-07-23 17:33:27,546 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,549 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,549 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 18(reduce at PCA.scala:57)
2014-07-23 17:33:27,549 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 19)
2014-07-23 17:33:27,551 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,551 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 18 (MappedRDD[25] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,554 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 18 (MappedRDD[25] at map at PCA.scala:57)
2014-07-23 17:33:27,554 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 2 tasks
2014-07-23 17:33:27,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:0 as TID 20 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:27,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 18.0:1 as TID 21 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,556 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 18.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:27,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 20
2014-07-23 17:33:27,557 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 21
2014-07-23 17:33:27,559 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,560 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,561 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,562 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,713 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 20 is 678
2014-07-23 17:33:27,713 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 20 directly to driver
2014-07-23 17:33:27,715 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 20 in 160 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,715 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 0)
2014-07-23 17:33:27,716 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 20
2014-07-23 17:33:27,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 21 is 678
2014-07-23 17:33:27,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 21 directly to driver
2014-07-23 17:33:27,717 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 21
2014-07-23 17:33:27,719 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(18, 1)
2014-07-23 17:33:27,719 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 21 in 164 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,719 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,719 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 18 (reduce at PCA.scala:57) finished in 0.165 s
2014-07-23 17:33:27,720 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.173464065 s
2014-07-23 17:33:27,727 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,729 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,729 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 20(reduce at PCA.scala:57)
2014-07-23 17:33:27,729 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 21)
2014-07-23 17:33:27,731 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,731 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 20 (MappedRDD[27] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,734 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 20 (MappedRDD[27] at map at PCA.scala:57)
2014-07-23 17:33:27,734 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2014-07-23 17:33:27,735 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:0 as TID 22 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,736 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:0 as 2520 bytes in 1 ms
2014-07-23 17:33:27,736 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 20.0:1 as TID 23 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,737 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 20.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:27,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 22
2014-07-23 17:33:27,738 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 23
2014-07-23 17:33:27,740 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,742 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:27,746 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,753 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,808 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 22 is 678
2014-07-23 17:33:27,808 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 22 directly to driver
2014-07-23 17:33:27,810 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 22 in 74 ms on localhost (progress: 1/2)
2014-07-23 17:33:27,810 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 0)
2014-07-23 17:33:27,810 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 22
2014-07-23 17:33:27,858 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 23 is 678
2014-07-23 17:33:27,859 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 23 directly to driver
2014-07-23 17:33:27,860 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 23 in 124 ms on localhost (progress: 2/2)
2014-07-23 17:33:27,861 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2014-07-23 17:33:27,861 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(20, 1)
2014-07-23 17:33:27,861 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 20 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:33:27,862 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.135191823 s
2014-07-23 17:33:27,869 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 23
2014-07-23 17:33:27,869 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:27,872 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:27,872 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 22(reduce at PCA.scala:57)
2014-07-23 17:33:27,872 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 23)
2014-07-23 17:33:27,873 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:27,874 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 22 (MappedRDD[29] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:27,877 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 22 (MappedRDD[29] at map at PCA.scala:57)
2014-07-23 17:33:27,877 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 22.0 with 2 tasks
2014-07-23 17:33:27,878 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:0 as TID 24 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,878 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:27,878 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 22.0:1 as TID 25 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:27,879 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 22.0:1 as 2519 bytes in 1 ms
2014-07-23 17:33:27,879 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 25
2014-07-23 17:33:27,882 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,885 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:27,885 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 24
2014-07-23 17:33:27,890 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:27,892 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,003 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 25 is 678
2014-07-23 17:33:28,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 25 directly to driver
2014-07-23 17:33:28,004 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 25
2014-07-23 17:33:28,005 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 25 in 127 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,005 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 1)
2014-07-23 17:33:28,009 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 24 is 678
2014-07-23 17:33:28,010 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 24 directly to driver
2014-07-23 17:33:28,010 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 24
2014-07-23 17:33:28,011 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(22, 0)
2014-07-23 17:33:28,011 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 24 in 133 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,011 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,011 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 22 (reduce at PCA.scala:57) finished in 0.118 s
2014-07-23 17:33:28,011 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.14167795 s
2014-07-23 17:33:28,018 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,020 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,022 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 24(reduce at PCA.scala:57)
2014-07-23 17:33:28,023 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 25)
2014-07-23 17:33:28,024 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,025 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 24 (MappedRDD[31] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,028 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 24 (MappedRDD[31] at map at PCA.scala:57)
2014-07-23 17:33:28,028 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 2 tasks
2014-07-23 17:33:28,029 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:0 as TID 26 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,029 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:28,030 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 24.0:1 as TID 27 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,031 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 24.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:28,032 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 26
2014-07-23 17:33:28,034 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,036 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 27
2014-07-23 17:33:28,036 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,038 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,040 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,088 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 26 is 678
2014-07-23 17:33:28,088 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 26 directly to driver
2014-07-23 17:33:28,090 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 26 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,090 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 0)
2014-07-23 17:33:28,090 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 26
2014-07-23 17:33:28,119 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 27 is 678
2014-07-23 17:33:28,119 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 27 directly to driver
2014-07-23 17:33:28,120 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 27
2014-07-23 17:33:28,121 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 27 in 91 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,121 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,122 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(24, 1)
2014-07-23 17:33:28,122 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 24 (reduce at PCA.scala:57) finished in 0.083 s
2014-07-23 17:33:28,123 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104337293 s
2014-07-23 17:33:28,133 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,135 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,135 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 26(reduce at PCA.scala:57)
2014-07-23 17:33:28,136 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 27)
2014-07-23 17:33:28,139 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,140 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 26 (MappedRDD[33] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,144 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 26 (MappedRDD[33] at map at PCA.scala:57)
2014-07-23 17:33:28,144 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2014-07-23 17:33:28,145 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:0 as TID 28 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,145 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:28,146 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 26.0:1 as TID 29 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,146 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 26.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:28,147 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 28
2014-07-23 17:33:28,149 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,150 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,151 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 29
2014-07-23 17:33:28,153 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,156 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,204 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 29 is 678
2014-07-23 17:33:28,204 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 29 directly to driver
2014-07-23 17:33:28,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 29
2014-07-23 17:33:28,205 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 29 in 59 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,206 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 1)
2014-07-23 17:33:28,211 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 28 is 678
2014-07-23 17:33:28,211 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 28 directly to driver
2014-07-23 17:33:28,212 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 28 in 67 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,213 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,213 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(26, 0)
2014-07-23 17:33:28,213 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 26 (reduce at PCA.scala:57) finished in 0.068 s
2014-07-23 17:33:28,214 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.080487275 s
2014-07-23 17:33:28,223 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 28
2014-07-23 17:33:28,224 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,226 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,226 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 28(reduce at PCA.scala:57)
2014-07-23 17:33:28,226 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 29)
2014-07-23 17:33:28,228 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,229 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 28 (MappedRDD[35] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 28 (MappedRDD[35] at map at PCA.scala:57)
2014-07-23 17:33:28,232 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 28.0 with 2 tasks
2014-07-23 17:33:28,233 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:0 as TID 30 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,233 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:28,234 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 28.0:1 as TID 31 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,234 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 28.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:28,235 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 31
2014-07-23 17:33:28,237 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,239 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,240 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 30
2014-07-23 17:33:28,242 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,249 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,346 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 31 is 678
2014-07-23 17:33:28,346 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 31 directly to driver
2014-07-23 17:33:28,348 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 31 in 114 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,349 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 1)
2014-07-23 17:33:28,349 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 31
2014-07-23 17:33:28,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 30 is 678
2014-07-23 17:33:28,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 30 directly to driver
2014-07-23 17:33:28,354 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 30
2014-07-23 17:33:28,355 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(28, 0)
2014-07-23 17:33:28,355 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 30 in 121 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,355 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,355 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 28 (reduce at PCA.scala:57) finished in 0.110 s
2014-07-23 17:33:28,356 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.131215868 s
2014-07-23 17:33:28,361 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,363 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,363 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 30(reduce at PCA.scala:57)
2014-07-23 17:33:28,363 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 31)
2014-07-23 17:33:28,365 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,365 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 30 (MappedRDD[37] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,368 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 30 (MappedRDD[37] at map at PCA.scala:57)
2014-07-23 17:33:28,368 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 2 tasks
2014-07-23 17:33:28,369 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:0 as TID 32 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,369 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:28,369 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 30.0:1 as TID 33 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,370 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 30.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:28,373 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 33
2014-07-23 17:33:28,375 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,378 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,383 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 32
2014-07-23 17:33:28,389 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,391 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,501 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 33 is 678
2014-07-23 17:33:28,506 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 33 directly to driver
2014-07-23 17:33:28,507 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 33 in 138 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,508 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 1)
2014-07-23 17:33:28,508 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 33
2014-07-23 17:33:28,506 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 32 is 678
2014-07-23 17:33:28,508 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 32 directly to driver
2014-07-23 17:33:28,510 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 32 in 140 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,510 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,510 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(30, 0)
2014-07-23 17:33:28,510 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 30 (reduce at PCA.scala:57) finished in 0.125 s
2014-07-23 17:33:28,511 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.149786995 s
2014-07-23 17:33:28,518 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 32
2014-07-23 17:33:28,518 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,520 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,520 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 32(reduce at PCA.scala:57)
2014-07-23 17:33:28,520 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 33)
2014-07-23 17:33:28,522 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,522 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 32 (MappedRDD[39] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,525 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 32 (MappedRDD[39] at map at PCA.scala:57)
2014-07-23 17:33:28,525 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 32.0 with 2 tasks
2014-07-23 17:33:28,526 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:0 as TID 34 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,526 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:28,527 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 32.0:1 as TID 35 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,527 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 32.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:28,528 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 35
2014-07-23 17:33:28,530 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,532 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,538 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 34
2014-07-23 17:33:28,540 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,543 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,607 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 34 is 678
2014-07-23 17:33:28,608 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 34 directly to driver
2014-07-23 17:33:28,609 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 34 in 83 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,610 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 0)
2014-07-23 17:33:28,610 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 34
2014-07-23 17:33:28,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 35 is 678
2014-07-23 17:33:28,646 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 35 directly to driver
2014-07-23 17:33:28,647 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 35
2014-07-23 17:33:28,647 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 35 in 120 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,647 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,648 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(32, 1)
2014-07-23 17:33:28,648 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 32 (reduce at PCA.scala:57) finished in 0.107 s
2014-07-23 17:33:28,648 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.130316178 s
2014-07-23 17:33:28,661 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,663 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,664 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 34(reduce at PCA.scala:57)
2014-07-23 17:33:28,664 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 35)
2014-07-23 17:33:28,665 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,666 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 34 (MappedRDD[41] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 34 (MappedRDD[41] at map at PCA.scala:57)
2014-07-23 17:33:28,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 34.0 with 2 tasks
2014-07-23 17:33:28,670 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:0 as TID 36 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,670 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:28,670 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 34.0:1 as TID 37 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,671 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 34.0:1 as 2520 bytes in 1 ms
2014-07-23 17:33:28,671 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 36
2014-07-23 17:33:28,673 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,676 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 37
2014-07-23 17:33:28,678 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,680 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,681 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,814 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 36 is 678
2014-07-23 17:33:28,815 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 36 directly to driver
2014-07-23 17:33:28,815 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 37 is 678
2014-07-23 17:33:28,815 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 37 directly to driver
2014-07-23 17:33:28,815 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 37
2014-07-23 17:33:28,816 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 36
2014-07-23 17:33:28,816 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 0)
2014-07-23 17:33:28,816 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 36 in 147 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,817 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(34, 1)
2014-07-23 17:33:28,817 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 37 in 147 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,817 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,817 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 34 (reduce at PCA.scala:57) finished in 0.126 s
2014-07-23 17:33:28,818 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.156190307 s
2014-07-23 17:33:28,828 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:28,830 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:28,830 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 36(reduce at PCA.scala:57)
2014-07-23 17:33:28,830 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 37)
2014-07-23 17:33:28,833 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:28,834 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 36 (MappedRDD[43] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:28,836 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 36 (MappedRDD[43] at map at PCA.scala:57)
2014-07-23 17:33:28,836 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 2 tasks
2014-07-23 17:33:28,837 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:0 as TID 38 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,838 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:0 as 2520 bytes in 1 ms
2014-07-23 17:33:28,838 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 36.0:1 as TID 39 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:28,838 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 36.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:28,839 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 39
2014-07-23 17:33:28,841 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,843 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 38
2014-07-23 17:33:28,845 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:28,847 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:28,849 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:28,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 38 is 678
2014-07-23 17:33:28,993 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 38 directly to driver
2014-07-23 17:33:28,994 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 38 in 157 ms on localhost (progress: 1/2)
2014-07-23 17:33:28,995 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 0)
2014-07-23 17:33:28,995 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 38
2014-07-23 17:33:28,993 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 39 is 678
2014-07-23 17:33:28,995 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 39 directly to driver
2014-07-23 17:33:28,997 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 39 in 158 ms on localhost (progress: 2/2)
2014-07-23 17:33:28,997 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2014-07-23 17:33:28,997 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(36, 1)
2014-07-23 17:33:28,997 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 36 (reduce at PCA.scala:57) finished in 0.149 s
2014-07-23 17:33:28,998 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.170362571 s
2014-07-23 17:33:29,009 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,012 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 39
2014-07-23 17:33:29,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 38(reduce at PCA.scala:57)
2014-07-23 17:33:29,014 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 39)
2014-07-23 17:33:29,016 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 38 (MappedRDD[45] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,019 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 38 (MappedRDD[45] at map at PCA.scala:57)
2014-07-23 17:33:29,022 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 38.0 with 2 tasks
2014-07-23 17:33:29,023 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:0 as TID 40 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,024 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:0 as 2521 bytes in 1 ms
2014-07-23 17:33:29,024 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 38.0:1 as TID 41 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,025 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 38.0:1 as 2521 bytes in 1 ms
2014-07-23 17:33:29,025 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 41
2014-07-23 17:33:29,027 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,030 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 40
2014-07-23 17:33:29,032 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,034 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,035 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 40 is 678
2014-07-23 17:33:29,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 40 directly to driver
2014-07-23 17:33:29,204 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 40
2014-07-23 17:33:29,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 41 is 678
2014-07-23 17:33:29,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 41 directly to driver
2014-07-23 17:33:29,205 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 41
2014-07-23 17:33:29,206 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 0)
2014-07-23 17:33:29,206 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 40 in 182 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,206 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(38, 1)
2014-07-23 17:33:29,206 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 41 in 182 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,206 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,206 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 38 (reduce at PCA.scala:57) finished in 0.167 s
2014-07-23 17:33:29,207 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.1975771 s
2014-07-23 17:33:29,221 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,225 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,225 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 40(reduce at PCA.scala:57)
2014-07-23 17:33:29,226 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 41)
2014-07-23 17:33:29,227 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,228 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 40 (MappedRDD[47] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,230 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 40 (MappedRDD[47] at map at PCA.scala:57)
2014-07-23 17:33:29,230 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 40.0 with 2 tasks
2014-07-23 17:33:29,236 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:0 as TID 42 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,237 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:29,237 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 40.0:1 as TID 43 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,237 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 40.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:29,238 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 42
2014-07-23 17:33:29,240 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,240 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 43
2014-07-23 17:33:29,242 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,242 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,244 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,311 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 42 is 678
2014-07-23 17:33:29,312 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 42 directly to driver
2014-07-23 17:33:29,313 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 42 in 77 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,314 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 0)
2014-07-23 17:33:29,314 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 42
2014-07-23 17:33:29,342 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 43 is 678
2014-07-23 17:33:29,342 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 43 directly to driver
2014-07-23 17:33:29,344 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 43 in 106 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,344 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,345 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(40, 1)
2014-07-23 17:33:29,345 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 40 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:33:29,346 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.124409219 s
2014-07-23 17:33:29,353 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,354 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 43
2014-07-23 17:33:29,355 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,355 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 42(reduce at PCA.scala:57)
2014-07-23 17:33:29,356 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 43)
2014-07-23 17:33:29,357 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,359 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 42 (MappedRDD[49] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,362 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 42 (MappedRDD[49] at map at PCA.scala:57)
2014-07-23 17:33:29,362 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 2 tasks
2014-07-23 17:33:29,363 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:0 as TID 44 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,363 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:29,363 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 42.0:1 as TID 45 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,364 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 42.0:1 as 2520 bytes in 1 ms
2014-07-23 17:33:29,364 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 45
2014-07-23 17:33:29,367 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,369 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,370 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 44
2014-07-23 17:33:29,374 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,379 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,501 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 45 is 678
2014-07-23 17:33:29,504 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 45 directly to driver
2014-07-23 17:33:29,505 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 45 in 142 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 1)
2014-07-23 17:33:29,507 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 45
2014-07-23 17:33:29,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 44 is 678
2014-07-23 17:33:29,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 44 directly to driver
2014-07-23 17:33:29,513 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 44
2014-07-23 17:33:29,514 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(42, 0)
2014-07-23 17:33:29,514 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 44 in 151 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,514 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,514 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 42 (reduce at PCA.scala:57) finished in 0.138 s
2014-07-23 17:33:29,514 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.160876304 s
2014-07-23 17:33:29,522 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,524 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,524 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 44(reduce at PCA.scala:57)
2014-07-23 17:33:29,524 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 45)
2014-07-23 17:33:29,525 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,526 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 44 (MappedRDD[51] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,528 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 44 (MappedRDD[51] at map at PCA.scala:57)
2014-07-23 17:33:29,528 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 2 tasks
2014-07-23 17:33:29,529 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:0 as TID 46 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,529 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:29,530 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 44.0:1 as TID 47 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,530 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 44.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:29,531 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 47
2014-07-23 17:33:29,531 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 46
2014-07-23 17:33:29,533 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,533 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,535 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,535 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,593 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 46 is 678
2014-07-23 17:33:29,593 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 46 directly to driver
2014-07-23 17:33:29,594 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 46
2014-07-23 17:33:29,594 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 0)
2014-07-23 17:33:29,594 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 46 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,600 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 47 is 678
2014-07-23 17:33:29,600 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 47 directly to driver
2014-07-23 17:33:29,600 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 47
2014-07-23 17:33:29,601 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(44, 1)
2014-07-23 17:33:29,601 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 47 in 70 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,601 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,601 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 44 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:33:29,601 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.079127453 s
2014-07-23 17:33:29,606 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,608 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,608 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 46(reduce at PCA.scala:57)
2014-07-23 17:33:29,608 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 47)
2014-07-23 17:33:29,609 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,609 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 46 (MappedRDD[53] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,612 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 46 (MappedRDD[53] at map at PCA.scala:57)
2014-07-23 17:33:29,612 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 46.0 with 2 tasks
2014-07-23 17:33:29,613 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:0 as TID 48 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,613 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:29,613 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 46.0:1 as TID 49 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,614 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 46.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:29,614 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 48
2014-07-23 17:33:29,617 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,618 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 49
2014-07-23 17:33:29,619 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,619 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,624 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,677 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 48 is 678
2014-07-23 17:33:29,678 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 48 directly to driver
2014-07-23 17:33:29,678 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 48
2014-07-23 17:33:29,679 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 0)
2014-07-23 17:33:29,679 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 48 in 66 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,688 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 49 is 678
2014-07-23 17:33:29,688 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 49 directly to driver
2014-07-23 17:33:29,688 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 49
2014-07-23 17:33:29,689 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(46, 1)
2014-07-23 17:33:29,689 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 49 in 76 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,689 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,689 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 46 (reduce at PCA.scala:57) finished in 0.077 s
2014-07-23 17:33:29,690 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.083598456 s
2014-07-23 17:33:29,696 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,697 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,697 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 48(reduce at PCA.scala:57)
2014-07-23 17:33:29,697 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 49)
2014-07-23 17:33:29,699 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,699 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 48 (MappedRDD[55] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,703 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 48 (MappedRDD[55] at map at PCA.scala:57)
2014-07-23 17:33:29,704 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 2 tasks
2014-07-23 17:33:29,704 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:0 as TID 50 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,705 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:29,705 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 48.0:1 as TID 51 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,706 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 48.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:29,706 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 51
2014-07-23 17:33:29,709 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,712 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,715 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 50
2014-07-23 17:33:29,717 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,723 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,780 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 51 is 678
2014-07-23 17:33:29,780 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 51 directly to driver
2014-07-23 17:33:29,783 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 51 in 77 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,783 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 1)
2014-07-23 17:33:29,784 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 51
2014-07-23 17:33:29,785 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 50 is 678
2014-07-23 17:33:29,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 50 directly to driver
2014-07-23 17:33:29,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 50
2014-07-23 17:33:29,787 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(48, 0)
2014-07-23 17:33:29,787 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 50 in 83 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,787 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,787 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 48 (reduce at PCA.scala:57) finished in 0.083 s
2014-07-23 17:33:29,788 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.091688001 s
2014-07-23 17:33:29,793 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,795 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,795 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 50(reduce at PCA.scala:57)
2014-07-23 17:33:29,795 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 51)
2014-07-23 17:33:29,796 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,797 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 50 (MappedRDD[57] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,799 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 50 (MappedRDD[57] at map at PCA.scala:57)
2014-07-23 17:33:29,799 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2014-07-23 17:33:29,800 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:0 as TID 52 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,800 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:29,800 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 50.0:1 as TID 53 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,801 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 50.0:1 as 2520 bytes in 1 ms
2014-07-23 17:33:29,801 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 53
2014-07-23 17:33:29,803 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 52
2014-07-23 17:33:29,803 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,805 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,807 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,808 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,851 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 52 is 678
2014-07-23 17:33:29,851 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 52 directly to driver
2014-07-23 17:33:29,852 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 52 in 52 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,853 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 0)
2014-07-23 17:33:29,853 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 52
2014-07-23 17:33:29,855 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 53 is 678
2014-07-23 17:33:29,856 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 53 directly to driver
2014-07-23 17:33:29,856 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 53
2014-07-23 17:33:29,857 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(50, 1)
2014-07-23 17:33:29,857 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 53 in 56 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,857 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,857 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 50 (reduce at PCA.scala:57) finished in 0.051 s
2014-07-23 17:33:29,857 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.064095462 s
2014-07-23 17:33:29,862 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,863 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,863 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 52(reduce at PCA.scala:57)
2014-07-23 17:33:29,863 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 53)
2014-07-23 17:33:29,865 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,865 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 52 (MappedRDD[59] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,867 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 52 (MappedRDD[59] at map at PCA.scala:57)
2014-07-23 17:33:29,867 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 52.0 with 2 tasks
2014-07-23 17:33:29,868 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:0 as TID 54 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,868 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:29,869 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 52.0:1 as TID 55 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,869 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 52.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:29,869 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 54
2014-07-23 17:33:29,870 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 55
2014-07-23 17:33:29,872 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,874 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:29,877 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,879 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,938 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 55 is 678
2014-07-23 17:33:29,938 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 55 directly to driver
2014-07-23 17:33:29,938 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 55
2014-07-23 17:33:29,939 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 1)
2014-07-23 17:33:29,939 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 55 in 70 ms on localhost (progress: 1/2)
2014-07-23 17:33:29,940 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 54 is 678
2014-07-23 17:33:29,940 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 54 directly to driver
2014-07-23 17:33:29,940 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 54
2014-07-23 17:33:29,947 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(52, 0)
2014-07-23 17:33:29,947 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 54 in 78 ms on localhost (progress: 2/2)
2014-07-23 17:33:29,947 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2014-07-23 17:33:29,947 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 52 (reduce at PCA.scala:57) finished in 0.080 s
2014-07-23 17:33:29,947 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.085791432 s
2014-07-23 17:33:29,954 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:29,955 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:29,955 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 54(reduce at PCA.scala:57)
2014-07-23 17:33:29,955 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 55)
2014-07-23 17:33:29,960 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:29,960 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 54 (MappedRDD[61] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:29,963 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 54 (MappedRDD[61] at map at PCA.scala:57)
2014-07-23 17:33:29,963 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 2 tasks
2014-07-23 17:33:29,963 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:0 as TID 56 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,964 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:0 as 2523 bytes in 1 ms
2014-07-23 17:33:29,964 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 54.0:1 as TID 57 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:29,964 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 54.0:1 as 2523 bytes in 0 ms
2014-07-23 17:33:29,965 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 56
2014-07-23 17:33:29,965 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 57
2014-07-23 17:33:29,967 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,968 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:29,969 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:29,969 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,031 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 57 is 678
2014-07-23 17:33:30,031 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 57 directly to driver
2014-07-23 17:33:30,032 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 57 in 68 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,032 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 1)
2014-07-23 17:33:30,033 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 57
2014-07-23 17:33:30,040 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 56 is 678
2014-07-23 17:33:30,040 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 56 directly to driver
2014-07-23 17:33:30,040 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 56
2014-07-23 17:33:30,041 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(54, 0)
2014-07-23 17:33:30,041 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 56 in 78 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,041 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,041 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 54 (reduce at PCA.scala:57) finished in 0.078 s
2014-07-23 17:33:30,042 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.087988936 s
2014-07-23 17:33:30,047 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,048 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,048 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 56(reduce at PCA.scala:57)
2014-07-23 17:33:30,048 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 57)
2014-07-23 17:33:30,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 56 (MappedRDD[63] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,052 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 56 (MappedRDD[63] at map at PCA.scala:57)
2014-07-23 17:33:30,052 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 2 tasks
2014-07-23 17:33:30,054 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:0 as TID 58 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,054 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:30,055 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 56.0:1 as TID 59 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,055 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 56.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:30,056 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 59
2014-07-23 17:33:30,056 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 58
2014-07-23 17:33:30,058 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,058 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,060 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,060 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,131 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 58 is 678
2014-07-23 17:33:30,131 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 58 directly to driver
2014-07-23 17:33:30,132 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 58
2014-07-23 17:33:30,133 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 0)
2014-07-23 17:33:30,133 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 58 in 79 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,133 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 59 is 678
2014-07-23 17:33:30,133 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 59 directly to driver
2014-07-23 17:33:30,133 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 59
2014-07-23 17:33:30,134 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(56, 1)
2014-07-23 17:33:30,134 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 59 in 79 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,135 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,135 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 56 (reduce at PCA.scala:57) finished in 0.079 s
2014-07-23 17:33:30,135 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.088481089 s
2014-07-23 17:33:30,140 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,142 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,142 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 58(reduce at PCA.scala:57)
2014-07-23 17:33:30,142 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 59)
2014-07-23 17:33:30,143 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,144 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 58 (MappedRDD[65] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,146 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 58 (MappedRDD[65] at map at PCA.scala:57)
2014-07-23 17:33:30,146 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 58.0 with 2 tasks
2014-07-23 17:33:30,147 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:0 as TID 60 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,147 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:30,148 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 58.0:1 as TID 61 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,148 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 58.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:30,148 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 60
2014-07-23 17:33:30,148 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 61
2014-07-23 17:33:30,151 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,153 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,161 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,166 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,267 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 60 is 678
2014-07-23 17:33:30,267 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 60 directly to driver
2014-07-23 17:33:30,269 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 60 in 122 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,269 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 0)
2014-07-23 17:33:30,270 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 60
2014-07-23 17:33:30,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 61 is 678
2014-07-23 17:33:30,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 61 directly to driver
2014-07-23 17:33:30,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 61
2014-07-23 17:33:30,277 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 61 in 129 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,277 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,277 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(58, 1)
2014-07-23 17:33:30,277 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 58 (reduce at PCA.scala:57) finished in 0.131 s
2014-07-23 17:33:30,279 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.139040017 s
2014-07-23 17:33:30,285 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,287 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,287 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 60(reduce at PCA.scala:57)
2014-07-23 17:33:30,287 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 61)
2014-07-23 17:33:30,288 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,289 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 60 (MappedRDD[67] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,290 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 60 (MappedRDD[67] at map at PCA.scala:57)
2014-07-23 17:33:30,291 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 2 tasks
2014-07-23 17:33:30,291 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:0 as TID 62 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:0 as 2519 bytes in 1 ms
2014-07-23 17:33:30,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 60.0:1 as TID 63 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 60.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:30,293 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 63
2014-07-23 17:33:30,295 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,295 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 62
2014-07-23 17:33:30,296 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,297 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,299 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 62 is 678
2014-07-23 17:33:30,363 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 62 directly to driver
2014-07-23 17:33:30,364 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 62
2014-07-23 17:33:30,365 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 0)
2014-07-23 17:33:30,365 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 62 in 73 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,398 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 63 is 678
2014-07-23 17:33:30,398 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 63 directly to driver
2014-07-23 17:33:30,398 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 63
2014-07-23 17:33:30,399 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(60, 1)
2014-07-23 17:33:30,399 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 63 in 106 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,399 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,399 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 60 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:33:30,399 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.114560576 s
2014-07-23 17:33:30,404 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,405 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,405 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 62(reduce at PCA.scala:57)
2014-07-23 17:33:30,405 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 63)
2014-07-23 17:33:30,406 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,407 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 62 (MappedRDD[69] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,408 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 62 (MappedRDD[69] at map at PCA.scala:57)
2014-07-23 17:33:30,409 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 2 tasks
2014-07-23 17:33:30,409 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:0 as TID 64 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:30,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 62.0:1 as TID 65 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,410 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 62.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:30,411 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 64
2014-07-23 17:33:30,411 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 65
2014-07-23 17:33:30,415 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,415 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,417 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,477 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 65 is 678
2014-07-23 17:33:30,477 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 65 directly to driver
2014-07-23 17:33:30,478 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 65 in 68 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,478 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 1)
2014-07-23 17:33:30,479 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 65
2014-07-23 17:33:30,511 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 64 is 678
2014-07-23 17:33:30,511 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 64 directly to driver
2014-07-23 17:33:30,511 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 64
2014-07-23 17:33:30,512 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(62, 0)
2014-07-23 17:33:30,512 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 64 in 103 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,512 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,512 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 62 (reduce at PCA.scala:57) finished in 0.103 s
2014-07-23 17:33:30,513 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.108949796 s
2014-07-23 17:33:30,517 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,519 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,519 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 64(reduce at PCA.scala:57)
2014-07-23 17:33:30,519 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 65)
2014-07-23 17:33:30,520 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,521 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 64 (MappedRDD[71] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,522 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 64 (MappedRDD[71] at map at PCA.scala:57)
2014-07-23 17:33:30,522 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 64.0 with 2 tasks
2014-07-23 17:33:30,523 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:0 as TID 66 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,524 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:30,524 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 64.0:1 as TID 67 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,524 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 64.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:30,525 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 66
2014-07-23 17:33:30,525 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 67
2014-07-23 17:33:30,527 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,528 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,531 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,533 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,592 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 67 is 678
2014-07-23 17:33:30,593 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 67 directly to driver
2014-07-23 17:33:30,593 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 67
2014-07-23 17:33:30,594 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 67 in 69 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,594 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 1)
2014-07-23 17:33:30,621 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 66 is 678
2014-07-23 17:33:30,621 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 66 directly to driver
2014-07-23 17:33:30,621 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 66
2014-07-23 17:33:30,622 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(64, 0)
2014-07-23 17:33:30,622 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 66 in 99 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,622 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,622 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 64 (reduce at PCA.scala:57) finished in 0.099 s
2014-07-23 17:33:30,623 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.105248114 s
2014-07-23 17:33:30,627 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,629 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,629 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 66(reduce at PCA.scala:57)
2014-07-23 17:33:30,629 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 67)
2014-07-23 17:33:30,630 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,630 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 66 (MappedRDD[73] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 66 (MappedRDD[73] at map at PCA.scala:57)
2014-07-23 17:33:30,632 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 2 tasks
2014-07-23 17:33:30,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:0 as TID 68 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,633 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:30,634 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 66.0:1 as TID 69 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,634 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 66.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:30,635 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 69
2014-07-23 17:33:30,637 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,642 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,642 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 68
2014-07-23 17:33:30,644 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,645 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,698 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 69 is 678
2014-07-23 17:33:30,698 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 69 directly to driver
2014-07-23 17:33:30,698 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 69
2014-07-23 17:33:30,701 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 69 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,701 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 1)
2014-07-23 17:33:30,706 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 68 is 678
2014-07-23 17:33:30,706 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 68 directly to driver
2014-07-23 17:33:30,707 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 68
2014-07-23 17:33:30,707 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(66, 0)
2014-07-23 17:33:30,707 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 68 in 74 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,708 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,708 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 66 (reduce at PCA.scala:57) finished in 0.074 s
2014-07-23 17:33:30,708 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.080431752 s
2014-07-23 17:33:30,712 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,714 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,714 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 68(reduce at PCA.scala:57)
2014-07-23 17:33:30,714 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 69)
2014-07-23 17:33:30,720 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,720 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 68 (MappedRDD[75] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,722 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 68 (MappedRDD[75] at map at PCA.scala:57)
2014-07-23 17:33:30,723 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 68.0 with 2 tasks
2014-07-23 17:33:30,723 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:0 as TID 70 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,724 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:30,724 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 68.0:1 as TID 71 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,724 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 68.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:30,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 70
2014-07-23 17:33:30,725 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 71
2014-07-23 17:33:30,726 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,726 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,727 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,727 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 70 is 678
2014-07-23 17:33:30,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 70 directly to driver
2014-07-23 17:33:30,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 70
2014-07-23 17:33:30,788 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 0)
2014-07-23 17:33:30,788 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 70 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 71 is 678
2014-07-23 17:33:30,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 71 directly to driver
2014-07-23 17:33:30,798 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 71
2014-07-23 17:33:30,799 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(68, 1)
2014-07-23 17:33:30,799 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 71 in 74 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,799 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,799 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 68 (reduce at PCA.scala:57) finished in 0.076 s
2014-07-23 17:33:30,799 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.086673818 s
2014-07-23 17:33:30,804 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,805 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,805 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 70(reduce at PCA.scala:57)
2014-07-23 17:33:30,805 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 71)
2014-07-23 17:33:30,806 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,806 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 70 (MappedRDD[77] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,808 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 70 (MappedRDD[77] at map at PCA.scala:57)
2014-07-23 17:33:30,808 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 70.0 with 2 tasks
2014-07-23 17:33:30,809 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:0 as TID 72 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,809 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:30,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 70.0:1 as TID 73 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,810 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 70.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:30,810 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 72
2014-07-23 17:33:30,811 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 73
2014-07-23 17:33:30,812 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,812 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,813 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,813 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,872 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 73 is 678
2014-07-23 17:33:30,872 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 73 directly to driver
2014-07-23 17:33:30,872 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 72 is 678
2014-07-23 17:33:30,872 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 72 directly to driver
2014-07-23 17:33:30,872 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 72
2014-07-23 17:33:30,873 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 1)
2014-07-23 17:33:30,874 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 73 in 63 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,874 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 73
2014-07-23 17:33:30,874 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 72 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,874 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,874 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(70, 0)
2014-07-23 17:33:30,874 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 70 (reduce at PCA.scala:57) finished in 0.065 s
2014-07-23 17:33:30,875 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070891348 s
2014-07-23 17:33:30,879 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,881 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,881 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 72(reduce at PCA.scala:57)
2014-07-23 17:33:30,881 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 73)
2014-07-23 17:33:30,882 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,882 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 72 (MappedRDD[79] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,884 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 72 (MappedRDD[79] at map at PCA.scala:57)
2014-07-23 17:33:30,884 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 2 tasks
2014-07-23 17:33:30,885 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:0 as TID 74 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,885 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:30,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 72.0:1 as TID 75 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,886 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 72.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:30,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 74
2014-07-23 17:33:30,887 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 75
2014-07-23 17:33:30,888 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:30,896 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,899 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,941 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 74 is 678
2014-07-23 17:33:30,941 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 74 directly to driver
2014-07-23 17:33:30,941 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 74
2014-07-23 17:33:30,942 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 0)
2014-07-23 17:33:30,943 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 74 in 57 ms on localhost (progress: 1/2)
2014-07-23 17:33:30,956 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 75 is 678
2014-07-23 17:33:30,956 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 75 directly to driver
2014-07-23 17:33:30,956 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 75
2014-07-23 17:33:30,957 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(72, 1)
2014-07-23 17:33:30,957 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 75 in 70 ms on localhost (progress: 2/2)
2014-07-23 17:33:30,957 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2014-07-23 17:33:30,957 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 72 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:33:30,957 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.077867329 s
2014-07-23 17:33:30,961 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:30,963 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:30,963 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 74(reduce at PCA.scala:57)
2014-07-23 17:33:30,963 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 75)
2014-07-23 17:33:30,964 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:30,964 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 74 (MappedRDD[81] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:30,966 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 74 (MappedRDD[81] at map at PCA.scala:57)
2014-07-23 17:33:30,966 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 2 tasks
2014-07-23 17:33:30,967 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:0 as TID 76 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,967 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:0 as 2518 bytes in 0 ms
2014-07-23 17:33:30,968 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 74.0:1 as TID 77 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:30,968 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 74.0:1 as 2518 bytes in 0 ms
2014-07-23 17:33:30,968 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 76
2014-07-23 17:33:30,970 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,971 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 77
2014-07-23 17:33:30,972 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:30,974 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:30,976 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,053 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 77 is 678
2014-07-23 17:33:31,053 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 77 directly to driver
2014-07-23 17:33:31,053 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 77
2014-07-23 17:33:31,055 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 76 is 678
2014-07-23 17:33:31,055 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 76 directly to driver
2014-07-23 17:33:31,055 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 76
2014-07-23 17:33:31,055 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 77 in 87 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,055 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 1)
2014-07-23 17:33:31,056 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 76 in 89 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,056 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,056 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(74, 0)
2014-07-23 17:33:31,057 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 74 (reduce at PCA.scala:57) finished in 0.090 s
2014-07-23 17:33:31,057 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.095406814 s
2014-07-23 17:33:31,065 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,067 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,070 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 76(reduce at PCA.scala:57)
2014-07-23 17:33:31,070 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 77)
2014-07-23 17:33:31,071 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,072 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 76 (MappedRDD[83] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,074 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 76 (MappedRDD[83] at map at PCA.scala:57)
2014-07-23 17:33:31,074 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 76.0 with 2 tasks
2014-07-23 17:33:31,074 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:0 as TID 78 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,075 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:0 as 2521 bytes in 1 ms
2014-07-23 17:33:31,075 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 76.0:1 as TID 79 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,075 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 76.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:31,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 79
2014-07-23 17:33:31,077 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,078 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 78
2014-07-23 17:33:31,080 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,080 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,081 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,141 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 79 is 678
2014-07-23 17:33:31,141 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 79 directly to driver
2014-07-23 17:33:31,142 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 79
2014-07-23 17:33:31,142 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 79 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,142 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 1)
2014-07-23 17:33:31,143 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 78 is 678
2014-07-23 17:33:31,143 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 78 directly to driver
2014-07-23 17:33:31,143 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 78
2014-07-23 17:33:31,144 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(76, 0)
2014-07-23 17:33:31,144 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 78 in 70 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,144 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,144 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 76 (reduce at PCA.scala:57) finished in 0.070 s
2014-07-23 17:33:31,144 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.078840448 s
2014-07-23 17:33:31,149 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,150 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,150 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 78(reduce at PCA.scala:57)
2014-07-23 17:33:31,150 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 79)
2014-07-23 17:33:31,151 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,152 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 78 (MappedRDD[85] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,154 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 78 (MappedRDD[85] at map at PCA.scala:57)
2014-07-23 17:33:31,154 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 2 tasks
2014-07-23 17:33:31,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:0 as TID 80 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:31,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 78.0:1 as TID 81 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,155 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 78.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:31,156 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 80
2014-07-23 17:33:31,156 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 81
2014-07-23 17:33:31,157 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,157 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,158 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,158 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,238 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 81 is 678
2014-07-23 17:33:31,238 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 81 directly to driver
2014-07-23 17:33:31,238 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 81
2014-07-23 17:33:31,239 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 1)
2014-07-23 17:33:31,239 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 81 in 84 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 80 is 678
2014-07-23 17:33:31,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 80 directly to driver
2014-07-23 17:33:31,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 80
2014-07-23 17:33:31,243 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(78, 0)
2014-07-23 17:33:31,243 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 80 in 89 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,243 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,243 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 78 (reduce at PCA.scala:57) finished in 0.089 s
2014-07-23 17:33:31,243 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.094476966 s
2014-07-23 17:33:31,248 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,250 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,250 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 80(reduce at PCA.scala:57)
2014-07-23 17:33:31,250 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 81)
2014-07-23 17:33:31,251 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,252 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 80 (MappedRDD[87] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,253 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 80 (MappedRDD[87] at map at PCA.scala:57)
2014-07-23 17:33:31,253 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 2 tasks
2014-07-23 17:33:31,254 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:0 as TID 82 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,254 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:31,255 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 80.0:1 as TID 83 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,255 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 80.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:31,255 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 82
2014-07-23 17:33:31,256 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 83
2014-07-23 17:33:31,257 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,257 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,258 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,258 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,323 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 83 is 678
2014-07-23 17:33:31,323 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 83 directly to driver
2014-07-23 17:33:31,324 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 82 is 678
2014-07-23 17:33:31,324 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 82 directly to driver
2014-07-23 17:33:31,325 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 1)
2014-07-23 17:33:31,325 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 83 in 69 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 82
2014-07-23 17:33:31,325 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(80, 0)
2014-07-23 17:33:31,325 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 82 in 71 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,325 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,325 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 80 (reduce at PCA.scala:57) finished in 0.071 s
2014-07-23 17:33:31,326 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.077676726 s
2014-07-23 17:33:31,331 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,331 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 83
2014-07-23 17:33:31,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 82(reduce at PCA.scala:57)
2014-07-23 17:33:31,332 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 83)
2014-07-23 17:33:31,333 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,334 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 82 (MappedRDD[89] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,335 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 82 (MappedRDD[89] at map at PCA.scala:57)
2014-07-23 17:33:31,335 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 82.0 with 2 tasks
2014-07-23 17:33:31,336 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:0 as TID 84 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:31,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 82.0:1 as TID 85 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,337 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 82.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:31,337 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 84
2014-07-23 17:33:31,338 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 85
2014-07-23 17:33:31,339 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,339 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,340 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,343 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,405 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 85 is 678
2014-07-23 17:33:31,405 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 85 directly to driver
2014-07-23 17:33:31,406 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 85 in 69 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,407 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 1)
2014-07-23 17:33:31,407 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 85
2014-07-23 17:33:31,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 84 is 678
2014-07-23 17:33:31,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 84 directly to driver
2014-07-23 17:33:31,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 84
2014-07-23 17:33:31,408 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(82, 0)
2014-07-23 17:33:31,408 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 84 in 72 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,409 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,409 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 82 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:33:31,409 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.078405739 s
2014-07-23 17:33:31,413 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,415 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,415 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 84(reduce at PCA.scala:57)
2014-07-23 17:33:31,415 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 85)
2014-07-23 17:33:31,416 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,416 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 84 (MappedRDD[91] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,418 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 84 (MappedRDD[91] at map at PCA.scala:57)
2014-07-23 17:33:31,418 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 2 tasks
2014-07-23 17:33:31,419 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:0 as TID 86 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,419 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:31,420 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 84.0:1 as TID 87 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,420 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 84.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:31,420 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 86
2014-07-23 17:33:31,421 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 87
2014-07-23 17:33:31,422 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,423 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,427 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,428 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,488 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 86 is 678
2014-07-23 17:33:31,488 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 86 directly to driver
2014-07-23 17:33:31,488 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 86
2014-07-23 17:33:31,489 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 0)
2014-07-23 17:33:31,489 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 86 in 70 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,497 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 87 is 678
2014-07-23 17:33:31,497 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 87 directly to driver
2014-07-23 17:33:31,497 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 87
2014-07-23 17:33:31,498 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(84, 1)
2014-07-23 17:33:31,498 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 87 in 79 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,498 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,498 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 84 (reduce at PCA.scala:57) finished in 0.079 s
2014-07-23 17:33:31,498 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.084924573 s
2014-07-23 17:33:31,503 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,504 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,505 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 86(reduce at PCA.scala:57)
2014-07-23 17:33:31,505 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 87)
2014-07-23 17:33:31,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,506 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 86 (MappedRDD[93] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,508 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 86 (MappedRDD[93] at map at PCA.scala:57)
2014-07-23 17:33:31,508 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 86.0 with 2 tasks
2014-07-23 17:33:31,509 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:0 as TID 88 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,509 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:31,509 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 86.0:1 as TID 89 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,510 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 86.0:1 as 2521 bytes in 1 ms
2014-07-23 17:33:31,510 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 88
2014-07-23 17:33:31,511 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 89
2014-07-23 17:33:31,512 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,512 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,513 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,513 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 89 is 678
2014-07-23 17:33:31,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 89 directly to driver
2014-07-23 17:33:31,573 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 89
2014-07-23 17:33:31,574 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 1)
2014-07-23 17:33:31,575 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 89 in 65 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 88 is 678
2014-07-23 17:33:31,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 88 directly to driver
2014-07-23 17:33:31,578 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 88
2014-07-23 17:33:31,579 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(86, 0)
2014-07-23 17:33:31,579 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 88 in 71 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,579 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,579 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 86 (reduce at PCA.scala:57) finished in 0.071 s
2014-07-23 17:33:31,579 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.076308518 s
2014-07-23 17:33:31,586 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,588 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,588 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 88(reduce at PCA.scala:57)
2014-07-23 17:33:31,588 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 89)
2014-07-23 17:33:31,589 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,590 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 88 (MappedRDD[95] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,592 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 88 (MappedRDD[95] at map at PCA.scala:57)
2014-07-23 17:33:31,592 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 88.0 with 2 tasks
2014-07-23 17:33:31,593 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:0 as TID 90 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,593 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:31,594 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 88.0:1 as TID 91 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,594 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 88.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:31,594 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 91
2014-07-23 17:33:31,594 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 90
2014-07-23 17:33:31,596 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,596 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,597 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,597 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,656 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 91 is 678
2014-07-23 17:33:31,656 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 91 directly to driver
2014-07-23 17:33:31,656 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 90 is 678
2014-07-23 17:33:31,656 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 90 directly to driver
2014-07-23 17:33:31,656 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 90
2014-07-23 17:33:31,657 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 1)
2014-07-23 17:33:31,657 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 91 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,657 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 91
2014-07-23 17:33:31,658 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(88, 0)
2014-07-23 17:33:31,658 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 90 in 64 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,658 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,658 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 88 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:31,658 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.07200743 s
2014-07-23 17:33:31,663 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,664 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,664 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 90(reduce at PCA.scala:57)
2014-07-23 17:33:31,664 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 91)
2014-07-23 17:33:31,665 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,666 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 90 (MappedRDD[97] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,668 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 90 (MappedRDD[97] at map at PCA.scala:57)
2014-07-23 17:33:31,668 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 2 tasks
2014-07-23 17:33:31,668 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:0 as TID 92 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,669 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:31,669 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 90.0:1 as TID 93 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,669 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 90.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:31,669 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 92
2014-07-23 17:33:31,671 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,671 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 93
2014-07-23 17:33:31,672 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,673 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,674 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,734 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 92 is 678
2014-07-23 17:33:31,734 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 92 directly to driver
2014-07-23 17:33:31,734 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 92
2014-07-23 17:33:31,735 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 0)
2014-07-23 17:33:31,735 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 92 in 66 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,738 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 93 is 678
2014-07-23 17:33:31,738 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 93 directly to driver
2014-07-23 17:33:31,739 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 93
2014-07-23 17:33:31,740 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 93 in 71 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,740 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,740 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(90, 1)
2014-07-23 17:33:31,740 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 90 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:33:31,741 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.077701414 s
2014-07-23 17:33:31,745 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,746 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,746 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 92(reduce at PCA.scala:57)
2014-07-23 17:33:31,746 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 93)
2014-07-23 17:33:31,747 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,748 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 92 (MappedRDD[99] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,750 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 92 (MappedRDD[99] at map at PCA.scala:57)
2014-07-23 17:33:31,750 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 92.0 with 2 tasks
2014-07-23 17:33:31,751 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:0 as TID 94 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,751 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:31,751 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 92.0:1 as TID 95 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,752 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 92.0:1 as 2520 bytes in 1 ms
2014-07-23 17:33:31,752 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 94
2014-07-23 17:33:31,753 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,754 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,755 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 95
2014-07-23 17:33:31,756 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,757 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 94 is 678
2014-07-23 17:33:31,823 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 94 directly to driver
2014-07-23 17:33:31,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 95 is 678
2014-07-23 17:33:31,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 95 directly to driver
2014-07-23 17:33:31,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 95
2014-07-23 17:33:31,825 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 0)
2014-07-23 17:33:31,825 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 94 in 73 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,825 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 94
2014-07-23 17:33:31,825 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(92, 1)
2014-07-23 17:33:31,825 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 95 in 74 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,825 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,825 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 92 (reduce at PCA.scala:57) finished in 0.075 s
2014-07-23 17:33:31,826 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.080748502 s
2014-07-23 17:33:31,830 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,832 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,832 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 94(reduce at PCA.scala:57)
2014-07-23 17:33:31,832 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 95)
2014-07-23 17:33:31,833 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,833 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 94 (MappedRDD[101] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,836 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 94 (MappedRDD[101] at map at PCA.scala:57)
2014-07-23 17:33:31,836 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 94.0 with 2 tasks
2014-07-23 17:33:31,837 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:0 as TID 96 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,838 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:0 as 2520 bytes in 1 ms
2014-07-23 17:33:31,838 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 94.0:1 as TID 97 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,838 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 94.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:31,839 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 97
2014-07-23 17:33:31,840 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,841 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,842 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 96
2014-07-23 17:33:31,844 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,845 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,905 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 96 is 678
2014-07-23 17:33:31,905 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 97 is 678
2014-07-23 17:33:31,905 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 96 directly to driver
2014-07-23 17:33:31,906 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 97 directly to driver
2014-07-23 17:33:31,906 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 96
2014-07-23 17:33:31,907 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 97 in 69 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,907 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 1)
2014-07-23 17:33:31,908 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 97
2014-07-23 17:33:31,912 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 96 in 75 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,912 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,912 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(94, 0)
2014-07-23 17:33:31,912 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 94 (reduce at PCA.scala:57) finished in 0.070 s
2014-07-23 17:33:31,913 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.082312384 s
2014-07-23 17:33:31,917 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,921 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,921 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 96(reduce at PCA.scala:57)
2014-07-23 17:33:31,921 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 97)
2014-07-23 17:33:31,922 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,923 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 96 (MappedRDD[103] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,925 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 96 (MappedRDD[103] at map at PCA.scala:57)
2014-07-23 17:33:31,925 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 2 tasks
2014-07-23 17:33:31,925 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:0 as TID 98 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,926 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:31,926 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 96.0:1 as TID 99 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,926 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 96.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:31,927 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 98
2014-07-23 17:33:31,927 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 99
2014-07-23 17:33:31,928 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,928 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:31,929 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:31,929 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:31,983 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 99 is 678
2014-07-23 17:33:31,983 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 99 directly to driver
2014-07-23 17:33:31,984 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 99 in 58 ms on localhost (progress: 1/2)
2014-07-23 17:33:31,984 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 1)
2014-07-23 17:33:31,985 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 99
2014-07-23 17:33:31,986 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 98 is 678
2014-07-23 17:33:31,986 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 98 directly to driver
2014-07-23 17:33:31,986 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 98
2014-07-23 17:33:31,986 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(96, 0)
2014-07-23 17:33:31,986 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 98 in 61 ms on localhost (progress: 2/2)
2014-07-23 17:33:31,986 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2014-07-23 17:33:31,987 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 96 (reduce at PCA.scala:57) finished in 0.058 s
2014-07-23 17:33:31,987 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.069416093 s
2014-07-23 17:33:31,991 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:31,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:31,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 98(reduce at PCA.scala:57)
2014-07-23 17:33:31,993 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 99)
2014-07-23 17:33:31,994 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:31,994 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 98 (MappedRDD[105] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:31,996 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 98 (MappedRDD[105] at map at PCA.scala:57)
2014-07-23 17:33:31,996 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 2 tasks
2014-07-23 17:33:31,997 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:0 as TID 100 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,997 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:0 as 2517 bytes in 0 ms
2014-07-23 17:33:31,997 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 98.0:1 as TID 101 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:31,998 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 98.0:1 as 2517 bytes in 0 ms
2014-07-23 17:33:31,998 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 101
2014-07-23 17:33:31,999 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,001 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,001 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 100
2014-07-23 17:33:32,002 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,004 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 101 is 678
2014-07-23 17:33:32,075 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 100 is 678
2014-07-23 17:33:32,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 101 directly to driver
2014-07-23 17:33:32,075 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 100 directly to driver
2014-07-23 17:33:32,075 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 101
2014-07-23 17:33:32,076 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 100
2014-07-23 17:33:32,076 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 101 in 79 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,076 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 1)
2014-07-23 17:33:32,076 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(98, 0)
2014-07-23 17:33:32,076 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 100 in 79 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,077 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,077 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 98 (reduce at PCA.scala:57) finished in 0.080 s
2014-07-23 17:33:32,077 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.085665714 s
2014-07-23 17:33:32,082 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,083 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,083 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 100(reduce at PCA.scala:57)
2014-07-23 17:33:32,083 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 101)
2014-07-23 17:33:32,084 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,085 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 100 (MappedRDD[107] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,086 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 100 (MappedRDD[107] at map at PCA.scala:57)
2014-07-23 17:33:32,086 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 100.0 with 2 tasks
2014-07-23 17:33:32,087 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:0 as TID 102 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,087 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:32,088 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 100.0:1 as TID 103 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,088 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 100.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:32,088 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 102
2014-07-23 17:33:32,088 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 103
2014-07-23 17:33:32,090 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,090 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,091 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,091 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,148 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 102 is 678
2014-07-23 17:33:32,148 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 102 directly to driver
2014-07-23 17:33:32,148 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 102
2014-07-23 17:33:32,149 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 0)
2014-07-23 17:33:32,149 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 102 in 62 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,151 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 103 is 678
2014-07-23 17:33:32,151 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 103 directly to driver
2014-07-23 17:33:32,151 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 103
2014-07-23 17:33:32,152 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(100, 1)
2014-07-23 17:33:32,152 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 103 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,152 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,152 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 100 (reduce at PCA.scala:57) finished in 0.065 s
2014-07-23 17:33:32,153 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070721899 s
2014-07-23 17:33:32,157 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,158 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,158 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 102(reduce at PCA.scala:57)
2014-07-23 17:33:32,158 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 103)
2014-07-23 17:33:32,160 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,161 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 102 (MappedRDD[109] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,163 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 102 (MappedRDD[109] at map at PCA.scala:57)
2014-07-23 17:33:32,163 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 2 tasks
2014-07-23 17:33:32,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:0 as TID 104 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:32,164 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 102.0:1 as TID 105 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,165 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 102.0:1 as 2519 bytes in 1 ms
2014-07-23 17:33:32,165 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 105
2014-07-23 17:33:32,166 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 104
2014-07-23 17:33:32,168 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,169 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,170 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,171 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,233 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 105 is 678
2014-07-23 17:33:32,233 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 105 directly to driver
2014-07-23 17:33:32,234 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 105
2014-07-23 17:33:32,236 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 1)
2014-07-23 17:33:32,236 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 105 in 71 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,243 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 104 is 678
2014-07-23 17:33:32,243 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 104 directly to driver
2014-07-23 17:33:32,244 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 104
2014-07-23 17:33:32,244 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(102, 0)
2014-07-23 17:33:32,244 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 104 in 80 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,244 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,244 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 102 (reduce at PCA.scala:57) finished in 0.078 s
2014-07-23 17:33:32,245 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.08780813 s
2014-07-23 17:33:32,250 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,251 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,251 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 104(reduce at PCA.scala:57)
2014-07-23 17:33:32,252 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 105)
2014-07-23 17:33:32,252 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,253 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 104 (MappedRDD[111] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,255 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 104 (MappedRDD[111] at map at PCA.scala:57)
2014-07-23 17:33:32,255 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 104.0 with 2 tasks
2014-07-23 17:33:32,255 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:0 as TID 106 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,256 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:32,256 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 104.0:1 as TID 107 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,256 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 104.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:32,256 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 106
2014-07-23 17:33:32,256 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 107
2014-07-23 17:33:32,258 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,258 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,259 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,259 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,322 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 106 is 678
2014-07-23 17:33:32,322 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 106 directly to driver
2014-07-23 17:33:32,322 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 106
2014-07-23 17:33:32,322 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 0)
2014-07-23 17:33:32,323 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 106 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,326 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 107 is 678
2014-07-23 17:33:32,326 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 107 directly to driver
2014-07-23 17:33:32,326 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 107
2014-07-23 17:33:32,327 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(104, 1)
2014-07-23 17:33:32,327 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 107 in 71 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,327 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,327 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 104 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:33:32,328 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.077452623 s
2014-07-23 17:33:32,332 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 106(reduce at PCA.scala:57)
2014-07-23 17:33:32,333 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 107)
2014-07-23 17:33:32,334 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,335 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 106 (MappedRDD[113] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,336 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 106 (MappedRDD[113] at map at PCA.scala:57)
2014-07-23 17:33:32,336 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 106.0 with 2 tasks
2014-07-23 17:33:32,337 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:0 as TID 108 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,337 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:32,337 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 106.0:1 as TID 109 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,338 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 106.0:1 as 2521 bytes in 1 ms
2014-07-23 17:33:32,338 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 108
2014-07-23 17:33:32,339 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,340 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,344 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 109
2014-07-23 17:33:32,345 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,347 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 108 is 678
2014-07-23 17:33:32,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 108 directly to driver
2014-07-23 17:33:32,401 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 108
2014-07-23 17:33:32,402 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 108 in 65 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,402 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 0)
2014-07-23 17:33:32,412 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 109 is 678
2014-07-23 17:33:32,412 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 109 directly to driver
2014-07-23 17:33:32,412 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 109
2014-07-23 17:33:32,413 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(106, 1)
2014-07-23 17:33:32,413 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 109 in 75 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,413 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,413 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 106 (reduce at PCA.scala:57) finished in 0.076 s
2014-07-23 17:33:32,413 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.081112681 s
2014-07-23 17:33:32,417 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,419 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,419 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 108(reduce at PCA.scala:57)
2014-07-23 17:33:32,419 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 109)
2014-07-23 17:33:32,420 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,421 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 108 (MappedRDD[115] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,423 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 108 (MappedRDD[115] at map at PCA.scala:57)
2014-07-23 17:33:32,423 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 2 tasks
2014-07-23 17:33:32,424 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:0 as TID 110 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,424 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:32,424 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 108.0:1 as TID 111 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,424 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 108.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:32,425 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 110
2014-07-23 17:33:32,425 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 111
2014-07-23 17:33:32,426 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,426 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,427 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,427 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,489 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 111 is 678
2014-07-23 17:33:32,489 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 111 directly to driver
2014-07-23 17:33:32,490 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 111 in 66 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 1)
2014-07-23 17:33:32,490 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 111
2014-07-23 17:33:32,491 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 110 is 678
2014-07-23 17:33:32,491 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 110 directly to driver
2014-07-23 17:33:32,491 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 110
2014-07-23 17:33:32,491 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(108, 0)
2014-07-23 17:33:32,492 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 110 in 68 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,492 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,492 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 108 (reduce at PCA.scala:57) finished in 0.067 s
2014-07-23 17:33:32,492 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.074558755 s
2014-07-23 17:33:32,496 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,498 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,498 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 110(reduce at PCA.scala:57)
2014-07-23 17:33:32,498 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 111)
2014-07-23 17:33:32,499 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,499 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 110 (MappedRDD[117] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,501 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 110 (MappedRDD[117] at map at PCA.scala:57)
2014-07-23 17:33:32,501 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 110.0 with 2 tasks
2014-07-23 17:33:32,502 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:0 as TID 112 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,502 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:32,502 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 110.0:1 as TID 113 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,502 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 110.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:32,503 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 112
2014-07-23 17:33:32,503 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 113
2014-07-23 17:33:32,504 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,505 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,505 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,506 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,562 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 112 is 678
2014-07-23 17:33:32,562 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 112 directly to driver
2014-07-23 17:33:32,562 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 112
2014-07-23 17:33:32,563 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 0)
2014-07-23 17:33:32,563 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 112 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,564 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 113 is 678
2014-07-23 17:33:32,565 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 113 directly to driver
2014-07-23 17:33:32,565 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 113
2014-07-23 17:33:32,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(110, 1)
2014-07-23 17:33:32,565 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 113 in 63 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,565 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,565 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 110 (reduce at PCA.scala:57) finished in 0.064 s
2014-07-23 17:33:32,566 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.06927369 s
2014-07-23 17:33:32,570 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,572 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,572 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 112(reduce at PCA.scala:57)
2014-07-23 17:33:32,572 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 113)
2014-07-23 17:33:32,573 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,573 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 112 (MappedRDD[119] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,575 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 112 (MappedRDD[119] at map at PCA.scala:57)
2014-07-23 17:33:32,575 [spark-akka.actor.default-dispatcher-5] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 112.0 with 2 tasks
2014-07-23 17:33:32,575 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:0 as TID 114 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,576 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:0 as 2520 bytes in 1 ms
2014-07-23 17:33:32,576 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 112.0:1 as TID 115 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,576 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 112.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:32,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 114
2014-07-23 17:33:32,578 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,579 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 115
2014-07-23 17:33:32,580 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,580 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,581 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,642 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 114 is 678
2014-07-23 17:33:32,642 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 114 directly to driver
2014-07-23 17:33:32,643 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 114
2014-07-23 17:33:32,643 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 0)
2014-07-23 17:33:32,643 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 114 in 68 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,648 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 115 is 678
2014-07-23 17:33:32,648 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 115 directly to driver
2014-07-23 17:33:32,648 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 115
2014-07-23 17:33:32,649 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(112, 1)
2014-07-23 17:33:32,649 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 115 in 73 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,649 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,649 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 112 (reduce at PCA.scala:57) finished in 0.074 s
2014-07-23 17:33:32,649 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.078927437 s
2014-07-23 17:33:32,653 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,655 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,655 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 114(reduce at PCA.scala:57)
2014-07-23 17:33:32,655 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 115)
2014-07-23 17:33:32,656 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,656 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 114 (MappedRDD[121] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,658 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 114 (MappedRDD[121] at map at PCA.scala:57)
2014-07-23 17:33:32,658 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 2 tasks
2014-07-23 17:33:32,659 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:0 as TID 116 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,659 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:32,660 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 114.0:1 as TID 117 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,660 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 114.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:32,660 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 116
2014-07-23 17:33:32,661 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 117
2014-07-23 17:33:32,662 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,663 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,664 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,665 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 117 is 678
2014-07-23 17:33:32,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 117 directly to driver
2014-07-23 17:33:32,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 117
2014-07-23 17:33:32,726 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 1)
2014-07-23 17:33:32,726 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 117 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,729 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 116 is 678
2014-07-23 17:33:32,729 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 116 directly to driver
2014-07-23 17:33:32,729 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 116
2014-07-23 17:33:32,730 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(114, 0)
2014-07-23 17:33:32,730 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 116 in 71 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,730 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,730 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 114 (reduce at PCA.scala:57) finished in 0.071 s
2014-07-23 17:33:32,730 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.076799029 s
2014-07-23 17:33:32,734 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 116(reduce at PCA.scala:57)
2014-07-23 17:33:32,736 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 117)
2014-07-23 17:33:32,737 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,738 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 116 (MappedRDD[123] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,739 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 116 (MappedRDD[123] at map at PCA.scala:57)
2014-07-23 17:33:32,740 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 116.0 with 2 tasks
2014-07-23 17:33:32,740 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:0 as TID 118 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,741 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:0 as 2522 bytes in 1 ms
2014-07-23 17:33:32,741 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 116.0:1 as TID 119 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,742 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 116.0:1 as 2522 bytes in 1 ms
2014-07-23 17:33:32,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 118
2014-07-23 17:33:32,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 119
2014-07-23 17:33:32,743 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,743 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,744 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,744 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 119 is 678
2014-07-23 17:33:32,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 119 directly to driver
2014-07-23 17:33:32,809 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 119
2014-07-23 17:33:32,810 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 1)
2014-07-23 17:33:32,810 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 119 in 68 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,814 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 118 is 678
2014-07-23 17:33:32,814 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 118 directly to driver
2014-07-23 17:33:32,814 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 118
2014-07-23 17:33:32,815 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(116, 0)
2014-07-23 17:33:32,815 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 118 in 75 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,815 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,815 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 116 (reduce at PCA.scala:57) finished in 0.075 s
2014-07-23 17:33:32,815 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.080897164 s
2014-07-23 17:33:32,820 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,821 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,821 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 118(reduce at PCA.scala:57)
2014-07-23 17:33:32,821 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 119)
2014-07-23 17:33:32,822 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,823 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 118 (MappedRDD[125] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,824 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 118 (MappedRDD[125] at map at PCA.scala:57)
2014-07-23 17:33:32,824 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 118.0 with 2 tasks
2014-07-23 17:33:32,825 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:0 as TID 120 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,825 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:32,825 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 118.0:1 as TID 121 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,825 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 118.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:32,826 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 120
2014-07-23 17:33:32,827 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,828 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 121
2014-07-23 17:33:32,829 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,830 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,832 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 121 is 678
2014-07-23 17:33:32,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 121 directly to driver
2014-07-23 17:33:32,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 121
2014-07-23 17:33:32,887 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 121 in 62 ms on localhost (progress: 1/2)
2014-07-23 17:33:32,889 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 1)
2014-07-23 17:33:32,895 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 120 is 678
2014-07-23 17:33:32,895 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 120 directly to driver
2014-07-23 17:33:32,895 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 120
2014-07-23 17:33:32,896 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(118, 0)
2014-07-23 17:33:32,896 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 120 in 70 ms on localhost (progress: 2/2)
2014-07-23 17:33:32,896 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2014-07-23 17:33:32,896 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 118 (reduce at PCA.scala:57) finished in 0.072 s
2014-07-23 17:33:32,896 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.076378966 s
2014-07-23 17:33:32,902 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:32,904 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:32,904 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 120(reduce at PCA.scala:57)
2014-07-23 17:33:32,904 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 121)
2014-07-23 17:33:32,905 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:32,906 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 120 (MappedRDD[127] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:32,908 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 120 (MappedRDD[127] at map at PCA.scala:57)
2014-07-23 17:33:32,908 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 2 tasks
2014-07-23 17:33:32,909 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:0 as TID 122 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,909 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:32,909 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 120.0:1 as TID 123 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:32,910 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 120.0:1 as 2521 bytes in 1 ms
2014-07-23 17:33:32,910 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 122
2014-07-23 17:33:32,912 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,913 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:32,917 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 123
2014-07-23 17:33:32,919 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:32,920 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:32,999 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 122 is 678
2014-07-23 17:33:32,999 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 122 directly to driver
2014-07-23 17:33:32,999 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 122
2014-07-23 17:33:33,000 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 0)
2014-07-23 17:33:33,000 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 122 in 91 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,005 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 123 is 678
2014-07-23 17:33:33,005 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 123 directly to driver
2014-07-23 17:33:33,006 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 123
2014-07-23 17:33:33,006 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(120, 1)
2014-07-23 17:33:33,006 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 123 in 97 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,006 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,006 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 120 (reduce at PCA.scala:57) finished in 0.089 s
2014-07-23 17:33:33,007 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.104671799 s
2014-07-23 17:33:33,011 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,013 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,013 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 122(reduce at PCA.scala:57)
2014-07-23 17:33:33,013 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 123)
2014-07-23 17:33:33,014 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,014 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 122 (MappedRDD[129] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,017 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 122 (MappedRDD[129] at map at PCA.scala:57)
2014-07-23 17:33:33,017 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 122.0 with 2 tasks
2014-07-23 17:33:33,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 122.0:0 as TID 124 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 122.0:0 as 2518 bytes in 0 ms
2014-07-23 17:33:33,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 122.0:1 as TID 125 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,018 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 122.0:1 as 2518 bytes in 0 ms
2014-07-23 17:33:33,019 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 124
2014-07-23 17:33:33,020 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,021 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 125
2014-07-23 17:33:33,022 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,023 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,025 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,072 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 125 is 678
2014-07-23 17:33:33,072 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 124 is 678
2014-07-23 17:33:33,072 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 125 directly to driver
2014-07-23 17:33:33,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 124 directly to driver
2014-07-23 17:33:33,073 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 124
2014-07-23 17:33:33,073 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 125
2014-07-23 17:33:33,073 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(122, 1)
2014-07-23 17:33:33,073 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 125 in 55 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,074 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(122, 0)
2014-07-23 17:33:33,074 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 124 in 57 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,074 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,074 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 122 (reduce at PCA.scala:57) finished in 0.055 s
2014-07-23 17:33:33,074 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.063207065 s
2014-07-23 17:33:33,080 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,082 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,082 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 124(reduce at PCA.scala:57)
2014-07-23 17:33:33,082 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 125)
2014-07-23 17:33:33,083 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,083 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 124 (MappedRDD[131] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,085 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 124 (MappedRDD[131] at map at PCA.scala:57)
2014-07-23 17:33:33,085 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 124.0 with 2 tasks
2014-07-23 17:33:33,085 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 124.0:0 as TID 126 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,085 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 124.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:33,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 124.0:1 as TID 127 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 124.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:33,086 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 126
2014-07-23 17:33:33,087 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 127
2014-07-23 17:33:33,088 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,089 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,090 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,092 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,146 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 127 is 678
2014-07-23 17:33:33,146 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 127 directly to driver
2014-07-23 17:33:33,147 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 127 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,147 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(124, 1)
2014-07-23 17:33:33,148 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 127
2014-07-23 17:33:33,150 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 126 is 678
2014-07-23 17:33:33,150 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 126 directly to driver
2014-07-23 17:33:33,151 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 126
2014-07-23 17:33:33,151 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(124, 0)
2014-07-23 17:33:33,151 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 126 in 66 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,151 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,151 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 124 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:33,152 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.071472435 s
2014-07-23 17:33:33,156 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,158 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,158 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 126(reduce at PCA.scala:57)
2014-07-23 17:33:33,158 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 127)
2014-07-23 17:33:33,159 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,159 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 126 (MappedRDD[133] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,161 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 126 (MappedRDD[133] at map at PCA.scala:57)
2014-07-23 17:33:33,161 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 126.0 with 2 tasks
2014-07-23 17:33:33,161 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 126.0:0 as TID 128 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,162 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 126.0:0 as 2524 bytes in 0 ms
2014-07-23 17:33:33,162 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 126.0:1 as TID 129 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,162 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 126.0:1 as 2524 bytes in 0 ms
2014-07-23 17:33:33,162 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 128
2014-07-23 17:33:33,163 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 129
2014-07-23 17:33:33,163 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,164 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,165 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,165 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,228 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 129 is 678
2014-07-23 17:33:33,228 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 129 directly to driver
2014-07-23 17:33:33,228 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 128 is 678
2014-07-23 17:33:33,228 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 128 directly to driver
2014-07-23 17:33:33,228 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 128
2014-07-23 17:33:33,229 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(126, 1)
2014-07-23 17:33:33,229 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 129 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,230 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 129
2014-07-23 17:33:33,230 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(126, 0)
2014-07-23 17:33:33,230 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 128 in 69 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,230 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,230 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 126 (reduce at PCA.scala:57) finished in 0.069 s
2014-07-23 17:33:33,231 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.074328584 s
2014-07-23 17:33:33,235 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,236 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,236 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 128(reduce at PCA.scala:57)
2014-07-23 17:33:33,236 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 129)
2014-07-23 17:33:33,238 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,238 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 128 (MappedRDD[135] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,240 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 128 (MappedRDD[135] at map at PCA.scala:57)
2014-07-23 17:33:33,240 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 128.0 with 2 tasks
2014-07-23 17:33:33,240 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 128.0:0 as TID 130 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 128.0:0 as 2522 bytes in 1 ms
2014-07-23 17:33:33,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 128.0:1 as TID 131 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,241 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 128.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:33,242 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 131
2014-07-23 17:33:33,243 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,244 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 130
2014-07-23 17:33:33,245 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,247 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,250 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,324 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 131 is 678
2014-07-23 17:33:33,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 131 directly to driver
2014-07-23 17:33:33,325 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 131
2014-07-23 17:33:33,326 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(128, 1)
2014-07-23 17:33:33,326 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 131 in 85 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,328 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 130 is 678
2014-07-23 17:33:33,328 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 130 directly to driver
2014-07-23 17:33:33,328 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 130
2014-07-23 17:33:33,328 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(128, 0)
2014-07-23 17:33:33,328 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 130 in 88 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,329 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 128 (reduce at PCA.scala:57) finished in 0.084 s
2014-07-23 17:33:33,329 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 128.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,329 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.093883263 s
2014-07-23 17:33:33,333 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,334 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,334 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 130(reduce at PCA.scala:57)
2014-07-23 17:33:33,334 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 131)
2014-07-23 17:33:33,335 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,336 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 130 (MappedRDD[137] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,337 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 130 (MappedRDD[137] at map at PCA.scala:57)
2014-07-23 17:33:33,337 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 130.0 with 2 tasks
2014-07-23 17:33:33,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 130.0:0 as TID 132 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 130.0:0 as 2523 bytes in 0 ms
2014-07-23 17:33:33,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 130.0:1 as TID 133 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,338 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 130.0:1 as 2523 bytes in 0 ms
2014-07-23 17:33:33,339 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 132
2014-07-23 17:33:33,339 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 133
2014-07-23 17:33:33,340 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,340 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,341 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,341 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,402 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 132 is 678
2014-07-23 17:33:33,402 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 132 directly to driver
2014-07-23 17:33:33,403 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 132
2014-07-23 17:33:33,403 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(130, 0)
2014-07-23 17:33:33,403 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 132 in 65 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,406 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 133 is 678
2014-07-23 17:33:33,406 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 133 directly to driver
2014-07-23 17:33:33,407 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 133 in 69 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,407 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,407 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(130, 1)
2014-07-23 17:33:33,408 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 130 (reduce at PCA.scala:57) finished in 0.070 s
2014-07-23 17:33:33,408 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.074922442 s
2014-07-23 17:33:33,411 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 133
2014-07-23 17:33:33,413 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,414 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,414 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 132(reduce at PCA.scala:57)
2014-07-23 17:33:33,414 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 133)
2014-07-23 17:33:33,415 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,415 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 132 (MappedRDD[139] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,417 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 132 (MappedRDD[139] at map at PCA.scala:57)
2014-07-23 17:33:33,417 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 132.0 with 2 tasks
2014-07-23 17:33:33,417 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 132.0:0 as TID 134 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,418 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 132.0:0 as 2520 bytes in 1 ms
2014-07-23 17:33:33,418 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 132.0:1 as TID 135 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,418 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 132.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:33,418 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 134
2014-07-23 17:33:33,419 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 135
2014-07-23 17:33:33,419 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,420 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,421 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,428 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,478 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 135 is 678
2014-07-23 17:33:33,478 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 135 directly to driver
2014-07-23 17:33:33,479 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 135
2014-07-23 17:33:33,479 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(132, 1)
2014-07-23 17:33:33,479 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 135 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,483 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 134 is 678
2014-07-23 17:33:33,483 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 134 directly to driver
2014-07-23 17:33:33,483 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 134
2014-07-23 17:33:33,484 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(132, 0)
2014-07-23 17:33:33,484 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 134 in 67 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,484 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,484 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 132 (reduce at PCA.scala:57) finished in 0.067 s
2014-07-23 17:33:33,484 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.071527179 s
2014-07-23 17:33:33,489 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 134(reduce at PCA.scala:57)
2014-07-23 17:33:33,490 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 135)
2014-07-23 17:33:33,491 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,492 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 134 (MappedRDD[141] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,493 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 134 (MappedRDD[141] at map at PCA.scala:57)
2014-07-23 17:33:33,493 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 134.0 with 2 tasks
2014-07-23 17:33:33,494 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 134.0:0 as TID 136 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,494 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 134.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:33,494 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 134.0:1 as TID 137 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,494 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 134.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:33,495 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 136
2014-07-23 17:33:33,495 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 137
2014-07-23 17:33:33,496 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,496 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,497 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,497 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,556 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 136 is 678
2014-07-23 17:33:33,557 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 136 directly to driver
2014-07-23 17:33:33,558 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 136 in 63 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,558 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(134, 0)
2014-07-23 17:33:33,558 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 136
2014-07-23 17:33:33,561 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 137 is 678
2014-07-23 17:33:33,561 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 137 directly to driver
2014-07-23 17:33:33,561 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 137
2014-07-23 17:33:33,562 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(134, 1)
2014-07-23 17:33:33,562 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 137 in 68 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,562 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 134.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,562 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 134 (reduce at PCA.scala:57) finished in 0.069 s
2014-07-23 17:33:33,562 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.073516658 s
2014-07-23 17:33:33,567 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 136(reduce at PCA.scala:57)
2014-07-23 17:33:33,568 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 137)
2014-07-23 17:33:33,569 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,570 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 136 (MappedRDD[143] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,571 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 136 (MappedRDD[143] at map at PCA.scala:57)
2014-07-23 17:33:33,571 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 136.0 with 2 tasks
2014-07-23 17:33:33,572 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 136.0:0 as TID 138 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,572 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 136.0:0 as 2523 bytes in 0 ms
2014-07-23 17:33:33,572 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 136.0:1 as TID 139 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,572 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 136.0:1 as 2523 bytes in 0 ms
2014-07-23 17:33:33,572 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 138
2014-07-23 17:33:33,573 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 139
2014-07-23 17:33:33,575 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,576 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,576 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,579 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,639 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 139 is 678
2014-07-23 17:33:33,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 139 directly to driver
2014-07-23 17:33:33,640 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 139
2014-07-23 17:33:33,640 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 139 in 68 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,640 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(136, 1)
2014-07-23 17:33:33,645 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 138 is 678
2014-07-23 17:33:33,645 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 138 directly to driver
2014-07-23 17:33:33,645 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 138
2014-07-23 17:33:33,646 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 138 in 75 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,646 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 136.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,646 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(136, 0)
2014-07-23 17:33:33,646 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 136 (reduce at PCA.scala:57) finished in 0.075 s
2014-07-23 17:33:33,647 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.080018602 s
2014-07-23 17:33:33,651 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,652 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,653 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 138(reduce at PCA.scala:57)
2014-07-23 17:33:33,653 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 139)
2014-07-23 17:33:33,654 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,654 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 138 (MappedRDD[145] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,655 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 138 (MappedRDD[145] at map at PCA.scala:57)
2014-07-23 17:33:33,655 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 138.0 with 2 tasks
2014-07-23 17:33:33,656 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 138.0:0 as TID 140 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,656 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 138.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:33,656 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 138.0:1 as TID 141 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,657 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 138.0:1 as 2520 bytes in 1 ms
2014-07-23 17:33:33,657 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 141
2014-07-23 17:33:33,658 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,659 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,659 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 140
2014-07-23 17:33:33,661 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,662 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,719 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 141 is 678
2014-07-23 17:33:33,719 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 141 directly to driver
2014-07-23 17:33:33,720 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 141
2014-07-23 17:33:33,720 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(138, 1)
2014-07-23 17:33:33,720 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 141 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 140 is 678
2014-07-23 17:33:33,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 140 directly to driver
2014-07-23 17:33:33,725 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 140
2014-07-23 17:33:33,726 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(138, 0)
2014-07-23 17:33:33,726 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 140 in 69 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,726 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,726 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 138 (reduce at PCA.scala:57) finished in 0.070 s
2014-07-23 17:33:33,726 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.074913701 s
2014-07-23 17:33:33,730 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 140(reduce at PCA.scala:57)
2014-07-23 17:33:33,732 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 141)
2014-07-23 17:33:33,733 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,733 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 140 (MappedRDD[147] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,734 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 140 (MappedRDD[147] at map at PCA.scala:57)
2014-07-23 17:33:33,734 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 140.0 with 2 tasks
2014-07-23 17:33:33,735 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 140.0:0 as TID 142 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,735 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 140.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:33,735 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 140.0:1 as TID 143 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,736 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 140.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:33,736 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 142
2014-07-23 17:33:33,737 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 143
2014-07-23 17:33:33,738 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,739 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,740 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,741 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,802 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 142 is 678
2014-07-23 17:33:33,802 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 142 directly to driver
2014-07-23 17:33:33,802 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 142
2014-07-23 17:33:33,803 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 142 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,804 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(140, 0)
2014-07-23 17:33:33,816 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 143 is 678
2014-07-23 17:33:33,816 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 143 directly to driver
2014-07-23 17:33:33,816 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 143
2014-07-23 17:33:33,816 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(140, 1)
2014-07-23 17:33:33,816 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 143 in 81 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,817 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 140.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,817 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 140 (reduce at PCA.scala:57) finished in 0.081 s
2014-07-23 17:33:33,817 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.086456294 s
2014-07-23 17:33:33,821 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 142(reduce at PCA.scala:57)
2014-07-23 17:33:33,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 143)
2014-07-23 17:33:33,824 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,824 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 142 (MappedRDD[149] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,825 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 142 (MappedRDD[149] at map at PCA.scala:57)
2014-07-23 17:33:33,825 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 142.0 with 2 tasks
2014-07-23 17:33:33,826 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 142.0:0 as TID 144 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,826 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 142.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:33,826 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 142.0:1 as TID 145 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,826 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 142.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:33,827 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 144
2014-07-23 17:33:33,827 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 145
2014-07-23 17:33:33,828 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,829 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,830 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,831 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,913 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 144 is 678
2014-07-23 17:33:33,913 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 144 directly to driver
2014-07-23 17:33:33,913 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 144
2014-07-23 17:33:33,914 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(142, 0)
2014-07-23 17:33:33,914 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 144 in 88 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,919 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 145 is 678
2014-07-23 17:33:33,919 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 145 directly to driver
2014-07-23 17:33:33,919 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 145
2014-07-23 17:33:33,920 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(142, 1)
2014-07-23 17:33:33,920 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 145 in 93 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,920 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 142.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,920 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 142 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:33:33,920 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099231869 s
2014-07-23 17:33:33,925 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,926 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,926 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 144(reduce at PCA.scala:57)
2014-07-23 17:33:33,926 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 145)
2014-07-23 17:33:33,928 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,928 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 144 (MappedRDD[151] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,929 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 144 (MappedRDD[151] at map at PCA.scala:57)
2014-07-23 17:33:33,930 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 144.0 with 2 tasks
2014-07-23 17:33:33,930 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 144.0:0 as TID 146 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,931 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 144.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:33,931 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 144.0:1 as TID 147 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:33,931 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 144.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:33,931 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 146
2014-07-23 17:33:33,932 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 147
2014-07-23 17:33:33,934 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,935 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:33,936 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:33,937 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:33,986 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 146 is 678
2014-07-23 17:33:33,987 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 146 directly to driver
2014-07-23 17:33:33,988 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 146 in 57 ms on localhost (progress: 1/2)
2014-07-23 17:33:33,988 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(144, 0)
2014-07-23 17:33:33,988 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 146
2014-07-23 17:33:33,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 147 is 678
2014-07-23 17:33:33,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 147 directly to driver
2014-07-23 17:33:33,990 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 147
2014-07-23 17:33:33,991 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(144, 1)
2014-07-23 17:33:33,991 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 144 (reduce at PCA.scala:57) finished in 0.060 s
2014-07-23 17:33:33,991 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 147 in 59 ms on localhost (progress: 2/2)
2014-07-23 17:33:33,991 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2014-07-23 17:33:33,991 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.066342645 s
2014-07-23 17:33:33,995 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:33,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:33,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 146(reduce at PCA.scala:57)
2014-07-23 17:33:33,997 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 147)
2014-07-23 17:33:33,998 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:33,998 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 146 (MappedRDD[153] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:33,999 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 146 (MappedRDD[153] at map at PCA.scala:57)
2014-07-23 17:33:34,000 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 146.0 with 2 tasks
2014-07-23 17:33:34,000 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 146.0:0 as TID 148 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,000 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 146.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:34,001 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 146.0:1 as TID 149 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,001 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 146.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:34,001 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 148
2014-07-23 17:33:34,001 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 149
2014-07-23 17:33:34,002 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,002 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,003 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,048 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 148 is 678
2014-07-23 17:33:34,048 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 148 directly to driver
2014-07-23 17:33:34,048 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 148
2014-07-23 17:33:34,049 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(146, 0)
2014-07-23 17:33:34,049 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 148 in 49 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,051 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 149 is 678
2014-07-23 17:33:34,051 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 149 directly to driver
2014-07-23 17:33:34,051 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 149
2014-07-23 17:33:34,052 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(146, 1)
2014-07-23 17:33:34,052 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 146 (reduce at PCA.scala:57) finished in 0.052 s
2014-07-23 17:33:34,052 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 149 in 52 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,052 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 146.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,052 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.056811888 s
2014-07-23 17:33:34,057 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,058 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,058 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 148(reduce at PCA.scala:57)
2014-07-23 17:33:34,058 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 149)
2014-07-23 17:33:34,059 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,059 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 148 (MappedRDD[155] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,061 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 148 (MappedRDD[155] at map at PCA.scala:57)
2014-07-23 17:33:34,061 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 148.0 with 2 tasks
2014-07-23 17:33:34,061 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 148.0:0 as TID 150 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,062 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 148.0:0 as 2522 bytes in 1 ms
2014-07-23 17:33:34,062 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 148.0:1 as TID 151 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,062 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 148.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:34,062 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 150
2014-07-23 17:33:34,063 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 151
2014-07-23 17:33:34,064 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,065 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,066 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,067 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 150 is 678
2014-07-23 17:33:34,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 150 directly to driver
2014-07-23 17:33:34,125 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 150
2014-07-23 17:33:34,125 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 150 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,126 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(148, 0)
2014-07-23 17:33:34,130 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 151 is 678
2014-07-23 17:33:34,130 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 151 directly to driver
2014-07-23 17:33:34,130 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 151
2014-07-23 17:33:34,131 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(148, 1)
2014-07-23 17:33:34,131 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 148 (reduce at PCA.scala:57) finished in 0.070 s
2014-07-23 17:33:34,131 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 151 in 69 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,131 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,131 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.074504089 s
2014-07-23 17:33:34,136 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,137 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,137 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 150(reduce at PCA.scala:57)
2014-07-23 17:33:34,137 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 151)
2014-07-23 17:33:34,138 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,138 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 150 (MappedRDD[157] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,140 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 150 (MappedRDD[157] at map at PCA.scala:57)
2014-07-23 17:33:34,140 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 150.0 with 2 tasks
2014-07-23 17:33:34,140 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 150.0:0 as TID 152 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,141 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 150.0:0 as 2521 bytes in 1 ms
2014-07-23 17:33:34,141 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 150.0:1 as TID 153 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,141 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 150.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:34,141 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 152
2014-07-23 17:33:34,142 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 153
2014-07-23 17:33:34,143 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,143 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,144 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,149 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,209 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 153 is 678
2014-07-23 17:33:34,209 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 153 directly to driver
2014-07-23 17:33:34,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 152 is 678
2014-07-23 17:33:34,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 152 directly to driver
2014-07-23 17:33:34,209 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 152
2014-07-23 17:33:34,210 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 153
2014-07-23 17:33:34,210 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(150, 0)
2014-07-23 17:33:34,210 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 152 in 70 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,211 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(150, 1)
2014-07-23 17:33:34,211 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 153 in 70 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,211 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,211 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 150 (reduce at PCA.scala:57) finished in 0.071 s
2014-07-23 17:33:34,211 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.075211857 s
2014-07-23 17:33:34,216 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,217 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,217 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 152(reduce at PCA.scala:57)
2014-07-23 17:33:34,217 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 153)
2014-07-23 17:33:34,218 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,219 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 152 (MappedRDD[159] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,220 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 152 (MappedRDD[159] at map at PCA.scala:57)
2014-07-23 17:33:34,220 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 152.0 with 2 tasks
2014-07-23 17:33:34,221 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 152.0:0 as TID 154 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,221 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 152.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:34,221 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 152.0:1 as TID 155 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,221 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 152.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:34,222 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 154
2014-07-23 17:33:34,222 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 155
2014-07-23 17:33:34,223 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,224 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,224 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,225 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,287 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 155 is 678
2014-07-23 17:33:34,287 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 155 directly to driver
2014-07-23 17:33:34,291 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 155 in 70 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,292 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(152, 1)
2014-07-23 17:33:34,292 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 155
2014-07-23 17:33:34,293 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 154 is 678
2014-07-23 17:33:34,293 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 154 directly to driver
2014-07-23 17:33:34,294 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 154
2014-07-23 17:33:34,295 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 154 in 73 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,295 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(152, 0)
2014-07-23 17:33:34,295 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 152.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,295 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 152 (reduce at PCA.scala:57) finished in 0.074 s
2014-07-23 17:33:34,295 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.079352072 s
2014-07-23 17:33:34,300 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,301 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,301 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 154(reduce at PCA.scala:57)
2014-07-23 17:33:34,301 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 155)
2014-07-23 17:33:34,303 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,303 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 154 (MappedRDD[161] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,304 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 154 (MappedRDD[161] at map at PCA.scala:57)
2014-07-23 17:33:34,304 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 154.0 with 2 tasks
2014-07-23 17:33:34,305 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 154.0:0 as TID 156 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,305 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 154.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:34,305 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 154.0:1 as TID 157 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,306 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 154.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:34,306 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 156
2014-07-23 17:33:34,306 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 157
2014-07-23 17:33:34,307 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,307 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,308 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,322 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 156 is 678
2014-07-23 17:33:34,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 156 directly to driver
2014-07-23 17:33:34,364 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 156
2014-07-23 17:33:34,365 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(154, 0)
2014-07-23 17:33:34,365 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 156 in 59 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,392 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 157 is 678
2014-07-23 17:33:34,392 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 157 directly to driver
2014-07-23 17:33:34,392 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 157
2014-07-23 17:33:34,393 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(154, 1)
2014-07-23 17:33:34,393 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 154 (reduce at PCA.scala:57) finished in 0.088 s
2014-07-23 17:33:34,393 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 157 in 88 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,393 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 154.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,393 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.093189931 s
2014-07-23 17:33:34,398 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,399 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,399 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 156(reduce at PCA.scala:57)
2014-07-23 17:33:34,399 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 157)
2014-07-23 17:33:34,400 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,401 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 156 (MappedRDD[163] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,402 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 156 (MappedRDD[163] at map at PCA.scala:57)
2014-07-23 17:33:34,402 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 156.0 with 2 tasks
2014-07-23 17:33:34,403 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 156.0:0 as TID 158 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,403 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 156.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:34,403 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 156.0:1 as TID 159 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,403 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 156.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:34,404 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 158
2014-07-23 17:33:34,405 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 159
2014-07-23 17:33:34,406 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,407 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,408 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,409 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 159 is 678
2014-07-23 17:33:34,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 159 directly to driver
2014-07-23 17:33:34,497 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 159
2014-07-23 17:33:34,498 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(156, 1)
2014-07-23 17:33:34,498 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 159 in 95 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,499 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 158 is 678
2014-07-23 17:33:34,499 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 158 directly to driver
2014-07-23 17:33:34,500 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 158
2014-07-23 17:33:34,500 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 158 in 97 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,500 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(156, 0)
2014-07-23 17:33:34,500 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,501 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 156 (reduce at PCA.scala:57) finished in 0.098 s
2014-07-23 17:33:34,501 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.103254879 s
2014-07-23 17:33:34,505 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,507 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,507 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 158(reduce at PCA.scala:57)
2014-07-23 17:33:34,507 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 159)
2014-07-23 17:33:34,508 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,508 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 158 (MappedRDD[165] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,509 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 158 (MappedRDD[165] at map at PCA.scala:57)
2014-07-23 17:33:34,509 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 158.0 with 2 tasks
2014-07-23 17:33:34,510 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 158.0:0 as TID 160 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,510 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 158.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:34,511 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 158.0:1 as TID 161 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,511 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 158.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:34,511 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 161
2014-07-23 17:33:34,511 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 160
2014-07-23 17:33:34,512 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,512 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,513 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,513 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 160 is 678
2014-07-23 17:33:34,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 160 directly to driver
2014-07-23 17:33:34,574 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 160
2014-07-23 17:33:34,575 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 160 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,577 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 161 is 678
2014-07-23 17:33:34,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 161 directly to driver
2014-07-23 17:33:34,575 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(158, 0)
2014-07-23 17:33:34,578 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 161
2014-07-23 17:33:34,578 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(158, 1)
2014-07-23 17:33:34,578 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 161 in 68 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,579 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 158.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,579 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 158 (reduce at PCA.scala:57) finished in 0.068 s
2014-07-23 17:33:34,579 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.073729111 s
2014-07-23 17:33:34,584 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,585 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,585 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 160(reduce at PCA.scala:57)
2014-07-23 17:33:34,585 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 161)
2014-07-23 17:33:34,586 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,587 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 160 (MappedRDD[167] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 160 (MappedRDD[167] at map at PCA.scala:57)
2014-07-23 17:33:34,588 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 160.0 with 2 tasks
2014-07-23 17:33:34,589 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 160.0:0 as TID 162 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,589 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 160.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:34,589 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 160.0:1 as TID 163 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,589 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 160.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:34,590 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 162
2014-07-23 17:33:34,590 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 163
2014-07-23 17:33:34,591 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,591 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,592 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,601 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,653 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 163 is 678
2014-07-23 17:33:34,653 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 163 directly to driver
2014-07-23 17:33:34,654 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 163
2014-07-23 17:33:34,654 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(160, 1)
2014-07-23 17:33:34,654 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 163 in 65 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,665 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 162 is 678
2014-07-23 17:33:34,665 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 162 directly to driver
2014-07-23 17:33:34,665 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 162
2014-07-23 17:33:34,666 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 162 in 77 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,666 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 160.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,666 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(160, 0)
2014-07-23 17:33:34,667 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 160 (reduce at PCA.scala:57) finished in 0.078 s
2014-07-23 17:33:34,667 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.082570096 s
2014-07-23 17:33:34,671 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,672 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,672 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 162(reduce at PCA.scala:57)
2014-07-23 17:33:34,672 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 163)
2014-07-23 17:33:34,673 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,674 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 162 (MappedRDD[169] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,675 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 162 (MappedRDD[169] at map at PCA.scala:57)
2014-07-23 17:33:34,675 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 162.0 with 2 tasks
2014-07-23 17:33:34,675 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 162.0:0 as TID 164 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,676 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 162.0:0 as 2523 bytes in 1 ms
2014-07-23 17:33:34,676 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 162.0:1 as TID 165 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,676 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 162.0:1 as 2523 bytes in 0 ms
2014-07-23 17:33:34,676 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 164
2014-07-23 17:33:34,677 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,677 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 165
2014-07-23 17:33:34,678 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,679 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,680 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 165 is 678
2014-07-23 17:33:34,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 165 directly to driver
2014-07-23 17:33:34,742 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 165
2014-07-23 17:33:34,743 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(162, 1)
2014-07-23 17:33:34,743 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 165 in 67 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,744 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 164 is 678
2014-07-23 17:33:34,744 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 164 directly to driver
2014-07-23 17:33:34,744 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 164
2014-07-23 17:33:34,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(162, 0)
2014-07-23 17:33:34,744 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 164 in 69 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,744 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 162 (reduce at PCA.scala:57) finished in 0.069 s
2014-07-23 17:33:34,745 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.073705663 s
2014-07-23 17:33:34,749 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,751 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,751 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 164(reduce at PCA.scala:57)
2014-07-23 17:33:34,751 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 165)
2014-07-23 17:33:34,752 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,752 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 164 (MappedRDD[171] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,753 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 164 (MappedRDD[171] at map at PCA.scala:57)
2014-07-23 17:33:34,753 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 164.0 with 2 tasks
2014-07-23 17:33:34,754 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 164.0:0 as TID 166 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,754 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 164.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:34,754 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 164.0:1 as TID 167 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,755 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 164.0:1 as 2521 bytes in 1 ms
2014-07-23 17:33:34,755 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 166
2014-07-23 17:33:34,755 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 167
2014-07-23 17:33:34,756 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,756 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,757 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,757 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,838 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 167 is 678
2014-07-23 17:33:34,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 167 directly to driver
2014-07-23 17:33:34,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 167
2014-07-23 17:33:34,840 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(164, 1)
2014-07-23 17:33:34,840 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 167 in 85 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,840 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 166 is 678
2014-07-23 17:33:34,841 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 166 directly to driver
2014-07-23 17:33:34,841 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 166
2014-07-23 17:33:34,841 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(164, 0)
2014-07-23 17:33:34,841 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 164 (reduce at PCA.scala:57) finished in 0.087 s
2014-07-23 17:33:34,841 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 166 in 87 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,842 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,842 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.092405547 s
2014-07-23 17:33:34,846 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,847 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,847 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 166(reduce at PCA.scala:57)
2014-07-23 17:33:34,847 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 167)
2014-07-23 17:33:34,848 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,848 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 166 (MappedRDD[173] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,850 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 166 (MappedRDD[173] at map at PCA.scala:57)
2014-07-23 17:33:34,850 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 166.0 with 2 tasks
2014-07-23 17:33:34,850 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 166.0:0 as TID 168 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,850 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 166.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:34,851 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 166.0:1 as TID 169 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,851 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 166.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:34,852 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 168
2014-07-23 17:33:34,852 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 169
2014-07-23 17:33:34,853 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,853 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,854 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,854 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,910 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 168 is 678
2014-07-23 17:33:34,910 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 169 is 678
2014-07-23 17:33:34,911 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 168 directly to driver
2014-07-23 17:33:34,911 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 169 directly to driver
2014-07-23 17:33:34,911 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 169
2014-07-23 17:33:34,911 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(166, 0)
2014-07-23 17:33:34,911 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 168
2014-07-23 17:33:34,911 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 168 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,912 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 169 in 61 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,912 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,913 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(166, 1)
2014-07-23 17:33:34,913 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 166 (reduce at PCA.scala:57) finished in 0.063 s
2014-07-23 17:33:34,913 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.067099086 s
2014-07-23 17:33:34,917 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,918 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,919 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 168(reduce at PCA.scala:57)
2014-07-23 17:33:34,919 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 169)
2014-07-23 17:33:34,920 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,920 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 168 (MappedRDD[175] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,921 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 168 (MappedRDD[175] at map at PCA.scala:57)
2014-07-23 17:33:34,921 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 168.0 with 2 tasks
2014-07-23 17:33:34,922 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 168.0:0 as TID 170 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,922 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 168.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:34,922 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 168.0:1 as TID 171 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,923 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 168.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:34,923 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 171
2014-07-23 17:33:34,924 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 170
2014-07-23 17:33:34,924 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,925 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,926 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:34,927 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,981 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 171 is 678
2014-07-23 17:33:34,981 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 171 directly to driver
2014-07-23 17:33:34,982 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 171 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:34,983 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(168, 1)
2014-07-23 17:33:34,983 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 171
2014-07-23 17:33:34,984 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 170 is 678
2014-07-23 17:33:34,984 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 170 directly to driver
2014-07-23 17:33:34,984 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 170
2014-07-23 17:33:34,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(168, 0)
2014-07-23 17:33:34,984 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 168 (reduce at PCA.scala:57) finished in 0.061 s
2014-07-23 17:33:34,985 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.067452987 s
2014-07-23 17:33:34,984 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 170 in 62 ms on localhost (progress: 2/2)
2014-07-23 17:33:34,985 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2014-07-23 17:33:34,989 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:34,990 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:34,990 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 170(reduce at PCA.scala:57)
2014-07-23 17:33:34,991 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 171)
2014-07-23 17:33:34,992 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:34,992 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 170 (MappedRDD[177] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:34,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 170 (MappedRDD[177] at map at PCA.scala:57)
2014-07-23 17:33:34,993 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 170.0 with 2 tasks
2014-07-23 17:33:34,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 170.0:0 as TID 172 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 170.0:0 as 2518 bytes in 0 ms
2014-07-23 17:33:34,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 170.0:1 as TID 173 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:34,994 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 170.0:1 as 2518 bytes in 0 ms
2014-07-23 17:33:34,995 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 172
2014-07-23 17:33:34,995 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 173
2014-07-23 17:33:34,996 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,996 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:34,996 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:34,997 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,038 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 172 is 678
2014-07-23 17:33:35,038 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 172 directly to driver
2014-07-23 17:33:35,038 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 172
2014-07-23 17:33:35,039 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(170, 0)
2014-07-23 17:33:35,039 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 172 in 45 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,043 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 173 is 678
2014-07-23 17:33:35,043 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 173 directly to driver
2014-07-23 17:33:35,043 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 173
2014-07-23 17:33:35,044 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(170, 1)
2014-07-23 17:33:35,044 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 173 in 50 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,044 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,044 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 170 (reduce at PCA.scala:57) finished in 0.051 s
2014-07-23 17:33:35,044 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.054731612 s
2014-07-23 17:33:35,048 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 172(reduce at PCA.scala:57)
2014-07-23 17:33:35,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 173)
2014-07-23 17:33:35,050 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,051 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 172 (MappedRDD[179] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,052 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 172 (MappedRDD[179] at map at PCA.scala:57)
2014-07-23 17:33:35,052 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 172.0 with 2 tasks
2014-07-23 17:33:35,053 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 172.0:0 as TID 174 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,053 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 172.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:35,053 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 172.0:1 as TID 175 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,053 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 172.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:35,054 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 174
2014-07-23 17:33:35,054 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,055 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,055 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 175
2014-07-23 17:33:35,057 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,058 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,108 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 174 is 678
2014-07-23 17:33:35,108 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 174 directly to driver
2014-07-23 17:33:35,108 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 174
2014-07-23 17:33:35,109 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 174 in 56 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,109 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(172, 0)
2014-07-23 17:33:35,117 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 175 is 678
2014-07-23 17:33:35,117 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 175 directly to driver
2014-07-23 17:33:35,117 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 175
2014-07-23 17:33:35,118 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(172, 1)
2014-07-23 17:33:35,118 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 175 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,118 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 172.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,118 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 172 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:35,118 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.069936887 s
2014-07-23 17:33:35,123 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,124 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,124 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 174(reduce at PCA.scala:57)
2014-07-23 17:33:35,124 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 175)
2014-07-23 17:33:35,125 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,125 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 174 (MappedRDD[181] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,126 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 174 (MappedRDD[181] at map at PCA.scala:57)
2014-07-23 17:33:35,126 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 174.0 with 2 tasks
2014-07-23 17:33:35,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 174.0:0 as TID 176 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 174.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,127 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 174.0:1 as TID 177 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,128 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 174.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,128 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 177
2014-07-23 17:33:35,128 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 176
2014-07-23 17:33:35,129 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,129 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,130 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,130 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 177 is 678
2014-07-23 17:33:35,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 177 directly to driver
2014-07-23 17:33:35,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 177
2014-07-23 17:33:35,192 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(174, 1)
2014-07-23 17:33:35,192 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 177 in 65 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,192 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 176 is 678
2014-07-23 17:33:35,192 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 176 directly to driver
2014-07-23 17:33:35,192 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 176
2014-07-23 17:33:35,193 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(174, 0)
2014-07-23 17:33:35,193 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 174 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:35,193 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 176 in 66 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,193 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,193 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070665165 s
2014-07-23 17:33:35,197 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,199 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,199 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 176(reduce at PCA.scala:57)
2014-07-23 17:33:35,199 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 177)
2014-07-23 17:33:35,200 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,201 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 176 (MappedRDD[183] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,202 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 176 (MappedRDD[183] at map at PCA.scala:57)
2014-07-23 17:33:35,202 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 176.0 with 2 tasks
2014-07-23 17:33:35,202 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 176.0:0 as TID 178 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,203 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 176.0:0 as 2523 bytes in 0 ms
2014-07-23 17:33:35,203 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 176.0:1 as TID 179 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,203 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 176.0:1 as 2523 bytes in 0 ms
2014-07-23 17:33:35,203 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 178
2014-07-23 17:33:35,203 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 179
2014-07-23 17:33:35,205 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,205 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,206 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,206 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,262 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 179 is 678
2014-07-23 17:33:35,262 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 179 directly to driver
2014-07-23 17:33:35,263 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 179
2014-07-23 17:33:35,263 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(176, 1)
2014-07-23 17:33:35,263 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 179 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,265 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 178 is 678
2014-07-23 17:33:35,265 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 178 directly to driver
2014-07-23 17:33:35,265 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 178
2014-07-23 17:33:35,265 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(176, 0)
2014-07-23 17:33:35,265 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 178 in 63 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,266 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 176.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,266 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 176 (reduce at PCA.scala:57) finished in 0.064 s
2014-07-23 17:33:35,266 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.06825306 s
2014-07-23 17:33:35,270 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,271 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,271 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 178(reduce at PCA.scala:57)
2014-07-23 17:33:35,271 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 179)
2014-07-23 17:33:35,272 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,273 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 178 (MappedRDD[185] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,274 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 178 (MappedRDD[185] at map at PCA.scala:57)
2014-07-23 17:33:35,274 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 178.0 with 2 tasks
2014-07-23 17:33:35,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 178.0:0 as TID 180 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 178.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 178.0:1 as TID 181 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 178.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,276 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 181
2014-07-23 17:33:35,276 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 180
2014-07-23 17:33:35,277 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,277 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,278 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,278 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,338 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 181 is 678
2014-07-23 17:33:35,338 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 181 directly to driver
2014-07-23 17:33:35,338 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 181
2014-07-23 17:33:35,339 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(178, 1)
2014-07-23 17:33:35,339 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 181 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,340 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 180 is 678
2014-07-23 17:33:35,340 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 180 directly to driver
2014-07-23 17:33:35,340 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 180
2014-07-23 17:33:35,343 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(178, 0)
2014-07-23 17:33:35,343 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 180 in 67 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,343 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 178 (reduce at PCA.scala:57) finished in 0.069 s
2014-07-23 17:33:35,343 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 178.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,343 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.072620197 s
2014-07-23 17:33:35,348 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,349 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,349 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 180(reduce at PCA.scala:57)
2014-07-23 17:33:35,349 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 181)
2014-07-23 17:33:35,350 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,350 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 180 (MappedRDD[187] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,352 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 180 (MappedRDD[187] at map at PCA.scala:57)
2014-07-23 17:33:35,352 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 180.0 with 2 tasks
2014-07-23 17:33:35,352 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 180.0:0 as TID 182 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,352 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 180.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 180.0:1 as TID 183 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,353 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 180.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,353 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 182
2014-07-23 17:33:35,353 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 183
2014-07-23 17:33:35,354 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,355 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,355 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,355 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,416 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 183 is 678
2014-07-23 17:33:35,416 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 183 directly to driver
2014-07-23 17:33:35,416 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 183
2014-07-23 17:33:35,417 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(180, 1)
2014-07-23 17:33:35,417 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 183 in 64 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,418 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 182 is 678
2014-07-23 17:33:35,418 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 182 directly to driver
2014-07-23 17:33:35,418 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 182
2014-07-23 17:33:35,418 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(180, 0)
2014-07-23 17:33:35,419 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 180 (reduce at PCA.scala:57) finished in 0.067 s
2014-07-23 17:33:35,419 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 182 in 66 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,419 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,419 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070815167 s
2014-07-23 17:33:35,424 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,428 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,429 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 182(reduce at PCA.scala:57)
2014-07-23 17:33:35,429 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 183)
2014-07-23 17:33:35,437 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,438 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 182 (MappedRDD[189] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,439 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 182 (MappedRDD[189] at map at PCA.scala:57)
2014-07-23 17:33:35,439 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 182.0 with 2 tasks
2014-07-23 17:33:35,440 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 182.0:0 as TID 184 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,440 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 182.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,440 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 182.0:1 as TID 185 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,441 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 182.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,441 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 184
2014-07-23 17:33:35,442 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,443 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,447 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 185
2014-07-23 17:33:35,449 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,450 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 184 is 678
2014-07-23 17:33:35,549 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 184 directly to driver
2014-07-23 17:33:35,554 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 184 in 114 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(182, 0)
2014-07-23 17:33:35,555 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 184
2014-07-23 17:33:35,553 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 185 is 678
2014-07-23 17:33:35,555 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 185 directly to driver
2014-07-23 17:33:35,556 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 185
2014-07-23 17:33:35,556 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(182, 1)
2014-07-23 17:33:35,556 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 185 in 116 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,556 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 182 (reduce at PCA.scala:57) finished in 0.108 s
2014-07-23 17:33:35,556 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,556 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.132250668 s
2014-07-23 17:33:35,561 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,562 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,562 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 184(reduce at PCA.scala:57)
2014-07-23 17:33:35,562 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 185)
2014-07-23 17:33:35,563 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,563 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 184 (MappedRDD[191] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,564 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 184 (MappedRDD[191] at map at PCA.scala:57)
2014-07-23 17:33:35,565 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 184.0 with 2 tasks
2014-07-23 17:33:35,565 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 184.0:0 as TID 186 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,566 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 184.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:35,566 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 184.0:1 as TID 187 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,566 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 184.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:35,566 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 187
2014-07-23 17:33:35,567 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,567 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 186
2014-07-23 17:33:35,568 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,568 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,569 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,633 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 186 is 678
2014-07-23 17:33:35,633 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 186 directly to driver
2014-07-23 17:33:35,633 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 186
2014-07-23 17:33:35,634 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 186 in 68 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,634 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(184, 0)
2014-07-23 17:33:35,659 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 187 is 678
2014-07-23 17:33:35,659 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 187 directly to driver
2014-07-23 17:33:35,659 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 187
2014-07-23 17:33:35,660 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 187 in 93 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,660 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,660 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(184, 1)
2014-07-23 17:33:35,660 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 184 (reduce at PCA.scala:57) finished in 0.095 s
2014-07-23 17:33:35,661 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.099708226 s
2014-07-23 17:33:35,665 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,666 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,666 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 186(reduce at PCA.scala:57)
2014-07-23 17:33:35,666 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 187)
2014-07-23 17:33:35,668 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,669 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 186 (MappedRDD[193] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,670 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 186 (MappedRDD[193] at map at PCA.scala:57)
2014-07-23 17:33:35,670 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 186.0 with 2 tasks
2014-07-23 17:33:35,670 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 186.0:0 as TID 188 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,670 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 186.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,671 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 186.0:1 as TID 189 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,671 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 186.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,671 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 189
2014-07-23 17:33:35,671 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 188
2014-07-23 17:33:35,672 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,673 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,673 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,753 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 189 is 678
2014-07-23 17:33:35,753 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 188 is 678
2014-07-23 17:33:35,753 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 189 directly to driver
2014-07-23 17:33:35,753 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 188 directly to driver
2014-07-23 17:33:35,753 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 189
2014-07-23 17:33:35,754 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 188
2014-07-23 17:33:35,754 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 189 in 83 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,754 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(186, 1)
2014-07-23 17:33:35,754 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 188 in 84 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,754 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,754 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(186, 0)
2014-07-23 17:33:35,754 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 186 (reduce at PCA.scala:57) finished in 0.084 s
2014-07-23 17:33:35,755 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.089342508 s
2014-07-23 17:33:35,759 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,761 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,761 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 188(reduce at PCA.scala:57)
2014-07-23 17:33:35,761 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 189)
2014-07-23 17:33:35,765 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,774 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 188 (MappedRDD[195] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,776 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 188 (MappedRDD[195] at map at PCA.scala:57)
2014-07-23 17:33:35,776 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 188.0 with 2 tasks
2014-07-23 17:33:35,776 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 188.0:0 as TID 190 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,777 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 188.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,777 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 188.0:1 as TID 191 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,777 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 188.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,777 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 190
2014-07-23 17:33:35,778 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,779 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,779 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 191
2014-07-23 17:33:35,781 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,782 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 190 is 678
2014-07-23 17:33:35,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 190 directly to driver
2014-07-23 17:33:35,839 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 190
2014-07-23 17:33:35,839 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(188, 0)
2014-07-23 17:33:35,839 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 190 in 63 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,842 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 191 is 678
2014-07-23 17:33:35,842 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 191 directly to driver
2014-07-23 17:33:35,842 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 191
2014-07-23 17:33:35,844 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 191 in 66 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,844 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 188.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,844 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(188, 1)
2014-07-23 17:33:35,844 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 188 (reduce at PCA.scala:57) finished in 0.067 s
2014-07-23 17:33:35,844 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.085021417 s
2014-07-23 17:33:35,849 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,850 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,850 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 190(reduce at PCA.scala:57)
2014-07-23 17:33:35,850 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 191)
2014-07-23 17:33:35,851 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,851 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 190 (MappedRDD[197] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,852 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 190 (MappedRDD[197] at map at PCA.scala:57)
2014-07-23 17:33:35,852 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 190.0 with 2 tasks
2014-07-23 17:33:35,853 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 190.0:0 as TID 192 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,853 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 190.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:35,853 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 190.0:1 as TID 193 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,853 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 190.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:35,853 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 192
2014-07-23 17:33:35,854 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,855 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,855 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 193
2014-07-23 17:33:35,856 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,857 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,914 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 192 is 678
2014-07-23 17:33:35,914 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 192 directly to driver
2014-07-23 17:33:35,915 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 192 in 62 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,915 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(190, 0)
2014-07-23 17:33:35,915 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 192
2014-07-23 17:33:35,918 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 193 is 678
2014-07-23 17:33:35,918 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 193 directly to driver
2014-07-23 17:33:35,918 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 193
2014-07-23 17:33:35,918 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(190, 1)
2014-07-23 17:33:35,918 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 190 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:35,918 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 193 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,919 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 190.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,919 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070074756 s
2014-07-23 17:33:35,924 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,925 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,925 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 192(reduce at PCA.scala:57)
2014-07-23 17:33:35,925 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 193)
2014-07-23 17:33:35,926 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,926 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 192 (MappedRDD[199] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:35,930 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 192 (MappedRDD[199] at map at PCA.scala:57)
2014-07-23 17:33:35,931 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 192.0 with 2 tasks
2014-07-23 17:33:35,932 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 192.0:0 as TID 194 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,933 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 192.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:35,933 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 192.0:1 as TID 195 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:35,933 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 192.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:35,933 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 195
2014-07-23 17:33:35,934 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,935 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:35,936 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 194
2014-07-23 17:33:35,936 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:35,937 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:35,989 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 194 is 678
2014-07-23 17:33:35,989 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 194 directly to driver
2014-07-23 17:33:35,989 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 194
2014-07-23 17:33:35,990 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 194 in 57 ms on localhost (progress: 1/2)
2014-07-23 17:33:35,990 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(192, 0)
2014-07-23 17:33:35,991 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 195 is 678
2014-07-23 17:33:35,991 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 195 directly to driver
2014-07-23 17:33:35,991 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 195
2014-07-23 17:33:35,992 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(192, 1)
2014-07-23 17:33:35,992 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 195 in 58 ms on localhost (progress: 2/2)
2014-07-23 17:33:35,992 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2014-07-23 17:33:35,992 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 192 (reduce at PCA.scala:57) finished in 0.060 s
2014-07-23 17:33:35,992 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.068352222 s
2014-07-23 17:33:35,996 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:35,998 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:35,998 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 194(reduce at PCA.scala:57)
2014-07-23 17:33:35,998 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 195)
2014-07-23 17:33:35,998 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:35,999 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 194 (MappedRDD[201] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,000 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 194 (MappedRDD[201] at map at PCA.scala:57)
2014-07-23 17:33:36,000 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 194.0 with 2 tasks
2014-07-23 17:33:36,001 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 194.0:0 as TID 196 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,001 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 194.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:36,001 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 194.0:1 as TID 197 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,002 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 194.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:36,002 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 196
2014-07-23 17:33:36,002 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 197
2014-07-23 17:33:36,003 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,003 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,003 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,045 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 197 is 678
2014-07-23 17:33:36,045 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 197 directly to driver
2014-07-23 17:33:36,045 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 197
2014-07-23 17:33:36,047 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 196 is 678
2014-07-23 17:33:36,045 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 197 in 44 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,048 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 196 directly to driver
2014-07-23 17:33:36,048 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 196
2014-07-23 17:33:36,051 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 196 in 50 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,051 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,045 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(194, 1)
2014-07-23 17:33:36,051 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(194, 0)
2014-07-23 17:33:36,051 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 194 (reduce at PCA.scala:57) finished in 0.050 s
2014-07-23 17:33:36,052 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.055224923 s
2014-07-23 17:33:36,056 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,057 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,057 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 196(reduce at PCA.scala:57)
2014-07-23 17:33:36,057 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 197)
2014-07-23 17:33:36,059 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,059 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 196 (MappedRDD[203] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,060 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 196 (MappedRDD[203] at map at PCA.scala:57)
2014-07-23 17:33:36,061 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 196.0 with 2 tasks
2014-07-23 17:33:36,061 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 196.0:0 as TID 198 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,062 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 196.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:36,062 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 196.0:1 as TID 199 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,062 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 196.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:36,062 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 199
2014-07-23 17:33:36,063 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 198
2014-07-23 17:33:36,064 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,065 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,066 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,067 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 199 is 678
2014-07-23 17:33:36,122 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 199 directly to driver
2014-07-23 17:33:36,123 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 199
2014-07-23 17:33:36,123 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 199 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,123 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(196, 1)
2014-07-23 17:33:36,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 198 is 678
2014-07-23 17:33:36,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 198 directly to driver
2014-07-23 17:33:36,124 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 198
2014-07-23 17:33:36,125 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 198 in 64 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,126 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 196.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,125 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(196, 0)
2014-07-23 17:33:36,126 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 196 (reduce at PCA.scala:57) finished in 0.064 s
2014-07-23 17:33:36,126 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.069808961 s
2014-07-23 17:33:36,130 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,131 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,131 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 198(reduce at PCA.scala:57)
2014-07-23 17:33:36,131 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 199)
2014-07-23 17:33:36,132 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,132 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 198 (MappedRDD[205] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 198 (MappedRDD[205] at map at PCA.scala:57)
2014-07-23 17:33:36,133 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 198.0 with 2 tasks
2014-07-23 17:33:36,134 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 198.0:0 as TID 200 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,134 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 198.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:36,134 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 198.0:1 as TID 201 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,135 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 198.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:36,135 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 200
2014-07-23 17:33:36,135 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 201
2014-07-23 17:33:36,136 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,136 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,136 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,137 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,189 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 200 is 678
2014-07-23 17:33:36,189 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 200 directly to driver
2014-07-23 17:33:36,190 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 200
2014-07-23 17:33:36,190 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(198, 0)
2014-07-23 17:33:36,190 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 200 in 56 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 201 is 678
2014-07-23 17:33:36,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 201 directly to driver
2014-07-23 17:33:36,191 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 201
2014-07-23 17:33:36,192 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(198, 1)
2014-07-23 17:33:36,192 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 198 (reduce at PCA.scala:57) finished in 0.058 s
2014-07-23 17:33:36,192 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 201 in 58 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,192 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,192 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.062374267 s
2014-07-23 17:33:36,196 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,198 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,198 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 200(reduce at PCA.scala:57)
2014-07-23 17:33:36,198 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 201)
2014-07-23 17:33:36,199 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,199 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 200 (MappedRDD[207] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,200 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 200 (MappedRDD[207] at map at PCA.scala:57)
2014-07-23 17:33:36,200 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 200.0 with 2 tasks
2014-07-23 17:33:36,201 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 200.0:0 as TID 202 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,201 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 200.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:36,201 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 200.0:1 as TID 203 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,201 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 200.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:36,201 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 202
2014-07-23 17:33:36,202 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 203
2014-07-23 17:33:36,203 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,203 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,204 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,205 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,266 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 202 is 678
2014-07-23 17:33:36,266 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 202 directly to driver
2014-07-23 17:33:36,266 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 202
2014-07-23 17:33:36,267 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 202 in 66 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,267 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(200, 0)
2014-07-23 17:33:36,269 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 203 is 678
2014-07-23 17:33:36,269 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 203 directly to driver
2014-07-23 17:33:36,269 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 203
2014-07-23 17:33:36,270 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(200, 1)
2014-07-23 17:33:36,270 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 200 (reduce at PCA.scala:57) finished in 0.070 s
2014-07-23 17:33:36,270 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 203 in 68 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,270 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,270 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.073414244 s
2014-07-23 17:33:36,274 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 202(reduce at PCA.scala:57)
2014-07-23 17:33:36,275 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 203)
2014-07-23 17:33:36,277 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,277 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 202 (MappedRDD[209] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,279 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 202 (MappedRDD[209] at map at PCA.scala:57)
2014-07-23 17:33:36,279 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 202.0 with 2 tasks
2014-07-23 17:33:36,279 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 202.0:0 as TID 204 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,279 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 202.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:36,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 202.0:1 as TID 205 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,280 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 202.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:36,280 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 204
2014-07-23 17:33:36,281 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,282 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,283 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 205
2014-07-23 17:33:36,285 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,286 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,340 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 204 is 678
2014-07-23 17:33:36,340 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 204 directly to driver
2014-07-23 17:33:36,340 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 204
2014-07-23 17:33:36,340 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(202, 0)
2014-07-23 17:33:36,340 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 204 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,347 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 205 is 678
2014-07-23 17:33:36,347 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 205 directly to driver
2014-07-23 17:33:36,348 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 205 in 68 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,348 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(202, 1)
2014-07-23 17:33:36,348 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 202 (reduce at PCA.scala:57) finished in 0.069 s
2014-07-23 17:33:36,348 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 202.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,348 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.074263666 s
2014-07-23 17:33:36,351 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 205
2014-07-23 17:33:36,353 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 204(reduce at PCA.scala:57)
2014-07-23 17:33:36,354 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 205)
2014-07-23 17:33:36,355 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,355 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 204 (MappedRDD[211] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,356 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 204 (MappedRDD[211] at map at PCA.scala:57)
2014-07-23 17:33:36,357 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 2 tasks
2014-07-23 17:33:36,357 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 204.0:0 as TID 206 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,357 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 204.0:0 as 2519 bytes in 0 ms
2014-07-23 17:33:36,358 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 204.0:1 as TID 207 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,358 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 204.0:1 as 2519 bytes in 0 ms
2014-07-23 17:33:36,358 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 206
2014-07-23 17:33:36,359 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,359 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 207
2014-07-23 17:33:36,360 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,360 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,361 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,419 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 207 is 678
2014-07-23 17:33:36,419 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 207 directly to driver
2014-07-23 17:33:36,420 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 207
2014-07-23 17:33:36,420 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 207 in 63 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,420 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(204, 1)
2014-07-23 17:33:36,420 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 206 is 678
2014-07-23 17:33:36,420 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 206 directly to driver
2014-07-23 17:33:36,420 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 206
2014-07-23 17:33:36,421 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(204, 0)
2014-07-23 17:33:36,421 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 206 in 64 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,421 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 204 (reduce at PCA.scala:57) finished in 0.064 s
2014-07-23 17:33:36,421 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,421 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.068826165 s
2014-07-23 17:33:36,426 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,427 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,427 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 206(reduce at PCA.scala:57)
2014-07-23 17:33:36,427 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 207)
2014-07-23 17:33:36,428 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,429 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 206 (MappedRDD[213] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,430 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 206 (MappedRDD[213] at map at PCA.scala:57)
2014-07-23 17:33:36,430 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 206.0 with 2 tasks
2014-07-23 17:33:36,431 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 206.0:0 as TID 208 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,431 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 206.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:36,431 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 206.0:1 as TID 209 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,431 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 206.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:36,432 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 209
2014-07-23 17:33:36,432 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 208
2014-07-23 17:33:36,433 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,433 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,433 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,433 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,491 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 209 is 678
2014-07-23 17:33:36,491 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 209 directly to driver
2014-07-23 17:33:36,491 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 209
2014-07-23 17:33:36,492 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(206, 1)
2014-07-23 17:33:36,492 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 209 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,495 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 208 is 678
2014-07-23 17:33:36,495 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 208 directly to driver
2014-07-23 17:33:36,495 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 208
2014-07-23 17:33:36,496 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(206, 0)
2014-07-23 17:33:36,496 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 206 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:36,496 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 208 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,496 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,497 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070552553 s
2014-07-23 17:33:36,501 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,502 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,502 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 208(reduce at PCA.scala:57)
2014-07-23 17:33:36,502 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 209)
2014-07-23 17:33:36,503 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,503 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 208 (MappedRDD[215] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,504 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 208 (MappedRDD[215] at map at PCA.scala:57)
2014-07-23 17:33:36,504 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 208.0 with 2 tasks
2014-07-23 17:33:36,505 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 208.0:0 as TID 210 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,505 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 208.0:0 as 2524 bytes in 0 ms
2014-07-23 17:33:36,506 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 208.0:1 as TID 211 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,506 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 208.0:1 as 2524 bytes in 0 ms
2014-07-23 17:33:36,507 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 211
2014-07-23 17:33:36,508 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,509 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,510 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 210
2014-07-23 17:33:36,511 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,512 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,583 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 211 is 678
2014-07-23 17:33:36,583 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 211 directly to driver
2014-07-23 17:33:36,583 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 211
2014-07-23 17:33:36,583 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(208, 1)
2014-07-23 17:33:36,583 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 211 in 77 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,586 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 210 is 678
2014-07-23 17:33:36,586 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 210 directly to driver
2014-07-23 17:33:36,586 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 210
2014-07-23 17:33:36,587 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(208, 0)
2014-07-23 17:33:36,587 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 210 in 82 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,587 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 208.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,587 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 208 (reduce at PCA.scala:57) finished in 0.082 s
2014-07-23 17:33:36,587 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.086343819 s
2014-07-23 17:33:36,592 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,593 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,593 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 210(reduce at PCA.scala:57)
2014-07-23 17:33:36,593 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 211)
2014-07-23 17:33:36,599 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,600 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 210 (MappedRDD[217] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,601 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 210 (MappedRDD[217] at map at PCA.scala:57)
2014-07-23 17:33:36,601 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 210.0 with 2 tasks
2014-07-23 17:33:36,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 210.0:0 as TID 212 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 210.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:36,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 210.0:1 as TID 213 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,602 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 210.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:36,603 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 213
2014-07-23 17:33:36,603 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 212
2014-07-23 17:33:36,604 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,604 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,605 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,605 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,664 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 213 is 678
2014-07-23 17:33:36,665 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 213 directly to driver
2014-07-23 17:33:36,665 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 213
2014-07-23 17:33:36,665 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(210, 1)
2014-07-23 17:33:36,665 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 213 in 63 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 212 is 678
2014-07-23 17:33:36,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 212 directly to driver
2014-07-23 17:33:36,667 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 212
2014-07-23 17:33:36,668 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(210, 0)
2014-07-23 17:33:36,668 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 212 in 67 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,668 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 210 (reduce at PCA.scala:57) finished in 0.067 s
2014-07-23 17:33:36,668 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 210.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,668 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.076423169 s
2014-07-23 17:33:36,673 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,674 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,674 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 212(reduce at PCA.scala:57)
2014-07-23 17:33:36,674 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 213)
2014-07-23 17:33:36,675 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,675 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 212 (MappedRDD[219] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,676 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 212 (MappedRDD[219] at map at PCA.scala:57)
2014-07-23 17:33:36,676 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 212.0 with 2 tasks
2014-07-23 17:33:36,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 212.0:0 as TID 214 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 212.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:36,677 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 212.0:1 as TID 215 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,678 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 212.0:1 as 2521 bytes in 1 ms
2014-07-23 17:33:36,678 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 214
2014-07-23 17:33:36,679 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,680 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 215
2014-07-23 17:33:36,680 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,681 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,681 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,738 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 214 is 678
2014-07-23 17:33:36,738 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 214 directly to driver
2014-07-23 17:33:36,738 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 214
2014-07-23 17:33:36,739 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 214 in 62 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,739 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(212, 0)
2014-07-23 17:33:36,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 215 is 678
2014-07-23 17:33:36,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 215 directly to driver
2014-07-23 17:33:36,742 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 215
2014-07-23 17:33:36,743 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(212, 1)
2014-07-23 17:33:36,743 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 215 in 66 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,743 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 212.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,743 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 212 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:36,743 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.070055459 s
2014-07-23 17:33:36,747 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,748 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,748 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 214(reduce at PCA.scala:57)
2014-07-23 17:33:36,748 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 215)
2014-07-23 17:33:36,749 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,750 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 214 (MappedRDD[221] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,751 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 214 (MappedRDD[221] at map at PCA.scala:57)
2014-07-23 17:33:36,751 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 214.0 with 2 tasks
2014-07-23 17:33:36,751 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 214.0:0 as TID 216 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,751 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 214.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:36,752 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 214.0:1 as TID 217 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,752 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 214.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:36,752 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 216
2014-07-23 17:33:36,753 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 217
2014-07-23 17:33:36,754 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,755 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,756 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,756 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,810 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 216 is 678
2014-07-23 17:33:36,810 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 216 directly to driver
2014-07-23 17:33:36,811 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 216 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,812 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(214, 0)
2014-07-23 17:33:36,812 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 216
2014-07-23 17:33:36,812 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 217 is 678
2014-07-23 17:33:36,812 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 217 directly to driver
2014-07-23 17:33:36,812 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 217
2014-07-23 17:33:36,813 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(214, 1)
2014-07-23 17:33:36,813 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 217 in 60 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,813 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 214.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,813 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 214 (reduce at PCA.scala:57) finished in 0.062 s
2014-07-23 17:33:36,813 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.06566566 s
2014-07-23 17:33:36,817 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,818 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,818 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 216(reduce at PCA.scala:57)
2014-07-23 17:33:36,818 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 217)
2014-07-23 17:33:36,819 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,819 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 216 (MappedRDD[223] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,821 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 216 (MappedRDD[223] at map at PCA.scala:57)
2014-07-23 17:33:36,821 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 216.0 with 2 tasks
2014-07-23 17:33:36,821 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 216.0:0 as TID 218 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,821 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 216.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:36,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 216.0:1 as TID 219 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,822 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 216.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:36,822 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 218
2014-07-23 17:33:36,823 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 219
2014-07-23 17:33:36,824 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,824 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,824 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,824 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,875 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 218 is 678
2014-07-23 17:33:36,875 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 218 directly to driver
2014-07-23 17:33:36,875 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 219 is 678
2014-07-23 17:33:36,875 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 219 directly to driver
2014-07-23 17:33:36,875 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 219
2014-07-23 17:33:36,875 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 218
2014-07-23 17:33:36,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(216, 0)
2014-07-23 17:33:36,876 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 218 in 55 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(216, 1)
2014-07-23 17:33:36,876 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 216 (reduce at PCA.scala:57) finished in 0.055 s
2014-07-23 17:33:36,877 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.059633756 s
2014-07-23 17:33:36,876 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 219 in 55 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,880 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 216.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,881 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,882 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,882 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 218(reduce at PCA.scala:57)
2014-07-23 17:33:36,882 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 219)
2014-07-23 17:33:36,883 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,883 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 218 (MappedRDD[225] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,884 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 218 (MappedRDD[225] at map at PCA.scala:57)
2014-07-23 17:33:36,884 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 218.0 with 2 tasks
2014-07-23 17:33:36,885 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 218.0:0 as TID 220 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,885 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 218.0:0 as 2518 bytes in 0 ms
2014-07-23 17:33:36,885 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 218.0:1 as TID 221 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,885 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 218.0:1 as 2518 bytes in 0 ms
2014-07-23 17:33:36,886 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 221
2014-07-23 17:33:36,887 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 220
2014-07-23 17:33:36,888 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,889 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:36,890 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,890 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,943 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 221 is 678
2014-07-23 17:33:36,943 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 221 directly to driver
2014-07-23 17:33:36,943 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 220 is 678
2014-07-23 17:33:36,943 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 220 directly to driver
2014-07-23 17:33:36,943 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 220
2014-07-23 17:33:36,944 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 221
2014-07-23 17:33:36,944 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 221 in 59 ms on localhost (progress: 1/2)
2014-07-23 17:33:36,944 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(218, 1)
2014-07-23 17:33:36,944 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(218, 0)
2014-07-23 17:33:36,944 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 218 (reduce at PCA.scala:57) finished in 0.059 s
2014-07-23 17:33:36,944 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 220 in 59 ms on localhost (progress: 2/2)
2014-07-23 17:33:36,944 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 218.0, whose tasks have all completed, from pool 
2014-07-23 17:33:36,944 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.063638748 s
2014-07-23 17:33:36,948 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:36,949 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:36,950 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 220(reduce at PCA.scala:57)
2014-07-23 17:33:36,950 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 221)
2014-07-23 17:33:36,951 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:36,952 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 220 (MappedRDD[227] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:36,953 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 220 (MappedRDD[227] at map at PCA.scala:57)
2014-07-23 17:33:36,953 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 220.0 with 2 tasks
2014-07-23 17:33:36,953 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 220.0:0 as TID 222 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,954 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 220.0:0 as 2520 bytes in 1 ms
2014-07-23 17:33:36,954 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 220.0:1 as TID 223 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:36,954 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 220.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:36,954 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 222
2014-07-23 17:33:36,955 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,955 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 223
2014-07-23 17:33:36,956 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:36,956 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:36,957 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 223 is 678
2014-07-23 17:33:37,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 223 directly to driver
2014-07-23 17:33:37,006 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 223
2014-07-23 17:33:37,007 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(220, 1)
2014-07-23 17:33:37,007 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 223 in 52 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,007 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 222 is 678
2014-07-23 17:33:37,007 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 222 directly to driver
2014-07-23 17:33:37,007 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 222
2014-07-23 17:33:37,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(220, 0)
2014-07-23 17:33:37,008 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 222 in 55 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,008 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 220.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,008 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 220 (reduce at PCA.scala:57) finished in 0.055 s
2014-07-23 17:33:37,008 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.059769066 s
2014-07-23 17:33:37,013 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,014 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,014 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 222(reduce at PCA.scala:57)
2014-07-23 17:33:37,014 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 223)
2014-07-23 17:33:37,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 222 (MappedRDD[229] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,016 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 222 (MappedRDD[229] at map at PCA.scala:57)
2014-07-23 17:33:37,016 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 222.0 with 2 tasks
2014-07-23 17:33:37,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 222.0:0 as TID 224 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 222.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:37,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 222.0:1 as TID 225 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,017 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 222.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:37,018 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 224
2014-07-23 17:33:37,019 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,019 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 225
2014-07-23 17:33:37,020 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,020 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,021 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 225 is 678
2014-07-23 17:33:37,077 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 225 directly to driver
2014-07-23 17:33:37,078 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(222, 1)
2014-07-23 17:33:37,078 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 225 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,079 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 225
2014-07-23 17:33:37,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 224 is 678
2014-07-23 17:33:37,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 224 directly to driver
2014-07-23 17:33:37,080 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 224
2014-07-23 17:33:37,081 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(222, 0)
2014-07-23 17:33:37,081 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 224 in 64 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,081 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 222 (reduce at PCA.scala:57) finished in 0.065 s
2014-07-23 17:33:37,081 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.068720796 s
2014-07-23 17:33:37,081 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 222.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,085 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,086 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,087 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 224(reduce at PCA.scala:57)
2014-07-23 17:33:37,087 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 225)
2014-07-23 17:33:37,089 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,090 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 224 (MappedRDD[231] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 224 (MappedRDD[231] at map at PCA.scala:57)
2014-07-23 17:33:37,091 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 224.0 with 2 tasks
2014-07-23 17:33:37,091 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 224.0:0 as TID 226 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,092 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 224.0:0 as 2523 bytes in 0 ms
2014-07-23 17:33:37,092 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 224.0:1 as TID 227 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,092 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 224.0:1 as 2523 bytes in 0 ms
2014-07-23 17:33:37,092 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 226
2014-07-23 17:33:37,093 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,094 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 227
2014-07-23 17:33:37,094 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,095 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,096 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,152 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 227 is 678
2014-07-23 17:33:37,152 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 227 directly to driver
2014-07-23 17:33:37,152 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 227
2014-07-23 17:33:37,152 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(224, 1)
2014-07-23 17:33:37,152 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 227 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 226 is 678
2014-07-23 17:33:37,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 226 directly to driver
2014-07-23 17:33:37,153 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 226
2014-07-23 17:33:37,154 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(224, 0)
2014-07-23 17:33:37,154 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 224 (reduce at PCA.scala:57) finished in 0.063 s
2014-07-23 17:33:37,154 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 226 in 63 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,154 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 224.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,154 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.068731138 s
2014-07-23 17:33:37,158 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,159 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,159 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 226(reduce at PCA.scala:57)
2014-07-23 17:33:37,160 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 227)
2014-07-23 17:33:37,161 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,162 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 226 (MappedRDD[233] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 226 (MappedRDD[233] at map at PCA.scala:57)
2014-07-23 17:33:37,163 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 226.0 with 2 tasks
2014-07-23 17:33:37,164 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 226.0:0 as TID 228 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,164 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 226.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:37,164 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 226.0:1 as TID 229 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,165 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 226.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:37,165 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 228
2014-07-23 17:33:37,166 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,166 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,167 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 229
2014-07-23 17:33:37,169 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,172 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,224 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 228 is 678
2014-07-23 17:33:37,224 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 228 directly to driver
2014-07-23 17:33:37,224 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 228
2014-07-23 17:33:37,225 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(226, 0)
2014-07-23 17:33:37,225 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 228 in 61 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,228 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 229 is 678
2014-07-23 17:33:37,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 229 directly to driver
2014-07-23 17:33:37,229 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 229
2014-07-23 17:33:37,229 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(226, 1)
2014-07-23 17:33:37,229 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 226 (reduce at PCA.scala:57) finished in 0.065 s
2014-07-23 17:33:37,229 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 229 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,229 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 226.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,230 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.071165643 s
2014-07-23 17:33:37,234 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,235 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,235 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 228(reduce at PCA.scala:57)
2014-07-23 17:33:37,235 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 229)
2014-07-23 17:33:37,236 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,236 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 228 (MappedRDD[235] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,237 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 228 (MappedRDD[235] at map at PCA.scala:57)
2014-07-23 17:33:37,237 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 228.0 with 2 tasks
2014-07-23 17:33:37,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 228.0:0 as TID 230 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 228.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:37,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 228.0:1 as TID 231 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,238 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 228.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:37,239 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 230
2014-07-23 17:33:37,239 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 231
2014-07-23 17:33:37,240 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,241 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,244 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,245 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,296 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 231 is 678
2014-07-23 17:33:37,296 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 231 directly to driver
2014-07-23 17:33:37,296 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 231
2014-07-23 17:33:37,297 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 231 in 59 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,297 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(228, 1)
2014-07-23 17:33:37,302 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 230 is 678
2014-07-23 17:33:37,302 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 230 directly to driver
2014-07-23 17:33:37,303 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 230
2014-07-23 17:33:37,303 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 230 in 65 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,303 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(228, 0)
2014-07-23 17:33:37,303 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 228.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,303 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 228 (reduce at PCA.scala:57) finished in 0.066 s
2014-07-23 17:33:37,303 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.069535952 s
2014-07-23 17:33:37,308 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,309 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,309 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 230(reduce at PCA.scala:57)
2014-07-23 17:33:37,309 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 231)
2014-07-23 17:33:37,310 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,310 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 230 (MappedRDD[237] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,311 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 230 (MappedRDD[237] at map at PCA.scala:57)
2014-07-23 17:33:37,311 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 230.0 with 2 tasks
2014-07-23 17:33:37,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 230.0:0 as TID 232 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 230.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:37,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 230.0:1 as TID 233 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,312 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 230.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:37,312 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 232
2014-07-23 17:33:37,312 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 233
2014-07-23 17:33:37,313 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,313 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,314 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,314 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,394 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 233 is 678
2014-07-23 17:33:37,394 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 233 directly to driver
2014-07-23 17:33:37,395 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 233 in 83 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,395 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(230, 1)
2014-07-23 17:33:37,396 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 233
2014-07-23 17:33:37,397 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 232 is 678
2014-07-23 17:33:37,397 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 232 directly to driver
2014-07-23 17:33:37,398 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 232
2014-07-23 17:33:37,398 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 232 in 87 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,398 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 230.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,398 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(230, 0)
2014-07-23 17:33:37,398 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 230 (reduce at PCA.scala:57) finished in 0.087 s
2014-07-23 17:33:37,398 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.090755025 s
2014-07-23 17:33:37,403 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,404 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,404 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 232(reduce at PCA.scala:57)
2014-07-23 17:33:37,404 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 233)
2014-07-23 17:33:37,405 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,405 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 232 (MappedRDD[239] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,406 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 232 (MappedRDD[239] at map at PCA.scala:57)
2014-07-23 17:33:37,406 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 232.0 with 2 tasks
2014-07-23 17:33:37,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 232.0:0 as TID 234 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 232.0:0 as 2522 bytes in 0 ms
2014-07-23 17:33:37,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 232.0:1 as TID 235 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,407 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 232.0:1 as 2522 bytes in 0 ms
2014-07-23 17:33:37,408 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 235
2014-07-23 17:33:37,409 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,410 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,412 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 234
2014-07-23 17:33:37,413 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,414 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,462 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 235 is 678
2014-07-23 17:33:37,462 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 235 directly to driver
2014-07-23 17:33:37,462 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 235
2014-07-23 17:33:37,462 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(232, 1)
2014-07-23 17:33:37,462 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 235 in 55 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,468 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 234 is 678
2014-07-23 17:33:37,469 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 234 directly to driver
2014-07-23 17:33:37,469 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 234
2014-07-23 17:33:37,469 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 234 in 62 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,469 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 232.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,469 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(232, 0)
2014-07-23 17:33:37,470 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 232 (reduce at PCA.scala:57) finished in 0.062 s
2014-07-23 17:33:37,470 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.066672956 s
2014-07-23 17:33:37,474 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,475 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,475 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 234(reduce at PCA.scala:57)
2014-07-23 17:33:37,475 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 235)
2014-07-23 17:33:37,476 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,476 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 234 (MappedRDD[241] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,484 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 234 (MappedRDD[241] at map at PCA.scala:57)
2014-07-23 17:33:37,484 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 234.0 with 2 tasks
2014-07-23 17:33:37,485 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 234.0:0 as TID 236 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,485 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 234.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:37,485 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 234.0:1 as TID 237 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,486 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 234.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:37,486 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 236
2014-07-23 17:33:37,487 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,487 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,491 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 237
2014-07-23 17:33:37,493 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,493 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,545 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 236 is 678
2014-07-23 17:33:37,545 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 236 directly to driver
2014-07-23 17:33:37,545 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 236
2014-07-23 17:33:37,546 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 236 in 60 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,546 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(234, 0)
2014-07-23 17:33:37,548 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 237 is 678
2014-07-23 17:33:37,548 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 237 directly to driver
2014-07-23 17:33:37,549 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 237
2014-07-23 17:33:37,549 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 237 in 64 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,549 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(234, 1)
2014-07-23 17:33:37,549 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 234.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,550 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 234 (reduce at PCA.scala:57) finished in 0.060 s
2014-07-23 17:33:37,550 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.075839364 s
2014-07-23 17:33:37,554 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 236(reduce at PCA.scala:57)
2014-07-23 17:33:37,555 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 237)
2014-07-23 17:33:37,556 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,556 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 236 (MappedRDD[243] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,557 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 236 (MappedRDD[243] at map at PCA.scala:57)
2014-07-23 17:33:37,557 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 236.0 with 2 tasks
2014-07-23 17:33:37,558 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 236.0:0 as TID 238 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,558 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 236.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:37,558 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 236.0:1 as TID 239 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,558 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 236.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:37,558 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 238
2014-07-23 17:33:37,559 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 239
2014-07-23 17:33:37,559 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,559 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,560 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,560 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,614 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 238 is 678
2014-07-23 17:33:37,614 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 238 directly to driver
2014-07-23 17:33:37,614 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 238
2014-07-23 17:33:37,615 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 238 in 57 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,615 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(236, 0)
2014-07-23 17:33:37,615 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 239 is 678
2014-07-23 17:33:37,615 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 239 directly to driver
2014-07-23 17:33:37,616 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 239
2014-07-23 17:33:37,616 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(236, 1)
2014-07-23 17:33:37,616 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 239 in 58 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,616 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 236.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,616 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 236 (reduce at PCA.scala:57) finished in 0.059 s
2014-07-23 17:33:37,616 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.062490474 s
2014-07-23 17:33:37,622 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 238(reduce at PCA.scala:57)
2014-07-23 17:33:37,623 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 239)
2014-07-23 17:33:37,624 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,624 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 238 (MappedRDD[245] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,625 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 238 (MappedRDD[245] at map at PCA.scala:57)
2014-07-23 17:33:37,625 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 238.0 with 2 tasks
2014-07-23 17:33:37,626 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 238.0:0 as TID 240 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,626 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 238.0:0 as 2521 bytes in 0 ms
2014-07-23 17:33:37,626 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 238.0:1 as TID 241 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,626 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 238.0:1 as 2521 bytes in 0 ms
2014-07-23 17:33:37,626 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 240
2014-07-23 17:33:37,627 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 241
2014-07-23 17:33:37,627 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,628 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,628 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,628 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,677 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 241 is 678
2014-07-23 17:33:37,677 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 241 directly to driver
2014-07-23 17:33:37,678 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 241 in 52 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,678 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(238, 1)
2014-07-23 17:33:37,679 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 241
2014-07-23 17:33:37,679 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 240 is 678
2014-07-23 17:33:37,679 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 240 directly to driver
2014-07-23 17:33:37,679 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 240
2014-07-23 17:33:37,680 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(238, 0)
2014-07-23 17:33:37,680 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 240 in 53 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,680 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 238.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,680 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 238 (reduce at PCA.scala:57) finished in 0.055 s
2014-07-23 17:33:37,680 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.057922979 s
2014-07-23 17:33:37,684 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,685 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,685 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 240(reduce at PCA.scala:57)
2014-07-23 17:33:37,685 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 241)
2014-07-23 17:33:37,686 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,686 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 240 (MappedRDD[247] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,687 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 240 (MappedRDD[247] at map at PCA.scala:57)
2014-07-23 17:33:37,687 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 240.0 with 2 tasks
2014-07-23 17:33:37,688 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 240.0:0 as TID 242 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,688 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 240.0:0 as 2520 bytes in 0 ms
2014-07-23 17:33:37,688 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 240.0:1 as TID 243 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,688 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 240.0:1 as 2520 bytes in 0 ms
2014-07-23 17:33:37,689 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 242
2014-07-23 17:33:37,689 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 243
2014-07-23 17:33:37,690 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,690 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,690 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,691 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,736 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 243 is 678
2014-07-23 17:33:37,736 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 243 directly to driver
2014-07-23 17:33:37,737 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 243
2014-07-23 17:33:37,737 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 242 is 678
2014-07-23 17:33:37,737 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(240, 1)
2014-07-23 17:33:37,737 [Result resolver thread-2] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 243 in 48 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,737 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 242 directly to driver
2014-07-23 17:33:37,737 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 242
2014-07-23 17:33:37,738 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(240, 0)
2014-07-23 17:33:37,738 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 242 in 49 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,738 [Result resolver thread-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 240.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,738 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 240 (reduce at PCA.scala:57) finished in 0.050 s
2014-07-23 17:33:37,738 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.054043446 s
2014-07-23 17:33:37,743 [main] INFO  [org.apache.spark.SparkContext] - Starting job: reduce at PCA.scala:57
2014-07-23 17:33:37,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (reduce at PCA.scala:57) with 2 output partitions (allowLocal=false)
2014-07-23 17:33:37,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Final stage: Stage 242(reduce at PCA.scala:57)
2014-07-23 17:33:37,744 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(Stage 243)
2014-07-23 17:33:37,745 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2014-07-23 17:33:37,745 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting Stage 242 (MappedRDD[249] at map at PCA.scala:57), which has no missing parents
2014-07-23 17:33:37,746 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from Stage 242 (MappedRDD[249] at map at PCA.scala:57)
2014-07-23 17:33:37,746 [spark-akka.actor.default-dispatcher-3] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 242.0 with 2 tasks
2014-07-23 17:33:37,746 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 242.0:0 as TID 244 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,747 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 242.0:0 as 2518 bytes in 1 ms
2014-07-23 17:33:37,747 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Starting task 242.0:1 as TID 245 on executor localhost: localhost (PROCESS_LOCAL)
2014-07-23 17:33:37,747 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.TaskSetManager] - Serialized task 242.0:1 as 2518 bytes in 0 ms
2014-07-23 17:33:37,747 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Running task ID 244
2014-07-23 17:33:37,747 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Running task ID 245
2014-07-23 17:33:37,748 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,748 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block broadcast_0 locally
2014-07-23 17:33:37,749 [Executor task launch worker-1] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_0 locally
2014-07-23 17:33:37,749 [Executor task launch worker-0] INFO  [org.apache.spark.storage.BlockManager] - Found block rdd_7_1 locally
2014-07-23 17:33:37,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 245 is 678
2014-07-23 17:33:37,786 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Sending result for 245 directly to driver
2014-07-23 17:33:37,787 [Executor task launch worker-0] INFO  [org.apache.spark.executor.Executor] - Finished task ID 245
2014-07-23 17:33:37,787 [Result resolver thread-0] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 245 in 39 ms on localhost (progress: 1/2)
2014-07-23 17:33:37,787 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(242, 1)
2014-07-23 17:33:37,801 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Serialized size of result for 244 is 678
2014-07-23 17:33:37,801 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Sending result for 244 directly to driver
2014-07-23 17:33:37,801 [Executor task launch worker-1] INFO  [org.apache.spark.executor.Executor] - Finished task ID 244
2014-07-23 17:33:37,802 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSetManager] - Finished TID 244 in 56 ms on localhost (progress: 2/2)
2014-07-23 17:33:37,802 [Result resolver thread-1] INFO  [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 242.0, whose tasks have all completed, from pool 
2014-07-23 17:33:37,802 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Completed ResultTask(242, 0)
2014-07-23 17:33:37,802 [spark-akka.actor.default-dispatcher-4] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stage 242 (reduce at PCA.scala:57) finished in 0.056 s
2014-07-23 17:33:37,803 [main] INFO  [org.apache.spark.SparkContext] - Job finished: reduce at PCA.scala:57, took 0.060073087 s
2014-07-23 17:33:37,906 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2014-07-23 17:33:37,906 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2014-07-23 17:33:37,906 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/,null}
2014-07-23 17:33:37,906 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/static,null}
2014-07-23 17:33:37,906 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2014-07-23 17:33:37,906 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/executors,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/environment,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/storage,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2014-07-23 17:33:37,907 [main] INFO  [org.eclipse.jetty.server.handler.ContextHandler] - stopped o.e.j.s.ServletContextHandler{/stages,null}
2014-07-23 17:33:37,959 [main] INFO  [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://10.74.147.225:4040
2014-07-23 17:33:37,960 [main] INFO  [org.apache.spark.scheduler.DAGScheduler] - Stopping DAGScheduler
2014-07-23 17:33:39,015 [spark-akka.actor.default-dispatcher-2] INFO  [org.apache.spark.MapOutputTrackerMasterActor] - MapOutputTrackerActor stopped!
2014-07-23 17:33:39,069 [connection-manager-thread] INFO  [org.apache.spark.network.ConnectionManager] - Selector thread was interrupted!
2014-07-23 17:33:39,071 [main] INFO  [org.apache.spark.network.ConnectionManager] - ConnectionManager stopped
2014-07-23 17:33:39,077 [main] INFO  [org.apache.spark.storage.MemoryStore] - MemoryStore cleared
2014-07-23 17:33:39,078 [main] INFO  [org.apache.spark.storage.BlockManager] - BlockManager stopped
2014-07-23 17:33:39,078 [spark-akka.actor.default-dispatcher-13] INFO  [org.apache.spark.storage.BlockManagerMasterActor] - Stopping BlockManagerMaster
2014-07-23 17:33:39,079 [main] INFO  [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2014-07-23 17:33:39,081 [main] INFO  [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2014-07-23 17:33:39,089 [spark-akka.actor.default-dispatcher-4] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Shutting down remote daemon.
2014-07-23 17:33:39,093 [spark-akka.actor.default-dispatcher-4] INFO  [akka.remote.RemoteActorRefProvider$RemotingTerminator] - Remote daemon shut down; proceeding with flushing remote transports.
